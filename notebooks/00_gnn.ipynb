{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, f1_score, precision_score, recall_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.nn.norm import LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merged ID</th>\n",
       "      <th>merged parent area</th>\n",
       "      <th>M.P. major axis</th>\n",
       "      <th>M.P. aspect ratio</th>\n",
       "      <th>M.P. percent internal boundary length</th>\n",
       "      <th>GOS</th>\n",
       "      <th>Count Parent grains</th>\n",
       "      <th>Total Parent Area</th>\n",
       "      <th>Count Twin grains</th>\n",
       "      <th>Total Twinned Area</th>\n",
       "      <th>...</th>\n",
       "      <th>Schmid SF5</th>\n",
       "      <th>Schmid SF6</th>\n",
       "      <th>Taylor TF1</th>\n",
       "      <th>Taylor TF2</th>\n",
       "      <th>Taylor TF3</th>\n",
       "      <th>Taylor TF4</th>\n",
       "      <th>Taylor TF5</th>\n",
       "      <th>Taylor TF6</th>\n",
       "      <th>Neighbor Count</th>\n",
       "      <th>Neighbor Grain IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>11.418951</td>\n",
       "      <td>3.303548</td>\n",
       "      <td>61.764706</td>\n",
       "      <td>0.777758</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320974</td>\n",
       "      <td>0.470227</td>\n",
       "      <td>2.136972</td>\n",
       "      <td>2.846960</td>\n",
       "      <td>3.064860</td>\n",
       "      <td>2.262581</td>\n",
       "      <td>3.064860</td>\n",
       "      <td>2.262581</td>\n",
       "      <td>3</td>\n",
       "      <td>4,436,437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5.961390</td>\n",
       "      <td>2.537420</td>\n",
       "      <td>77.272727</td>\n",
       "      <td>0.552923</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379885</td>\n",
       "      <td>0.444008</td>\n",
       "      <td>2.080153</td>\n",
       "      <td>2.957410</td>\n",
       "      <td>3.329539</td>\n",
       "      <td>2.229734</td>\n",
       "      <td>2.960449</td>\n",
       "      <td>2.229734</td>\n",
       "      <td>1</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>5.817101</td>\n",
       "      <td>1.563343</td>\n",
       "      <td>90.476190</td>\n",
       "      <td>0.594562</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498814</td>\n",
       "      <td>0.498814</td>\n",
       "      <td>2.329955</td>\n",
       "      <td>2.025140</td>\n",
       "      <td>2.179495</td>\n",
       "      <td>2.179495</td>\n",
       "      <td>2.179495</td>\n",
       "      <td>2.179495</td>\n",
       "      <td>3</td>\n",
       "      <td>16,26,446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>14.193203</td>\n",
       "      <td>2.985210</td>\n",
       "      <td>63.414634</td>\n",
       "      <td>0.238788</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386806</td>\n",
       "      <td>0.468478</td>\n",
       "      <td>1.793094</td>\n",
       "      <td>2.465554</td>\n",
       "      <td>2.436545</td>\n",
       "      <td>2.211377</td>\n",
       "      <td>2.436545</td>\n",
       "      <td>2.211377</td>\n",
       "      <td>4</td>\n",
       "      <td>1,12,35,437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>5.671130</td>\n",
       "      <td>1.148170</td>\n",
       "      <td>86.956522</td>\n",
       "      <td>0.227919</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458077</td>\n",
       "      <td>0.496923</td>\n",
       "      <td>1.566975</td>\n",
       "      <td>1.806176</td>\n",
       "      <td>1.788028</td>\n",
       "      <td>1.788028</td>\n",
       "      <td>1.788028</td>\n",
       "      <td>1.788028</td>\n",
       "      <td>3</td>\n",
       "      <td>13,445,458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   merged ID  merged parent area  M.P. major axis  M.P. aspect ratio  \\\n",
       "0          1                  31        11.418951           3.303548   \n",
       "1          2                  11         5.961390           2.537420   \n",
       "2          3                  17         5.817101           1.563343   \n",
       "3          4                  53        14.193203           2.985210   \n",
       "4          5                  22         5.671130           1.148170   \n",
       "\n",
       "   M.P. percent internal boundary length       GOS  Count Parent grains  \\\n",
       "0                              61.764706  0.777758                    1   \n",
       "1                              77.272727  0.552923                    1   \n",
       "2                              90.476190  0.594562                    1   \n",
       "3                              63.414634  0.238788                    1   \n",
       "4                              86.956522  0.227919                    1   \n",
       "\n",
       "   Total Parent Area  Count Twin grains  Total Twinned Area  ...  Schmid SF5  \\\n",
       "0                 31                  0                   0  ...    0.320974   \n",
       "1                 11                  0                   0  ...    0.379885   \n",
       "2                 17                  0                   0  ...    0.498814   \n",
       "3                 53                  0                   0  ...    0.386806   \n",
       "4                 22                  0                   0  ...    0.458077   \n",
       "\n",
       "   Schmid SF6  Taylor TF1  Taylor TF2  Taylor TF3  Taylor TF4  Taylor TF5  \\\n",
       "0    0.470227    2.136972    2.846960    3.064860    2.262581    3.064860   \n",
       "1    0.444008    2.080153    2.957410    3.329539    2.229734    2.960449   \n",
       "2    0.498814    2.329955    2.025140    2.179495    2.179495    2.179495   \n",
       "3    0.468478    1.793094    2.465554    2.436545    2.211377    2.436545   \n",
       "4    0.496923    1.566975    1.806176    1.788028    1.788028    1.788028   \n",
       "\n",
       "   Taylor TF6  Neighbor Count  Neighbor Grain IDs  \n",
       "0    2.262581               3           4,436,437  \n",
       "1    2.229734               1                 452  \n",
       "2    2.179495               3           16,26,446  \n",
       "3    2.211377               4         1,12,35,437  \n",
       "4    1.788028               3          13,445,458  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = r\"C:\\Users\\msi\\Desktop\\workspace\\042_materials_GNN\\00_data\\data\\MergedGrainsData.xlsx\"\n",
    "df = pd.read_excel(csv_path, header=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['merged ID', 'merged parent area', 'M.P. major axis',\n",
       "       'M.P. aspect ratio', 'M.P. percent internal boundary length', 'GOS',\n",
       "       'Count Parent grains', 'Total Parent Area', 'Count Twin grains',\n",
       "       'Total Twinned Area', 'Total Other Area',\n",
       "       'Percent of grain that twinned', 'Schmid for Var1', 'Schmid for Var2',\n",
       "       'Schmid for Var3', 'Schmid for Var4', 'Schmid for Var5',\n",
       "       'Schmid for Var6', 'Area Twinned for Var1', 'Area Twinned for Var2',\n",
       "       'Area Twinned for Var3', 'Area Twinned for Var4',\n",
       "       'Area Twinned for Var5', 'Area Twinned for Var6', 'Rank for Var1',\n",
       "       'Rank for Var2', 'Rank for Var3', 'Rank for Var4', 'Rank for Var5',\n",
       "       'Rank for Var6', 'Twin Count for Var1', 'Twin Count for Var2',\n",
       "       'Twin Count for Var3', 'Twin Count for Var4', 'Twin Count for Var5',\n",
       "       'Twin Count for Var6', 'M.P. total boundary length',\n",
       "       'M.P. border boundary length', 'Parent grain', 'total other twins',\n",
       "       'total area of other twins', 'GAM', 'Phi1', 'Phi', 'Phi2', 'Schmid SF1',\n",
       "       'Schmid SF2', 'Schmid SF3', 'Schmid SF4', 'Schmid SF5', 'Schmid SF6',\n",
       "       'Taylor TF1', 'Taylor TF2', 'Taylor TF3', 'Taylor TF4', 'Taylor TF5',\n",
       "       'Taylor TF6', 'Neighbor Count', 'Neighbor Grain IDs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_COL = 'merged ID'\n",
    "FEATURE_COLS = [\n",
    "    'merged parent area',\n",
    "    'M.P. major axis',\n",
    "    'M.P. aspect ratio',\n",
    "    'GOS',\n",
    "    'Schmid for Var1',\n",
    "    'Schmid for Var2',\n",
    "    'Schmid for Var3',\n",
    "    'Schmid for Var4',\n",
    "    'Schmid for Var5',\n",
    "    'Schmid for Var6',\n",
    "    'GAM',\n",
    "    'Phi1',\n",
    "    'Phi',\n",
    "    'Phi2',\n",
    "    'Schmid SF1',\n",
    "    'Schmid SF2',\n",
    "    'Schmid SF3',\n",
    "    'Schmid SF4',\n",
    "    'Schmid SF5',\n",
    "    'Schmid SF6',\n",
    "    'Taylor TF1',\n",
    "    'Taylor TF2',\n",
    "    'Taylor TF3',\n",
    "    'Taylor TF4',\n",
    "    'Taylor TF5',\n",
    "    'Taylor TF6',\n",
    "]\n",
    "EDGE_COL = 'Neighbor Grain IDs'\n",
    "\n",
    "VAGUE_COLS = ['M.P. total boundary length', 'merged parent area',]\n",
    "FEATURE_COLS_INSIDE = [c for c in FEATURE_COLS if c not in VAGUE_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (~df[\"Percent of grain that twinned\"].isna()).map(int).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(116)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 556 entries, 0 to 555\n",
      "Data columns (total 26 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   merged parent area  556 non-null    int64  \n",
      " 1   M.P. major axis     556 non-null    float64\n",
      " 2   M.P. aspect ratio   556 non-null    float64\n",
      " 3   GOS                 556 non-null    float64\n",
      " 4   Schmid for Var1     556 non-null    float64\n",
      " 5   Schmid for Var2     556 non-null    float64\n",
      " 6   Schmid for Var3     556 non-null    float64\n",
      " 7   Schmid for Var4     556 non-null    float64\n",
      " 8   Schmid for Var5     556 non-null    float64\n",
      " 9   Schmid for Var6     556 non-null    float64\n",
      " 10  GAM                 556 non-null    float64\n",
      " 11  Phi1                556 non-null    float64\n",
      " 12  Phi                 556 non-null    float64\n",
      " 13  Phi2                556 non-null    float64\n",
      " 14  Schmid SF1          556 non-null    float64\n",
      " 15  Schmid SF2          556 non-null    float64\n",
      " 16  Schmid SF3          556 non-null    float64\n",
      " 17  Schmid SF4          556 non-null    float64\n",
      " 18  Schmid SF5          556 non-null    float64\n",
      " 19  Schmid SF6          556 non-null    float64\n",
      " 20  Taylor TF1          556 non-null    float64\n",
      " 21  Taylor TF2          556 non-null    float64\n",
      " 22  Taylor TF3          556 non-null    float64\n",
      " 23  Taylor TF4          556 non-null    float64\n",
      " 24  Taylor TF5          556 non-null    float64\n",
      " 25  Taylor TF6          556 non-null    float64\n",
      "dtypes: float64(25), int64(1)\n",
      "memory usage: 113.1 KB\n"
     ]
    }
   ],
   "source": [
    "df[FEATURE_COLS].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merged parent area</th>\n",
       "      <th>M.P. major axis</th>\n",
       "      <th>M.P. aspect ratio</th>\n",
       "      <th>GOS</th>\n",
       "      <th>Schmid for Var1</th>\n",
       "      <th>Schmid for Var2</th>\n",
       "      <th>Schmid for Var3</th>\n",
       "      <th>Schmid for Var4</th>\n",
       "      <th>Schmid for Var5</th>\n",
       "      <th>Schmid for Var6</th>\n",
       "      <th>...</th>\n",
       "      <th>Schmid SF3</th>\n",
       "      <th>Schmid SF4</th>\n",
       "      <th>Schmid SF5</th>\n",
       "      <th>Schmid SF6</th>\n",
       "      <th>Taylor TF1</th>\n",
       "      <th>Taylor TF2</th>\n",
       "      <th>Taylor TF3</th>\n",
       "      <th>Taylor TF4</th>\n",
       "      <th>Taylor TF5</th>\n",
       "      <th>Taylor TF6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>378.717626</td>\n",
       "      <td>22.041835</td>\n",
       "      <td>1.944941</td>\n",
       "      <td>0.815037</td>\n",
       "      <td>-0.029876</td>\n",
       "      <td>-0.028650</td>\n",
       "      <td>-0.089480</td>\n",
       "      <td>-0.089463</td>\n",
       "      <td>-0.032030</td>\n",
       "      <td>-0.033273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397973</td>\n",
       "      <td>0.345271</td>\n",
       "      <td>0.417507</td>\n",
       "      <td>0.469696</td>\n",
       "      <td>3.117065</td>\n",
       "      <td>2.495359</td>\n",
       "      <td>2.625999</td>\n",
       "      <td>2.186902</td>\n",
       "      <td>2.541564</td>\n",
       "      <td>2.186902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>894.719579</td>\n",
       "      <td>20.600790</td>\n",
       "      <td>1.225898</td>\n",
       "      <td>1.029579</td>\n",
       "      <td>0.252770</td>\n",
       "      <td>0.253761</td>\n",
       "      <td>0.261603</td>\n",
       "      <td>0.263904</td>\n",
       "      <td>0.212977</td>\n",
       "      <td>0.211375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080784</td>\n",
       "      <td>0.097375</td>\n",
       "      <td>0.067357</td>\n",
       "      <td>0.023282</td>\n",
       "      <td>1.789735</td>\n",
       "      <td>0.502685</td>\n",
       "      <td>0.535096</td>\n",
       "      <td>0.131231</td>\n",
       "      <td>0.451137</td>\n",
       "      <td>0.131231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.934175</td>\n",
       "      <td>1.011458</td>\n",
       "      <td>0.081182</td>\n",
       "      <td>-0.497607</td>\n",
       "      <td>-0.497533</td>\n",
       "      <td>-0.494256</td>\n",
       "      <td>-0.499242</td>\n",
       "      <td>-0.478946</td>\n",
       "      <td>-0.493438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199212</td>\n",
       "      <td>0.154567</td>\n",
       "      <td>0.240463</td>\n",
       "      <td>0.407622</td>\n",
       "      <td>0.343051</td>\n",
       "      <td>1.728016</td>\n",
       "      <td>1.671070</td>\n",
       "      <td>1.671070</td>\n",
       "      <td>1.671070</td>\n",
       "      <td>1.671070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>9.408231</td>\n",
       "      <td>1.382717</td>\n",
       "      <td>0.238839</td>\n",
       "      <td>-0.237504</td>\n",
       "      <td>-0.235677</td>\n",
       "      <td>-0.319444</td>\n",
       "      <td>-0.321071</td>\n",
       "      <td>-0.173901</td>\n",
       "      <td>-0.178136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336542</td>\n",
       "      <td>0.266259</td>\n",
       "      <td>0.369020</td>\n",
       "      <td>0.450301</td>\n",
       "      <td>2.050441</td>\n",
       "      <td>2.090709</td>\n",
       "      <td>2.161594</td>\n",
       "      <td>2.119063</td>\n",
       "      <td>2.161594</td>\n",
       "      <td>2.119063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>118.000000</td>\n",
       "      <td>16.657681</td>\n",
       "      <td>1.646023</td>\n",
       "      <td>0.336865</td>\n",
       "      <td>-0.010009</td>\n",
       "      <td>-0.009470</td>\n",
       "      <td>-0.099047</td>\n",
       "      <td>-0.100999</td>\n",
       "      <td>-0.025967</td>\n",
       "      <td>-0.029444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411386</td>\n",
       "      <td>0.357212</td>\n",
       "      <td>0.433389</td>\n",
       "      <td>0.472221</td>\n",
       "      <td>2.343809</td>\n",
       "      <td>2.398419</td>\n",
       "      <td>2.464556</td>\n",
       "      <td>2.190780</td>\n",
       "      <td>2.429161</td>\n",
       "      <td>2.190780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>295.250000</td>\n",
       "      <td>26.502485</td>\n",
       "      <td>2.053281</td>\n",
       "      <td>0.862920</td>\n",
       "      <td>0.158676</td>\n",
       "      <td>0.157748</td>\n",
       "      <td>0.096899</td>\n",
       "      <td>0.099201</td>\n",
       "      <td>0.066783</td>\n",
       "      <td>0.068265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472161</td>\n",
       "      <td>0.431320</td>\n",
       "      <td>0.476665</td>\n",
       "      <td>0.492381</td>\n",
       "      <td>3.660945</td>\n",
       "      <td>2.881138</td>\n",
       "      <td>3.102365</td>\n",
       "      <td>2.281140</td>\n",
       "      <td>2.934297</td>\n",
       "      <td>2.281140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8682.000000</td>\n",
       "      <td>198.455897</td>\n",
       "      <td>14.103105</td>\n",
       "      <td>7.110221</td>\n",
       "      <td>0.493265</td>\n",
       "      <td>0.492180</td>\n",
       "      <td>0.494435</td>\n",
       "      <td>0.490865</td>\n",
       "      <td>0.489465</td>\n",
       "      <td>0.494165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499897</td>\n",
       "      <td>0.499867</td>\n",
       "      <td>0.499997</td>\n",
       "      <td>0.499997</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.948792</td>\n",
       "      <td>3.747032</td>\n",
       "      <td>2.402268</td>\n",
       "      <td>3.492716</td>\n",
       "      <td>2.402268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       merged parent area  M.P. major axis  M.P. aspect ratio         GOS  \\\n",
       "count          556.000000       556.000000         556.000000  556.000000   \n",
       "mean           378.717626        22.041835           1.944941    0.815037   \n",
       "std            894.719579        20.600790           1.225898    1.029579   \n",
       "min             10.000000         3.934175           1.011458    0.081182   \n",
       "25%             42.000000         9.408231           1.382717    0.238839   \n",
       "50%            118.000000        16.657681           1.646023    0.336865   \n",
       "75%            295.250000        26.502485           2.053281    0.862920   \n",
       "max           8682.000000       198.455897          14.103105    7.110221   \n",
       "\n",
       "       Schmid for Var1  Schmid for Var2  Schmid for Var3  Schmid for Var4  \\\n",
       "count       556.000000       556.000000       556.000000       556.000000   \n",
       "mean         -0.029876        -0.028650        -0.089480        -0.089463   \n",
       "std           0.252770         0.253761         0.261603         0.263904   \n",
       "min          -0.497607        -0.497533        -0.494256        -0.499242   \n",
       "25%          -0.237504        -0.235677        -0.319444        -0.321071   \n",
       "50%          -0.010009        -0.009470        -0.099047        -0.100999   \n",
       "75%           0.158676         0.157748         0.096899         0.099201   \n",
       "max           0.493265         0.492180         0.494435         0.490865   \n",
       "\n",
       "       Schmid for Var5  Schmid for Var6  ...  Schmid SF3  Schmid SF4  \\\n",
       "count       556.000000       556.000000  ...  556.000000  556.000000   \n",
       "mean         -0.032030        -0.033273  ...    0.397973    0.345271   \n",
       "std           0.212977         0.211375  ...    0.080784    0.097375   \n",
       "min          -0.478946        -0.493438  ...    0.199212    0.154567   \n",
       "25%          -0.173901        -0.178136  ...    0.336542    0.266259   \n",
       "50%          -0.025967        -0.029444  ...    0.411386    0.357212   \n",
       "75%           0.066783         0.068265  ...    0.472161    0.431320   \n",
       "max           0.489465         0.494165  ...    0.499897    0.499867   \n",
       "\n",
       "       Schmid SF5  Schmid SF6  Taylor TF1  Taylor TF2  Taylor TF3  Taylor TF4  \\\n",
       "count  556.000000  556.000000  556.000000  556.000000  556.000000  556.000000   \n",
       "mean     0.417507    0.469696    3.117065    2.495359    2.625999    2.186902   \n",
       "std      0.067357    0.023282    1.789735    0.502685    0.535096    0.131231   \n",
       "min      0.240463    0.407622    0.343051    1.728016    1.671070    1.671070   \n",
       "25%      0.369020    0.450301    2.050441    2.090709    2.161594    2.119063   \n",
       "50%      0.433389    0.472221    2.343809    2.398419    2.464556    2.190780   \n",
       "75%      0.476665    0.492381    3.660945    2.881138    3.102365    2.281140   \n",
       "max      0.499997    0.499997   10.000000    3.948792    3.747032    2.402268   \n",
       "\n",
       "       Taylor TF5  Taylor TF6  \n",
       "count  556.000000  556.000000  \n",
       "mean     2.541564    2.186902  \n",
       "std      0.451137    0.131231  \n",
       "min      1.671070    1.671070  \n",
       "25%      2.161594    2.119063  \n",
       "50%      2.429161    2.190780  \n",
       "75%      2.934297    2.281140  \n",
       "max      3.492716    2.402268  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[FEATURE_COLS].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "edge_info = df[EDGE_COL].map(lambda x: list(map(int, x.split(\",\"))))\n",
    "for i, e_list in enumerate(edge_info):\n",
    "    for e in e_list:\n",
    "        new = [i, e-1]\n",
    "        edges.append(new)\n",
    "        \n",
    "edge_index = torch.Tensor(edges).to(dtype=torch.long).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_indices) = 389\n",
      "len(val_indices) = 83\n",
      "len(test_indices) = 84\n",
      "split done!\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1105)\n",
    "\n",
    "train_ratio = 0.7\n",
    "\n",
    "pos_indices = np.where(y == 1)[0]\n",
    "pos_indices_train, pos_indices_others = train_test_split(\n",
    "    pos_indices,\n",
    "    train_size=train_ratio\n",
    ")\n",
    "pos_indices_val, pos_indices_test = train_test_split(\n",
    "    pos_indices_others,\n",
    "    train_size=0.5\n",
    ")\n",
    "assert len(pos_indices) == len(pos_indices_train) + len(pos_indices_val) + len(pos_indices_test)\n",
    "assert set(pos_indices.tolist()) == set(pos_indices_train.tolist()) | set(pos_indices_val.tolist()) | set(pos_indices_test.tolist())\n",
    "assert len(set(pos_indices_train.tolist()).intersection(set(pos_indices_val.tolist())).intersection(set(pos_indices_test.tolist()))) == 0\n",
    "\n",
    "neg_indices = np.where(y == 0)[0]\n",
    "neg_indices_train, neg_indices_others = train_test_split(\n",
    "    neg_indices,\n",
    "    train_size=train_ratio\n",
    ")\n",
    "neg_indices_val, neg_indices_test = train_test_split(\n",
    "    neg_indices_others,\n",
    "    train_size=0.5\n",
    ")\n",
    "assert len(neg_indices) == len(neg_indices_train) + len(neg_indices_val) + len(neg_indices_test)\n",
    "assert set(neg_indices.tolist()) == set(neg_indices_train.tolist()) | set(neg_indices_val.tolist()) | set(neg_indices_test.tolist())\n",
    "assert len(set(neg_indices_train.tolist()).intersection(set(neg_indices_val.tolist())).intersection(set(neg_indices_test.tolist()))) == 0\n",
    "\n",
    "train_indices = pos_indices_train.tolist() + neg_indices_train.tolist()\n",
    "val_indices = pos_indices_val.tolist() + neg_indices_val.tolist()\n",
    "test_indices = pos_indices_test.tolist() + neg_indices_test.tolist()\n",
    "\n",
    "print(f\"{len(train_indices) = }\")\n",
    "print(f\"{len(val_indices) = }\")\n",
    "print(f\"{len(test_indices) = }\")\n",
    "\n",
    "print(\"split done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_train_mask = np.zeros_like(y)\n",
    "for i in train_indices:\n",
    "    tmp_train_mask[i-1] = 1\n",
    "train_mask = torch.Tensor(tmp_train_mask).to(dtype=bool)\n",
    "\n",
    "tmp_val_mask = np.zeros_like(y)\n",
    "for i in val_indices:\n",
    "    tmp_val_mask[i-1] = 1\n",
    "val_mask = torch.Tensor(tmp_val_mask).to(dtype=bool)\n",
    "\n",
    "tmp_test_mask = np.zeros_like(y)\n",
    "for i in test_indices:\n",
    "    tmp_test_mask[i-1] = 1\n",
    "test_mask = torch.Tensor(tmp_test_mask).to(dtype=bool)\n",
    "\n",
    "assert (train_mask.to(dtype=torch.int16) + val_mask.to(dtype=torch.int16) + test_mask.to(dtype=torch.int16) == 1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (389, 26) / (83, 26) / (84, 26)\n",
      "y_train.shape = (389,) / (83,) / (84,)\n"
     ]
    }
   ],
   "source": [
    "X_train = df.loc[train_mask.numpy(), FEATURE_COLS]\n",
    "X_val = df.loc[val_mask.numpy(), FEATURE_COLS]\n",
    "X_test = df.loc[test_mask.numpy(), FEATURE_COLS]\n",
    "y_train = y[train_mask.numpy()]\n",
    "y_val = y[val_mask.numpy()]\n",
    "y_test = y[test_mask.numpy()]\n",
    "\n",
    "print(f\"{X_train.shape = } / {X_val.shape} / {X_test.shape}\")\n",
    "print(f\"{y_train.shape = } / {y_val.shape} / {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_norm = scaler.transform(X_train)\n",
    "X_val_norm = scaler.transform(X_val)\n",
    "X_test_norm = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros_like(df[FEATURE_COLS])\n",
    "X[train_mask.numpy(), :] = X_train_norm\n",
    "X[val_mask.numpy(), :] = X_val_norm\n",
    "X[test_mask.numpy(), :] = X_test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(\n",
    "    x=torch.Tensor(X),\n",
    "    y=torch.Tensor(y),\n",
    "    edge_index=edge_index,\n",
    "    train_mask=train_mask,\n",
    "    val_mask=val_mask,\n",
    "    test_mask=test_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[556, 26], edge_index=[2, 3074], y=[556], train_mask=[556], val_mask=[556], test_mask=[556])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merged parent area</th>\n",
       "      <th>M.P. major axis</th>\n",
       "      <th>M.P. aspect ratio</th>\n",
       "      <th>GOS</th>\n",
       "      <th>Schmid for Var1</th>\n",
       "      <th>Schmid for Var2</th>\n",
       "      <th>Schmid for Var3</th>\n",
       "      <th>Schmid for Var4</th>\n",
       "      <th>Schmid for Var5</th>\n",
       "      <th>Schmid for Var6</th>\n",
       "      <th>...</th>\n",
       "      <th>Schmid SF3</th>\n",
       "      <th>Schmid SF4</th>\n",
       "      <th>Schmid SF5</th>\n",
       "      <th>Schmid SF6</th>\n",
       "      <th>Taylor TF1</th>\n",
       "      <th>Taylor TF2</th>\n",
       "      <th>Taylor TF3</th>\n",
       "      <th>Taylor TF4</th>\n",
       "      <th>Taylor TF5</th>\n",
       "      <th>Taylor TF6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>556.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.003988</td>\n",
       "      <td>-0.018495</td>\n",
       "      <td>-0.018334</td>\n",
       "      <td>0.010055</td>\n",
       "      <td>-0.012329</td>\n",
       "      <td>-0.014079</td>\n",
       "      <td>-0.026351</td>\n",
       "      <td>-0.025651</td>\n",
       "      <td>-0.047391</td>\n",
       "      <td>-0.046228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025202</td>\n",
       "      <td>0.030465</td>\n",
       "      <td>0.009895</td>\n",
       "      <td>0.017005</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>-0.047367</td>\n",
       "      <td>-0.040076</td>\n",
       "      <td>-0.025641</td>\n",
       "      <td>-0.050088</td>\n",
       "      <td>-0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.060606</td>\n",
       "      <td>0.987099</td>\n",
       "      <td>0.992013</td>\n",
       "      <td>1.056912</td>\n",
       "      <td>0.970104</td>\n",
       "      <td>0.973073</td>\n",
       "      <td>0.990515</td>\n",
       "      <td>0.989216</td>\n",
       "      <td>1.001312</td>\n",
       "      <td>1.003519</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011915</td>\n",
       "      <td>1.009151</td>\n",
       "      <td>1.006993</td>\n",
       "      <td>1.002598</td>\n",
       "      <td>0.983082</td>\n",
       "      <td>0.994384</td>\n",
       "      <td>1.003065</td>\n",
       "      <td>1.020877</td>\n",
       "      <td>0.990164</td>\n",
       "      <td>1.020877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.441068</td>\n",
       "      <td>-0.886134</td>\n",
       "      <td>-0.773721</td>\n",
       "      <td>-0.743282</td>\n",
       "      <td>-1.807429</td>\n",
       "      <td>-1.812057</td>\n",
       "      <td>-1.558967</td>\n",
       "      <td>-1.561661</td>\n",
       "      <td>-2.148574</td>\n",
       "      <td>-2.230896</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.464523</td>\n",
       "      <td>-1.945902</td>\n",
       "      <td>-2.636905</td>\n",
       "      <td>-2.656101</td>\n",
       "      <td>-1.518404</td>\n",
       "      <td>-1.565283</td>\n",
       "      <td>-1.830140</td>\n",
       "      <td>-4.038424</td>\n",
       "      <td>-1.960663</td>\n",
       "      <td>-4.038424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.403136</td>\n",
       "      <td>-0.623841</td>\n",
       "      <td>-0.473293</td>\n",
       "      <td>-0.581439</td>\n",
       "      <td>-0.809180</td>\n",
       "      <td>-0.807946</td>\n",
       "      <td>-0.897069</td>\n",
       "      <td>-0.893806</td>\n",
       "      <td>-0.714400</td>\n",
       "      <td>-0.733974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.744304</td>\n",
       "      <td>-0.788373</td>\n",
       "      <td>-0.714981</td>\n",
       "      <td>-0.818206</td>\n",
       "      <td>-0.580553</td>\n",
       "      <td>-0.847823</td>\n",
       "      <td>-0.910627</td>\n",
       "      <td>-0.553372</td>\n",
       "      <td>-0.884052</td>\n",
       "      <td>-0.553372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.313045</td>\n",
       "      <td>-0.276480</td>\n",
       "      <td>-0.260222</td>\n",
       "      <td>-0.480811</td>\n",
       "      <td>0.063917</td>\n",
       "      <td>0.059467</td>\n",
       "      <td>-0.062576</td>\n",
       "      <td>-0.068893</td>\n",
       "      <td>-0.018885</td>\n",
       "      <td>-0.028050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193208</td>\n",
       "      <td>0.154222</td>\n",
       "      <td>0.247341</td>\n",
       "      <td>0.125717</td>\n",
       "      <td>-0.419410</td>\n",
       "      <td>-0.239128</td>\n",
       "      <td>-0.342710</td>\n",
       "      <td>0.004530</td>\n",
       "      <td>-0.296792</td>\n",
       "      <td>0.004530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.102931</td>\n",
       "      <td>0.195240</td>\n",
       "      <td>0.069336</td>\n",
       "      <td>0.059210</td>\n",
       "      <td>0.711315</td>\n",
       "      <td>0.700680</td>\n",
       "      <td>0.679340</td>\n",
       "      <td>0.681537</td>\n",
       "      <td>0.417177</td>\n",
       "      <td>0.435834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954495</td>\n",
       "      <td>0.922244</td>\n",
       "      <td>0.894310</td>\n",
       "      <td>0.993846</td>\n",
       "      <td>0.304079</td>\n",
       "      <td>0.715758</td>\n",
       "      <td>0.852897</td>\n",
       "      <td>0.707459</td>\n",
       "      <td>0.811891</td>\n",
       "      <td>0.707459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.838771</td>\n",
       "      <td>8.434485</td>\n",
       "      <td>9.820211</td>\n",
       "      <td>6.472363</td>\n",
       "      <td>1.995428</td>\n",
       "      <td>1.983092</td>\n",
       "      <td>2.184545</td>\n",
       "      <td>2.149643</td>\n",
       "      <td>2.404420</td>\n",
       "      <td>2.457828</td>\n",
       "      <td>...</td>\n",
       "      <td>1.301916</td>\n",
       "      <td>1.632630</td>\n",
       "      <td>1.243128</td>\n",
       "      <td>1.321837</td>\n",
       "      <td>3.786053</td>\n",
       "      <td>2.827732</td>\n",
       "      <td>2.061357</td>\n",
       "      <td>1.649747</td>\n",
       "      <td>2.037519</td>\n",
       "      <td>1.649747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       merged parent area  M.P. major axis  M.P. aspect ratio         GOS  \\\n",
       "count          556.000000       556.000000         556.000000  556.000000   \n",
       "mean            -0.003988        -0.018495          -0.018334    0.010055   \n",
       "std              1.060606         0.987099           0.992013    1.056912   \n",
       "min             -0.441068        -0.886134          -0.773721   -0.743282   \n",
       "25%             -0.403136        -0.623841          -0.473293   -0.581439   \n",
       "50%             -0.313045        -0.276480          -0.260222   -0.480811   \n",
       "75%             -0.102931         0.195240           0.069336    0.059210   \n",
       "max              9.838771         8.434485           9.820211    6.472363   \n",
       "\n",
       "       Schmid for Var1  Schmid for Var2  Schmid for Var3  Schmid for Var4  \\\n",
       "count       556.000000       556.000000       556.000000       556.000000   \n",
       "mean         -0.012329        -0.014079        -0.026351        -0.025651   \n",
       "std           0.970104         0.973073         0.990515         0.989216   \n",
       "min          -1.807429        -1.812057        -1.558967        -1.561661   \n",
       "25%          -0.809180        -0.807946        -0.897069        -0.893806   \n",
       "50%           0.063917         0.059467        -0.062576        -0.068893   \n",
       "75%           0.711315         0.700680         0.679340         0.681537   \n",
       "max           1.995428         1.983092         2.184545         2.149643   \n",
       "\n",
       "       Schmid for Var5  Schmid for Var6  ...  Schmid SF3  Schmid SF4  \\\n",
       "count       556.000000       556.000000  ...  556.000000  556.000000   \n",
       "mean         -0.047391        -0.046228  ...    0.025202    0.030465   \n",
       "std           1.001312         1.003519  ...    1.011915    1.009151   \n",
       "min          -2.148574        -2.230896  ...   -2.464523   -1.945902   \n",
       "25%          -0.714400        -0.733974  ...   -0.744304   -0.788373   \n",
       "50%          -0.018885        -0.028050  ...    0.193208    0.154222   \n",
       "75%           0.417177         0.435834  ...    0.954495    0.922244   \n",
       "max           2.404420         2.457828  ...    1.301916    1.632630   \n",
       "\n",
       "       Schmid SF5  Schmid SF6  Taylor TF1  Taylor TF2  Taylor TF3  Taylor TF4  \\\n",
       "count  556.000000  556.000000  556.000000  556.000000  556.000000  556.000000   \n",
       "mean     0.009895    0.017005    0.005331   -0.047367   -0.040076   -0.025641   \n",
       "std      1.006993    1.002598    0.983082    0.994384    1.003065    1.020877   \n",
       "min     -2.636905   -2.656101   -1.518404   -1.565283   -1.830140   -4.038424   \n",
       "25%     -0.714981   -0.818206   -0.580553   -0.847823   -0.910627   -0.553372   \n",
       "50%      0.247341    0.125717   -0.419410   -0.239128   -0.342710    0.004530   \n",
       "75%      0.894310    0.993846    0.304079    0.715758    0.852897    0.707459   \n",
       "max      1.243128    1.321837    3.786053    2.827732    2.061357    1.649747   \n",
       "\n",
       "       Taylor TF5  Taylor TF6  \n",
       "count  556.000000  556.000000  \n",
       "mean    -0.050088   -0.025641  \n",
       "std      0.990164    1.020877  \n",
       "min     -1.960663   -4.038424  \n",
       "25%     -0.884052   -0.553372  \n",
       "50%     -0.296792    0.004530  \n",
       "75%      0.811891    0.707459  \n",
       "max      2.037519    1.649747  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X, columns=FEATURE_COLS).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.datasets import Planetoid\n",
    "# from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "# dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
    "# data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\msi\\Desktop\\workspace\\042_materials_GNN\\01_src\\gnn_node_classification\\.venv_gnn\\lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=5,\n",
    "    max_depth=50,\n",
    "    random_state=1105\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train_norm, y[train_mask])\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_true = y[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7619\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "f1 score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true, y_pred, normalize=None)\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    ")\n",
    "\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred):.4f}\")\n",
    "print(f\"f1 score: {f1_score(y_true, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\msi\\Desktop\\workspace\\042_materials_GNN\\01_src\\gnn_node_classification\\.venv_gnn\\lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(\n",
    "    random_state=1105\n",
    ")\n",
    "\n",
    "lr_model.fit(X_train_norm, y[train_mask])\n",
    "y_pred = lr_model.predict(X_test)\n",
    "y_true = y[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7857\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "f1 score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\msi\\Desktop\\workspace\\042_materials_GNN\\01_src\\gnn_node_classification\\.venv_gnn\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true, y_pred, normalize=None)\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    ")\n",
    "\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred):.4f}\")\n",
    "print(f\"f1 score: {f1_score(y_true, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\msi\\Desktop\\workspace\\042_materials_GNN\\01_src\\gnn_node_classification\\.venv_gnn\\lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but LinearSVC was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "class_weight = {\n",
    "    0: 1.0,\n",
    "    1: 4.0\n",
    "}\n",
    "svc_model = LinearSVC(\n",
    "    class_weight=class_weight,\n",
    "    random_state=1105\n",
    ")\n",
    "\n",
    "svc_model.fit(X_train_norm, y[train_mask])\n",
    "y_pred = svc_model.predict(X_test)\n",
    "y_true = y[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7857\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "f1 score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\msi\\Desktop\\workspace\\042_materials_GNN\\01_src\\gnn_node_classification\\.venv_gnn\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true, y_pred, normalize=None)\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    ")\n",
    "\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred):.4f}\")\n",
    "print(f\"f1 score: {f1_score(y_true, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(params):\n",
    "    num = sum(p.numel() for p in params if p.requires_grad)\n",
    "    print(f\"{num:,}\")\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339,138\n",
      "MLP model number of params: 339,138\n"
     ]
    }
   ],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.lin1 = Linear(data.num_features, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, hidden_channels * 2)\n",
    "        self.lin3 = Linear(hidden_channels * 2, hidden_channels * 4)\n",
    "        self.lin4 = Linear(hidden_channels * 4, hidden_channels * 8)\n",
    "        self.lin5 = Linear(hidden_channels * 8, hidden_channels * 4)\n",
    "        self.lin6 = Linear(hidden_channels * 4, hidden_channels * 2)\n",
    "        self.lin7 = Linear(hidden_channels * 2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin3(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin4(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin5(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin6(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin7(x)\n",
    "        return x\n",
    "    \n",
    "model = MLP(hidden_channels=64)\n",
    "print(f\"MLP model number of params: {count_parameters(model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train_loss: 0.6882 / Val_loss: 0.6851\n",
      "Epoch: 002, Train_loss: 0.6875 / Val_loss: 0.6836\n",
      "Epoch: 003, Train_loss: 0.6855 / Val_loss: 0.6821\n",
      "Epoch: 004, Train_loss: 0.6831 / Val_loss: 0.6806\n",
      "Epoch: 005, Train_loss: 0.6848 / Val_loss: 0.6791\n",
      "Epoch: 006, Train_loss: 0.6817 / Val_loss: 0.6777\n",
      "Epoch: 007, Train_loss: 0.6803 / Val_loss: 0.6762\n",
      "Epoch: 008, Train_loss: 0.6777 / Val_loss: 0.6746\n",
      "Epoch: 009, Train_loss: 0.6783 / Val_loss: 0.6730\n",
      "Epoch: 010, Train_loss: 0.6751 / Val_loss: 0.6714\n",
      "Epoch: 011, Train_loss: 0.6747 / Val_loss: 0.6697\n",
      "Epoch: 012, Train_loss: 0.6734 / Val_loss: 0.6680\n",
      "Epoch: 013, Train_loss: 0.6747 / Val_loss: 0.6661\n",
      "Epoch: 014, Train_loss: 0.6746 / Val_loss: 0.6643\n",
      "Epoch: 015, Train_loss: 0.6775 / Val_loss: 0.6627\n",
      "Epoch: 016, Train_loss: 0.6646 / Val_loss: 0.6609\n",
      "Epoch: 017, Train_loss: 0.6712 / Val_loss: 0.6593\n",
      "Epoch: 018, Train_loss: 0.6674 / Val_loss: 0.6577\n",
      "Epoch: 019, Train_loss: 0.6673 / Val_loss: 0.6560\n",
      "Epoch: 020, Train_loss: 0.6749 / Val_loss: 0.6546\n",
      "Epoch: 021, Train_loss: 0.6623 / Val_loss: 0.6531\n",
      "Epoch: 022, Train_loss: 0.6591 / Val_loss: 0.6514\n",
      "Epoch: 023, Train_loss: 0.6664 / Val_loss: 0.6499\n",
      "Epoch: 024, Train_loss: 0.6622 / Val_loss: 0.6482\n",
      "Epoch: 025, Train_loss: 0.6580 / Val_loss: 0.6465\n",
      "Epoch: 026, Train_loss: 0.6628 / Val_loss: 0.6448\n",
      "Epoch: 027, Train_loss: 0.6586 / Val_loss: 0.6431\n",
      "Epoch: 028, Train_loss: 0.6588 / Val_loss: 0.6414\n",
      "Epoch: 029, Train_loss: 0.6550 / Val_loss: 0.6395\n",
      "Epoch: 030, Train_loss: 0.6583 / Val_loss: 0.6378\n",
      "Epoch: 031, Train_loss: 0.6571 / Val_loss: 0.6360\n",
      "Epoch: 032, Train_loss: 0.6474 / Val_loss: 0.6340\n",
      "Epoch: 033, Train_loss: 0.6462 / Val_loss: 0.6317\n",
      "Epoch: 034, Train_loss: 0.6487 / Val_loss: 0.6294\n",
      "Epoch: 035, Train_loss: 0.6568 / Val_loss: 0.6273\n",
      "Epoch: 036, Train_loss: 0.6308 / Val_loss: 0.6244\n",
      "Epoch: 037, Train_loss: 0.6429 / Val_loss: 0.6216\n",
      "Epoch: 038, Train_loss: 0.6391 / Val_loss: 0.6186\n",
      "Epoch: 039, Train_loss: 0.6343 / Val_loss: 0.6153\n",
      "Epoch: 040, Train_loss: 0.6249 / Val_loss: 0.6115\n",
      "Epoch: 041, Train_loss: 0.6249 / Val_loss: 0.6079\n",
      "Epoch: 042, Train_loss: 0.6476 / Val_loss: 0.6053\n",
      "Epoch: 043, Train_loss: 0.6239 / Val_loss: 0.6031\n",
      "Epoch: 044, Train_loss: 0.6140 / Val_loss: 0.6007\n",
      "Epoch: 045, Train_loss: 0.6268 / Val_loss: 0.5987\n",
      "Epoch: 046, Train_loss: 0.5971 / Val_loss: 0.5962\n",
      "Epoch: 047, Train_loss: 0.6037 / Val_loss: 0.5936\n",
      "Epoch: 048, Train_loss: 0.6160 / Val_loss: 0.5916\n",
      "Epoch: 049, Train_loss: 0.6130 / Val_loss: 0.5901\n",
      "Epoch: 050, Train_loss: 0.6127 / Val_loss: 0.5893\n",
      "Epoch: 051, Train_loss: 0.6094 / Val_loss: 0.5888\n",
      "Epoch: 052, Train_loss: 0.5945 / Val_loss: 0.5881\n",
      "Epoch: 053, Train_loss: 0.6275 / Val_loss: 0.5879\n",
      "Epoch: 054, Train_loss: 0.6015 / Val_loss: 0.5876\n",
      "Epoch: 055, Train_loss: 0.5918 / Val_loss: 0.5868\n",
      "Epoch: 056, Train_loss: 0.6223 / Val_loss: 0.5864\n",
      "Epoch: 057, Train_loss: 0.6062 / Val_loss: 0.5861\n",
      "Epoch: 058, Train_loss: 0.6096 / Val_loss: 0.5860\n",
      "Epoch: 059, Train_loss: 0.6065 / Val_loss: 0.5854\n",
      "Epoch: 060, Train_loss: 0.5955 / Val_loss: 0.5846\n",
      "Epoch: 061, Train_loss: 0.5958 / Val_loss: 0.5840\n",
      "Epoch: 062, Train_loss: 0.5678 / Val_loss: 0.5823\n",
      "Epoch: 063, Train_loss: 0.6159 / Val_loss: 0.5811\n",
      "Epoch: 064, Train_loss: 0.5592 / Val_loss: 0.5790\n",
      "Epoch: 065, Train_loss: 0.5819 / Val_loss: 0.5770\n",
      "Epoch: 066, Train_loss: 0.6048 / Val_loss: 0.5758\n",
      "Epoch: 067, Train_loss: 0.5715 / Val_loss: 0.5743\n",
      "Epoch: 068, Train_loss: 0.5726 / Val_loss: 0.5727\n",
      "Epoch: 069, Train_loss: 0.5793 / Val_loss: 0.5714\n",
      "Epoch: 070, Train_loss: 0.5620 / Val_loss: 0.5700\n",
      "Epoch: 071, Train_loss: 0.5725 / Val_loss: 0.5687\n",
      "Epoch: 072, Train_loss: 0.6055 / Val_loss: 0.5678\n",
      "Epoch: 073, Train_loss: 0.5958 / Val_loss: 0.5672\n",
      "Epoch: 074, Train_loss: 0.5505 / Val_loss: 0.5666\n",
      "Epoch: 075, Train_loss: 0.5697 / Val_loss: 0.5659\n",
      "Epoch: 076, Train_loss: 0.5436 / Val_loss: 0.5647\n",
      "Epoch: 077, Train_loss: 0.5316 / Val_loss: 0.5628\n",
      "Epoch: 078, Train_loss: 0.5370 / Val_loss: 0.5614\n",
      "Epoch: 079, Train_loss: 0.5222 / Val_loss: 0.5605\n",
      "Epoch: 080, Train_loss: 0.5396 / Val_loss: 0.5598\n",
      "Epoch: 081, Train_loss: 0.5085 / Val_loss: 0.5597\n",
      "Epoch: 082, Train_loss: 0.5120 / Val_loss: 0.5597\n",
      "Epoch: 083, Train_loss: 0.4934 / Val_loss: 0.5601\n",
      "Epoch: 084, Train_loss: 0.5155 / Val_loss: 0.5605\n",
      "Epoch: 085, Train_loss: 0.5227 / Val_loss: 0.5608\n",
      "Epoch: 086, Train_loss: 0.5424 / Val_loss: 0.5611\n",
      "Epoch: 087, Train_loss: 0.5203 / Val_loss: 0.5617\n",
      "Epoch: 088, Train_loss: 0.4989 / Val_loss: 0.5624\n",
      "Epoch: 089, Train_loss: 0.5360 / Val_loss: 0.5630\n",
      "Epoch: 090, Train_loss: 0.5161 / Val_loss: 0.5632\n",
      "Epoch: 091, Train_loss: 0.5209 / Val_loss: 0.5628\n",
      "Epoch: 092, Train_loss: 0.4900 / Val_loss: 0.5622\n",
      "Epoch: 093, Train_loss: 0.4847 / Val_loss: 0.5612\n",
      "Epoch: 094, Train_loss: 0.5185 / Val_loss: 0.5602\n",
      "Epoch: 095, Train_loss: 0.4872 / Val_loss: 0.5595\n",
      "Epoch: 096, Train_loss: 0.5151 / Val_loss: 0.5585\n",
      "Epoch: 097, Train_loss: 0.5352 / Val_loss: 0.5577\n",
      "Epoch: 098, Train_loss: 0.4626 / Val_loss: 0.5568\n",
      "Epoch: 099, Train_loss: 0.4968 / Val_loss: 0.5560\n",
      "Epoch: 100, Train_loss: 0.5095 / Val_loss: 0.5548\n",
      "Epoch: 101, Train_loss: 0.4991 / Val_loss: 0.5535\n",
      "Epoch: 102, Train_loss: 0.4637 / Val_loss: 0.5518\n",
      "Epoch: 103, Train_loss: 0.5082 / Val_loss: 0.5497\n",
      "Epoch: 104, Train_loss: 0.5024 / Val_loss: 0.5478\n",
      "Epoch: 105, Train_loss: 0.4922 / Val_loss: 0.5461\n",
      "Epoch: 106, Train_loss: 0.5031 / Val_loss: 0.5445\n",
      "Epoch: 107, Train_loss: 0.4482 / Val_loss: 0.5427\n",
      "Epoch: 108, Train_loss: 0.4872 / Val_loss: 0.5409\n",
      "Epoch: 109, Train_loss: 0.4806 / Val_loss: 0.5396\n",
      "Epoch: 110, Train_loss: 0.4546 / Val_loss: 0.5386\n",
      "Epoch: 111, Train_loss: 0.4782 / Val_loss: 0.5377\n",
      "Epoch: 112, Train_loss: 0.4886 / Val_loss: 0.5370\n",
      "Epoch: 113, Train_loss: 0.4846 / Val_loss: 0.5358\n",
      "Epoch: 114, Train_loss: 0.4638 / Val_loss: 0.5353\n",
      "Epoch: 115, Train_loss: 0.4540 / Val_loss: 0.5348\n",
      "Epoch: 116, Train_loss: 0.4963 / Val_loss: 0.5347\n",
      "Epoch: 117, Train_loss: 0.4350 / Val_loss: 0.5348\n",
      "Epoch: 118, Train_loss: 0.4681 / Val_loss: 0.5349\n",
      "Epoch: 119, Train_loss: 0.4672 / Val_loss: 0.5351\n",
      "Epoch: 120, Train_loss: 0.4542 / Val_loss: 0.5359\n",
      "Epoch: 121, Train_loss: 0.4379 / Val_loss: 0.5367\n",
      "Epoch: 122, Train_loss: 0.4301 / Val_loss: 0.5373\n",
      "Epoch: 123, Train_loss: 0.4899 / Val_loss: 0.5377\n",
      "Epoch: 124, Train_loss: 0.4786 / Val_loss: 0.5378\n",
      "Epoch: 125, Train_loss: 0.4349 / Val_loss: 0.5381\n",
      "Epoch: 126, Train_loss: 0.4505 / Val_loss: 0.5381\n",
      "Epoch: 127, Train_loss: 0.5007 / Val_loss: 0.5380\n",
      "Epoch: 128, Train_loss: 0.4847 / Val_loss: 0.5375\n",
      "Epoch: 129, Train_loss: 0.4675 / Val_loss: 0.5366\n",
      "Epoch: 130, Train_loss: 0.4612 / Val_loss: 0.5357\n",
      "Epoch: 131, Train_loss: 0.4378 / Val_loss: 0.5353\n",
      "Epoch: 132, Train_loss: 0.4059 / Val_loss: 0.5349\n",
      "Epoch: 133, Train_loss: 0.4679 / Val_loss: 0.5344\n",
      "Epoch: 134, Train_loss: 0.4582 / Val_loss: 0.5338\n",
      "Epoch: 135, Train_loss: 0.4523 / Val_loss: 0.5331\n",
      "Epoch: 136, Train_loss: 0.4250 / Val_loss: 0.5328\n",
      "Epoch: 137, Train_loss: 0.4161 / Val_loss: 0.5326\n",
      "Epoch: 138, Train_loss: 0.4397 / Val_loss: 0.5325\n",
      "Epoch: 139, Train_loss: 0.4669 / Val_loss: 0.5325\n",
      "Epoch: 140, Train_loss: 0.4291 / Val_loss: 0.5322\n",
      "Epoch: 141, Train_loss: 0.4161 / Val_loss: 0.5319\n",
      "Epoch: 142, Train_loss: 0.4289 / Val_loss: 0.5317\n",
      "Epoch: 143, Train_loss: 0.4086 / Val_loss: 0.5315\n",
      "Epoch: 144, Train_loss: 0.4203 / Val_loss: 0.5317\n",
      "Epoch: 145, Train_loss: 0.4129 / Val_loss: 0.5321\n",
      "Epoch: 146, Train_loss: 0.4346 / Val_loss: 0.5325\n",
      "Epoch: 147, Train_loss: 0.4398 / Val_loss: 0.5324\n",
      "Epoch: 148, Train_loss: 0.4390 / Val_loss: 0.5310\n",
      "Epoch: 149, Train_loss: 0.4458 / Val_loss: 0.5296\n",
      "Epoch: 150, Train_loss: 0.4258 / Val_loss: 0.5287\n",
      "Epoch: 151, Train_loss: 0.3843 / Val_loss: 0.5281\n",
      "Epoch: 152, Train_loss: 0.3893 / Val_loss: 0.5283\n",
      "Epoch: 153, Train_loss: 0.4276 / Val_loss: 0.5281\n",
      "Epoch: 154, Train_loss: 0.4402 / Val_loss: 0.5274\n",
      "Epoch: 155, Train_loss: 0.4146 / Val_loss: 0.5269\n",
      "Epoch: 156, Train_loss: 0.4572 / Val_loss: 0.5261\n",
      "Epoch: 157, Train_loss: 0.4038 / Val_loss: 0.5256\n",
      "Epoch: 158, Train_loss: 0.4383 / Val_loss: 0.5259\n",
      "Epoch: 159, Train_loss: 0.3840 / Val_loss: 0.5263\n",
      "Epoch: 160, Train_loss: 0.4289 / Val_loss: 0.5261\n",
      "Epoch: 161, Train_loss: 0.4250 / Val_loss: 0.5259\n",
      "Epoch: 162, Train_loss: 0.3927 / Val_loss: 0.5263\n",
      "Epoch: 163, Train_loss: 0.4344 / Val_loss: 0.5265\n",
      "Epoch: 164, Train_loss: 0.4200 / Val_loss: 0.5271\n",
      "Epoch: 165, Train_loss: 0.4214 / Val_loss: 0.5285\n",
      "Epoch: 166, Train_loss: 0.3812 / Val_loss: 0.5299\n",
      "Epoch: 167, Train_loss: 0.3997 / Val_loss: 0.5311\n",
      "Epoch: 168, Train_loss: 0.3828 / Val_loss: 0.5320\n",
      "Epoch: 169, Train_loss: 0.4006 / Val_loss: 0.5325\n",
      "Epoch: 170, Train_loss: 0.4258 / Val_loss: 0.5319\n",
      "Epoch: 171, Train_loss: 0.3728 / Val_loss: 0.5328\n",
      "Epoch: 172, Train_loss: 0.3628 / Val_loss: 0.5342\n",
      "Epoch: 173, Train_loss: 0.4218 / Val_loss: 0.5340\n",
      "Epoch: 174, Train_loss: 0.3924 / Val_loss: 0.5343\n",
      "Epoch: 175, Train_loss: 0.4435 / Val_loss: 0.5332\n",
      "Epoch: 176, Train_loss: 0.3804 / Val_loss: 0.5323\n",
      "Epoch: 177, Train_loss: 0.3844 / Val_loss: 0.5315\n",
      "Epoch: 178, Train_loss: 0.3952 / Val_loss: 0.5308\n",
      "Epoch: 179, Train_loss: 0.3497 / Val_loss: 0.5301\n",
      "Epoch: 180, Train_loss: 0.3815 / Val_loss: 0.5302\n",
      "Epoch: 181, Train_loss: 0.3459 / Val_loss: 0.5310\n",
      "Epoch: 182, Train_loss: 0.3752 / Val_loss: 0.5326\n",
      "Epoch: 183, Train_loss: 0.3856 / Val_loss: 0.5332\n",
      "Epoch: 184, Train_loss: 0.3788 / Val_loss: 0.5339\n",
      "Epoch: 185, Train_loss: 0.3712 / Val_loss: 0.5348\n",
      "Epoch: 186, Train_loss: 0.3929 / Val_loss: 0.5349\n",
      "Epoch: 187, Train_loss: 0.3691 / Val_loss: 0.5354\n",
      "Epoch: 188, Train_loss: 0.3911 / Val_loss: 0.5351\n",
      "Epoch: 189, Train_loss: 0.4142 / Val_loss: 0.5339\n",
      "Epoch: 190, Train_loss: 0.3549 / Val_loss: 0.5330\n",
      "Epoch: 191, Train_loss: 0.4130 / Val_loss: 0.5323\n",
      "Epoch: 192, Train_loss: 0.3476 / Val_loss: 0.5322\n",
      "Epoch: 193, Train_loss: 0.3641 / Val_loss: 0.5321\n",
      "Epoch: 194, Train_loss: 0.4290 / Val_loss: 0.5314\n",
      "Epoch: 195, Train_loss: 0.3673 / Val_loss: 0.5315\n",
      "Epoch: 196, Train_loss: 0.3463 / Val_loss: 0.5327\n",
      "Epoch: 197, Train_loss: 0.3695 / Val_loss: 0.5343\n",
      "Epoch: 198, Train_loss: 0.3767 / Val_loss: 0.5364\n",
      "Epoch: 199, Train_loss: 0.3785 / Val_loss: 0.5377\n",
      "Epoch: 200, Train_loss: 0.3727 / Val_loss: 0.5389\n",
      "Epoch: 201, Train_loss: 0.3715 / Val_loss: 0.5396\n",
      "Epoch: 202, Train_loss: 0.3900 / Val_loss: 0.5388\n",
      "Epoch: 203, Train_loss: 0.3560 / Val_loss: 0.5386\n",
      "Epoch: 204, Train_loss: 0.3986 / Val_loss: 0.5379\n",
      "Epoch: 205, Train_loss: 0.3668 / Val_loss: 0.5367\n",
      "Epoch: 206, Train_loss: 0.3529 / Val_loss: 0.5365\n",
      "Epoch: 207, Train_loss: 0.3695 / Val_loss: 0.5362\n",
      "Epoch: 208, Train_loss: 0.3722 / Val_loss: 0.5358\n",
      "Epoch: 209, Train_loss: 0.3698 / Val_loss: 0.5354\n",
      "Epoch: 210, Train_loss: 0.3431 / Val_loss: 0.5353\n",
      "Epoch: 211, Train_loss: 0.3412 / Val_loss: 0.5354\n",
      "Epoch: 212, Train_loss: 0.3373 / Val_loss: 0.5360\n",
      "Epoch: 213, Train_loss: 0.3598 / Val_loss: 0.5362\n",
      "Epoch: 214, Train_loss: 0.3981 / Val_loss: 0.5354\n",
      "Epoch: 215, Train_loss: 0.3560 / Val_loss: 0.5347\n",
      "Epoch: 216, Train_loss: 0.3463 / Val_loss: 0.5357\n",
      "Epoch: 217, Train_loss: 0.3576 / Val_loss: 0.5367\n",
      "Epoch: 218, Train_loss: 0.3630 / Val_loss: 0.5384\n",
      "Epoch: 219, Train_loss: 0.3674 / Val_loss: 0.5396\n",
      "Epoch: 220, Train_loss: 0.3274 / Val_loss: 0.5412\n",
      "Epoch: 221, Train_loss: 0.3703 / Val_loss: 0.5426\n",
      "Epoch: 222, Train_loss: 0.3400 / Val_loss: 0.5452\n",
      "Epoch: 223, Train_loss: 0.3495 / Val_loss: 0.5470\n",
      "Epoch: 224, Train_loss: 0.3382 / Val_loss: 0.5478\n",
      "Epoch: 225, Train_loss: 0.3414 / Val_loss: 0.5480\n",
      "Epoch: 226, Train_loss: 0.3186 / Val_loss: 0.5495\n",
      "Epoch: 227, Train_loss: 0.3199 / Val_loss: 0.5517\n",
      "Epoch: 228, Train_loss: 0.3677 / Val_loss: 0.5541\n",
      "Epoch: 229, Train_loss: 0.3344 / Val_loss: 0.5571\n",
      "Epoch: 230, Train_loss: 0.3649 / Val_loss: 0.5591\n",
      "Epoch: 231, Train_loss: 0.3934 / Val_loss: 0.5606\n",
      "Epoch: 232, Train_loss: 0.3232 / Val_loss: 0.5621\n",
      "Epoch: 233, Train_loss: 0.3566 / Val_loss: 0.5630\n",
      "Epoch: 234, Train_loss: 0.3686 / Val_loss: 0.5634\n",
      "Epoch: 235, Train_loss: 0.3230 / Val_loss: 0.5642\n",
      "Epoch: 236, Train_loss: 0.3248 / Val_loss: 0.5657\n",
      "Epoch: 237, Train_loss: 0.3769 / Val_loss: 0.5653\n",
      "Epoch: 238, Train_loss: 0.3911 / Val_loss: 0.5628\n",
      "Epoch: 239, Train_loss: 0.3640 / Val_loss: 0.5607\n",
      "Epoch: 240, Train_loss: 0.3206 / Val_loss: 0.5601\n",
      "Epoch: 241, Train_loss: 0.3449 / Val_loss: 0.5597\n",
      "Epoch: 242, Train_loss: 0.3357 / Val_loss: 0.5603\n",
      "Epoch: 243, Train_loss: 0.3170 / Val_loss: 0.5622\n",
      "Epoch: 244, Train_loss: 0.3151 / Val_loss: 0.5648\n",
      "Epoch: 245, Train_loss: 0.3730 / Val_loss: 0.5666\n",
      "Epoch: 246, Train_loss: 0.3322 / Val_loss: 0.5689\n",
      "Epoch: 247, Train_loss: 0.3519 / Val_loss: 0.5720\n",
      "Epoch: 248, Train_loss: 0.3229 / Val_loss: 0.5760\n",
      "Epoch: 249, Train_loss: 0.3174 / Val_loss: 0.5810\n",
      "Epoch: 250, Train_loss: 0.3941 / Val_loss: 0.5821\n",
      "Epoch: 251, Train_loss: 0.2968 / Val_loss: 0.5842\n",
      "Epoch: 252, Train_loss: 0.3457 / Val_loss: 0.5868\n",
      "Epoch: 253, Train_loss: 0.3315 / Val_loss: 0.5893\n",
      "Epoch: 254, Train_loss: 0.2898 / Val_loss: 0.5928\n",
      "Epoch: 255, Train_loss: 0.3116 / Val_loss: 0.5963\n",
      "Epoch: 256, Train_loss: 0.3194 / Val_loss: 0.6001\n",
      "Epoch: 257, Train_loss: 0.3208 / Val_loss: 0.6028\n",
      "Epoch: 258, Train_loss: 0.3553 / Val_loss: 0.6049\n",
      "Epoch: 259, Train_loss: 0.3174 / Val_loss: 0.6080\n",
      "Epoch: 260, Train_loss: 0.3587 / Val_loss: 0.6093\n",
      "Epoch: 261, Train_loss: 0.3633 / Val_loss: 0.6078\n",
      "Epoch: 262, Train_loss: 0.2985 / Val_loss: 0.6081\n",
      "Epoch: 263, Train_loss: 0.3014 / Val_loss: 0.6102\n",
      "Epoch: 264, Train_loss: 0.2987 / Val_loss: 0.6128\n",
      "Epoch: 265, Train_loss: 0.2986 / Val_loss: 0.6150\n",
      "Epoch: 266, Train_loss: 0.3477 / Val_loss: 0.6154\n",
      "Epoch: 267, Train_loss: 0.3242 / Val_loss: 0.6158\n",
      "Epoch: 268, Train_loss: 0.3091 / Val_loss: 0.6158\n",
      "Epoch: 269, Train_loss: 0.3140 / Val_loss: 0.6141\n",
      "Epoch: 270, Train_loss: 0.3306 / Val_loss: 0.6106\n",
      "Epoch: 271, Train_loss: 0.3147 / Val_loss: 0.6087\n",
      "Epoch: 272, Train_loss: 0.2925 / Val_loss: 0.6072\n",
      "Epoch: 273, Train_loss: 0.2999 / Val_loss: 0.6063\n",
      "Epoch: 274, Train_loss: 0.3582 / Val_loss: 0.6033\n",
      "Epoch: 275, Train_loss: 0.3040 / Val_loss: 0.6004\n",
      "Epoch: 276, Train_loss: 0.3205 / Val_loss: 0.5966\n",
      "Epoch: 277, Train_loss: 0.2768 / Val_loss: 0.5950\n",
      "Epoch: 278, Train_loss: 0.3544 / Val_loss: 0.5929\n",
      "Epoch: 279, Train_loss: 0.3298 / Val_loss: 0.5919\n",
      "Epoch: 280, Train_loss: 0.3278 / Val_loss: 0.5915\n",
      "Epoch: 281, Train_loss: 0.3284 / Val_loss: 0.5903\n",
      "Epoch: 282, Train_loss: 0.2895 / Val_loss: 0.5905\n",
      "Epoch: 283, Train_loss: 0.3654 / Val_loss: 0.5901\n",
      "Epoch: 284, Train_loss: 0.3060 / Val_loss: 0.5908\n",
      "Epoch: 285, Train_loss: 0.3128 / Val_loss: 0.5914\n",
      "Epoch: 286, Train_loss: 0.3411 / Val_loss: 0.5912\n",
      "Epoch: 287, Train_loss: 0.2978 / Val_loss: 0.5923\n",
      "Epoch: 288, Train_loss: 0.3146 / Val_loss: 0.5932\n",
      "Epoch: 289, Train_loss: 0.3074 / Val_loss: 0.5939\n",
      "Epoch: 290, Train_loss: 0.3304 / Val_loss: 0.5951\n",
      "Epoch: 291, Train_loss: 0.3196 / Val_loss: 0.5950\n",
      "Epoch: 292, Train_loss: 0.3263 / Val_loss: 0.5953\n",
      "Epoch: 293, Train_loss: 0.3229 / Val_loss: 0.5951\n",
      "Epoch: 294, Train_loss: 0.3100 / Val_loss: 0.5950\n",
      "Epoch: 295, Train_loss: 0.3009 / Val_loss: 0.5953\n",
      "Epoch: 296, Train_loss: 0.3077 / Val_loss: 0.5964\n",
      "Epoch: 297, Train_loss: 0.3147 / Val_loss: 0.5995\n",
      "Epoch: 298, Train_loss: 0.3257 / Val_loss: 0.6030\n",
      "Epoch: 299, Train_loss: 0.3214 / Val_loss: 0.6069\n",
      "Epoch: 300, Train_loss: 0.3143 / Val_loss: 0.6093\n",
      "Epoch: 301, Train_loss: 0.2915 / Val_loss: 0.6135\n",
      "Epoch: 302, Train_loss: 0.2813 / Val_loss: 0.6174\n",
      "Epoch: 303, Train_loss: 0.3173 / Val_loss: 0.6220\n",
      "Epoch: 304, Train_loss: 0.3096 / Val_loss: 0.6273\n",
      "Epoch: 305, Train_loss: 0.3116 / Val_loss: 0.6297\n",
      "Epoch: 306, Train_loss: 0.2778 / Val_loss: 0.6343\n",
      "Epoch: 307, Train_loss: 0.2609 / Val_loss: 0.6397\n",
      "Epoch: 308, Train_loss: 0.2816 / Val_loss: 0.6433\n",
      "Epoch: 309, Train_loss: 0.3025 / Val_loss: 0.6484\n",
      "Epoch: 310, Train_loss: 0.3127 / Val_loss: 0.6521\n",
      "Epoch: 311, Train_loss: 0.2913 / Val_loss: 0.6548\n",
      "Epoch: 312, Train_loss: 0.2682 / Val_loss: 0.6576\n",
      "Epoch: 313, Train_loss: 0.2937 / Val_loss: 0.6574\n",
      "Epoch: 314, Train_loss: 0.3001 / Val_loss: 0.6556\n",
      "Epoch: 315, Train_loss: 0.2901 / Val_loss: 0.6519\n",
      "Epoch: 316, Train_loss: 0.3019 / Val_loss: 0.6474\n",
      "Epoch: 317, Train_loss: 0.2916 / Val_loss: 0.6439\n",
      "Epoch: 318, Train_loss: 0.3199 / Val_loss: 0.6403\n",
      "Epoch: 319, Train_loss: 0.2618 / Val_loss: 0.6395\n",
      "Epoch: 320, Train_loss: 0.2746 / Val_loss: 0.6416\n",
      "Epoch: 321, Train_loss: 0.2728 / Val_loss: 0.6451\n",
      "Epoch: 322, Train_loss: 0.3164 / Val_loss: 0.6471\n",
      "Epoch: 323, Train_loss: 0.2832 / Val_loss: 0.6502\n",
      "Epoch: 324, Train_loss: 0.2991 / Val_loss: 0.6510\n",
      "Epoch: 325, Train_loss: 0.3051 / Val_loss: 0.6525\n",
      "Epoch: 326, Train_loss: 0.3057 / Val_loss: 0.6517\n",
      "Epoch: 327, Train_loss: 0.3170 / Val_loss: 0.6497\n",
      "Epoch: 328, Train_loss: 0.2897 / Val_loss: 0.6486\n",
      "Epoch: 329, Train_loss: 0.3189 / Val_loss: 0.6465\n",
      "Epoch: 330, Train_loss: 0.2721 / Val_loss: 0.6463\n",
      "Epoch: 331, Train_loss: 0.2923 / Val_loss: 0.6469\n",
      "Epoch: 332, Train_loss: 0.2547 / Val_loss: 0.6512\n",
      "Epoch: 333, Train_loss: 0.2744 / Val_loss: 0.6554\n",
      "Epoch: 334, Train_loss: 0.3067 / Val_loss: 0.6589\n",
      "Epoch: 335, Train_loss: 0.2476 / Val_loss: 0.6617\n",
      "Epoch: 336, Train_loss: 0.3298 / Val_loss: 0.6619\n",
      "Epoch: 337, Train_loss: 0.2873 / Val_loss: 0.6623\n",
      "Epoch: 338, Train_loss: 0.2718 / Val_loss: 0.6631\n",
      "Epoch: 339, Train_loss: 0.2700 / Val_loss: 0.6624\n",
      "Epoch: 340, Train_loss: 0.2615 / Val_loss: 0.6627\n",
      "Epoch: 341, Train_loss: 0.2963 / Val_loss: 0.6638\n",
      "Epoch: 342, Train_loss: 0.2888 / Val_loss: 0.6655\n",
      "Epoch: 343, Train_loss: 0.2872 / Val_loss: 0.6678\n",
      "Epoch: 344, Train_loss: 0.2584 / Val_loss: 0.6717\n",
      "Epoch: 345, Train_loss: 0.2596 / Val_loss: 0.6773\n",
      "Epoch: 346, Train_loss: 0.2717 / Val_loss: 0.6822\n",
      "Epoch: 347, Train_loss: 0.3012 / Val_loss: 0.6869\n",
      "Epoch: 348, Train_loss: 0.2842 / Val_loss: 0.6908\n",
      "Epoch: 349, Train_loss: 0.2798 / Val_loss: 0.6912\n",
      "Epoch: 350, Train_loss: 0.2505 / Val_loss: 0.6940\n",
      "Epoch: 351, Train_loss: 0.2344 / Val_loss: 0.6960\n",
      "Epoch: 352, Train_loss: 0.2944 / Val_loss: 0.6969\n",
      "Epoch: 353, Train_loss: 0.2673 / Val_loss: 0.6964\n",
      "Epoch: 354, Train_loss: 0.3113 / Val_loss: 0.6925\n",
      "Epoch: 355, Train_loss: 0.2684 / Val_loss: 0.6895\n",
      "Epoch: 356, Train_loss: 0.2790 / Val_loss: 0.6895\n",
      "Epoch: 357, Train_loss: 0.3013 / Val_loss: 0.6895\n",
      "Epoch: 358, Train_loss: 0.2710 / Val_loss: 0.6897\n",
      "Epoch: 359, Train_loss: 0.2773 / Val_loss: 0.6914\n",
      "Epoch: 360, Train_loss: 0.2893 / Val_loss: 0.6942\n",
      "Epoch: 361, Train_loss: 0.2408 / Val_loss: 0.6985\n",
      "Epoch: 362, Train_loss: 0.2464 / Val_loss: 0.7056\n",
      "Epoch: 363, Train_loss: 0.2566 / Val_loss: 0.7149\n",
      "Epoch: 364, Train_loss: 0.2761 / Val_loss: 0.7225\n",
      "Epoch: 365, Train_loss: 0.2690 / Val_loss: 0.7310\n",
      "Epoch: 366, Train_loss: 0.2904 / Val_loss: 0.7357\n",
      "Epoch: 367, Train_loss: 0.2807 / Val_loss: 0.7373\n",
      "Epoch: 368, Train_loss: 0.2638 / Val_loss: 0.7346\n",
      "Epoch: 369, Train_loss: 0.2817 / Val_loss: 0.7299\n",
      "Epoch: 370, Train_loss: 0.2870 / Val_loss: 0.7205\n",
      "Epoch: 371, Train_loss: 0.2307 / Val_loss: 0.7148\n",
      "Epoch: 372, Train_loss: 0.2532 / Val_loss: 0.7113\n",
      "Epoch: 373, Train_loss: 0.2752 / Val_loss: 0.7053\n",
      "Epoch: 374, Train_loss: 0.2532 / Val_loss: 0.7015\n",
      "Epoch: 375, Train_loss: 0.2584 / Val_loss: 0.7000\n",
      "Epoch: 376, Train_loss: 0.2689 / Val_loss: 0.6985\n",
      "Epoch: 377, Train_loss: 0.2647 / Val_loss: 0.6964\n",
      "Epoch: 378, Train_loss: 0.2363 / Val_loss: 0.6961\n",
      "Epoch: 379, Train_loss: 0.2403 / Val_loss: 0.6986\n",
      "Epoch: 380, Train_loss: 0.3005 / Val_loss: 0.7012\n",
      "Epoch: 381, Train_loss: 0.2534 / Val_loss: 0.7053\n",
      "Epoch: 382, Train_loss: 0.2934 / Val_loss: 0.7104\n",
      "Epoch: 383, Train_loss: 0.2589 / Val_loss: 0.7160\n",
      "Epoch: 384, Train_loss: 0.2542 / Val_loss: 0.7222\n",
      "Epoch: 385, Train_loss: 0.2775 / Val_loss: 0.7278\n",
      "Epoch: 386, Train_loss: 0.2503 / Val_loss: 0.7356\n",
      "Epoch: 387, Train_loss: 0.2496 / Val_loss: 0.7438\n",
      "Epoch: 388, Train_loss: 0.2596 / Val_loss: 0.7493\n",
      "Epoch: 389, Train_loss: 0.2404 / Val_loss: 0.7549\n",
      "Epoch: 390, Train_loss: 0.2666 / Val_loss: 0.7600\n",
      "Epoch: 391, Train_loss: 0.2353 / Val_loss: 0.7649\n",
      "Epoch: 392, Train_loss: 0.2499 / Val_loss: 0.7691\n",
      "Epoch: 393, Train_loss: 0.2834 / Val_loss: 0.7718\n",
      "Epoch: 394, Train_loss: 0.2527 / Val_loss: 0.7746\n",
      "Epoch: 395, Train_loss: 0.2265 / Val_loss: 0.7785\n",
      "Epoch: 396, Train_loss: 0.2473 / Val_loss: 0.7837\n",
      "Epoch: 397, Train_loss: 0.2458 / Val_loss: 0.7906\n",
      "Epoch: 398, Train_loss: 0.2415 / Val_loss: 0.7948\n",
      "Epoch: 399, Train_loss: 0.2351 / Val_loss: 0.7990\n",
      "Epoch: 400, Train_loss: 0.2246 / Val_loss: 0.8024\n",
      "Epoch: 401, Train_loss: 0.2625 / Val_loss: 0.8048\n",
      "Epoch: 402, Train_loss: 0.2214 / Val_loss: 0.8109\n",
      "Epoch: 403, Train_loss: 0.2610 / Val_loss: 0.8135\n",
      "Epoch: 404, Train_loss: 0.2575 / Val_loss: 0.8156\n",
      "Epoch: 405, Train_loss: 0.2303 / Val_loss: 0.8175\n",
      "Epoch: 406, Train_loss: 0.2403 / Val_loss: 0.8177\n",
      "Epoch: 407, Train_loss: 0.2772 / Val_loss: 0.8133\n",
      "Epoch: 408, Train_loss: 0.2451 / Val_loss: 0.8116\n",
      "Epoch: 409, Train_loss: 0.2552 / Val_loss: 0.8086\n",
      "Epoch: 410, Train_loss: 0.2829 / Val_loss: 0.8003\n",
      "Epoch: 411, Train_loss: 0.2483 / Val_loss: 0.7942\n",
      "Epoch: 412, Train_loss: 0.2436 / Val_loss: 0.7915\n",
      "Epoch: 413, Train_loss: 0.2281 / Val_loss: 0.7896\n",
      "Epoch: 414, Train_loss: 0.2822 / Val_loss: 0.7848\n",
      "Epoch: 415, Train_loss: 0.2531 / Val_loss: 0.7811\n",
      "Epoch: 416, Train_loss: 0.3031 / Val_loss: 0.7741\n",
      "Epoch: 417, Train_loss: 0.2567 / Val_loss: 0.7685\n",
      "Epoch: 418, Train_loss: 0.2647 / Val_loss: 0.7622\n",
      "Epoch: 419, Train_loss: 0.2708 / Val_loss: 0.7530\n",
      "Epoch: 420, Train_loss: 0.2497 / Val_loss: 0.7463\n",
      "Epoch: 421, Train_loss: 0.2550 / Val_loss: 0.7392\n",
      "Epoch: 422, Train_loss: 0.2683 / Val_loss: 0.7342\n",
      "Epoch: 423, Train_loss: 0.2660 / Val_loss: 0.7297\n",
      "Epoch: 424, Train_loss: 0.2435 / Val_loss: 0.7290\n",
      "Epoch: 425, Train_loss: 0.2415 / Val_loss: 0.7301\n",
      "Epoch: 426, Train_loss: 0.2182 / Val_loss: 0.7334\n",
      "Epoch: 427, Train_loss: 0.2264 / Val_loss: 0.7416\n",
      "Epoch: 428, Train_loss: 0.2294 / Val_loss: 0.7510\n",
      "Epoch: 429, Train_loss: 0.2425 / Val_loss: 0.7617\n",
      "Epoch: 430, Train_loss: 0.2277 / Val_loss: 0.7758\n",
      "Epoch: 431, Train_loss: 0.2187 / Val_loss: 0.7954\n",
      "Epoch: 432, Train_loss: 0.2700 / Val_loss: 0.8161\n",
      "Epoch: 433, Train_loss: 0.2154 / Val_loss: 0.8369\n",
      "Epoch: 434, Train_loss: 0.2445 / Val_loss: 0.8526\n",
      "Epoch: 435, Train_loss: 0.2675 / Val_loss: 0.8659\n",
      "Epoch: 436, Train_loss: 0.2474 / Val_loss: 0.8774\n",
      "Epoch: 437, Train_loss: 0.2678 / Val_loss: 0.8821\n",
      "Epoch: 438, Train_loss: 0.2424 / Val_loss: 0.8850\n",
      "Epoch: 439, Train_loss: 0.2414 / Val_loss: 0.8810\n",
      "Epoch: 440, Train_loss: 0.2181 / Val_loss: 0.8750\n",
      "Epoch: 441, Train_loss: 0.2223 / Val_loss: 0.8688\n",
      "Epoch: 442, Train_loss: 0.2273 / Val_loss: 0.8652\n",
      "Epoch: 443, Train_loss: 0.2443 / Val_loss: 0.8605\n",
      "Epoch: 444, Train_loss: 0.2410 / Val_loss: 0.8560\n",
      "Epoch: 445, Train_loss: 0.2396 / Val_loss: 0.8565\n",
      "Epoch: 446, Train_loss: 0.2228 / Val_loss: 0.8639\n",
      "Epoch: 447, Train_loss: 0.2187 / Val_loss: 0.8724\n",
      "Epoch: 448, Train_loss: 0.2081 / Val_loss: 0.8844\n",
      "Epoch: 449, Train_loss: 0.2224 / Val_loss: 0.8987\n",
      "Epoch: 450, Train_loss: 0.2149 / Val_loss: 0.9157\n",
      "Epoch: 451, Train_loss: 0.1585 / Val_loss: 0.9392\n",
      "Epoch: 452, Train_loss: 0.2574 / Val_loss: 0.9591\n",
      "Epoch: 453, Train_loss: 0.2396 / Val_loss: 0.9758\n",
      "Epoch: 454, Train_loss: 0.2162 / Val_loss: 0.9857\n",
      "Epoch: 455, Train_loss: 0.2362 / Val_loss: 0.9936\n",
      "Epoch: 456, Train_loss: 0.2405 / Val_loss: 0.9995\n",
      "Epoch: 457, Train_loss: 0.2237 / Val_loss: 0.9951\n",
      "Epoch: 458, Train_loss: 0.2197 / Val_loss: 0.9910\n",
      "Epoch: 459, Train_loss: 0.2161 / Val_loss: 0.9873\n",
      "Epoch: 460, Train_loss: 0.2478 / Val_loss: 0.9804\n",
      "Epoch: 461, Train_loss: 0.2766 / Val_loss: 0.9638\n",
      "Epoch: 462, Train_loss: 0.2747 / Val_loss: 0.9431\n",
      "Epoch: 463, Train_loss: 0.1970 / Val_loss: 0.9276\n",
      "Epoch: 464, Train_loss: 0.2329 / Val_loss: 0.9173\n",
      "Epoch: 465, Train_loss: 0.2111 / Val_loss: 0.9126\n",
      "Epoch: 466, Train_loss: 0.2366 / Val_loss: 0.9113\n",
      "Epoch: 467, Train_loss: 0.2662 / Val_loss: 0.9075\n",
      "Epoch: 468, Train_loss: 0.2065 / Val_loss: 0.9143\n",
      "Epoch: 469, Train_loss: 0.2243 / Val_loss: 0.9205\n",
      "Epoch: 470, Train_loss: 0.2161 / Val_loss: 0.9276\n",
      "Epoch: 471, Train_loss: 0.2356 / Val_loss: 0.9337\n",
      "Epoch: 472, Train_loss: 0.2256 / Val_loss: 0.9387\n",
      "Epoch: 473, Train_loss: 0.2218 / Val_loss: 0.9448\n",
      "Epoch: 474, Train_loss: 0.2448 / Val_loss: 0.9511\n",
      "Epoch: 475, Train_loss: 0.2237 / Val_loss: 0.9621\n",
      "Epoch: 476, Train_loss: 0.2152 / Val_loss: 0.9692\n",
      "Epoch: 477, Train_loss: 0.2006 / Val_loss: 0.9773\n",
      "Epoch: 478, Train_loss: 0.1983 / Val_loss: 0.9901\n",
      "Epoch: 479, Train_loss: 0.2235 / Val_loss: 1.0007\n",
      "Epoch: 480, Train_loss: 0.2049 / Val_loss: 1.0082\n",
      "Epoch: 481, Train_loss: 0.2118 / Val_loss: 1.0189\n",
      "Epoch: 482, Train_loss: 0.2297 / Val_loss: 1.0226\n",
      "Epoch: 483, Train_loss: 0.2122 / Val_loss: 1.0296\n",
      "Epoch: 484, Train_loss: 0.2286 / Val_loss: 1.0353\n",
      "Epoch: 485, Train_loss: 0.2625 / Val_loss: 1.0310\n",
      "Epoch: 486, Train_loss: 0.1943 / Val_loss: 1.0298\n",
      "Epoch: 487, Train_loss: 0.1974 / Val_loss: 1.0347\n",
      "Epoch: 488, Train_loss: 0.1911 / Val_loss: 1.0380\n",
      "Epoch: 489, Train_loss: 0.2290 / Val_loss: 1.0427\n",
      "Epoch: 490, Train_loss: 0.1885 / Val_loss: 1.0459\n",
      "Epoch: 491, Train_loss: 0.2087 / Val_loss: 1.0492\n",
      "Epoch: 492, Train_loss: 0.1879 / Val_loss: 1.0516\n",
      "Epoch: 493, Train_loss: 0.2058 / Val_loss: 1.0552\n",
      "Epoch: 494, Train_loss: 0.2596 / Val_loss: 1.0468\n",
      "Epoch: 495, Train_loss: 0.2274 / Val_loss: 1.0347\n",
      "Epoch: 496, Train_loss: 0.2373 / Val_loss: 1.0205\n",
      "Epoch: 497, Train_loss: 0.2313 / Val_loss: 1.0066\n",
      "Epoch: 498, Train_loss: 0.2393 / Val_loss: 0.9887\n",
      "Epoch: 499, Train_loss: 0.2259 / Val_loss: 0.9761\n",
      "Epoch: 500, Train_loss: 0.1702 / Val_loss: 0.9663\n",
      "Epoch: 501, Train_loss: 0.2100 / Val_loss: 0.9542\n",
      "Epoch: 502, Train_loss: 0.2230 / Val_loss: 0.9448\n",
      "Epoch: 503, Train_loss: 0.2251 / Val_loss: 0.9382\n",
      "Epoch: 504, Train_loss: 0.1817 / Val_loss: 0.9335\n",
      "Epoch: 505, Train_loss: 0.2326 / Val_loss: 0.9249\n",
      "Epoch: 506, Train_loss: 0.2116 / Val_loss: 0.9149\n",
      "Epoch: 507, Train_loss: 0.2379 / Val_loss: 0.9104\n",
      "Epoch: 508, Train_loss: 0.2283 / Val_loss: 0.9103\n",
      "Epoch: 509, Train_loss: 0.2113 / Val_loss: 0.9167\n",
      "Epoch: 510, Train_loss: 0.2076 / Val_loss: 0.9297\n",
      "Epoch: 511, Train_loss: 0.2024 / Val_loss: 0.9491\n",
      "Epoch: 512, Train_loss: 0.2083 / Val_loss: 0.9719\n",
      "Epoch: 513, Train_loss: 0.1789 / Val_loss: 1.0002\n",
      "Epoch: 514, Train_loss: 0.2276 / Val_loss: 1.0226\n",
      "Epoch: 515, Train_loss: 0.2163 / Val_loss: 1.0403\n",
      "Epoch: 516, Train_loss: 0.1989 / Val_loss: 1.0637\n",
      "Epoch: 517, Train_loss: 0.2080 / Val_loss: 1.0865\n",
      "Epoch: 518, Train_loss: 0.1999 / Val_loss: 1.1080\n",
      "Epoch: 519, Train_loss: 0.2101 / Val_loss: 1.1256\n",
      "Epoch: 520, Train_loss: 0.1821 / Val_loss: 1.1477\n",
      "Epoch: 521, Train_loss: 0.2176 / Val_loss: 1.1556\n",
      "Epoch: 522, Train_loss: 0.1687 / Val_loss: 1.1686\n",
      "Epoch: 523, Train_loss: 0.2046 / Val_loss: 1.1747\n",
      "Epoch: 524, Train_loss: 0.2165 / Val_loss: 1.1768\n",
      "Epoch: 525, Train_loss: 0.1904 / Val_loss: 1.1603\n",
      "Epoch: 526, Train_loss: 0.2023 / Val_loss: 1.1461\n",
      "Epoch: 527, Train_loss: 0.2268 / Val_loss: 1.1266\n",
      "Epoch: 528, Train_loss: 0.2447 / Val_loss: 1.1036\n",
      "Epoch: 529, Train_loss: 0.2396 / Val_loss: 1.0810\n",
      "Epoch: 530, Train_loss: 0.2320 / Val_loss: 1.0620\n",
      "Epoch: 531, Train_loss: 0.2289 / Val_loss: 1.0494\n",
      "Epoch: 532, Train_loss: 0.1963 / Val_loss: 1.0447\n",
      "Epoch: 533, Train_loss: 0.2255 / Val_loss: 1.0424\n",
      "Epoch: 534, Train_loss: 0.2029 / Val_loss: 1.0480\n",
      "Epoch: 535, Train_loss: 0.1983 / Val_loss: 1.0608\n",
      "Epoch: 536, Train_loss: 0.2253 / Val_loss: 1.0741\n",
      "Epoch: 537, Train_loss: 0.1791 / Val_loss: 1.0927\n",
      "Epoch: 538, Train_loss: 0.1959 / Val_loss: 1.1187\n",
      "Epoch: 539, Train_loss: 0.2287 / Val_loss: 1.1383\n",
      "Epoch: 540, Train_loss: 0.1765 / Val_loss: 1.1649\n",
      "Epoch: 541, Train_loss: 0.2198 / Val_loss: 1.1854\n",
      "Epoch: 542, Train_loss: 0.1940 / Val_loss: 1.2077\n",
      "Epoch: 543, Train_loss: 0.2390 / Val_loss: 1.2248\n",
      "Epoch: 544, Train_loss: 0.2241 / Val_loss: 1.2266\n",
      "Epoch: 545, Train_loss: 0.1847 / Val_loss: 1.2195\n",
      "Epoch: 546, Train_loss: 0.1738 / Val_loss: 1.2071\n",
      "Epoch: 547, Train_loss: 0.2086 / Val_loss: 1.1857\n",
      "Epoch: 548, Train_loss: 0.1952 / Val_loss: 1.1689\n",
      "Epoch: 549, Train_loss: 0.2080 / Val_loss: 1.1528\n",
      "Epoch: 550, Train_loss: 0.1740 / Val_loss: 1.1463\n",
      "Epoch: 551, Train_loss: 0.2189 / Val_loss: 1.1345\n",
      "Epoch: 552, Train_loss: 0.1964 / Val_loss: 1.1265\n",
      "Epoch: 553, Train_loss: 0.2295 / Val_loss: 1.1191\n",
      "Epoch: 554, Train_loss: 0.1984 / Val_loss: 1.1118\n",
      "Epoch: 555, Train_loss: 0.1756 / Val_loss: 1.1083\n",
      "Epoch: 556, Train_loss: 0.1602 / Val_loss: 1.1093\n",
      "Epoch: 557, Train_loss: 0.2317 / Val_loss: 1.1059\n",
      "Epoch: 558, Train_loss: 0.2332 / Val_loss: 1.1020\n",
      "Epoch: 559, Train_loss: 0.2151 / Val_loss: 1.1052\n",
      "Epoch: 560, Train_loss: 0.1855 / Val_loss: 1.1144\n",
      "Epoch: 561, Train_loss: 0.2096 / Val_loss: 1.1257\n",
      "Epoch: 562, Train_loss: 0.2001 / Val_loss: 1.1403\n",
      "Epoch: 563, Train_loss: 0.1869 / Val_loss: 1.1520\n",
      "Epoch: 564, Train_loss: 0.1911 / Val_loss: 1.1619\n",
      "Epoch: 565, Train_loss: 0.1695 / Val_loss: 1.1780\n",
      "Epoch: 566, Train_loss: 0.1702 / Val_loss: 1.1946\n",
      "Epoch: 567, Train_loss: 0.1807 / Val_loss: 1.2048\n",
      "Epoch: 568, Train_loss: 0.1838 / Val_loss: 1.2181\n",
      "Epoch: 569, Train_loss: 0.2153 / Val_loss: 1.2257\n",
      "Epoch: 570, Train_loss: 0.2190 / Val_loss: 1.2246\n",
      "Epoch: 571, Train_loss: 0.1948 / Val_loss: 1.2241\n",
      "Epoch: 572, Train_loss: 0.1706 / Val_loss: 1.2286\n",
      "Epoch: 573, Train_loss: 0.1790 / Val_loss: 1.2335\n",
      "Epoch: 574, Train_loss: 0.1866 / Val_loss: 1.2432\n",
      "Epoch: 575, Train_loss: 0.1703 / Val_loss: 1.2562\n",
      "Epoch: 576, Train_loss: 0.2176 / Val_loss: 1.2727\n",
      "Epoch: 577, Train_loss: 0.1674 / Val_loss: 1.2973\n",
      "Epoch: 578, Train_loss: 0.1784 / Val_loss: 1.3171\n",
      "Epoch: 579, Train_loss: 0.1566 / Val_loss: 1.3391\n",
      "Epoch: 580, Train_loss: 0.1970 / Val_loss: 1.3488\n",
      "Epoch: 581, Train_loss: 0.1673 / Val_loss: 1.3554\n",
      "Epoch: 582, Train_loss: 0.2015 / Val_loss: 1.3536\n",
      "Epoch: 583, Train_loss: 0.2106 / Val_loss: 1.3474\n",
      "Epoch: 584, Train_loss: 0.2259 / Val_loss: 1.3435\n",
      "Epoch: 585, Train_loss: 0.1880 / Val_loss: 1.3428\n",
      "Epoch: 586, Train_loss: 0.1623 / Val_loss: 1.3461\n",
      "Epoch: 587, Train_loss: 0.1737 / Val_loss: 1.3490\n",
      "Epoch: 588, Train_loss: 0.1553 / Val_loss: 1.3542\n",
      "Epoch: 589, Train_loss: 0.1969 / Val_loss: 1.3560\n",
      "Epoch: 590, Train_loss: 0.1678 / Val_loss: 1.3582\n",
      "Epoch: 591, Train_loss: 0.2100 / Val_loss: 1.3580\n",
      "Epoch: 592, Train_loss: 0.2039 / Val_loss: 1.3549\n",
      "Epoch: 593, Train_loss: 0.1599 / Val_loss: 1.3496\n",
      "Epoch: 594, Train_loss: 0.2097 / Val_loss: 1.3388\n",
      "Epoch: 595, Train_loss: 0.1797 / Val_loss: 1.3294\n",
      "Epoch: 596, Train_loss: 0.1888 / Val_loss: 1.3209\n",
      "Epoch: 597, Train_loss: 0.1597 / Val_loss: 1.3216\n",
      "Epoch: 598, Train_loss: 0.2038 / Val_loss: 1.3230\n",
      "Epoch: 599, Train_loss: 0.2284 / Val_loss: 1.3206\n",
      "Epoch: 600, Train_loss: 0.1970 / Val_loss: 1.3177\n",
      "Epoch: 601, Train_loss: 0.2170 / Val_loss: 1.3052\n",
      "Epoch: 602, Train_loss: 0.1996 / Val_loss: 1.2917\n",
      "Epoch: 603, Train_loss: 0.1741 / Val_loss: 1.2834\n",
      "Epoch: 604, Train_loss: 0.2099 / Val_loss: 1.2711\n",
      "Epoch: 605, Train_loss: 0.2068 / Val_loss: 1.2502\n",
      "Epoch: 606, Train_loss: 0.2457 / Val_loss: 1.2268\n",
      "Epoch: 607, Train_loss: 0.1965 / Val_loss: 1.2172\n",
      "Epoch: 608, Train_loss: 0.1916 / Val_loss: 1.2167\n",
      "Epoch: 609, Train_loss: 0.2070 / Val_loss: 1.2189\n",
      "Epoch: 610, Train_loss: 0.1963 / Val_loss: 1.2266\n",
      "Epoch: 611, Train_loss: 0.1839 / Val_loss: 1.2358\n",
      "Epoch: 612, Train_loss: 0.1695 / Val_loss: 1.2497\n",
      "Epoch: 613, Train_loss: 0.1878 / Val_loss: 1.2622\n",
      "Epoch: 614, Train_loss: 0.2132 / Val_loss: 1.2733\n",
      "Epoch: 615, Train_loss: 0.1663 / Val_loss: 1.2893\n",
      "Epoch: 616, Train_loss: 0.2029 / Val_loss: 1.3026\n",
      "Epoch: 617, Train_loss: 0.1580 / Val_loss: 1.3139\n",
      "Epoch: 618, Train_loss: 0.2370 / Val_loss: 1.3179\n",
      "Epoch: 619, Train_loss: 0.1934 / Val_loss: 1.3223\n",
      "Epoch: 620, Train_loss: 0.1681 / Val_loss: 1.3296\n",
      "Epoch: 621, Train_loss: 0.2201 / Val_loss: 1.3257\n",
      "Epoch: 622, Train_loss: 0.1907 / Val_loss: 1.3190\n",
      "Epoch: 623, Train_loss: 0.1728 / Val_loss: 1.3173\n",
      "Epoch: 624, Train_loss: 0.1658 / Val_loss: 1.3244\n",
      "Epoch: 625, Train_loss: 0.2084 / Val_loss: 1.3317\n",
      "Epoch: 626, Train_loss: 0.1950 / Val_loss: 1.3397\n",
      "Epoch: 627, Train_loss: 0.1855 / Val_loss: 1.3460\n",
      "Epoch: 628, Train_loss: 0.1377 / Val_loss: 1.3610\n",
      "Epoch: 629, Train_loss: 0.1615 / Val_loss: 1.3812\n",
      "Epoch: 630, Train_loss: 0.1578 / Val_loss: 1.4035\n",
      "Epoch: 631, Train_loss: 0.1963 / Val_loss: 1.4204\n",
      "Epoch: 632, Train_loss: 0.1789 / Val_loss: 1.4395\n",
      "Epoch: 633, Train_loss: 0.1780 / Val_loss: 1.4571\n",
      "Epoch: 634, Train_loss: 0.1712 / Val_loss: 1.4806\n",
      "Epoch: 635, Train_loss: 0.1742 / Val_loss: 1.4999\n",
      "Epoch: 636, Train_loss: 0.1710 / Val_loss: 1.5168\n",
      "Epoch: 637, Train_loss: 0.1979 / Val_loss: 1.5139\n",
      "Epoch: 638, Train_loss: 0.1846 / Val_loss: 1.4999\n",
      "Epoch: 639, Train_loss: 0.2076 / Val_loss: 1.4802\n",
      "Epoch: 640, Train_loss: 0.1522 / Val_loss: 1.4731\n",
      "Epoch: 641, Train_loss: 0.2336 / Val_loss: 1.4452\n",
      "Epoch: 642, Train_loss: 0.1673 / Val_loss: 1.4261\n",
      "Epoch: 643, Train_loss: 0.1955 / Val_loss: 1.4057\n",
      "Epoch: 644, Train_loss: 0.1732 / Val_loss: 1.3940\n",
      "Epoch: 645, Train_loss: 0.1683 / Val_loss: 1.3893\n",
      "Epoch: 646, Train_loss: 0.1724 / Val_loss: 1.3891\n",
      "Epoch: 647, Train_loss: 0.1730 / Val_loss: 1.3940\n",
      "Epoch: 648, Train_loss: 0.1614 / Val_loss: 1.4078\n",
      "Epoch: 649, Train_loss: 0.1682 / Val_loss: 1.4124\n",
      "Epoch: 650, Train_loss: 0.1889 / Val_loss: 1.4203\n",
      "Epoch: 651, Train_loss: 0.1419 / Val_loss: 1.4327\n",
      "Epoch: 652, Train_loss: 0.1597 / Val_loss: 1.4513\n",
      "Epoch: 653, Train_loss: 0.1806 / Val_loss: 1.4720\n",
      "Epoch: 654, Train_loss: 0.1608 / Val_loss: 1.4812\n",
      "Epoch: 655, Train_loss: 0.1616 / Val_loss: 1.4996\n",
      "Epoch: 656, Train_loss: 0.1707 / Val_loss: 1.5216\n",
      "Epoch: 657, Train_loss: 0.1614 / Val_loss: 1.5439\n",
      "Epoch: 658, Train_loss: 0.1810 / Val_loss: 1.5566\n",
      "Epoch: 659, Train_loss: 0.1455 / Val_loss: 1.5708\n",
      "Epoch: 660, Train_loss: 0.1565 / Val_loss: 1.5888\n",
      "Epoch: 661, Train_loss: 0.1615 / Val_loss: 1.6013\n",
      "Epoch: 662, Train_loss: 0.1888 / Val_loss: 1.6135\n",
      "Epoch: 663, Train_loss: 0.1651 / Val_loss: 1.6154\n",
      "Epoch: 664, Train_loss: 0.1952 / Val_loss: 1.6074\n",
      "Epoch: 665, Train_loss: 0.1750 / Val_loss: 1.6010\n",
      "Epoch: 666, Train_loss: 0.1657 / Val_loss: 1.5986\n",
      "Epoch: 667, Train_loss: 0.1914 / Val_loss: 1.5957\n",
      "Epoch: 668, Train_loss: 0.1434 / Val_loss: 1.6043\n",
      "Epoch: 669, Train_loss: 0.1317 / Val_loss: 1.6205\n",
      "Epoch: 670, Train_loss: 0.1656 / Val_loss: 1.6386\n",
      "Epoch: 671, Train_loss: 0.1501 / Val_loss: 1.6585\n",
      "Epoch: 672, Train_loss: 0.1708 / Val_loss: 1.6765\n",
      "Epoch: 673, Train_loss: 0.1629 / Val_loss: 1.6868\n",
      "Epoch: 674, Train_loss: 0.1468 / Val_loss: 1.7011\n",
      "Epoch: 675, Train_loss: 0.1591 / Val_loss: 1.7056\n",
      "Epoch: 676, Train_loss: 0.1720 / Val_loss: 1.7032\n",
      "Epoch: 677, Train_loss: 0.1532 / Val_loss: 1.7030\n",
      "Epoch: 678, Train_loss: 0.1753 / Val_loss: 1.7007\n",
      "Epoch: 679, Train_loss: 0.1739 / Val_loss: 1.6896\n",
      "Epoch: 680, Train_loss: 0.1905 / Val_loss: 1.6773\n",
      "Epoch: 681, Train_loss: 0.1845 / Val_loss: 1.6593\n",
      "Epoch: 682, Train_loss: 0.1327 / Val_loss: 1.6517\n",
      "Epoch: 683, Train_loss: 0.1244 / Val_loss: 1.6506\n",
      "Epoch: 684, Train_loss: 0.1417 / Val_loss: 1.6524\n",
      "Epoch: 685, Train_loss: 0.1725 / Val_loss: 1.6542\n",
      "Epoch: 686, Train_loss: 0.1433 / Val_loss: 1.6612\n",
      "Epoch: 687, Train_loss: 0.1403 / Val_loss: 1.6779\n",
      "Epoch: 688, Train_loss: 0.1196 / Val_loss: 1.7075\n",
      "Epoch: 689, Train_loss: 0.1521 / Val_loss: 1.7326\n",
      "Epoch: 690, Train_loss: 0.1465 / Val_loss: 1.7626\n",
      "Epoch: 691, Train_loss: 0.1484 / Val_loss: 1.7885\n",
      "Epoch: 692, Train_loss: 0.1800 / Val_loss: 1.8066\n",
      "Epoch: 693, Train_loss: 0.1457 / Val_loss: 1.8283\n",
      "Epoch: 694, Train_loss: 0.1616 / Val_loss: 1.8378\n",
      "Epoch: 695, Train_loss: 0.1801 / Val_loss: 1.8359\n",
      "Epoch: 696, Train_loss: 0.1755 / Val_loss: 1.8231\n",
      "Epoch: 697, Train_loss: 0.1273 / Val_loss: 1.8163\n",
      "Epoch: 698, Train_loss: 0.1589 / Val_loss: 1.8110\n",
      "Epoch: 699, Train_loss: 0.1604 / Val_loss: 1.8015\n",
      "Epoch: 700, Train_loss: 0.1460 / Val_loss: 1.7929\n",
      "Epoch: 701, Train_loss: 0.1438 / Val_loss: 1.7930\n",
      "Epoch: 702, Train_loss: 0.1120 / Val_loss: 1.8082\n",
      "Epoch: 703, Train_loss: 0.1567 / Val_loss: 1.8227\n",
      "Epoch: 704, Train_loss: 0.1272 / Val_loss: 1.8427\n",
      "Epoch: 705, Train_loss: 0.1698 / Val_loss: 1.8557\n",
      "Epoch: 706, Train_loss: 0.1600 / Val_loss: 1.8665\n",
      "Epoch: 707, Train_loss: 0.1453 / Val_loss: 1.8811\n",
      "Epoch: 708, Train_loss: 0.1906 / Val_loss: 1.8883\n",
      "Epoch: 709, Train_loss: 0.1225 / Val_loss: 1.8994\n",
      "Epoch: 710, Train_loss: 0.1483 / Val_loss: 1.9086\n",
      "Epoch: 711, Train_loss: 0.1653 / Val_loss: 1.9206\n",
      "Epoch: 712, Train_loss: 0.1295 / Val_loss: 1.9299\n",
      "Epoch: 713, Train_loss: 0.1487 / Val_loss: 1.9384\n",
      "Epoch: 714, Train_loss: 0.1405 / Val_loss: 1.9464\n",
      "Epoch: 715, Train_loss: 0.1497 / Val_loss: 1.9566\n",
      "Epoch: 716, Train_loss: 0.1447 / Val_loss: 1.9588\n",
      "Epoch: 717, Train_loss: 0.1148 / Val_loss: 1.9638\n",
      "Epoch: 718, Train_loss: 0.1908 / Val_loss: 1.9589\n",
      "Epoch: 719, Train_loss: 0.1534 / Val_loss: 1.9576\n",
      "Epoch: 720, Train_loss: 0.1497 / Val_loss: 1.9588\n",
      "Epoch: 721, Train_loss: 0.1524 / Val_loss: 1.9711\n",
      "Epoch: 722, Train_loss: 0.1458 / Val_loss: 1.9824\n",
      "Epoch: 723, Train_loss: 0.1641 / Val_loss: 1.9885\n",
      "Epoch: 724, Train_loss: 0.1413 / Val_loss: 1.9966\n",
      "Epoch: 725, Train_loss: 0.1364 / Val_loss: 2.0014\n",
      "Epoch: 726, Train_loss: 0.1462 / Val_loss: 2.0013\n",
      "Epoch: 727, Train_loss: 0.1856 / Val_loss: 1.9790\n",
      "Epoch: 728, Train_loss: 0.1696 / Val_loss: 1.9557\n",
      "Epoch: 729, Train_loss: 0.1538 / Val_loss: 1.9390\n",
      "Epoch: 730, Train_loss: 0.1622 / Val_loss: 1.9297\n",
      "Epoch: 731, Train_loss: 0.2138 / Val_loss: 1.9224\n",
      "Epoch: 732, Train_loss: 0.1301 / Val_loss: 1.9358\n",
      "Epoch: 733, Train_loss: 0.1452 / Val_loss: 1.9581\n",
      "Epoch: 734, Train_loss: 0.1420 / Val_loss: 1.9800\n",
      "Epoch: 735, Train_loss: 0.1437 / Val_loss: 2.0022\n",
      "Epoch: 736, Train_loss: 0.1553 / Val_loss: 2.0122\n",
      "Epoch: 737, Train_loss: 0.1435 / Val_loss: 2.0226\n",
      "Epoch: 738, Train_loss: 0.1454 / Val_loss: 2.0337\n",
      "Epoch: 739, Train_loss: 0.1334 / Val_loss: 2.0450\n",
      "Epoch: 740, Train_loss: 0.1553 / Val_loss: 2.0640\n",
      "Epoch: 741, Train_loss: 0.1512 / Val_loss: 2.0716\n",
      "Epoch: 742, Train_loss: 0.1946 / Val_loss: 2.0587\n",
      "Epoch: 743, Train_loss: 0.1660 / Val_loss: 2.0506\n",
      "Epoch: 744, Train_loss: 0.1638 / Val_loss: 2.0427\n",
      "Epoch: 745, Train_loss: 0.1870 / Val_loss: 2.0145\n",
      "Epoch: 746, Train_loss: 0.1522 / Val_loss: 1.9896\n",
      "Epoch: 747, Train_loss: 0.1953 / Val_loss: 1.9464\n",
      "Epoch: 748, Train_loss: 0.1951 / Val_loss: 1.8978\n",
      "Epoch: 749, Train_loss: 0.1681 / Val_loss: 1.8629\n",
      "Epoch: 750, Train_loss: 0.1487 / Val_loss: 1.8377\n",
      "Epoch: 751, Train_loss: 0.1374 / Val_loss: 1.8173\n",
      "Epoch: 752, Train_loss: 0.1552 / Val_loss: 1.8117\n",
      "Epoch: 753, Train_loss: 0.1497 / Val_loss: 1.8189\n",
      "Epoch: 754, Train_loss: 0.1526 / Val_loss: 1.8285\n",
      "Epoch: 755, Train_loss: 0.1626 / Val_loss: 1.8401\n",
      "Epoch: 756, Train_loss: 0.1271 / Val_loss: 1.8555\n",
      "Epoch: 757, Train_loss: 0.1674 / Val_loss: 1.8665\n",
      "Epoch: 758, Train_loss: 0.1798 / Val_loss: 1.8691\n",
      "Epoch: 759, Train_loss: 0.1419 / Val_loss: 1.8673\n",
      "Epoch: 760, Train_loss: 0.1078 / Val_loss: 1.8757\n",
      "Epoch: 761, Train_loss: 0.1498 / Val_loss: 1.8910\n",
      "Epoch: 762, Train_loss: 0.1227 / Val_loss: 1.9101\n",
      "Epoch: 763, Train_loss: 0.1311 / Val_loss: 1.9361\n",
      "Epoch: 764, Train_loss: 0.1593 / Val_loss: 1.9564\n",
      "Epoch: 765, Train_loss: 0.1409 / Val_loss: 1.9769\n",
      "Epoch: 766, Train_loss: 0.1524 / Val_loss: 1.9811\n",
      "Epoch: 767, Train_loss: 0.1607 / Val_loss: 1.9866\n",
      "Epoch: 768, Train_loss: 0.1482 / Val_loss: 1.9948\n",
      "Epoch: 769, Train_loss: 0.1594 / Val_loss: 1.9893\n",
      "Epoch: 770, Train_loss: 0.1568 / Val_loss: 1.9863\n",
      "Epoch: 771, Train_loss: 0.1395 / Val_loss: 1.9900\n",
      "Epoch: 772, Train_loss: 0.1392 / Val_loss: 2.0011\n",
      "Epoch: 773, Train_loss: 0.1608 / Val_loss: 2.0150\n",
      "Epoch: 774, Train_loss: 0.1554 / Val_loss: 2.0245\n",
      "Epoch: 775, Train_loss: 0.1366 / Val_loss: 2.0251\n",
      "Epoch: 776, Train_loss: 0.1302 / Val_loss: 2.0313\n",
      "Epoch: 777, Train_loss: 0.1405 / Val_loss: 2.0488\n",
      "Epoch: 778, Train_loss: 0.1327 / Val_loss: 2.0719\n",
      "Epoch: 779, Train_loss: 0.1359 / Val_loss: 2.0944\n",
      "Epoch: 780, Train_loss: 0.1405 / Val_loss: 2.1184\n",
      "Epoch: 781, Train_loss: 0.1447 / Val_loss: 2.1411\n",
      "Epoch: 782, Train_loss: 0.1847 / Val_loss: 2.1467\n",
      "Epoch: 783, Train_loss: 0.1419 / Val_loss: 2.1504\n",
      "Epoch: 784, Train_loss: 0.1399 / Val_loss: 2.1498\n",
      "Epoch: 785, Train_loss: 0.1414 / Val_loss: 2.1508\n",
      "Epoch: 786, Train_loss: 0.1271 / Val_loss: 2.1499\n",
      "Epoch: 787, Train_loss: 0.1394 / Val_loss: 2.1482\n",
      "Epoch: 788, Train_loss: 0.1619 / Val_loss: 2.1314\n",
      "Epoch: 789, Train_loss: 0.1658 / Val_loss: 2.1019\n",
      "Epoch: 790, Train_loss: 0.1120 / Val_loss: 2.0831\n",
      "Epoch: 791, Train_loss: 0.1257 / Val_loss: 2.0821\n",
      "Epoch: 792, Train_loss: 0.1009 / Val_loss: 2.0894\n",
      "Epoch: 793, Train_loss: 0.1197 / Val_loss: 2.1023\n",
      "Epoch: 794, Train_loss: 0.1290 / Val_loss: 2.1139\n",
      "Epoch: 795, Train_loss: 0.1271 / Val_loss: 2.1389\n",
      "Epoch: 796, Train_loss: 0.1422 / Val_loss: 2.1663\n",
      "Epoch: 797, Train_loss: 0.1697 / Val_loss: 2.1769\n",
      "Epoch: 798, Train_loss: 0.1951 / Val_loss: 2.1687\n",
      "Epoch: 799, Train_loss: 0.1487 / Val_loss: 2.1661\n",
      "Epoch: 800, Train_loss: 0.1537 / Val_loss: 2.1611\n",
      "Epoch: 801, Train_loss: 0.1461 / Val_loss: 2.1416\n",
      "Epoch: 802, Train_loss: 0.1484 / Val_loss: 2.1253\n",
      "Epoch: 803, Train_loss: 0.1422 / Val_loss: 2.1156\n",
      "Epoch: 804, Train_loss: 0.1487 / Val_loss: 2.0944\n",
      "Epoch: 805, Train_loss: 0.2019 / Val_loss: 2.0589\n",
      "Epoch: 806, Train_loss: 0.1489 / Val_loss: 2.0235\n",
      "Epoch: 807, Train_loss: 0.1468 / Val_loss: 1.9951\n",
      "Epoch: 808, Train_loss: 0.1241 / Val_loss: 1.9812\n",
      "Epoch: 809, Train_loss: 0.1489 / Val_loss: 1.9764\n",
      "Epoch: 810, Train_loss: 0.1555 / Val_loss: 1.9715\n",
      "Epoch: 811, Train_loss: 0.1165 / Val_loss: 1.9795\n",
      "Epoch: 812, Train_loss: 0.1557 / Val_loss: 1.9939\n",
      "Epoch: 813, Train_loss: 0.1375 / Val_loss: 2.0084\n",
      "Epoch: 814, Train_loss: 0.1594 / Val_loss: 2.0269\n",
      "Epoch: 815, Train_loss: 0.1811 / Val_loss: 2.0284\n",
      "Epoch: 816, Train_loss: 0.1321 / Val_loss: 2.0351\n",
      "Epoch: 817, Train_loss: 0.2002 / Val_loss: 2.0247\n",
      "Epoch: 818, Train_loss: 0.1411 / Val_loss: 2.0164\n",
      "Epoch: 819, Train_loss: 0.1605 / Val_loss: 2.0172\n",
      "Epoch: 820, Train_loss: 0.1572 / Val_loss: 2.0142\n",
      "Epoch: 821, Train_loss: 0.1581 / Val_loss: 2.0021\n",
      "Epoch: 822, Train_loss: 0.1428 / Val_loss: 1.9927\n",
      "Epoch: 823, Train_loss: 0.1239 / Val_loss: 1.9905\n",
      "Epoch: 824, Train_loss: 0.1133 / Val_loss: 1.9986\n",
      "Epoch: 825, Train_loss: 0.1630 / Val_loss: 2.0058\n",
      "Epoch: 826, Train_loss: 0.1176 / Val_loss: 2.0259\n",
      "Epoch: 827, Train_loss: 0.1509 / Val_loss: 2.0488\n",
      "Epoch: 828, Train_loss: 0.1472 / Val_loss: 2.0722\n",
      "Epoch: 829, Train_loss: 0.1471 / Val_loss: 2.0902\n",
      "Epoch: 830, Train_loss: 0.1346 / Val_loss: 2.1223\n",
      "Epoch: 831, Train_loss: 0.1664 / Val_loss: 2.1346\n",
      "Epoch: 832, Train_loss: 0.1149 / Val_loss: 2.1505\n",
      "Epoch: 833, Train_loss: 0.1359 / Val_loss: 2.1731\n",
      "Epoch: 834, Train_loss: 0.1326 / Val_loss: 2.1949\n",
      "Epoch: 835, Train_loss: 0.1683 / Val_loss: 2.1970\n",
      "Epoch: 836, Train_loss: 0.1289 / Val_loss: 2.2026\n",
      "Epoch: 837, Train_loss: 0.0988 / Val_loss: 2.2185\n",
      "Epoch: 838, Train_loss: 0.1514 / Val_loss: 2.2285\n",
      "Epoch: 839, Train_loss: 0.1641 / Val_loss: 2.2320\n",
      "Epoch: 840, Train_loss: 0.1669 / Val_loss: 2.2264\n",
      "Epoch: 841, Train_loss: 0.1518 / Val_loss: 2.2049\n",
      "Epoch: 842, Train_loss: 0.1169 / Val_loss: 2.1890\n",
      "Epoch: 843, Train_loss: 0.1368 / Val_loss: 2.1686\n",
      "Epoch: 844, Train_loss: 0.1319 / Val_loss: 2.1619\n",
      "Epoch: 845, Train_loss: 0.1313 / Val_loss: 2.1532\n",
      "Epoch: 846, Train_loss: 0.1260 / Val_loss: 2.1534\n",
      "Epoch: 847, Train_loss: 0.1301 / Val_loss: 2.1630\n",
      "Epoch: 848, Train_loss: 0.1046 / Val_loss: 2.1818\n",
      "Epoch: 849, Train_loss: 0.1508 / Val_loss: 2.1914\n",
      "Epoch: 850, Train_loss: 0.1412 / Val_loss: 2.1865\n",
      "Epoch: 851, Train_loss: 0.1106 / Val_loss: 2.1753\n",
      "Epoch: 852, Train_loss: 0.1207 / Val_loss: 2.1645\n",
      "Epoch: 853, Train_loss: 0.1230 / Val_loss: 2.1553\n",
      "Epoch: 854, Train_loss: 0.1206 / Val_loss: 2.1510\n",
      "Epoch: 855, Train_loss: 0.1614 / Val_loss: 2.1511\n",
      "Epoch: 856, Train_loss: 0.1792 / Val_loss: 2.1331\n",
      "Epoch: 857, Train_loss: 0.1355 / Val_loss: 2.1210\n",
      "Epoch: 858, Train_loss: 0.1297 / Val_loss: 2.1107\n",
      "Epoch: 859, Train_loss: 0.1397 / Val_loss: 2.1077\n",
      "Epoch: 860, Train_loss: 0.1414 / Val_loss: 2.1090\n",
      "Epoch: 861, Train_loss: 0.1121 / Val_loss: 2.1206\n",
      "Epoch: 862, Train_loss: 0.1114 / Val_loss: 2.1438\n",
      "Epoch: 863, Train_loss: 0.1306 / Val_loss: 2.1675\n",
      "Epoch: 864, Train_loss: 0.1280 / Val_loss: 2.1865\n",
      "Epoch: 865, Train_loss: 0.1222 / Val_loss: 2.2115\n",
      "Epoch: 866, Train_loss: 0.1337 / Val_loss: 2.2407\n",
      "Epoch: 867, Train_loss: 0.1604 / Val_loss: 2.2636\n",
      "Epoch: 868, Train_loss: 0.1438 / Val_loss: 2.2985\n",
      "Epoch: 869, Train_loss: 0.1381 / Val_loss: 2.3218\n",
      "Epoch: 870, Train_loss: 0.1076 / Val_loss: 2.3527\n",
      "Epoch: 871, Train_loss: 0.1186 / Val_loss: 2.3847\n",
      "Epoch: 872, Train_loss: 0.1113 / Val_loss: 2.4142\n",
      "Epoch: 873, Train_loss: 0.1295 / Val_loss: 2.4374\n",
      "Epoch: 874, Train_loss: 0.1855 / Val_loss: 2.4300\n",
      "Epoch: 875, Train_loss: 0.1228 / Val_loss: 2.4222\n",
      "Epoch: 876, Train_loss: 0.1058 / Val_loss: 2.4281\n",
      "Epoch: 877, Train_loss: 0.1198 / Val_loss: 2.4337\n",
      "Epoch: 878, Train_loss: 0.1495 / Val_loss: 2.4424\n",
      "Epoch: 879, Train_loss: 0.1103 / Val_loss: 2.4555\n",
      "Epoch: 880, Train_loss: 0.1717 / Val_loss: 2.4635\n",
      "Epoch: 881, Train_loss: 0.1018 / Val_loss: 2.4788\n",
      "Epoch: 882, Train_loss: 0.1471 / Val_loss: 2.4847\n",
      "Epoch: 883, Train_loss: 0.1273 / Val_loss: 2.4775\n",
      "Epoch: 884, Train_loss: 0.1435 / Val_loss: 2.4682\n",
      "Epoch: 885, Train_loss: 0.1202 / Val_loss: 2.4666\n",
      "Epoch: 886, Train_loss: 0.1267 / Val_loss: 2.4583\n",
      "Epoch: 887, Train_loss: 0.1363 / Val_loss: 2.4498\n",
      "Epoch: 888, Train_loss: 0.1407 / Val_loss: 2.4281\n",
      "Epoch: 889, Train_loss: 0.1524 / Val_loss: 2.3960\n",
      "Epoch: 890, Train_loss: 0.1200 / Val_loss: 2.3735\n",
      "Epoch: 891, Train_loss: 0.1146 / Val_loss: 2.3611\n",
      "Epoch: 892, Train_loss: 0.1536 / Val_loss: 2.3448\n",
      "Epoch: 893, Train_loss: 0.1259 / Val_loss: 2.3377\n",
      "Epoch: 894, Train_loss: 0.1267 / Val_loss: 2.3361\n",
      "Epoch: 895, Train_loss: 0.1316 / Val_loss: 2.3437\n",
      "Epoch: 896, Train_loss: 0.1323 / Val_loss: 2.3501\n",
      "Epoch: 897, Train_loss: 0.1409 / Val_loss: 2.3634\n",
      "Epoch: 898, Train_loss: 0.1211 / Val_loss: 2.3903\n",
      "Epoch: 899, Train_loss: 0.1179 / Val_loss: 2.4231\n",
      "Epoch: 900, Train_loss: 0.1121 / Val_loss: 2.4700\n",
      "Epoch: 901, Train_loss: 0.0949 / Val_loss: 2.5175\n",
      "Epoch: 902, Train_loss: 0.1203 / Val_loss: 2.5537\n",
      "Epoch: 903, Train_loss: 0.1290 / Val_loss: 2.5822\n",
      "Epoch: 904, Train_loss: 0.1447 / Val_loss: 2.5794\n",
      "Epoch: 905, Train_loss: 0.1195 / Val_loss: 2.5635\n",
      "Epoch: 906, Train_loss: 0.1569 / Val_loss: 2.5348\n",
      "Epoch: 907, Train_loss: 0.1025 / Val_loss: 2.5196\n",
      "Epoch: 908, Train_loss: 0.1296 / Val_loss: 2.5033\n",
      "Epoch: 909, Train_loss: 0.1028 / Val_loss: 2.4955\n",
      "Epoch: 910, Train_loss: 0.1325 / Val_loss: 2.4925\n",
      "Epoch: 911, Train_loss: 0.1114 / Val_loss: 2.4950\n",
      "Epoch: 912, Train_loss: 0.1351 / Val_loss: 2.5032\n",
      "Epoch: 913, Train_loss: 0.1123 / Val_loss: 2.5188\n",
      "Epoch: 914, Train_loss: 0.1217 / Val_loss: 2.5361\n",
      "Epoch: 915, Train_loss: 0.1503 / Val_loss: 2.5635\n",
      "Epoch: 916, Train_loss: 0.1402 / Val_loss: 2.5949\n",
      "Epoch: 917, Train_loss: 0.0987 / Val_loss: 2.6270\n",
      "Epoch: 918, Train_loss: 0.1274 / Val_loss: 2.6627\n",
      "Epoch: 919, Train_loss: 0.1411 / Val_loss: 2.6737\n",
      "Epoch: 920, Train_loss: 0.1491 / Val_loss: 2.6577\n",
      "Epoch: 921, Train_loss: 0.1053 / Val_loss: 2.6527\n",
      "Epoch: 922, Train_loss: 0.1649 / Val_loss: 2.6324\n",
      "Epoch: 923, Train_loss: 0.1289 / Val_loss: 2.6283\n",
      "Epoch: 924, Train_loss: 0.1218 / Val_loss: 2.6279\n",
      "Epoch: 925, Train_loss: 0.1055 / Val_loss: 2.6346\n",
      "Epoch: 926, Train_loss: 0.1290 / Val_loss: 2.6490\n",
      "Epoch: 927, Train_loss: 0.1244 / Val_loss: 2.6688\n",
      "Epoch: 928, Train_loss: 0.0972 / Val_loss: 2.6917\n",
      "Epoch: 929, Train_loss: 0.1446 / Val_loss: 2.6802\n",
      "Epoch: 930, Train_loss: 0.1266 / Val_loss: 2.6650\n",
      "Epoch: 931, Train_loss: 0.1041 / Val_loss: 2.6563\n",
      "Epoch: 932, Train_loss: 0.1474 / Val_loss: 2.6379\n",
      "Epoch: 933, Train_loss: 0.1260 / Val_loss: 2.6074\n",
      "Epoch: 934, Train_loss: 0.1517 / Val_loss: 2.5750\n",
      "Epoch: 935, Train_loss: 0.1112 / Val_loss: 2.5570\n",
      "Epoch: 936, Train_loss: 0.1308 / Val_loss: 2.5448\n",
      "Epoch: 937, Train_loss: 0.0881 / Val_loss: 2.5423\n",
      "Epoch: 938, Train_loss: 0.1233 / Val_loss: 2.5426\n",
      "Epoch: 939, Train_loss: 0.0987 / Val_loss: 2.5500\n",
      "Epoch: 940, Train_loss: 0.1240 / Val_loss: 2.5574\n",
      "Epoch: 941, Train_loss: 0.1282 / Val_loss: 2.5654\n",
      "Epoch: 942, Train_loss: 0.1351 / Val_loss: 2.5658\n",
      "Epoch: 943, Train_loss: 0.1155 / Val_loss: 2.5776\n",
      "Epoch: 944, Train_loss: 0.1290 / Val_loss: 2.5987\n",
      "Epoch: 945, Train_loss: 0.0974 / Val_loss: 2.6177\n",
      "Epoch: 946, Train_loss: 0.1184 / Val_loss: 2.6392\n",
      "Epoch: 947, Train_loss: 0.1208 / Val_loss: 2.6638\n",
      "Epoch: 948, Train_loss: 0.1239 / Val_loss: 2.7035\n",
      "Epoch: 949, Train_loss: 0.1253 / Val_loss: 2.7288\n",
      "Epoch: 950, Train_loss: 0.1457 / Val_loss: 2.7456\n",
      "Epoch: 951, Train_loss: 0.1158 / Val_loss: 2.7711\n",
      "Epoch: 952, Train_loss: 0.0988 / Val_loss: 2.7948\n",
      "Epoch: 953, Train_loss: 0.1036 / Val_loss: 2.8170\n",
      "Epoch: 954, Train_loss: 0.1245 / Val_loss: 2.8236\n",
      "Epoch: 955, Train_loss: 0.0880 / Val_loss: 2.8289\n",
      "Epoch: 956, Train_loss: 0.1116 / Val_loss: 2.8196\n",
      "Epoch: 957, Train_loss: 0.1134 / Val_loss: 2.8112\n",
      "Epoch: 958, Train_loss: 0.1078 / Val_loss: 2.7979\n",
      "Epoch: 959, Train_loss: 0.1197 / Val_loss: 2.7942\n",
      "Epoch: 960, Train_loss: 0.1007 / Val_loss: 2.7921\n",
      "Epoch: 961, Train_loss: 0.0801 / Val_loss: 2.7927\n",
      "Epoch: 962, Train_loss: 0.1294 / Val_loss: 2.7987\n",
      "Epoch: 963, Train_loss: 0.1283 / Val_loss: 2.8063\n",
      "Epoch: 964, Train_loss: 0.1219 / Val_loss: 2.8145\n",
      "Epoch: 965, Train_loss: 0.1344 / Val_loss: 2.8118\n",
      "Epoch: 966, Train_loss: 0.1172 / Val_loss: 2.8122\n",
      "Epoch: 967, Train_loss: 0.0850 / Val_loss: 2.8242\n",
      "Epoch: 968, Train_loss: 0.1452 / Val_loss: 2.8242\n",
      "Epoch: 969, Train_loss: 0.0802 / Val_loss: 2.8355\n",
      "Epoch: 970, Train_loss: 0.1528 / Val_loss: 2.8324\n",
      "Epoch: 971, Train_loss: 0.1295 / Val_loss: 2.8351\n",
      "Epoch: 972, Train_loss: 0.1305 / Val_loss: 2.8458\n",
      "Epoch: 973, Train_loss: 0.1274 / Val_loss: 2.8544\n",
      "Epoch: 974, Train_loss: 0.0829 / Val_loss: 2.8737\n",
      "Epoch: 975, Train_loss: 0.1321 / Val_loss: 2.8856\n",
      "Epoch: 976, Train_loss: 0.0983 / Val_loss: 2.9123\n",
      "Epoch: 977, Train_loss: 0.1097 / Val_loss: 2.9394\n",
      "Epoch: 978, Train_loss: 0.0967 / Val_loss: 2.9712\n",
      "Epoch: 979, Train_loss: 0.1194 / Val_loss: 2.9951\n",
      "Epoch: 980, Train_loss: 0.1016 / Val_loss: 3.0047\n",
      "Epoch: 981, Train_loss: 0.1021 / Val_loss: 3.0295\n",
      "Epoch: 982, Train_loss: 0.1103 / Val_loss: 3.0356\n",
      "Epoch: 983, Train_loss: 0.1154 / Val_loss: 3.0352\n",
      "Epoch: 984, Train_loss: 0.1443 / Val_loss: 3.0314\n",
      "Epoch: 985, Train_loss: 0.0818 / Val_loss: 3.0421\n",
      "Epoch: 986, Train_loss: 0.1038 / Val_loss: 3.0676\n",
      "Epoch: 987, Train_loss: 0.0944 / Val_loss: 3.0942\n",
      "Epoch: 988, Train_loss: 0.1105 / Val_loss: 3.1075\n",
      "Epoch: 989, Train_loss: 0.1112 / Val_loss: 3.1020\n",
      "Epoch: 990, Train_loss: 0.1243 / Val_loss: 3.0942\n",
      "Epoch: 991, Train_loss: 0.0791 / Val_loss: 3.0984\n",
      "Epoch: 992, Train_loss: 0.1160 / Val_loss: 3.1136\n",
      "Epoch: 993, Train_loss: 0.1250 / Val_loss: 3.1180\n",
      "Epoch: 994, Train_loss: 0.1410 / Val_loss: 3.1156\n",
      "Epoch: 995, Train_loss: 0.0831 / Val_loss: 3.1146\n",
      "Epoch: 996, Train_loss: 0.1060 / Val_loss: 3.1327\n",
      "Epoch: 997, Train_loss: 0.1047 / Val_loss: 3.1571\n",
      "Epoch: 998, Train_loss: 0.1359 / Val_loss: 3.1616\n",
      "Epoch: 999, Train_loss: 0.1173 / Val_loss: 3.1700\n",
      "Epoch: 1000, Train_loss: 0.0965 / Val_loss: 3.1997\n",
      "Epoch: 1001, Train_loss: 0.1164 / Val_loss: 3.2209\n",
      "Epoch: 1002, Train_loss: 0.1098 / Val_loss: 3.2294\n",
      "Epoch: 1003, Train_loss: 0.1062 / Val_loss: 3.2504\n",
      "Epoch: 1004, Train_loss: 0.1150 / Val_loss: 3.2588\n",
      "Epoch: 1005, Train_loss: 0.0844 / Val_loss: 3.2644\n",
      "Epoch: 1006, Train_loss: 0.0952 / Val_loss: 3.2698\n",
      "Epoch: 1007, Train_loss: 0.1213 / Val_loss: 3.2646\n",
      "Epoch: 1008, Train_loss: 0.0953 / Val_loss: 3.2316\n",
      "Epoch: 1009, Train_loss: 0.1200 / Val_loss: 3.2082\n",
      "Epoch: 1010, Train_loss: 0.0961 / Val_loss: 3.1964\n",
      "Epoch: 1011, Train_loss: 0.1085 / Val_loss: 3.1749\n",
      "Epoch: 1012, Train_loss: 0.1017 / Val_loss: 3.1605\n",
      "Epoch: 1013, Train_loss: 0.1199 / Val_loss: 3.1544\n",
      "Epoch: 1014, Train_loss: 0.0960 / Val_loss: 3.1509\n",
      "Epoch: 1015, Train_loss: 0.0815 / Val_loss: 3.1638\n",
      "Epoch: 1016, Train_loss: 0.0980 / Val_loss: 3.1875\n",
      "Epoch: 1017, Train_loss: 0.0907 / Val_loss: 3.2098\n",
      "Epoch: 1018, Train_loss: 0.1101 / Val_loss: 3.2244\n",
      "Epoch: 1019, Train_loss: 0.0809 / Val_loss: 3.2499\n",
      "Epoch: 1020, Train_loss: 0.0959 / Val_loss: 3.2706\n",
      "Epoch: 1021, Train_loss: 0.1158 / Val_loss: 3.2885\n",
      "Epoch: 1022, Train_loss: 0.0782 / Val_loss: 3.3148\n",
      "Epoch: 1023, Train_loss: 0.0745 / Val_loss: 3.3485\n",
      "Epoch: 1024, Train_loss: 0.1302 / Val_loss: 3.3554\n",
      "Epoch: 1025, Train_loss: 0.1002 / Val_loss: 3.3683\n",
      "Epoch: 1026, Train_loss: 0.1481 / Val_loss: 3.3798\n",
      "Epoch: 1027, Train_loss: 0.0932 / Val_loss: 3.4067\n",
      "Epoch: 1028, Train_loss: 0.0897 / Val_loss: 3.4304\n",
      "Epoch: 1029, Train_loss: 0.0954 / Val_loss: 3.4516\n",
      "Epoch: 1030, Train_loss: 0.1422 / Val_loss: 3.4486\n",
      "Epoch: 1031, Train_loss: 0.0978 / Val_loss: 3.4400\n",
      "Epoch: 1032, Train_loss: 0.1048 / Val_loss: 3.4458\n",
      "Epoch: 1033, Train_loss: 0.1125 / Val_loss: 3.4523\n",
      "Epoch: 1034, Train_loss: 0.0816 / Val_loss: 3.4709\n",
      "Epoch: 1035, Train_loss: 0.1010 / Val_loss: 3.4781\n",
      "Epoch: 1036, Train_loss: 0.1629 / Val_loss: 3.4548\n",
      "Epoch: 1037, Train_loss: 0.0869 / Val_loss: 3.4309\n",
      "Epoch: 1038, Train_loss: 0.0912 / Val_loss: 3.3939\n",
      "Epoch: 1039, Train_loss: 0.1302 / Val_loss: 3.3623\n",
      "Epoch: 1040, Train_loss: 0.1356 / Val_loss: 3.3362\n",
      "Epoch: 1041, Train_loss: 0.1061 / Val_loss: 3.3271\n",
      "Epoch: 1042, Train_loss: 0.1383 / Val_loss: 3.3175\n",
      "Epoch: 1043, Train_loss: 0.1220 / Val_loss: 3.3029\n",
      "Epoch: 1044, Train_loss: 0.1122 / Val_loss: 3.2931\n",
      "Epoch: 1045, Train_loss: 0.0782 / Val_loss: 3.2910\n",
      "Epoch: 1046, Train_loss: 0.0910 / Val_loss: 3.3085\n",
      "Epoch: 1047, Train_loss: 0.1109 / Val_loss: 3.3327\n",
      "Epoch: 1048, Train_loss: 0.1035 / Val_loss: 3.3666\n",
      "Epoch: 1049, Train_loss: 0.1274 / Val_loss: 3.3893\n",
      "Epoch: 1050, Train_loss: 0.1061 / Val_loss: 3.4056\n",
      "Epoch: 1051, Train_loss: 0.1036 / Val_loss: 3.4166\n",
      "Epoch: 1052, Train_loss: 0.0801 / Val_loss: 3.4350\n",
      "Epoch: 1053, Train_loss: 0.0849 / Val_loss: 3.4540\n",
      "Epoch: 1054, Train_loss: 0.1218 / Val_loss: 3.4700\n",
      "Epoch: 1055, Train_loss: 0.0950 / Val_loss: 3.4949\n",
      "Epoch: 1056, Train_loss: 0.0939 / Val_loss: 3.5201\n",
      "Epoch: 1057, Train_loss: 0.1158 / Val_loss: 3.5251\n",
      "Epoch: 1058, Train_loss: 0.1202 / Val_loss: 3.5430\n",
      "Epoch: 1059, Train_loss: 0.1179 / Val_loss: 3.5465\n",
      "Epoch: 1060, Train_loss: 0.0708 / Val_loss: 3.5562\n",
      "Epoch: 1061, Train_loss: 0.0878 / Val_loss: 3.5539\n",
      "Epoch: 1062, Train_loss: 0.0980 / Val_loss: 3.5413\n",
      "Epoch: 1063, Train_loss: 0.1034 / Val_loss: 3.5469\n",
      "Epoch: 1064, Train_loss: 0.0840 / Val_loss: 3.5492\n",
      "Epoch: 1065, Train_loss: 0.1200 / Val_loss: 3.5452\n",
      "Epoch: 1066, Train_loss: 0.1148 / Val_loss: 3.5393\n",
      "Epoch: 1067, Train_loss: 0.0988 / Val_loss: 3.5222\n",
      "Epoch: 1068, Train_loss: 0.0878 / Val_loss: 3.5163\n",
      "Epoch: 1069, Train_loss: 0.1106 / Val_loss: 3.5037\n",
      "Epoch: 1070, Train_loss: 0.1345 / Val_loss: 3.4609\n",
      "Epoch: 1071, Train_loss: 0.0896 / Val_loss: 3.4360\n",
      "Epoch: 1072, Train_loss: 0.0888 / Val_loss: 3.4269\n",
      "Epoch: 1073, Train_loss: 0.0732 / Val_loss: 3.4255\n",
      "Epoch: 1074, Train_loss: 0.0923 / Val_loss: 3.4285\n",
      "Epoch: 1075, Train_loss: 0.1130 / Val_loss: 3.4192\n",
      "Epoch: 1076, Train_loss: 0.1291 / Val_loss: 3.3798\n",
      "Epoch: 1077, Train_loss: 0.0988 / Val_loss: 3.3622\n",
      "Epoch: 1078, Train_loss: 0.0965 / Val_loss: 3.3495\n",
      "Epoch: 1079, Train_loss: 0.1142 / Val_loss: 3.3510\n",
      "Epoch: 1080, Train_loss: 0.1193 / Val_loss: 3.3567\n",
      "Epoch: 1081, Train_loss: 0.1215 / Val_loss: 3.3406\n",
      "Epoch: 1082, Train_loss: 0.0943 / Val_loss: 3.3165\n",
      "Epoch: 1083, Train_loss: 0.1119 / Val_loss: 3.2977\n",
      "Epoch: 1084, Train_loss: 0.0767 / Val_loss: 3.2892\n",
      "Epoch: 1085, Train_loss: 0.0931 / Val_loss: 3.2958\n",
      "Epoch: 1086, Train_loss: 0.1086 / Val_loss: 3.2987\n",
      "Epoch: 1087, Train_loss: 0.0953 / Val_loss: 3.3100\n",
      "Epoch: 1088, Train_loss: 0.1094 / Val_loss: 3.3101\n",
      "Epoch: 1089, Train_loss: 0.1209 / Val_loss: 3.3337\n",
      "Epoch: 1090, Train_loss: 0.1052 / Val_loss: 3.3534\n",
      "Epoch: 1091, Train_loss: 0.1071 / Val_loss: 3.3803\n",
      "Epoch: 1092, Train_loss: 0.0821 / Val_loss: 3.4147\n",
      "Epoch: 1093, Train_loss: 0.0793 / Val_loss: 3.4518\n",
      "Epoch: 1094, Train_loss: 0.0963 / Val_loss: 3.4721\n",
      "Epoch: 1095, Train_loss: 0.0983 / Val_loss: 3.4875\n",
      "Epoch: 1096, Train_loss: 0.1008 / Val_loss: 3.4997\n",
      "Epoch: 1097, Train_loss: 0.0888 / Val_loss: 3.5110\n",
      "Epoch: 1098, Train_loss: 0.0911 / Val_loss: 3.5210\n",
      "Epoch: 1099, Train_loss: 0.1214 / Val_loss: 3.5195\n",
      "Epoch: 1100, Train_loss: 0.1033 / Val_loss: 3.5186\n",
      "Epoch: 1101, Train_loss: 0.1060 / Val_loss: 3.5243\n",
      "Epoch: 1102, Train_loss: 0.0890 / Val_loss: 3.5501\n",
      "Epoch: 1103, Train_loss: 0.1011 / Val_loss: 3.5744\n",
      "Epoch: 1104, Train_loss: 0.0963 / Val_loss: 3.5928\n",
      "Epoch: 1105, Train_loss: 0.0925 / Val_loss: 3.6020\n",
      "Epoch: 1106, Train_loss: 0.0707 / Val_loss: 3.6295\n",
      "Epoch: 1107, Train_loss: 0.0856 / Val_loss: 3.6647\n",
      "Epoch: 1108, Train_loss: 0.0812 / Val_loss: 3.7038\n",
      "Epoch: 1109, Train_loss: 0.0977 / Val_loss: 3.7447\n",
      "Epoch: 1110, Train_loss: 0.0942 / Val_loss: 3.7753\n",
      "Epoch: 1111, Train_loss: 0.1133 / Val_loss: 3.7854\n",
      "Epoch: 1112, Train_loss: 0.1055 / Val_loss: 3.7970\n",
      "Epoch: 1113, Train_loss: 0.0909 / Val_loss: 3.8190\n",
      "Epoch: 1114, Train_loss: 0.0951 / Val_loss: 3.8425\n",
      "Epoch: 1115, Train_loss: 0.1261 / Val_loss: 3.8222\n",
      "Epoch: 1116, Train_loss: 0.1005 / Val_loss: 3.8197\n",
      "Epoch: 1117, Train_loss: 0.0767 / Val_loss: 3.8287\n",
      "Epoch: 1118, Train_loss: 0.0913 / Val_loss: 3.8485\n",
      "Epoch: 1119, Train_loss: 0.0906 / Val_loss: 3.8569\n",
      "Epoch: 1120, Train_loss: 0.0860 / Val_loss: 3.8849\n",
      "Epoch: 1121, Train_loss: 0.0920 / Val_loss: 3.9283\n",
      "Epoch: 1122, Train_loss: 0.0862 / Val_loss: 3.9671\n",
      "Epoch: 1123, Train_loss: 0.0972 / Val_loss: 4.0078\n",
      "Epoch: 1124, Train_loss: 0.1019 / Val_loss: 4.0332\n",
      "Epoch: 1125, Train_loss: 0.0928 / Val_loss: 4.0320\n",
      "Epoch: 1126, Train_loss: 0.1247 / Val_loss: 3.9931\n",
      "Epoch: 1127, Train_loss: 0.0856 / Val_loss: 3.9532\n",
      "Epoch: 1128, Train_loss: 0.0759 / Val_loss: 3.9314\n",
      "Epoch: 1129, Train_loss: 0.0759 / Val_loss: 3.9182\n",
      "Epoch: 1130, Train_loss: 0.1127 / Val_loss: 3.8996\n",
      "Epoch: 1131, Train_loss: 0.0798 / Val_loss: 3.8942\n",
      "Epoch: 1132, Train_loss: 0.1164 / Val_loss: 3.8936\n",
      "Epoch: 1133, Train_loss: 0.0782 / Val_loss: 3.9135\n",
      "Epoch: 1134, Train_loss: 0.1077 / Val_loss: 3.9198\n",
      "Epoch: 1135, Train_loss: 0.1063 / Val_loss: 3.9219\n",
      "Epoch: 1136, Train_loss: 0.1017 / Val_loss: 3.9225\n",
      "Epoch: 1137, Train_loss: 0.0884 / Val_loss: 3.9138\n",
      "Epoch: 1138, Train_loss: 0.0961 / Val_loss: 3.9118\n",
      "Epoch: 1139, Train_loss: 0.0710 / Val_loss: 3.9106\n",
      "Epoch: 1140, Train_loss: 0.0988 / Val_loss: 3.9109\n",
      "Epoch: 1141, Train_loss: 0.1122 / Val_loss: 3.9001\n",
      "Epoch: 1142, Train_loss: 0.0933 / Val_loss: 3.8795\n",
      "Epoch: 1143, Train_loss: 0.0665 / Val_loss: 3.8616\n",
      "Epoch: 1144, Train_loss: 0.0653 / Val_loss: 3.8557\n",
      "Epoch: 1145, Train_loss: 0.1176 / Val_loss: 3.8239\n",
      "Epoch: 1146, Train_loss: 0.0778 / Val_loss: 3.8147\n",
      "Epoch: 1147, Train_loss: 0.1125 / Val_loss: 3.8146\n",
      "Epoch: 1148, Train_loss: 0.0937 / Val_loss: 3.8206\n",
      "Epoch: 1149, Train_loss: 0.1228 / Val_loss: 3.8262\n",
      "Epoch: 1150, Train_loss: 0.0835 / Val_loss: 3.8544\n",
      "Epoch: 1151, Train_loss: 0.0839 / Val_loss: 3.8921\n",
      "Epoch: 1152, Train_loss: 0.1404 / Val_loss: 3.8816\n",
      "Epoch: 1153, Train_loss: 0.0833 / Val_loss: 3.8839\n",
      "Epoch: 1154, Train_loss: 0.0773 / Val_loss: 3.8931\n",
      "Epoch: 1155, Train_loss: 0.0703 / Val_loss: 3.9054\n",
      "Epoch: 1156, Train_loss: 0.1550 / Val_loss: 3.8805\n",
      "Epoch: 1157, Train_loss: 0.0514 / Val_loss: 3.8654\n",
      "Epoch: 1158, Train_loss: 0.0985 / Val_loss: 3.8642\n",
      "Epoch: 1159, Train_loss: 0.0753 / Val_loss: 3.8704\n",
      "Epoch: 1160, Train_loss: 0.0821 / Val_loss: 3.8725\n",
      "Epoch: 1161, Train_loss: 0.0700 / Val_loss: 3.8732\n",
      "Epoch: 1162, Train_loss: 0.0888 / Val_loss: 3.8699\n",
      "Epoch: 1163, Train_loss: 0.0986 / Val_loss: 3.8667\n",
      "Epoch: 1164, Train_loss: 0.0865 / Val_loss: 3.8836\n",
      "Epoch: 1165, Train_loss: 0.1024 / Val_loss: 3.9038\n",
      "Epoch: 1166, Train_loss: 0.0849 / Val_loss: 3.9131\n",
      "Epoch: 1167, Train_loss: 0.0913 / Val_loss: 3.9199\n",
      "Epoch: 1168, Train_loss: 0.0866 / Val_loss: 3.9243\n",
      "Epoch: 1169, Train_loss: 0.0845 / Val_loss: 3.9055\n",
      "Epoch: 1170, Train_loss: 0.0637 / Val_loss: 3.8952\n",
      "Epoch: 1171, Train_loss: 0.1094 / Val_loss: 3.8779\n",
      "Epoch: 1172, Train_loss: 0.0542 / Val_loss: 3.8795\n",
      "Epoch: 1173, Train_loss: 0.0705 / Val_loss: 3.8855\n",
      "Epoch: 1174, Train_loss: 0.0648 / Val_loss: 3.9069\n",
      "Epoch: 1175, Train_loss: 0.0903 / Val_loss: 3.8949\n",
      "Epoch: 1176, Train_loss: 0.1073 / Val_loss: 3.8779\n",
      "Epoch: 1177, Train_loss: 0.0949 / Val_loss: 3.8695\n",
      "Epoch: 1178, Train_loss: 0.0700 / Val_loss: 3.8590\n",
      "Epoch: 1179, Train_loss: 0.1181 / Val_loss: 3.8518\n",
      "Epoch: 1180, Train_loss: 0.0703 / Val_loss: 3.8572\n",
      "Epoch: 1181, Train_loss: 0.0637 / Val_loss: 3.8663\n",
      "Epoch: 1182, Train_loss: 0.0871 / Val_loss: 3.8725\n",
      "Epoch: 1183, Train_loss: 0.0622 / Val_loss: 3.8687\n",
      "Epoch: 1184, Train_loss: 0.1121 / Val_loss: 3.8722\n",
      "Epoch: 1185, Train_loss: 0.0826 / Val_loss: 3.8823\n",
      "Epoch: 1186, Train_loss: 0.0749 / Val_loss: 3.9006\n",
      "Epoch: 1187, Train_loss: 0.1138 / Val_loss: 3.9163\n",
      "Epoch: 1188, Train_loss: 0.0770 / Val_loss: 3.9353\n",
      "Epoch: 1189, Train_loss: 0.0687 / Val_loss: 3.9752\n",
      "Epoch: 1190, Train_loss: 0.0932 / Val_loss: 4.0356\n",
      "Epoch: 1191, Train_loss: 0.1022 / Val_loss: 4.0765\n",
      "Epoch: 1192, Train_loss: 0.0786 / Val_loss: 4.0992\n",
      "Epoch: 1193, Train_loss: 0.0857 / Val_loss: 4.1222\n",
      "Epoch: 1194, Train_loss: 0.0981 / Val_loss: 4.1384\n",
      "Epoch: 1195, Train_loss: 0.0715 / Val_loss: 4.1591\n",
      "Epoch: 1196, Train_loss: 0.0980 / Val_loss: 4.1821\n",
      "Epoch: 1197, Train_loss: 0.0894 / Val_loss: 4.2081\n",
      "Epoch: 1198, Train_loss: 0.0814 / Val_loss: 4.2499\n",
      "Epoch: 1199, Train_loss: 0.1084 / Val_loss: 4.2673\n",
      "Epoch: 1200, Train_loss: 0.0812 / Val_loss: 4.2924\n",
      "Epoch: 1201, Train_loss: 0.0968 / Val_loss: 4.3063\n",
      "Epoch: 1202, Train_loss: 0.0799 / Val_loss: 4.3206\n",
      "Epoch: 1203, Train_loss: 0.0510 / Val_loss: 4.3441\n",
      "Epoch: 1204, Train_loss: 0.0937 / Val_loss: 4.3531\n",
      "Epoch: 1205, Train_loss: 0.0638 / Val_loss: 4.3622\n",
      "Epoch: 1206, Train_loss: 0.1058 / Val_loss: 4.3458\n",
      "Epoch: 1207, Train_loss: 0.0718 / Val_loss: 4.3263\n",
      "Epoch: 1208, Train_loss: 0.1136 / Val_loss: 4.2637\n",
      "Epoch: 1209, Train_loss: 0.1409 / Val_loss: 4.2078\n",
      "Epoch: 1210, Train_loss: 0.0585 / Val_loss: 4.1666\n",
      "Epoch: 1211, Train_loss: 0.0614 / Val_loss: 4.1288\n",
      "Epoch: 1212, Train_loss: 0.0733 / Val_loss: 4.0983\n",
      "Epoch: 1213, Train_loss: 0.1030 / Val_loss: 4.0655\n",
      "Epoch: 1214, Train_loss: 0.0740 / Val_loss: 4.0199\n",
      "Epoch: 1215, Train_loss: 0.0892 / Val_loss: 3.9845\n",
      "Epoch: 1216, Train_loss: 0.1193 / Val_loss: 3.9284\n",
      "Epoch: 1217, Train_loss: 0.0569 / Val_loss: 3.8991\n",
      "Epoch: 1218, Train_loss: 0.0683 / Val_loss: 3.8887\n",
      "Epoch: 1219, Train_loss: 0.0635 / Val_loss: 3.8959\n",
      "Epoch: 1220, Train_loss: 0.0911 / Val_loss: 3.9105\n",
      "Epoch: 1221, Train_loss: 0.0987 / Val_loss: 3.8936\n",
      "Epoch: 1222, Train_loss: 0.0747 / Val_loss: 3.8832\n",
      "Epoch: 1223, Train_loss: 0.0755 / Val_loss: 3.8801\n",
      "Epoch: 1224, Train_loss: 0.0838 / Val_loss: 3.8787\n",
      "Epoch: 1225, Train_loss: 0.0884 / Val_loss: 3.8749\n",
      "Epoch: 1226, Train_loss: 0.0856 / Val_loss: 3.8686\n",
      "Epoch: 1227, Train_loss: 0.0667 / Val_loss: 3.8681\n",
      "Epoch: 1228, Train_loss: 0.0774 / Val_loss: 3.8741\n",
      "Epoch: 1229, Train_loss: 0.0859 / Val_loss: 3.8795\n",
      "Epoch: 1230, Train_loss: 0.0973 / Val_loss: 3.8779\n",
      "Epoch: 1231, Train_loss: 0.0939 / Val_loss: 3.8822\n",
      "Epoch: 1232, Train_loss: 0.0831 / Val_loss: 3.8715\n",
      "Epoch: 1233, Train_loss: 0.0815 / Val_loss: 3.8752\n",
      "Epoch: 1234, Train_loss: 0.0770 / Val_loss: 3.8887\n",
      "Epoch: 1235, Train_loss: 0.1054 / Val_loss: 3.8935\n",
      "Epoch: 1236, Train_loss: 0.0959 / Val_loss: 3.9016\n",
      "Epoch: 1237, Train_loss: 0.0941 / Val_loss: 3.9133\n",
      "Epoch: 1238, Train_loss: 0.0846 / Val_loss: 3.9269\n",
      "Epoch: 1239, Train_loss: 0.0548 / Val_loss: 3.9461\n",
      "Epoch: 1240, Train_loss: 0.0730 / Val_loss: 3.9641\n",
      "Epoch: 1241, Train_loss: 0.0627 / Val_loss: 3.9998\n",
      "Epoch: 1242, Train_loss: 0.1064 / Val_loss: 4.0237\n",
      "Epoch: 1243, Train_loss: 0.0732 / Val_loss: 4.0425\n",
      "Epoch: 1244, Train_loss: 0.0859 / Val_loss: 4.0564\n",
      "Epoch: 1245, Train_loss: 0.0632 / Val_loss: 4.0882\n",
      "Epoch: 1246, Train_loss: 0.1079 / Val_loss: 4.0778\n",
      "Epoch: 1247, Train_loss: 0.0770 / Val_loss: 4.0662\n",
      "Epoch: 1248, Train_loss: 0.0645 / Val_loss: 4.0558\n",
      "Epoch: 1249, Train_loss: 0.0720 / Val_loss: 4.0274\n",
      "Epoch: 1250, Train_loss: 0.0691 / Val_loss: 4.0014\n",
      "Epoch: 1251, Train_loss: 0.1012 / Val_loss: 3.9664\n",
      "Epoch: 1252, Train_loss: 0.0623 / Val_loss: 3.9570\n",
      "Epoch: 1253, Train_loss: 0.0953 / Val_loss: 3.9551\n",
      "Epoch: 1254, Train_loss: 0.0746 / Val_loss: 3.9695\n",
      "Epoch: 1255, Train_loss: 0.0954 / Val_loss: 3.9790\n",
      "Epoch: 1256, Train_loss: 0.0678 / Val_loss: 4.0047\n",
      "Epoch: 1257, Train_loss: 0.0744 / Val_loss: 4.0491\n",
      "Epoch: 1258, Train_loss: 0.0767 / Val_loss: 4.0858\n",
      "Epoch: 1259, Train_loss: 0.0676 / Val_loss: 4.1263\n",
      "Epoch: 1260, Train_loss: 0.0773 / Val_loss: 4.1792\n",
      "Epoch: 1261, Train_loss: 0.1062 / Val_loss: 4.2051\n",
      "Epoch: 1262, Train_loss: 0.0625 / Val_loss: 4.2458\n",
      "Epoch: 1263, Train_loss: 0.0707 / Val_loss: 4.2905\n",
      "Epoch: 1264, Train_loss: 0.0917 / Val_loss: 4.3288\n",
      "Epoch: 1265, Train_loss: 0.0687 / Val_loss: 4.3614\n",
      "Epoch: 1266, Train_loss: 0.0817 / Val_loss: 4.3896\n",
      "Epoch: 1267, Train_loss: 0.0796 / Val_loss: 4.4067\n",
      "Epoch: 1268, Train_loss: 0.0735 / Val_loss: 4.4283\n",
      "Epoch: 1269, Train_loss: 0.0987 / Val_loss: 4.4564\n",
      "Epoch: 1270, Train_loss: 0.1124 / Val_loss: 4.4534\n",
      "Epoch: 1271, Train_loss: 0.0582 / Val_loss: 4.4465\n",
      "Epoch: 1272, Train_loss: 0.0710 / Val_loss: 4.4443\n",
      "Epoch: 1273, Train_loss: 0.0741 / Val_loss: 4.4374\n",
      "Epoch: 1274, Train_loss: 0.0742 / Val_loss: 4.4451\n",
      "Epoch: 1275, Train_loss: 0.1292 / Val_loss: 4.4100\n",
      "Epoch: 1276, Train_loss: 0.0731 / Val_loss: 4.3898\n",
      "Epoch: 1277, Train_loss: 0.0710 / Val_loss: 4.3959\n",
      "Epoch: 1278, Train_loss: 0.0991 / Val_loss: 4.4095\n",
      "Epoch: 1279, Train_loss: 0.0927 / Val_loss: 4.4402\n",
      "Epoch: 1280, Train_loss: 0.0838 / Val_loss: 4.4852\n",
      "Epoch: 1281, Train_loss: 0.0760 / Val_loss: 4.5291\n",
      "Epoch: 1282, Train_loss: 0.0584 / Val_loss: 4.5657\n",
      "Epoch: 1283, Train_loss: 0.0571 / Val_loss: 4.6008\n",
      "Epoch: 1284, Train_loss: 0.0690 / Val_loss: 4.6395\n",
      "Epoch: 1285, Train_loss: 0.0799 / Val_loss: 4.6835\n",
      "Epoch: 1286, Train_loss: 0.0639 / Val_loss: 4.7466\n",
      "Epoch: 1287, Train_loss: 0.1035 / Val_loss: 4.7629\n",
      "Epoch: 1288, Train_loss: 0.1039 / Val_loss: 4.7682\n",
      "Epoch: 1289, Train_loss: 0.0630 / Val_loss: 4.7523\n",
      "Epoch: 1290, Train_loss: 0.0492 / Val_loss: 4.7431\n",
      "Epoch: 1291, Train_loss: 0.0626 / Val_loss: 4.7367\n",
      "Epoch: 1292, Train_loss: 0.1196 / Val_loss: 4.7086\n",
      "Epoch: 1293, Train_loss: 0.0802 / Val_loss: 4.6356\n",
      "Epoch: 1294, Train_loss: 0.0640 / Val_loss: 4.5690\n",
      "Epoch: 1295, Train_loss: 0.0754 / Val_loss: 4.5275\n",
      "Epoch: 1296, Train_loss: 0.0991 / Val_loss: 4.4839\n",
      "Epoch: 1297, Train_loss: 0.0499 / Val_loss: 4.4523\n",
      "Epoch: 1298, Train_loss: 0.0641 / Val_loss: 4.4376\n",
      "Epoch: 1299, Train_loss: 0.0550 / Val_loss: 4.4347\n",
      "Epoch: 1300, Train_loss: 0.0525 / Val_loss: 4.4451\n",
      "Epoch: 1301, Train_loss: 0.0524 / Val_loss: 4.4757\n",
      "Epoch: 1302, Train_loss: 0.0762 / Val_loss: 4.4897\n",
      "Epoch: 1303, Train_loss: 0.1058 / Val_loss: 4.4866\n",
      "Epoch: 1304, Train_loss: 0.0618 / Val_loss: 4.5020\n",
      "Epoch: 1305, Train_loss: 0.0785 / Val_loss: 4.5147\n",
      "Epoch: 1306, Train_loss: 0.0668 / Val_loss: 4.5397\n",
      "Epoch: 1307, Train_loss: 0.0683 / Val_loss: 4.5723\n",
      "Epoch: 1308, Train_loss: 0.0939 / Val_loss: 4.6025\n",
      "Epoch: 1309, Train_loss: 0.0882 / Val_loss: 4.6128\n",
      "Epoch: 1310, Train_loss: 0.0623 / Val_loss: 4.6271\n",
      "Epoch: 1311, Train_loss: 0.0921 / Val_loss: 4.6341\n",
      "Epoch: 1312, Train_loss: 0.0385 / Val_loss: 4.6543\n",
      "Epoch: 1313, Train_loss: 0.0774 / Val_loss: 4.6843\n",
      "Epoch: 1314, Train_loss: 0.0749 / Val_loss: 4.7125\n",
      "Epoch: 1315, Train_loss: 0.0476 / Val_loss: 4.7459\n",
      "Epoch: 1316, Train_loss: 0.0804 / Val_loss: 4.7702\n",
      "Epoch: 1317, Train_loss: 0.0710 / Val_loss: 4.7868\n",
      "Epoch: 1318, Train_loss: 0.0441 / Val_loss: 4.8076\n",
      "Epoch: 1319, Train_loss: 0.0711 / Val_loss: 4.8442\n",
      "Epoch: 1320, Train_loss: 0.0699 / Val_loss: 4.8675\n",
      "Epoch: 1321, Train_loss: 0.0531 / Val_loss: 4.8992\n",
      "Epoch: 1322, Train_loss: 0.0938 / Val_loss: 4.9275\n",
      "Epoch: 1323, Train_loss: 0.0662 / Val_loss: 4.9338\n",
      "Epoch: 1324, Train_loss: 0.0845 / Val_loss: 4.9136\n",
      "Epoch: 1325, Train_loss: 0.0562 / Val_loss: 4.8835\n",
      "Epoch: 1326, Train_loss: 0.0535 / Val_loss: 4.8597\n",
      "Epoch: 1327, Train_loss: 0.0701 / Val_loss: 4.8441\n",
      "Epoch: 1328, Train_loss: 0.0821 / Val_loss: 4.8060\n",
      "Epoch: 1329, Train_loss: 0.1037 / Val_loss: 4.7558\n",
      "Epoch: 1330, Train_loss: 0.0731 / Val_loss: 4.6886\n",
      "Epoch: 1331, Train_loss: 0.0787 / Val_loss: 4.6234\n",
      "Epoch: 1332, Train_loss: 0.0749 / Val_loss: 4.5833\n",
      "Epoch: 1333, Train_loss: 0.0799 / Val_loss: 4.5413\n",
      "Epoch: 1334, Train_loss: 0.0747 / Val_loss: 4.5178\n",
      "Epoch: 1335, Train_loss: 0.0937 / Val_loss: 4.4962\n",
      "Epoch: 1336, Train_loss: 0.0806 / Val_loss: 4.4658\n",
      "Epoch: 1337, Train_loss: 0.0821 / Val_loss: 4.4472\n",
      "Epoch: 1338, Train_loss: 0.0562 / Val_loss: 4.4446\n",
      "Epoch: 1339, Train_loss: 0.0910 / Val_loss: 4.4406\n",
      "Epoch: 1340, Train_loss: 0.1050 / Val_loss: 4.4601\n",
      "Epoch: 1341, Train_loss: 0.0787 / Val_loss: 4.4724\n",
      "Epoch: 1342, Train_loss: 0.1003 / Val_loss: 4.4660\n",
      "Epoch: 1343, Train_loss: 0.0741 / Val_loss: 4.4678\n",
      "Epoch: 1344, Train_loss: 0.0649 / Val_loss: 4.4916\n",
      "Epoch: 1345, Train_loss: 0.0804 / Val_loss: 4.4959\n",
      "Epoch: 1346, Train_loss: 0.0834 / Val_loss: 4.4812\n",
      "Epoch: 1347, Train_loss: 0.0644 / Val_loss: 4.4692\n",
      "Epoch: 1348, Train_loss: 0.0538 / Val_loss: 4.4624\n",
      "Epoch: 1349, Train_loss: 0.0804 / Val_loss: 4.4645\n",
      "Epoch: 1350, Train_loss: 0.0612 / Val_loss: 4.4788\n",
      "Epoch: 1351, Train_loss: 0.0642 / Val_loss: 4.5102\n",
      "Epoch: 1352, Train_loss: 0.0716 / Val_loss: 4.5470\n",
      "Epoch: 1353, Train_loss: 0.0525 / Val_loss: 4.5856\n",
      "Epoch: 1354, Train_loss: 0.0982 / Val_loss: 4.6090\n",
      "Epoch: 1355, Train_loss: 0.0815 / Val_loss: 4.6287\n",
      "Epoch: 1356, Train_loss: 0.0631 / Val_loss: 4.6578\n",
      "Epoch: 1357, Train_loss: 0.1072 / Val_loss: 4.6731\n",
      "Epoch: 1358, Train_loss: 0.0887 / Val_loss: 4.6746\n",
      "Epoch: 1359, Train_loss: 0.0706 / Val_loss: 4.6912\n",
      "Epoch: 1360, Train_loss: 0.0653 / Val_loss: 4.7126\n",
      "Epoch: 1361, Train_loss: 0.0884 / Val_loss: 4.7583\n",
      "Epoch: 1362, Train_loss: 0.0549 / Val_loss: 4.8037\n",
      "Epoch: 1363, Train_loss: 0.0839 / Val_loss: 4.8529\n",
      "Epoch: 1364, Train_loss: 0.0817 / Val_loss: 4.9203\n",
      "Epoch: 1365, Train_loss: 0.0753 / Val_loss: 4.9659\n",
      "Epoch: 1366, Train_loss: 0.0942 / Val_loss: 5.0293\n",
      "Epoch: 1367, Train_loss: 0.0407 / Val_loss: 5.1028\n",
      "Epoch: 1368, Train_loss: 0.0700 / Val_loss: 5.1389\n",
      "Epoch: 1369, Train_loss: 0.0782 / Val_loss: 5.1783\n",
      "Epoch: 1370, Train_loss: 0.0509 / Val_loss: 5.2140\n",
      "Epoch: 1371, Train_loss: 0.0554 / Val_loss: 5.2568\n",
      "Epoch: 1372, Train_loss: 0.0727 / Val_loss: 5.2681\n",
      "Epoch: 1373, Train_loss: 0.0716 / Val_loss: 5.2896\n",
      "Epoch: 1374, Train_loss: 0.0712 / Val_loss: 5.2801\n",
      "Epoch: 1375, Train_loss: 0.0662 / Val_loss: 5.2657\n",
      "Epoch: 1376, Train_loss: 0.0520 / Val_loss: 5.2499\n",
      "Epoch: 1377, Train_loss: 0.0714 / Val_loss: 5.2360\n",
      "Epoch: 1378, Train_loss: 0.0816 / Val_loss: 5.2290\n",
      "Epoch: 1379, Train_loss: 0.0451 / Val_loss: 5.2420\n",
      "Epoch: 1380, Train_loss: 0.0673 / Val_loss: 5.2552\n",
      "Epoch: 1381, Train_loss: 0.0597 / Val_loss: 5.2720\n",
      "Epoch: 1382, Train_loss: 0.0999 / Val_loss: 5.2821\n",
      "Epoch: 1383, Train_loss: 0.0537 / Val_loss: 5.2976\n",
      "Epoch: 1384, Train_loss: 0.0719 / Val_loss: 5.2935\n",
      "Epoch: 1385, Train_loss: 0.0635 / Val_loss: 5.3217\n",
      "Epoch: 1386, Train_loss: 0.0596 / Val_loss: 5.3478\n",
      "Epoch: 1387, Train_loss: 0.0550 / Val_loss: 5.3889\n",
      "Epoch: 1388, Train_loss: 0.0456 / Val_loss: 5.4332\n",
      "Epoch: 1389, Train_loss: 0.0309 / Val_loss: 5.4825\n",
      "Epoch: 1390, Train_loss: 0.0395 / Val_loss: 5.5400\n",
      "Epoch: 1391, Train_loss: 0.0622 / Val_loss: 5.6019\n",
      "Epoch: 1392, Train_loss: 0.0664 / Val_loss: 5.6625\n",
      "Epoch: 1393, Train_loss: 0.0580 / Val_loss: 5.7229\n",
      "Epoch: 1394, Train_loss: 0.0621 / Val_loss: 5.7586\n",
      "Epoch: 1395, Train_loss: 0.1084 / Val_loss: 5.7289\n",
      "Epoch: 1396, Train_loss: 0.0595 / Val_loss: 5.6946\n",
      "Epoch: 1397, Train_loss: 0.0689 / Val_loss: 5.6777\n",
      "Epoch: 1398, Train_loss: 0.0464 / Val_loss: 5.6698\n",
      "Epoch: 1399, Train_loss: 0.0792 / Val_loss: 5.6651\n",
      "Epoch: 1400, Train_loss: 0.1038 / Val_loss: 5.6292\n",
      "Epoch: 1401, Train_loss: 0.0398 / Val_loss: 5.6050\n",
      "Epoch: 1402, Train_loss: 0.0542 / Val_loss: 5.5881\n",
      "Epoch: 1403, Train_loss: 0.1427 / Val_loss: 5.5031\n",
      "Epoch: 1404, Train_loss: 0.0814 / Val_loss: 5.4188\n",
      "Epoch: 1405, Train_loss: 0.0711 / Val_loss: 5.3509\n",
      "Epoch: 1406, Train_loss: 0.0696 / Val_loss: 5.2904\n",
      "Epoch: 1407, Train_loss: 0.0438 / Val_loss: 5.2416\n",
      "Epoch: 1408, Train_loss: 0.0674 / Val_loss: 5.2005\n",
      "Epoch: 1409, Train_loss: 0.0757 / Val_loss: 5.1716\n",
      "Epoch: 1410, Train_loss: 0.0866 / Val_loss: 5.1465\n",
      "Epoch: 1411, Train_loss: 0.0653 / Val_loss: 5.1203\n",
      "Epoch: 1412, Train_loss: 0.0822 / Val_loss: 5.1153\n",
      "Epoch: 1413, Train_loss: 0.0645 / Val_loss: 5.1321\n",
      "Epoch: 1414, Train_loss: 0.0485 / Val_loss: 5.1450\n",
      "Epoch: 1415, Train_loss: 0.0663 / Val_loss: 5.1418\n",
      "Epoch: 1416, Train_loss: 0.0639 / Val_loss: 5.1251\n",
      "Epoch: 1417, Train_loss: 0.0492 / Val_loss: 5.1312\n",
      "Epoch: 1418, Train_loss: 0.0801 / Val_loss: 5.1287\n",
      "Epoch: 1419, Train_loss: 0.0632 / Val_loss: 5.1087\n",
      "Epoch: 1420, Train_loss: 0.1079 / Val_loss: 5.0328\n",
      "Epoch: 1421, Train_loss: 0.0618 / Val_loss: 4.9754\n",
      "Epoch: 1422, Train_loss: 0.0613 / Val_loss: 4.9433\n",
      "Epoch: 1423, Train_loss: 0.0692 / Val_loss: 4.9293\n",
      "Epoch: 1424, Train_loss: 0.1022 / Val_loss: 4.9204\n",
      "Epoch: 1425, Train_loss: 0.0561 / Val_loss: 4.9125\n",
      "Epoch: 1426, Train_loss: 0.0706 / Val_loss: 4.9071\n",
      "Epoch: 1427, Train_loss: 0.0792 / Val_loss: 4.9153\n",
      "Epoch: 1428, Train_loss: 0.0555 / Val_loss: 4.9364\n",
      "Epoch: 1429, Train_loss: 0.0937 / Val_loss: 4.9392\n",
      "Epoch: 1430, Train_loss: 0.0328 / Val_loss: 4.9507\n",
      "Epoch: 1431, Train_loss: 0.0450 / Val_loss: 4.9598\n",
      "Epoch: 1432, Train_loss: 0.0522 / Val_loss: 4.9719\n",
      "Epoch: 1433, Train_loss: 0.0696 / Val_loss: 4.9834\n",
      "Epoch: 1434, Train_loss: 0.0780 / Val_loss: 4.9742\n",
      "Epoch: 1435, Train_loss: 0.0565 / Val_loss: 4.9701\n",
      "Epoch: 1436, Train_loss: 0.0704 / Val_loss: 4.9718\n",
      "Epoch: 1437, Train_loss: 0.0548 / Val_loss: 4.9898\n",
      "Epoch: 1438, Train_loss: 0.0413 / Val_loss: 5.0335\n",
      "Epoch: 1439, Train_loss: 0.0576 / Val_loss: 5.1069\n",
      "Epoch: 1440, Train_loss: 0.0541 / Val_loss: 5.1684\n",
      "Epoch: 1441, Train_loss: 0.0567 / Val_loss: 5.2374\n",
      "Epoch: 1442, Train_loss: 0.0547 / Val_loss: 5.3110\n",
      "Epoch: 1443, Train_loss: 0.0774 / Val_loss: 5.3590\n",
      "Epoch: 1444, Train_loss: 0.0519 / Val_loss: 5.4068\n",
      "Epoch: 1445, Train_loss: 0.0475 / Val_loss: 5.4252\n",
      "Epoch: 1446, Train_loss: 0.0797 / Val_loss: 5.4275\n",
      "Epoch: 1447, Train_loss: 0.0427 / Val_loss: 5.4320\n",
      "Epoch: 1448, Train_loss: 0.0728 / Val_loss: 5.4394\n",
      "Epoch: 1449, Train_loss: 0.0555 / Val_loss: 5.4494\n",
      "Epoch: 1450, Train_loss: 0.0697 / Val_loss: 5.4696\n",
      "Epoch: 1451, Train_loss: 0.0651 / Val_loss: 5.4903\n",
      "Epoch: 1452, Train_loss: 0.0443 / Val_loss: 5.5030\n",
      "Epoch: 1453, Train_loss: 0.0887 / Val_loss: 5.4791\n",
      "Epoch: 1454, Train_loss: 0.0782 / Val_loss: 5.4446\n",
      "Epoch: 1455, Train_loss: 0.0673 / Val_loss: 5.3811\n",
      "Epoch: 1456, Train_loss: 0.0357 / Val_loss: 5.3359\n",
      "Epoch: 1457, Train_loss: 0.0565 / Val_loss: 5.2768\n",
      "Epoch: 1458, Train_loss: 0.0586 / Val_loss: 5.2188\n",
      "Epoch: 1459, Train_loss: 0.0500 / Val_loss: 5.1794\n",
      "Epoch: 1460, Train_loss: 0.0433 / Val_loss: 5.1564\n",
      "Epoch: 1461, Train_loss: 0.0563 / Val_loss: 5.1521\n",
      "Epoch: 1462, Train_loss: 0.0486 / Val_loss: 5.1765\n",
      "Epoch: 1463, Train_loss: 0.0775 / Val_loss: 5.1967\n",
      "Epoch: 1464, Train_loss: 0.0957 / Val_loss: 5.2331\n",
      "Epoch: 1465, Train_loss: 0.0581 / Val_loss: 5.2805\n",
      "Epoch: 1466, Train_loss: 0.0647 / Val_loss: 5.3500\n",
      "Epoch: 1467, Train_loss: 0.0433 / Val_loss: 5.4120\n",
      "Epoch: 1468, Train_loss: 0.0637 / Val_loss: 5.4828\n",
      "Epoch: 1469, Train_loss: 0.0938 / Val_loss: 5.5275\n",
      "Epoch: 1470, Train_loss: 0.0766 / Val_loss: 5.5463\n",
      "Epoch: 1471, Train_loss: 0.0601 / Val_loss: 5.5387\n",
      "Epoch: 1472, Train_loss: 0.0603 / Val_loss: 5.5418\n",
      "Epoch: 1473, Train_loss: 0.0888 / Val_loss: 5.5209\n",
      "Epoch: 1474, Train_loss: 0.0475 / Val_loss: 5.4963\n",
      "Epoch: 1475, Train_loss: 0.0644 / Val_loss: 5.4748\n",
      "Epoch: 1476, Train_loss: 0.0511 / Val_loss: 5.4809\n",
      "Epoch: 1477, Train_loss: 0.0575 / Val_loss: 5.4878\n",
      "Epoch: 1478, Train_loss: 0.0551 / Val_loss: 5.4796\n",
      "Epoch: 1479, Train_loss: 0.0644 / Val_loss: 5.4945\n",
      "Epoch: 1480, Train_loss: 0.0585 / Val_loss: 5.5163\n",
      "Epoch: 1481, Train_loss: 0.0339 / Val_loss: 5.5545\n",
      "Epoch: 1482, Train_loss: 0.0430 / Val_loss: 5.5944\n",
      "Epoch: 1483, Train_loss: 0.0552 / Val_loss: 5.6252\n",
      "Epoch: 1484, Train_loss: 0.0668 / Val_loss: 5.6758\n",
      "Epoch: 1485, Train_loss: 0.0194 / Val_loss: 5.7338\n",
      "Epoch: 1486, Train_loss: 0.0604 / Val_loss: 5.7987\n",
      "Epoch: 1487, Train_loss: 0.0619 / Val_loss: 5.8641\n",
      "Epoch: 1488, Train_loss: 0.0562 / Val_loss: 5.9219\n",
      "Epoch: 1489, Train_loss: 0.0667 / Val_loss: 5.9413\n",
      "Epoch: 1490, Train_loss: 0.0701 / Val_loss: 5.9189\n",
      "Epoch: 1491, Train_loss: 0.0619 / Val_loss: 5.8901\n",
      "Epoch: 1492, Train_loss: 0.0717 / Val_loss: 5.8685\n",
      "Epoch: 1493, Train_loss: 0.0631 / Val_loss: 5.8311\n",
      "Epoch: 1494, Train_loss: 0.0430 / Val_loss: 5.7908\n",
      "Epoch: 1495, Train_loss: 0.0582 / Val_loss: 5.7523\n",
      "Epoch: 1496, Train_loss: 0.0573 / Val_loss: 5.6696\n",
      "Epoch: 1497, Train_loss: 0.0747 / Val_loss: 5.5774\n",
      "Epoch: 1498, Train_loss: 0.0489 / Val_loss: 5.5104\n",
      "Epoch: 1499, Train_loss: 0.0705 / Val_loss: 5.4737\n",
      "Epoch: 1500, Train_loss: 0.0722 / Val_loss: 5.4425\n",
      "Epoch: 1501, Train_loss: 0.0578 / Val_loss: 5.4250\n",
      "Epoch: 1502, Train_loss: 0.0446 / Val_loss: 5.4145\n",
      "Epoch: 1503, Train_loss: 0.0759 / Val_loss: 5.4031\n",
      "Epoch: 1504, Train_loss: 0.0825 / Val_loss: 5.4085\n",
      "Epoch: 1505, Train_loss: 0.0638 / Val_loss: 5.4303\n",
      "Epoch: 1506, Train_loss: 0.0525 / Val_loss: 5.4728\n",
      "Epoch: 1507, Train_loss: 0.0477 / Val_loss: 5.5446\n",
      "Epoch: 1508, Train_loss: 0.0703 / Val_loss: 5.6090\n",
      "Epoch: 1509, Train_loss: 0.0478 / Val_loss: 5.6913\n",
      "Epoch: 1510, Train_loss: 0.0691 / Val_loss: 5.7758\n",
      "Epoch: 1511, Train_loss: 0.0688 / Val_loss: 5.8531\n",
      "Epoch: 1512, Train_loss: 0.0428 / Val_loss: 5.9400\n",
      "Epoch: 1513, Train_loss: 0.0669 / Val_loss: 5.9837\n",
      "Epoch: 1514, Train_loss: 0.0641 / Val_loss: 6.0288\n",
      "Epoch: 1515, Train_loss: 0.0371 / Val_loss: 6.0699\n",
      "Epoch: 1516, Train_loss: 0.0727 / Val_loss: 6.0775\n",
      "Epoch: 1517, Train_loss: 0.0544 / Val_loss: 6.0602\n",
      "Epoch: 1518, Train_loss: 0.0686 / Val_loss: 6.0021\n",
      "Epoch: 1519, Train_loss: 0.0598 / Val_loss: 5.9408\n",
      "Epoch: 1520, Train_loss: 0.0629 / Val_loss: 5.8952\n",
      "Epoch: 1521, Train_loss: 0.0415 / Val_loss: 5.8628\n",
      "Epoch: 1522, Train_loss: 0.0731 / Val_loss: 5.8342\n",
      "Epoch: 1523, Train_loss: 0.0716 / Val_loss: 5.7860\n",
      "Epoch: 1524, Train_loss: 0.0496 / Val_loss: 5.7490\n",
      "Epoch: 1525, Train_loss: 0.0557 / Val_loss: 5.7310\n",
      "Epoch: 1526, Train_loss: 0.0438 / Val_loss: 5.7284\n",
      "Epoch: 1527, Train_loss: 0.0833 / Val_loss: 5.7315\n",
      "Epoch: 1528, Train_loss: 0.0450 / Val_loss: 5.7453\n",
      "Epoch: 1529, Train_loss: 0.0747 / Val_loss: 5.7444\n",
      "Epoch: 1530, Train_loss: 0.0871 / Val_loss: 5.7117\n",
      "Epoch: 1531, Train_loss: 0.0891 / Val_loss: 5.6502\n",
      "Epoch: 1532, Train_loss: 0.0702 / Val_loss: 5.6003\n",
      "Epoch: 1533, Train_loss: 0.0683 / Val_loss: 5.5365\n",
      "Epoch: 1534, Train_loss: 0.0498 / Val_loss: 5.4879\n",
      "Epoch: 1535, Train_loss: 0.0842 / Val_loss: 5.4203\n",
      "Epoch: 1536, Train_loss: 0.0503 / Val_loss: 5.3746\n",
      "Epoch: 1537, Train_loss: 0.0742 / Val_loss: 5.3404\n",
      "Epoch: 1538, Train_loss: 0.0745 / Val_loss: 5.3002\n",
      "Epoch: 1539, Train_loss: 0.0548 / Val_loss: 5.2666\n",
      "Epoch: 1540, Train_loss: 0.0637 / Val_loss: 5.2521\n",
      "Epoch: 1541, Train_loss: 0.0404 / Val_loss: 5.2607\n",
      "Epoch: 1542, Train_loss: 0.0658 / Val_loss: 5.2409\n",
      "Epoch: 1543, Train_loss: 0.0492 / Val_loss: 5.2439\n",
      "Epoch: 1544, Train_loss: 0.0445 / Val_loss: 5.2622\n",
      "Epoch: 1545, Train_loss: 0.0792 / Val_loss: 5.2856\n",
      "Epoch: 1546, Train_loss: 0.0467 / Val_loss: 5.3224\n",
      "Epoch: 1547, Train_loss: 0.0573 / Val_loss: 5.3487\n",
      "Epoch: 1548, Train_loss: 0.0585 / Val_loss: 5.3568\n",
      "Epoch: 1549, Train_loss: 0.0507 / Val_loss: 5.3707\n",
      "Epoch: 1550, Train_loss: 0.0578 / Val_loss: 5.3731\n",
      "Epoch: 1551, Train_loss: 0.0479 / Val_loss: 5.3783\n",
      "Epoch: 1552, Train_loss: 0.0573 / Val_loss: 5.4023\n",
      "Epoch: 1553, Train_loss: 0.0561 / Val_loss: 5.4430\n",
      "Epoch: 1554, Train_loss: 0.0742 / Val_loss: 5.4608\n",
      "Epoch: 1555, Train_loss: 0.0639 / Val_loss: 5.5000\n",
      "Epoch: 1556, Train_loss: 0.0599 / Val_loss: 5.5499\n",
      "Epoch: 1557, Train_loss: 0.0515 / Val_loss: 5.6211\n",
      "Epoch: 1558, Train_loss: 0.0591 / Val_loss: 5.7450\n",
      "Epoch: 1559, Train_loss: 0.0515 / Val_loss: 5.8779\n",
      "Epoch: 1560, Train_loss: 0.0552 / Val_loss: 6.0114\n",
      "Epoch: 1561, Train_loss: 0.0569 / Val_loss: 6.1311\n",
      "Epoch: 1562, Train_loss: 0.0410 / Val_loss: 6.2433\n",
      "Epoch: 1563, Train_loss: 0.0629 / Val_loss: 6.3557\n",
      "Epoch: 1564, Train_loss: 0.0668 / Val_loss: 6.4201\n",
      "Epoch: 1565, Train_loss: 0.0437 / Val_loss: 6.4798\n",
      "Epoch: 1566, Train_loss: 0.0607 / Val_loss: 6.5061\n",
      "Epoch: 1567, Train_loss: 0.0643 / Val_loss: 6.5202\n",
      "Epoch: 1568, Train_loss: 0.0635 / Val_loss: 6.5035\n",
      "Epoch: 1569, Train_loss: 0.0489 / Val_loss: 6.5057\n",
      "Epoch: 1570, Train_loss: 0.0698 / Val_loss: 6.4844\n",
      "Epoch: 1571, Train_loss: 0.0593 / Val_loss: 6.4717\n",
      "Epoch: 1572, Train_loss: 0.0629 / Val_loss: 6.4235\n",
      "Epoch: 1573, Train_loss: 0.0381 / Val_loss: 6.3589\n",
      "Epoch: 1574, Train_loss: 0.0329 / Val_loss: 6.3172\n",
      "Epoch: 1575, Train_loss: 0.0699 / Val_loss: 6.2783\n",
      "Epoch: 1576, Train_loss: 0.0561 / Val_loss: 6.2133\n",
      "Epoch: 1577, Train_loss: 0.0624 / Val_loss: 6.1769\n",
      "Epoch: 1578, Train_loss: 0.0629 / Val_loss: 6.1256\n",
      "Epoch: 1579, Train_loss: 0.0361 / Val_loss: 6.0882\n",
      "Epoch: 1580, Train_loss: 0.0787 / Val_loss: 6.0587\n",
      "Epoch: 1581, Train_loss: 0.0555 / Val_loss: 6.0737\n",
      "Epoch: 1582, Train_loss: 0.0324 / Val_loss: 6.1057\n",
      "Epoch: 1583, Train_loss: 0.0628 / Val_loss: 6.1288\n",
      "Epoch: 1584, Train_loss: 0.0781 / Val_loss: 6.1179\n",
      "Epoch: 1585, Train_loss: 0.0696 / Val_loss: 6.1027\n",
      "Epoch: 1586, Train_loss: 0.0647 / Val_loss: 6.0757\n",
      "Epoch: 1587, Train_loss: 0.0354 / Val_loss: 6.0527\n",
      "Epoch: 1588, Train_loss: 0.0593 / Val_loss: 6.0379\n",
      "Epoch: 1589, Train_loss: 0.0715 / Val_loss: 6.0181\n",
      "Epoch: 1590, Train_loss: 0.0637 / Val_loss: 6.0008\n",
      "Epoch: 1591, Train_loss: 0.0705 / Val_loss: 5.9662\n",
      "Epoch: 1592, Train_loss: 0.0397 / Val_loss: 5.9553\n",
      "Epoch: 1593, Train_loss: 0.0570 / Val_loss: 5.9359\n",
      "Epoch: 1594, Train_loss: 0.0419 / Val_loss: 5.9295\n",
      "Epoch: 1595, Train_loss: 0.0601 / Val_loss: 5.9279\n",
      "Epoch: 1596, Train_loss: 0.0609 / Val_loss: 5.9132\n",
      "Epoch: 1597, Train_loss: 0.0456 / Val_loss: 5.9153\n",
      "Epoch: 1598, Train_loss: 0.0646 / Val_loss: 5.9252\n",
      "Epoch: 1599, Train_loss: 0.0508 / Val_loss: 5.9353\n",
      "Epoch: 1600, Train_loss: 0.0739 / Val_loss: 5.9656\n",
      "Epoch: 1601, Train_loss: 0.0485 / Val_loss: 5.9824\n",
      "Epoch: 1602, Train_loss: 0.0521 / Val_loss: 6.0089\n",
      "Epoch: 1603, Train_loss: 0.0490 / Val_loss: 6.0428\n",
      "Epoch: 1604, Train_loss: 0.0659 / Val_loss: 6.0769\n",
      "Epoch: 1605, Train_loss: 0.0338 / Val_loss: 6.1146\n",
      "Epoch: 1606, Train_loss: 0.1085 / Val_loss: 6.0707\n",
      "Epoch: 1607, Train_loss: 0.0735 / Val_loss: 6.0259\n",
      "Epoch: 1608, Train_loss: 0.0402 / Val_loss: 5.9971\n",
      "Epoch: 1609, Train_loss: 0.0740 / Val_loss: 5.9771\n",
      "Epoch: 1610, Train_loss: 0.0598 / Val_loss: 5.9603\n",
      "Epoch: 1611, Train_loss: 0.0823 / Val_loss: 5.9142\n",
      "Epoch: 1612, Train_loss: 0.0532 / Val_loss: 5.8795\n",
      "Epoch: 1613, Train_loss: 0.0457 / Val_loss: 5.8483\n",
      "Epoch: 1614, Train_loss: 0.0472 / Val_loss: 5.8663\n",
      "Epoch: 1615, Train_loss: 0.0440 / Val_loss: 5.8956\n",
      "Epoch: 1616, Train_loss: 0.0472 / Val_loss: 5.9105\n",
      "Epoch: 1617, Train_loss: 0.0519 / Val_loss: 5.9153\n",
      "Epoch: 1618, Train_loss: 0.0481 / Val_loss: 5.9277\n",
      "Epoch: 1619, Train_loss: 0.0447 / Val_loss: 5.9441\n",
      "Epoch: 1620, Train_loss: 0.0222 / Val_loss: 5.9731\n",
      "Epoch: 1621, Train_loss: 0.0512 / Val_loss: 6.0019\n",
      "Epoch: 1622, Train_loss: 0.0790 / Val_loss: 6.0108\n",
      "Epoch: 1623, Train_loss: 0.0434 / Val_loss: 6.0185\n",
      "Epoch: 1624, Train_loss: 0.0843 / Val_loss: 6.0448\n",
      "Epoch: 1625, Train_loss: 0.0438 / Val_loss: 6.0778\n",
      "Epoch: 1626, Train_loss: 0.0666 / Val_loss: 6.0860\n",
      "Epoch: 1627, Train_loss: 0.0597 / Val_loss: 6.0841\n",
      "Epoch: 1628, Train_loss: 0.0334 / Val_loss: 6.1006\n",
      "Epoch: 1629, Train_loss: 0.0445 / Val_loss: 6.1147\n",
      "Epoch: 1630, Train_loss: 0.0710 / Val_loss: 6.0949\n",
      "Epoch: 1631, Train_loss: 0.0726 / Val_loss: 6.0502\n",
      "Epoch: 1632, Train_loss: 0.0615 / Val_loss: 6.0066\n",
      "Epoch: 1633, Train_loss: 0.0625 / Val_loss: 5.9553\n",
      "Epoch: 1634, Train_loss: 0.0539 / Val_loss: 5.9157\n",
      "Epoch: 1635, Train_loss: 0.0440 / Val_loss: 5.8957\n",
      "Epoch: 1636, Train_loss: 0.0480 / Val_loss: 5.8954\n",
      "Epoch: 1637, Train_loss: 0.0649 / Val_loss: 5.9040\n",
      "Epoch: 1638, Train_loss: 0.0516 / Val_loss: 5.9083\n",
      "Epoch: 1639, Train_loss: 0.0457 / Val_loss: 5.9161\n",
      "Epoch: 1640, Train_loss: 0.0420 / Val_loss: 5.9288\n",
      "Epoch: 1641, Train_loss: 0.0781 / Val_loss: 5.9644\n",
      "Epoch: 1642, Train_loss: 0.0639 / Val_loss: 5.9695\n",
      "Epoch: 1643, Train_loss: 0.0388 / Val_loss: 5.9937\n",
      "Epoch: 1644, Train_loss: 0.0687 / Val_loss: 5.9994\n",
      "Epoch: 1645, Train_loss: 0.0460 / Val_loss: 6.0126\n",
      "Epoch: 1646, Train_loss: 0.0594 / Val_loss: 6.0088\n",
      "Epoch: 1647, Train_loss: 0.0547 / Val_loss: 6.0053\n",
      "Epoch: 1648, Train_loss: 0.0782 / Val_loss: 5.9768\n",
      "Epoch: 1649, Train_loss: 0.0608 / Val_loss: 5.9436\n",
      "Epoch: 1650, Train_loss: 0.0732 / Val_loss: 5.8987\n",
      "Epoch: 1651, Train_loss: 0.0528 / Val_loss: 5.8390\n",
      "Epoch: 1652, Train_loss: 0.0523 / Val_loss: 5.7833\n",
      "Epoch: 1653, Train_loss: 0.0566 / Val_loss: 5.7132\n",
      "Epoch: 1654, Train_loss: 0.0599 / Val_loss: 5.6584\n",
      "Epoch: 1655, Train_loss: 0.0334 / Val_loss: 5.6171\n",
      "Epoch: 1656, Train_loss: 0.0510 / Val_loss: 5.5779\n",
      "Epoch: 1657, Train_loss: 0.0688 / Val_loss: 5.5459\n",
      "Epoch: 1658, Train_loss: 0.0573 / Val_loss: 5.5011\n",
      "Epoch: 1659, Train_loss: 0.0706 / Val_loss: 5.4634\n",
      "Epoch: 1660, Train_loss: 0.0507 / Val_loss: 5.4422\n",
      "Epoch: 1661, Train_loss: 0.0350 / Val_loss: 5.4400\n",
      "Epoch: 1662, Train_loss: 0.0661 / Val_loss: 5.4580\n",
      "Epoch: 1663, Train_loss: 0.0656 / Val_loss: 5.4890\n",
      "Epoch: 1664, Train_loss: 0.0561 / Val_loss: 5.5272\n",
      "Epoch: 1665, Train_loss: 0.0605 / Val_loss: 5.5822\n",
      "Epoch: 1666, Train_loss: 0.0457 / Val_loss: 5.6380\n",
      "Epoch: 1667, Train_loss: 0.0439 / Val_loss: 5.7109\n",
      "Epoch: 1668, Train_loss: 0.0528 / Val_loss: 5.7810\n",
      "Epoch: 1669, Train_loss: 0.0410 / Val_loss: 5.8454\n",
      "Epoch: 1670, Train_loss: 0.0524 / Val_loss: 5.8940\n",
      "Epoch: 1671, Train_loss: 0.0628 / Val_loss: 5.9447\n",
      "Epoch: 1672, Train_loss: 0.0685 / Val_loss: 5.9944\n",
      "Epoch: 1673, Train_loss: 0.0515 / Val_loss: 6.0490\n",
      "Epoch: 1674, Train_loss: 0.0476 / Val_loss: 6.1126\n",
      "Epoch: 1675, Train_loss: 0.0470 / Val_loss: 6.1595\n",
      "Epoch: 1676, Train_loss: 0.0410 / Val_loss: 6.2108\n",
      "Epoch: 1677, Train_loss: 0.0286 / Val_loss: 6.2725\n",
      "Epoch: 1678, Train_loss: 0.0466 / Val_loss: 6.2969\n",
      "Epoch: 1679, Train_loss: 0.0750 / Val_loss: 6.2817\n",
      "Epoch: 1680, Train_loss: 0.0692 / Val_loss: 6.2252\n",
      "Epoch: 1681, Train_loss: 0.0439 / Val_loss: 6.1851\n",
      "Epoch: 1682, Train_loss: 0.0409 / Val_loss: 6.1609\n",
      "Epoch: 1683, Train_loss: 0.0442 / Val_loss: 6.1574\n",
      "Epoch: 1684, Train_loss: 0.0320 / Val_loss: 6.1697\n",
      "Epoch: 1685, Train_loss: 0.0456 / Val_loss: 6.1482\n",
      "Epoch: 1686, Train_loss: 0.0491 / Val_loss: 6.1279\n",
      "Epoch: 1687, Train_loss: 0.0647 / Val_loss: 6.0934\n",
      "Epoch: 1688, Train_loss: 0.0763 / Val_loss: 6.0801\n",
      "Epoch: 1689, Train_loss: 0.0379 / Val_loss: 6.0771\n",
      "Epoch: 1690, Train_loss: 0.0679 / Val_loss: 6.0713\n",
      "Epoch: 1691, Train_loss: 0.0667 / Val_loss: 6.0638\n",
      "Epoch: 1692, Train_loss: 0.0633 / Val_loss: 6.0568\n",
      "Epoch: 1693, Train_loss: 0.0473 / Val_loss: 6.0776\n",
      "Epoch: 1694, Train_loss: 0.0393 / Val_loss: 6.1000\n",
      "Epoch: 1695, Train_loss: 0.0593 / Val_loss: 6.0996\n",
      "Epoch: 1696, Train_loss: 0.0264 / Val_loss: 6.1108\n",
      "Epoch: 1697, Train_loss: 0.0424 / Val_loss: 6.1310\n",
      "Epoch: 1698, Train_loss: 0.0461 / Val_loss: 6.1625\n",
      "Epoch: 1699, Train_loss: 0.0615 / Val_loss: 6.1659\n",
      "Epoch: 1700, Train_loss: 0.0215 / Val_loss: 6.1706\n",
      "Epoch: 1701, Train_loss: 0.0344 / Val_loss: 6.1806\n",
      "Epoch: 1702, Train_loss: 0.0679 / Val_loss: 6.1954\n",
      "Epoch: 1703, Train_loss: 0.0645 / Val_loss: 6.2153\n",
      "Epoch: 1704, Train_loss: 0.0519 / Val_loss: 6.2366\n",
      "Epoch: 1705, Train_loss: 0.0440 / Val_loss: 6.2662\n",
      "Epoch: 1706, Train_loss: 0.0501 / Val_loss: 6.3033\n",
      "Epoch: 1707, Train_loss: 0.0561 / Val_loss: 6.3306\n",
      "Epoch: 1708, Train_loss: 0.0433 / Val_loss: 6.3648\n",
      "Epoch: 1709, Train_loss: 0.0326 / Val_loss: 6.4103\n",
      "Epoch: 1710, Train_loss: 0.0551 / Val_loss: 6.4742\n",
      "Epoch: 1711, Train_loss: 0.0316 / Val_loss: 6.5407\n",
      "Epoch: 1712, Train_loss: 0.0481 / Val_loss: 6.6007\n",
      "Epoch: 1713, Train_loss: 0.0586 / Val_loss: 6.6529\n",
      "Epoch: 1714, Train_loss: 0.0578 / Val_loss: 6.6704\n",
      "Epoch: 1715, Train_loss: 0.0429 / Val_loss: 6.6797\n",
      "Epoch: 1716, Train_loss: 0.0483 / Val_loss: 6.7061\n",
      "Epoch: 1717, Train_loss: 0.0422 / Val_loss: 6.7109\n",
      "Epoch: 1718, Train_loss: 0.0606 / Val_loss: 6.7024\n",
      "Epoch: 1719, Train_loss: 0.0290 / Val_loss: 6.6827\n",
      "Epoch: 1720, Train_loss: 0.0354 / Val_loss: 6.6796\n",
      "Epoch: 1721, Train_loss: 0.0606 / Val_loss: 6.6605\n",
      "Epoch: 1722, Train_loss: 0.0617 / Val_loss: 6.6568\n",
      "Epoch: 1723, Train_loss: 0.0294 / Val_loss: 6.6763\n",
      "Epoch: 1724, Train_loss: 0.0471 / Val_loss: 6.6993\n",
      "Epoch: 1725, Train_loss: 0.0355 / Val_loss: 6.7236\n",
      "Epoch: 1726, Train_loss: 0.0394 / Val_loss: 6.7452\n",
      "Epoch: 1727, Train_loss: 0.0680 / Val_loss: 6.7652\n",
      "Epoch: 1728, Train_loss: 0.0333 / Val_loss: 6.7878\n",
      "Epoch: 1729, Train_loss: 0.0358 / Val_loss: 6.8256\n",
      "Epoch: 1730, Train_loss: 0.0312 / Val_loss: 6.8588\n",
      "Epoch: 1731, Train_loss: 0.0289 / Val_loss: 6.9012\n",
      "Epoch: 1732, Train_loss: 0.0124 / Val_loss: 6.9471\n",
      "Epoch: 1733, Train_loss: 0.0416 / Val_loss: 6.9628\n",
      "Epoch: 1734, Train_loss: 0.0339 / Val_loss: 7.0014\n",
      "Epoch: 1735, Train_loss: 0.0529 / Val_loss: 7.0194\n",
      "Epoch: 1736, Train_loss: 0.0427 / Val_loss: 7.0103\n",
      "Epoch: 1737, Train_loss: 0.0376 / Val_loss: 7.0317\n",
      "Epoch: 1738, Train_loss: 0.0161 / Val_loss: 7.0650\n",
      "Epoch: 1739, Train_loss: 0.0582 / Val_loss: 7.0498\n",
      "Epoch: 1740, Train_loss: 0.0283 / Val_loss: 7.0448\n",
      "Epoch: 1741, Train_loss: 0.0411 / Val_loss: 7.0454\n",
      "Epoch: 1742, Train_loss: 0.0502 / Val_loss: 7.0543\n",
      "Epoch: 1743, Train_loss: 0.0536 / Val_loss: 7.0700\n",
      "Epoch: 1744, Train_loss: 0.0286 / Val_loss: 7.0984\n",
      "Epoch: 1745, Train_loss: 0.0284 / Val_loss: 7.1522\n",
      "Epoch: 1746, Train_loss: 0.0230 / Val_loss: 7.2140\n",
      "Epoch: 1747, Train_loss: 0.0311 / Val_loss: 7.2759\n",
      "Epoch: 1748, Train_loss: 0.0190 / Val_loss: 7.3263\n",
      "Epoch: 1749, Train_loss: 0.0342 / Val_loss: 7.3393\n",
      "Epoch: 1750, Train_loss: 0.0566 / Val_loss: 7.3231\n",
      "Epoch: 1751, Train_loss: 0.0789 / Val_loss: 7.2778\n",
      "Epoch: 1752, Train_loss: 0.0459 / Val_loss: 7.2095\n",
      "Epoch: 1753, Train_loss: 0.0538 / Val_loss: 7.0901\n",
      "Epoch: 1754, Train_loss: 0.0725 / Val_loss: 7.0016\n",
      "Epoch: 1755, Train_loss: 0.0432 / Val_loss: 6.9436\n",
      "Epoch: 1756, Train_loss: 0.0398 / Val_loss: 6.9028\n",
      "Epoch: 1757, Train_loss: 0.0641 / Val_loss: 6.8815\n",
      "Epoch: 1758, Train_loss: 0.0168 / Val_loss: 6.8958\n",
      "Epoch: 1759, Train_loss: 0.0374 / Val_loss: 6.9108\n",
      "Epoch: 1760, Train_loss: 0.0495 / Val_loss: 6.9106\n",
      "Epoch: 1761, Train_loss: 0.0268 / Val_loss: 6.9218\n",
      "Epoch: 1762, Train_loss: 0.0397 / Val_loss: 6.9253\n",
      "Epoch: 1763, Train_loss: 0.0372 / Val_loss: 6.9182\n",
      "Epoch: 1764, Train_loss: 0.0539 / Val_loss: 6.9181\n",
      "Epoch: 1765, Train_loss: 0.0747 / Val_loss: 6.8917\n",
      "Epoch: 1766, Train_loss: 0.0314 / Val_loss: 6.8791\n",
      "Epoch: 1767, Train_loss: 0.0461 / Val_loss: 6.8820\n",
      "Epoch: 1768, Train_loss: 0.0167 / Val_loss: 6.9017\n",
      "Epoch: 1769, Train_loss: 0.0381 / Val_loss: 6.9073\n",
      "Epoch: 1770, Train_loss: 0.0318 / Val_loss: 6.9204\n",
      "Epoch: 1771, Train_loss: 0.0488 / Val_loss: 6.9353\n",
      "Epoch: 1772, Train_loss: 0.0264 / Val_loss: 6.9373\n",
      "Epoch: 1773, Train_loss: 0.0531 / Val_loss: 6.9468\n",
      "Epoch: 1774, Train_loss: 0.0461 / Val_loss: 6.9467\n",
      "Epoch: 1775, Train_loss: 0.0731 / Val_loss: 6.9116\n",
      "Epoch: 1776, Train_loss: 0.0386 / Val_loss: 6.9087\n",
      "Epoch: 1777, Train_loss: 0.0420 / Val_loss: 6.9287\n",
      "Epoch: 1778, Train_loss: 0.0290 / Val_loss: 6.9704\n",
      "Epoch: 1779, Train_loss: 0.0617 / Val_loss: 7.0121\n",
      "Epoch: 1780, Train_loss: 0.0619 / Val_loss: 7.0629\n",
      "Epoch: 1781, Train_loss: 0.0371 / Val_loss: 7.1223\n",
      "Epoch: 1782, Train_loss: 0.0322 / Val_loss: 7.1929\n",
      "Epoch: 1783, Train_loss: 0.0682 / Val_loss: 7.1656\n",
      "Epoch: 1784, Train_loss: 0.0400 / Val_loss: 7.1441\n",
      "Epoch: 1785, Train_loss: 0.0446 / Val_loss: 7.0626\n",
      "Epoch: 1786, Train_loss: 0.0401 / Val_loss: 6.9830\n",
      "Epoch: 1787, Train_loss: 0.0415 / Val_loss: 6.9173\n",
      "Epoch: 1788, Train_loss: 0.0802 / Val_loss: 6.8443\n",
      "Epoch: 1789, Train_loss: 0.0555 / Val_loss: 6.8160\n",
      "Epoch: 1790, Train_loss: 0.0341 / Val_loss: 6.8063\n",
      "Epoch: 1791, Train_loss: 0.0209 / Val_loss: 6.8176\n",
      "Epoch: 1792, Train_loss: 0.0651 / Val_loss: 6.7661\n",
      "Epoch: 1793, Train_loss: 0.0262 / Val_loss: 6.7376\n",
      "Epoch: 1794, Train_loss: 0.0325 / Val_loss: 6.7345\n",
      "Epoch: 1795, Train_loss: 0.0675 / Val_loss: 6.7151\n",
      "Epoch: 1796, Train_loss: 0.0353 / Val_loss: 6.7143\n",
      "Epoch: 1797, Train_loss: 0.0356 / Val_loss: 6.7559\n",
      "Epoch: 1798, Train_loss: 0.0308 / Val_loss: 6.8160\n",
      "Epoch: 1799, Train_loss: 0.0597 / Val_loss: 6.8814\n",
      "Epoch: 1800, Train_loss: 0.0656 / Val_loss: 6.9044\n",
      "Epoch: 1801, Train_loss: 0.0593 / Val_loss: 6.9202\n",
      "Epoch: 1802, Train_loss: 0.0492 / Val_loss: 6.9013\n",
      "Epoch: 1803, Train_loss: 0.0491 / Val_loss: 6.8909\n",
      "Epoch: 1804, Train_loss: 0.0833 / Val_loss: 6.8423\n",
      "Epoch: 1805, Train_loss: 0.0734 / Val_loss: 6.7573\n",
      "Epoch: 1806, Train_loss: 0.0514 / Val_loss: 6.7040\n",
      "Epoch: 1807, Train_loss: 0.0487 / Val_loss: 6.6656\n",
      "Epoch: 1808, Train_loss: 0.0464 / Val_loss: 6.6675\n",
      "Epoch: 1809, Train_loss: 0.0430 / Val_loss: 6.6522\n",
      "Epoch: 1810, Train_loss: 0.0593 / Val_loss: 6.6454\n",
      "Epoch: 1811, Train_loss: 0.0451 / Val_loss: 6.6550\n",
      "Epoch: 1812, Train_loss: 0.0495 / Val_loss: 6.6592\n",
      "Epoch: 1813, Train_loss: 0.0527 / Val_loss: 6.6496\n",
      "Epoch: 1814, Train_loss: 0.0434 / Val_loss: 6.6646\n",
      "Epoch: 1815, Train_loss: 0.0381 / Val_loss: 6.6802\n",
      "Epoch: 1816, Train_loss: 0.0380 / Val_loss: 6.6942\n",
      "Epoch: 1817, Train_loss: 0.0495 / Val_loss: 6.7042\n",
      "Epoch: 1818, Train_loss: 0.0507 / Val_loss: 6.6902\n",
      "Epoch: 1819, Train_loss: 0.0427 / Val_loss: 6.6852\n",
      "Epoch: 1820, Train_loss: 0.0544 / Val_loss: 6.6897\n",
      "Epoch: 1821, Train_loss: 0.0328 / Val_loss: 6.7118\n",
      "Epoch: 1822, Train_loss: 0.0564 / Val_loss: 6.7642\n",
      "Epoch: 1823, Train_loss: 0.0507 / Val_loss: 6.8180\n",
      "Epoch: 1824, Train_loss: 0.0476 / Val_loss: 6.8433\n",
      "Epoch: 1825, Train_loss: 0.0343 / Val_loss: 6.8816\n",
      "Epoch: 1826, Train_loss: 0.0423 / Val_loss: 6.9176\n",
      "Epoch: 1827, Train_loss: 0.0610 / Val_loss: 6.9517\n",
      "Epoch: 1828, Train_loss: 0.0437 / Val_loss: 6.9794\n",
      "Epoch: 1829, Train_loss: 0.0455 / Val_loss: 7.0256\n",
      "Epoch: 1830, Train_loss: 0.0424 / Val_loss: 7.0675\n",
      "Epoch: 1831, Train_loss: 0.0491 / Val_loss: 7.0759\n",
      "Epoch: 1832, Train_loss: 0.0707 / Val_loss: 7.0923\n",
      "Epoch: 1833, Train_loss: 0.0440 / Val_loss: 7.0874\n",
      "Epoch: 1834, Train_loss: 0.0410 / Val_loss: 7.0981\n",
      "Epoch: 1835, Train_loss: 0.0447 / Val_loss: 7.0882\n",
      "Epoch: 1836, Train_loss: 0.0640 / Val_loss: 7.0496\n",
      "Epoch: 1837, Train_loss: 0.0402 / Val_loss: 6.9992\n",
      "Epoch: 1838, Train_loss: 0.0240 / Val_loss: 6.9681\n",
      "Epoch: 1839, Train_loss: 0.0679 / Val_loss: 6.9561\n",
      "Epoch: 1840, Train_loss: 0.0533 / Val_loss: 6.9477\n",
      "Epoch: 1841, Train_loss: 0.0630 / Val_loss: 6.9695\n",
      "Epoch: 1842, Train_loss: 0.0390 / Val_loss: 7.0035\n",
      "Epoch: 1843, Train_loss: 0.0434 / Val_loss: 7.0417\n",
      "Epoch: 1844, Train_loss: 0.0278 / Val_loss: 7.0781\n",
      "Epoch: 1845, Train_loss: 0.0206 / Val_loss: 7.1233\n",
      "Epoch: 1846, Train_loss: 0.0560 / Val_loss: 7.1437\n",
      "Epoch: 1847, Train_loss: 0.0300 / Val_loss: 7.1721\n",
      "Epoch: 1848, Train_loss: 0.0450 / Val_loss: 7.1988\n",
      "Epoch: 1849, Train_loss: 0.0751 / Val_loss: 7.1552\n",
      "Epoch: 1850, Train_loss: 0.0604 / Val_loss: 7.0811\n",
      "Epoch: 1851, Train_loss: 0.0307 / Val_loss: 7.0268\n",
      "Epoch: 1852, Train_loss: 0.0364 / Val_loss: 6.9901\n",
      "Epoch: 1853, Train_loss: 0.0667 / Val_loss: 6.9746\n",
      "Epoch: 1854, Train_loss: 0.0236 / Val_loss: 6.9707\n",
      "Epoch: 1855, Train_loss: 0.0812 / Val_loss: 6.9759\n",
      "Epoch: 1856, Train_loss: 0.0277 / Val_loss: 6.9835\n",
      "Epoch: 1857, Train_loss: 0.0389 / Val_loss: 7.0141\n",
      "Epoch: 1858, Train_loss: 0.0403 / Val_loss: 7.0819\n",
      "Epoch: 1859, Train_loss: 0.0405 / Val_loss: 7.1733\n",
      "Epoch: 1860, Train_loss: 0.0350 / Val_loss: 7.2728\n",
      "Epoch: 1861, Train_loss: 0.0437 / Val_loss: 7.3781\n",
      "Epoch: 1862, Train_loss: 0.0295 / Val_loss: 7.4928\n",
      "Epoch: 1863, Train_loss: 0.0573 / Val_loss: 7.5995\n",
      "Epoch: 1864, Train_loss: 0.0499 / Val_loss: 7.6526\n",
      "Epoch: 1865, Train_loss: 0.0439 / Val_loss: 7.6611\n",
      "Epoch: 1866, Train_loss: 0.0645 / Val_loss: 7.6245\n",
      "Epoch: 1867, Train_loss: 0.0678 / Val_loss: 7.5340\n",
      "Epoch: 1868, Train_loss: 0.0380 / Val_loss: 7.4517\n",
      "Epoch: 1869, Train_loss: 0.0245 / Val_loss: 7.3621\n",
      "Epoch: 1870, Train_loss: 0.0473 / Val_loss: 7.2774\n",
      "Epoch: 1871, Train_loss: 0.0440 / Val_loss: 7.1992\n",
      "Epoch: 1872, Train_loss: 0.0545 / Val_loss: 7.1282\n",
      "Epoch: 1873, Train_loss: 0.0377 / Val_loss: 7.0852\n",
      "Epoch: 1874, Train_loss: 0.0374 / Val_loss: 7.0459\n",
      "Epoch: 1875, Train_loss: 0.0505 / Val_loss: 7.0391\n",
      "Epoch: 1876, Train_loss: 0.0412 / Val_loss: 7.0335\n",
      "Epoch: 1877, Train_loss: 0.0322 / Val_loss: 7.0497\n",
      "Epoch: 1878, Train_loss: 0.0209 / Val_loss: 7.0563\n",
      "Epoch: 1879, Train_loss: 0.0572 / Val_loss: 7.0763\n",
      "Epoch: 1880, Train_loss: 0.0476 / Val_loss: 7.0799\n",
      "Epoch: 1881, Train_loss: 0.0388 / Val_loss: 7.1023\n",
      "Epoch: 1882, Train_loss: 0.0353 / Val_loss: 7.1144\n",
      "Epoch: 1883, Train_loss: 0.0323 / Val_loss: 7.1276\n",
      "Epoch: 1884, Train_loss: 0.0497 / Val_loss: 7.1196\n",
      "Epoch: 1885, Train_loss: 0.0567 / Val_loss: 7.1212\n",
      "Epoch: 1886, Train_loss: 0.0416 / Val_loss: 7.1185\n",
      "Epoch: 1887, Train_loss: 0.0151 / Val_loss: 7.1380\n",
      "Epoch: 1888, Train_loss: 0.0563 / Val_loss: 7.1310\n",
      "Epoch: 1889, Train_loss: 0.0273 / Val_loss: 7.1697\n",
      "Epoch: 1890, Train_loss: 0.0761 / Val_loss: 7.1795\n",
      "Epoch: 1891, Train_loss: 0.0367 / Val_loss: 7.2140\n",
      "Epoch: 1892, Train_loss: 0.0315 / Val_loss: 7.2679\n",
      "Epoch: 1893, Train_loss: 0.0491 / Val_loss: 7.3320\n",
      "Epoch: 1894, Train_loss: 0.0737 / Val_loss: 7.3717\n",
      "Epoch: 1895, Train_loss: 0.0227 / Val_loss: 7.4284\n",
      "Epoch: 1896, Train_loss: 0.0703 / Val_loss: 7.4150\n",
      "Epoch: 1897, Train_loss: 0.0274 / Val_loss: 7.4095\n",
      "Epoch: 1898, Train_loss: 0.0580 / Val_loss: 7.3926\n",
      "Epoch: 1899, Train_loss: 0.0577 / Val_loss: 7.3391\n",
      "Epoch: 1900, Train_loss: 0.0464 / Val_loss: 7.3303\n",
      "Epoch: 1901, Train_loss: 0.0207 / Val_loss: 7.3277\n",
      "Epoch: 1902, Train_loss: 0.0368 / Val_loss: 7.3233\n",
      "Epoch: 1903, Train_loss: 0.0525 / Val_loss: 7.3257\n",
      "Epoch: 1904, Train_loss: 0.0499 / Val_loss: 7.3143\n",
      "Epoch: 1905, Train_loss: 0.0403 / Val_loss: 7.3352\n",
      "Epoch: 1906, Train_loss: 0.0370 / Val_loss: 7.3569\n",
      "Epoch: 1907, Train_loss: 0.0529 / Val_loss: 7.3768\n",
      "Epoch: 1908, Train_loss: 0.0369 / Val_loss: 7.3899\n",
      "Epoch: 1909, Train_loss: 0.0620 / Val_loss: 7.4311\n",
      "Epoch: 1910, Train_loss: 0.0725 / Val_loss: 7.4818\n",
      "Epoch: 1911, Train_loss: 0.0426 / Val_loss: 7.5438\n",
      "Epoch: 1912, Train_loss: 0.0320 / Val_loss: 7.6110\n",
      "Epoch: 1913, Train_loss: 0.0389 / Val_loss: 7.6511\n",
      "Epoch: 1914, Train_loss: 0.0551 / Val_loss: 7.6434\n",
      "Epoch: 1915, Train_loss: 0.0430 / Val_loss: 7.6347\n",
      "Epoch: 1916, Train_loss: 0.0529 / Val_loss: 7.6257\n",
      "Epoch: 1917, Train_loss: 0.0676 / Val_loss: 7.5786\n",
      "Epoch: 1918, Train_loss: 0.0481 / Val_loss: 7.5507\n",
      "Epoch: 1919, Train_loss: 0.0562 / Val_loss: 7.4668\n",
      "Epoch: 1920, Train_loss: 0.0376 / Val_loss: 7.4328\n",
      "Epoch: 1921, Train_loss: 0.0467 / Val_loss: 7.3665\n",
      "Epoch: 1922, Train_loss: 0.0361 / Val_loss: 7.3180\n",
      "Epoch: 1923, Train_loss: 0.0481 / Val_loss: 7.2690\n",
      "Epoch: 1924, Train_loss: 0.0602 / Val_loss: 7.2082\n",
      "Epoch: 1925, Train_loss: 0.0195 / Val_loss: 7.1734\n",
      "Epoch: 1926, Train_loss: 0.0270 / Val_loss: 7.1297\n",
      "Epoch: 1927, Train_loss: 0.0446 / Val_loss: 7.1123\n",
      "Epoch: 1928, Train_loss: 0.0485 / Val_loss: 7.1225\n",
      "Epoch: 1929, Train_loss: 0.0435 / Val_loss: 7.1439\n",
      "Epoch: 1930, Train_loss: 0.0523 / Val_loss: 7.1851\n",
      "Epoch: 1931, Train_loss: 0.0444 / Val_loss: 7.2053\n",
      "Epoch: 1932, Train_loss: 0.0286 / Val_loss: 7.2415\n",
      "Epoch: 1933, Train_loss: 0.0381 / Val_loss: 7.2875\n",
      "Epoch: 1934, Train_loss: 0.0376 / Val_loss: 7.3359\n",
      "Epoch: 1935, Train_loss: 0.0320 / Val_loss: 7.3919\n",
      "Epoch: 1936, Train_loss: 0.0227 / Val_loss: 7.4465\n",
      "Epoch: 1937, Train_loss: 0.0254 / Val_loss: 7.4933\n",
      "Epoch: 1938, Train_loss: 0.0308 / Val_loss: 7.5368\n",
      "Epoch: 1939, Train_loss: 0.0333 / Val_loss: 7.5866\n",
      "Epoch: 1940, Train_loss: 0.0621 / Val_loss: 7.6408\n",
      "Epoch: 1941, Train_loss: 0.0240 / Val_loss: 7.7126\n",
      "Epoch: 1942, Train_loss: 0.0327 / Val_loss: 7.7841\n",
      "Epoch: 1943, Train_loss: 0.0299 / Val_loss: 7.8703\n",
      "Epoch: 1944, Train_loss: 0.0343 / Val_loss: 7.9456\n",
      "Epoch: 1945, Train_loss: 0.0421 / Val_loss: 7.9878\n",
      "Epoch: 1946, Train_loss: 0.0337 / Val_loss: 8.0463\n",
      "Epoch: 1947, Train_loss: 0.0445 / Val_loss: 8.1066\n",
      "Epoch: 1948, Train_loss: 0.0401 / Val_loss: 8.1491\n",
      "Epoch: 1949, Train_loss: 0.0300 / Val_loss: 8.1909\n",
      "Epoch: 1950, Train_loss: 0.0358 / Val_loss: 8.2406\n",
      "Epoch: 1951, Train_loss: 0.0266 / Val_loss: 8.2785\n",
      "Epoch: 1952, Train_loss: 0.0285 / Val_loss: 8.3356\n",
      "Epoch: 1953, Train_loss: 0.0129 / Val_loss: 8.4073\n",
      "Epoch: 1954, Train_loss: 0.0367 / Val_loss: 8.4801\n",
      "Epoch: 1955, Train_loss: 0.0500 / Val_loss: 8.5583\n",
      "Epoch: 1956, Train_loss: 0.0257 / Val_loss: 8.6646\n",
      "Epoch: 1957, Train_loss: 0.0456 / Val_loss: 8.7875\n",
      "Epoch: 1958, Train_loss: 0.0280 / Val_loss: 8.9041\n",
      "Epoch: 1959, Train_loss: 0.0261 / Val_loss: 8.9711\n",
      "Epoch: 1960, Train_loss: 0.0598 / Val_loss: 8.9922\n",
      "Epoch: 1961, Train_loss: 0.0361 / Val_loss: 8.9605\n",
      "Epoch: 1962, Train_loss: 0.0558 / Val_loss: 8.9057\n",
      "Epoch: 1963, Train_loss: 0.0457 / Val_loss: 8.7727\n",
      "Epoch: 1964, Train_loss: 0.0568 / Val_loss: 8.5791\n",
      "Epoch: 1965, Train_loss: 0.0312 / Val_loss: 8.4071\n",
      "Epoch: 1966, Train_loss: 0.0640 / Val_loss: 8.2740\n",
      "Epoch: 1967, Train_loss: 0.0201 / Val_loss: 8.1644\n",
      "Epoch: 1968, Train_loss: 0.0320 / Val_loss: 8.0234\n",
      "Epoch: 1969, Train_loss: 0.0653 / Val_loss: 7.9649\n",
      "Epoch: 1970, Train_loss: 0.0528 / Val_loss: 7.9348\n",
      "Epoch: 1971, Train_loss: 0.0489 / Val_loss: 7.8917\n",
      "Epoch: 1972, Train_loss: 0.0624 / Val_loss: 7.8753\n",
      "Epoch: 1973, Train_loss: 0.0559 / Val_loss: 7.8781\n",
      "Epoch: 1974, Train_loss: 0.0651 / Val_loss: 7.9159\n",
      "Epoch: 1975, Train_loss: 0.0219 / Val_loss: 7.9633\n",
      "Epoch: 1976, Train_loss: 0.0270 / Val_loss: 8.0125\n",
      "Epoch: 1977, Train_loss: 0.0454 / Val_loss: 8.0692\n",
      "Epoch: 1978, Train_loss: 0.0214 / Val_loss: 8.1497\n",
      "Epoch: 1979, Train_loss: 0.0460 / Val_loss: 8.2131\n",
      "Epoch: 1980, Train_loss: 0.0491 / Val_loss: 8.2214\n",
      "Epoch: 1981, Train_loss: 0.0462 / Val_loss: 8.2098\n",
      "Epoch: 1982, Train_loss: 0.0438 / Val_loss: 8.1753\n",
      "Epoch: 1983, Train_loss: 0.0264 / Val_loss: 8.1595\n",
      "Epoch: 1984, Train_loss: 0.0322 / Val_loss: 8.1494\n",
      "Epoch: 1985, Train_loss: 0.0356 / Val_loss: 8.1458\n",
      "Epoch: 1986, Train_loss: 0.0458 / Val_loss: 8.1560\n",
      "Epoch: 1987, Train_loss: 0.0282 / Val_loss: 8.1977\n",
      "Epoch: 1988, Train_loss: 0.0388 / Val_loss: 8.2332\n",
      "Epoch: 1989, Train_loss: 0.0323 / Val_loss: 8.2811\n",
      "Epoch: 1990, Train_loss: 0.0246 / Val_loss: 8.3506\n",
      "Epoch: 1991, Train_loss: 0.0800 / Val_loss: 8.4340\n",
      "Epoch: 1992, Train_loss: 0.0248 / Val_loss: 8.5236\n",
      "Epoch: 1993, Train_loss: 0.0404 / Val_loss: 8.6020\n",
      "Epoch: 1994, Train_loss: 0.0443 / Val_loss: 8.6510\n",
      "Epoch: 1995, Train_loss: 0.0404 / Val_loss: 8.6661\n",
      "Epoch: 1996, Train_loss: 0.0540 / Val_loss: 8.6584\n",
      "Epoch: 1997, Train_loss: 0.0345 / Val_loss: 8.6490\n",
      "Epoch: 1998, Train_loss: 0.0170 / Val_loss: 8.6496\n",
      "Epoch: 1999, Train_loss: 0.0411 / Val_loss: 8.6377\n",
      "Epoch: 2000, Train_loss: 0.0372 / Val_loss: 8.6058\n"
     ]
    }
   ],
   "source": [
    "weight = torch.Tensor([1.0, 2.5])\n",
    "log_softmax = torch.nn.LogSoftmax(dim=1)\n",
    "criterion = torch.nn.NLLLoss(weight=weight)  # Define loss criterion.\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-4)  # Define optimizer.\n",
    "\n",
    "losses = []\n",
    "v_losses = []\n",
    "best_v_loss = 100000\n",
    "COUNT = 2000\n",
    "val_early_stop_count = COUNT\n",
    "val_early_stop_continuous_flag = False\n",
    "\n",
    "for epoch in range(1, 2001):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    X_tmp = data.x[data.train_mask]\n",
    "    y_tmp = data.y[data.train_mask].to(dtype=torch.long)\n",
    "    preds = model(X_tmp)  # Perform a single forward pass.\n",
    "    loss = criterion(log_softmax(preds), y_tmp)  # Compute the loss solely based on the training nodes.\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        v_X_tmp = data.x[data.val_mask]\n",
    "        v_y_tmp = data.y[data.val_mask].to(dtype=torch.long)\n",
    "        v_preds = model(v_X_tmp)\n",
    "        v_loss = criterion(log_softmax(v_preds), v_y_tmp)\n",
    "        v_losses.append(v_loss.item())\n",
    "    print(f'Epoch: {epoch:03d}, Train_loss: {loss:.4f} / Val_loss: {v_loss:.4f}')\n",
    "    \n",
    "    if v_loss.item() < best_v_loss:\n",
    "        best_v_loss = v_loss.item()\n",
    "        val_early_stop_continuous_flag = False\n",
    "        val_early_stop_count = COUNT\n",
    "    else:\n",
    "        val_early_stop_continuous_flag = True\n",
    "        val_early_stop_count -= 1\n",
    "        if val_early_stop_count == 0:\n",
    "            print(f\"============== Early stopped at Epoch: {epoch}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.plot(v_losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Train\", \"Val\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8095\n",
      "Precision: 0.5625\n",
      "Recall: 0.5000\n",
      "f1 score: 0.5294\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "X_tmp_test = data.x[data.test_mask]\n",
    "y_tmp_test = data.y[data.test_mask]\n",
    "out = model(X_tmp_test)\n",
    "pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "\n",
    "cm = confusion_matrix(y_tmp_test, pred, normalize=None)\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    ")\n",
    "\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_tmp_test.numpy(), pred.numpy()):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_tmp_test.numpy(), pred.numpy()):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_tmp_test.numpy(), pred.numpy()):.4f}\")\n",
    "print(f\"f1 score: {f1_score(y_tmp_test.numpy(), pred.numpy()):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341,826\n",
      "GCN model number of params: 341,826\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234567)\n",
    "        self.conv1 = GCNConv(data.num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels * 2)\n",
    "        self.conv3 = GCNConv(hidden_channels * 2, hidden_channels * 4)\n",
    "        self.conv4 = GCNConv(hidden_channels * 4, hidden_channels * 8)\n",
    "        self.conv5 = GCNConv(hidden_channels * 8, hidden_channels * 4)\n",
    "        self.conv6 = GCNConv(hidden_channels * 4, hidden_channels * 2)\n",
    "        self.conv7 = GCNConv(hidden_channels * 2, 2)\n",
    "        self.norm1 = LayerNorm(hidden_channels)\n",
    "        self.norm2 = LayerNorm(hidden_channels * 2)\n",
    "        self.norm3 = LayerNorm(hidden_channels * 4)\n",
    "        self.norm4 = LayerNorm(hidden_channels * 8)\n",
    "        self.norm5 = LayerNorm(hidden_channels * 4)\n",
    "        self.norm6 = LayerNorm(hidden_channels * 2)\n",
    "        \n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.norm1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.norm2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.norm3(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = self.norm4(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = self.norm5(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv6(x, edge_index)\n",
    "        x = self.norm6(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv7(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=64)\n",
    "print(f\"GCN model number of params: {count_parameters(model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train_loss: 0.8221 / Val_loss: 0.8570\n",
      "Epoch: 002, Train_loss: 0.7607 / Val_loss: 0.7261\n",
      "Epoch: 003, Train_loss: 0.7550 / Val_loss: 0.8398\n",
      "Epoch: 004, Train_loss: 0.7822 / Val_loss: 0.7582\n",
      "Epoch: 005, Train_loss: 0.7208 / Val_loss: 0.8050\n",
      "Epoch: 006, Train_loss: 0.7443 / Val_loss: 0.7122\n",
      "Epoch: 007, Train_loss: 0.7298 / Val_loss: 0.6933\n",
      "Epoch: 008, Train_loss: 0.7257 / Val_loss: 0.7115\n",
      "Epoch: 009, Train_loss: 0.7552 / Val_loss: 0.7339\n",
      "Epoch: 010, Train_loss: 0.6908 / Val_loss: 0.6563\n",
      "Epoch: 011, Train_loss: 0.6958 / Val_loss: 0.6859\n",
      "Epoch: 012, Train_loss: 0.7203 / Val_loss: 0.7185\n",
      "Epoch: 013, Train_loss: 0.6947 / Val_loss: 0.6023\n",
      "Epoch: 014, Train_loss: 0.6896 / Val_loss: 0.6796\n",
      "Epoch: 015, Train_loss: 0.7034 / Val_loss: 0.7772\n",
      "Epoch: 016, Train_loss: 0.6859 / Val_loss: 0.6797\n",
      "Epoch: 017, Train_loss: 0.6715 / Val_loss: 0.7183\n",
      "Epoch: 018, Train_loss: 0.6676 / Val_loss: 0.6965\n",
      "Epoch: 019, Train_loss: 0.7092 / Val_loss: 0.7068\n",
      "Epoch: 020, Train_loss: 0.7023 / Val_loss: 0.6631\n",
      "Epoch: 021, Train_loss: 0.6625 / Val_loss: 0.6793\n",
      "Epoch: 022, Train_loss: 0.6548 / Val_loss: 0.6769\n",
      "Epoch: 023, Train_loss: 0.6961 / Val_loss: 0.6757\n",
      "Epoch: 024, Train_loss: 0.6648 / Val_loss: 0.6202\n",
      "Epoch: 025, Train_loss: 0.7043 / Val_loss: 0.6196\n",
      "Epoch: 026, Train_loss: 0.6743 / Val_loss: 0.6866\n",
      "Epoch: 027, Train_loss: 0.6628 / Val_loss: 0.6912\n",
      "Epoch: 028, Train_loss: 0.6766 / Val_loss: 0.7325\n",
      "Epoch: 029, Train_loss: 0.7056 / Val_loss: 0.6299\n",
      "Epoch: 030, Train_loss: 0.6815 / Val_loss: 0.6677\n",
      "Epoch: 031, Train_loss: 0.6754 / Val_loss: 0.7004\n",
      "Epoch: 032, Train_loss: 0.6889 / Val_loss: 0.6138\n",
      "Epoch: 033, Train_loss: 0.6744 / Val_loss: 0.6984\n",
      "Epoch: 034, Train_loss: 0.6856 / Val_loss: 0.7162\n",
      "Epoch: 035, Train_loss: 0.6539 / Val_loss: 0.6717\n",
      "Epoch: 036, Train_loss: 0.6532 / Val_loss: 0.6966\n",
      "Epoch: 037, Train_loss: 0.6725 / Val_loss: 0.6316\n",
      "Epoch: 038, Train_loss: 0.6645 / Val_loss: 0.6756\n",
      "Epoch: 039, Train_loss: 0.6561 / Val_loss: 0.6542\n",
      "Epoch: 040, Train_loss: 0.6684 / Val_loss: 0.6715\n",
      "Epoch: 041, Train_loss: 0.6412 / Val_loss: 0.6730\n",
      "Epoch: 042, Train_loss: 0.6538 / Val_loss: 0.6280\n",
      "Epoch: 043, Train_loss: 0.6606 / Val_loss: 0.6720\n",
      "Epoch: 044, Train_loss: 0.6857 / Val_loss: 0.7096\n",
      "Epoch: 045, Train_loss: 0.6521 / Val_loss: 0.6657\n",
      "Epoch: 046, Train_loss: 0.6701 / Val_loss: 0.6716\n",
      "Epoch: 047, Train_loss: 0.6621 / Val_loss: 0.7446\n",
      "Epoch: 048, Train_loss: 0.6575 / Val_loss: 0.6193\n",
      "Epoch: 049, Train_loss: 0.6620 / Val_loss: 0.6868\n",
      "Epoch: 050, Train_loss: 0.6288 / Val_loss: 0.6739\n",
      "Epoch: 051, Train_loss: 0.6717 / Val_loss: 0.6740\n",
      "Epoch: 052, Train_loss: 0.6422 / Val_loss: 0.6542\n",
      "Epoch: 053, Train_loss: 0.6462 / Val_loss: 0.6691\n",
      "Epoch: 054, Train_loss: 0.6369 / Val_loss: 0.6617\n",
      "Epoch: 055, Train_loss: 0.6500 / Val_loss: 0.7171\n",
      "Epoch: 056, Train_loss: 0.6435 / Val_loss: 0.6934\n",
      "Epoch: 057, Train_loss: 0.6531 / Val_loss: 0.7159\n",
      "Epoch: 058, Train_loss: 0.6437 / Val_loss: 0.6621\n",
      "Epoch: 059, Train_loss: 0.6385 / Val_loss: 0.6941\n",
      "Epoch: 060, Train_loss: 0.6511 / Val_loss: 0.7200\n",
      "Epoch: 061, Train_loss: 0.6707 / Val_loss: 0.7521\n",
      "Epoch: 062, Train_loss: 0.6573 / Val_loss: 0.6579\n",
      "Epoch: 063, Train_loss: 0.6349 / Val_loss: 0.7046\n",
      "Epoch: 064, Train_loss: 0.6391 / Val_loss: 0.6689\n",
      "Epoch: 065, Train_loss: 0.6599 / Val_loss: 0.6686\n",
      "Epoch: 066, Train_loss: 0.6487 / Val_loss: 0.7181\n",
      "Epoch: 067, Train_loss: 0.6402 / Val_loss: 0.7103\n",
      "Epoch: 068, Train_loss: 0.6650 / Val_loss: 0.7618\n",
      "Epoch: 069, Train_loss: 0.6391 / Val_loss: 0.7121\n",
      "Epoch: 070, Train_loss: 0.6350 / Val_loss: 0.7427\n",
      "Epoch: 071, Train_loss: 0.6481 / Val_loss: 0.6792\n",
      "Epoch: 072, Train_loss: 0.6275 / Val_loss: 0.7167\n",
      "Epoch: 073, Train_loss: 0.6328 / Val_loss: 0.7572\n",
      "Epoch: 074, Train_loss: 0.6401 / Val_loss: 0.7226\n",
      "Epoch: 075, Train_loss: 0.6382 / Val_loss: 0.7619\n",
      "Epoch: 076, Train_loss: 0.6395 / Val_loss: 0.7064\n",
      "Epoch: 077, Train_loss: 0.6410 / Val_loss: 0.6878\n",
      "Epoch: 078, Train_loss: 0.6327 / Val_loss: 0.7418\n",
      "Epoch: 079, Train_loss: 0.6387 / Val_loss: 0.7402\n",
      "Epoch: 080, Train_loss: 0.6674 / Val_loss: 0.6732\n",
      "Epoch: 081, Train_loss: 0.6446 / Val_loss: 0.7086\n",
      "Epoch: 082, Train_loss: 0.6218 / Val_loss: 0.7108\n",
      "Epoch: 083, Train_loss: 0.6389 / Val_loss: 0.7098\n",
      "Epoch: 084, Train_loss: 0.6496 / Val_loss: 0.7192\n",
      "Epoch: 085, Train_loss: 0.6327 / Val_loss: 0.7510\n",
      "Epoch: 086, Train_loss: 0.6633 / Val_loss: 0.6493\n",
      "Epoch: 087, Train_loss: 0.6451 / Val_loss: 0.7366\n",
      "Epoch: 088, Train_loss: 0.6622 / Val_loss: 0.7151\n",
      "Epoch: 089, Train_loss: 0.6337 / Val_loss: 0.7660\n",
      "Epoch: 090, Train_loss: 0.6474 / Val_loss: 0.6951\n",
      "Epoch: 091, Train_loss: 0.6404 / Val_loss: 0.7025\n",
      "Epoch: 092, Train_loss: 0.6533 / Val_loss: 0.7198\n",
      "Epoch: 093, Train_loss: 0.6420 / Val_loss: 0.7110\n",
      "Epoch: 094, Train_loss: 0.6164 / Val_loss: 0.7048\n",
      "Epoch: 095, Train_loss: 0.6376 / Val_loss: 0.7137\n",
      "Epoch: 096, Train_loss: 0.6355 / Val_loss: 0.7372\n",
      "Epoch: 097, Train_loss: 0.6700 / Val_loss: 0.6883\n",
      "Epoch: 098, Train_loss: 0.6289 / Val_loss: 0.7461\n",
      "Epoch: 099, Train_loss: 0.6321 / Val_loss: 0.6740\n",
      "Epoch: 100, Train_loss: 0.6159 / Val_loss: 0.7386\n",
      "Epoch: 101, Train_loss: 0.6139 / Val_loss: 0.7823\n",
      "Epoch: 102, Train_loss: 0.6267 / Val_loss: 0.6909\n",
      "Epoch: 103, Train_loss: 0.6391 / Val_loss: 0.7802\n",
      "Epoch: 104, Train_loss: 0.6357 / Val_loss: 0.7729\n",
      "Epoch: 105, Train_loss: 0.6454 / Val_loss: 0.6921\n",
      "Epoch: 106, Train_loss: 0.6357 / Val_loss: 0.7725\n",
      "Epoch: 107, Train_loss: 0.6422 / Val_loss: 0.6508\n",
      "Epoch: 108, Train_loss: 0.6406 / Val_loss: 0.7886\n",
      "Epoch: 109, Train_loss: 0.6306 / Val_loss: 0.7120\n",
      "Epoch: 110, Train_loss: 0.6490 / Val_loss: 0.7855\n",
      "Epoch: 111, Train_loss: 0.6497 / Val_loss: 0.7166\n",
      "Epoch: 112, Train_loss: 0.6372 / Val_loss: 0.7085\n",
      "Epoch: 113, Train_loss: 0.6173 / Val_loss: 0.6711\n",
      "Epoch: 114, Train_loss: 0.6079 / Val_loss: 0.6725\n",
      "Epoch: 115, Train_loss: 0.6419 / Val_loss: 0.6956\n",
      "Epoch: 116, Train_loss: 0.6340 / Val_loss: 0.7107\n",
      "Epoch: 117, Train_loss: 0.6210 / Val_loss: 0.7424\n",
      "Epoch: 118, Train_loss: 0.6280 / Val_loss: 0.7174\n",
      "Epoch: 119, Train_loss: 0.6263 / Val_loss: 0.7297\n",
      "Epoch: 120, Train_loss: 0.6221 / Val_loss: 0.7244\n",
      "Epoch: 121, Train_loss: 0.6344 / Val_loss: 0.7100\n",
      "Epoch: 122, Train_loss: 0.6140 / Val_loss: 0.7817\n",
      "Epoch: 123, Train_loss: 0.6412 / Val_loss: 0.7646\n",
      "Epoch: 124, Train_loss: 0.6329 / Val_loss: 0.6495\n",
      "Epoch: 125, Train_loss: 0.6333 / Val_loss: 0.7919\n",
      "Epoch: 126, Train_loss: 0.6288 / Val_loss: 0.7979\n",
      "Epoch: 127, Train_loss: 0.6194 / Val_loss: 0.7064\n",
      "Epoch: 128, Train_loss: 0.6301 / Val_loss: 0.6759\n",
      "Epoch: 129, Train_loss: 0.6215 / Val_loss: 0.7960\n",
      "Epoch: 130, Train_loss: 0.6245 / Val_loss: 0.7036\n",
      "Epoch: 131, Train_loss: 0.6236 / Val_loss: 0.7350\n",
      "Epoch: 132, Train_loss: 0.6224 / Val_loss: 0.7169\n",
      "Epoch: 133, Train_loss: 0.6306 / Val_loss: 0.7323\n",
      "Epoch: 134, Train_loss: 0.6284 / Val_loss: 0.7027\n",
      "Epoch: 135, Train_loss: 0.6237 / Val_loss: 0.7242\n",
      "Epoch: 136, Train_loss: 0.6295 / Val_loss: 0.7587\n",
      "Epoch: 137, Train_loss: 0.6017 / Val_loss: 0.7304\n",
      "Epoch: 138, Train_loss: 0.6185 / Val_loss: 0.7307\n",
      "Epoch: 139, Train_loss: 0.6177 / Val_loss: 0.7519\n",
      "Epoch: 140, Train_loss: 0.6196 / Val_loss: 0.7494\n",
      "Epoch: 141, Train_loss: 0.6339 / Val_loss: 0.7561\n",
      "Epoch: 142, Train_loss: 0.6133 / Val_loss: 0.7057\n",
      "Epoch: 143, Train_loss: 0.6333 / Val_loss: 0.8166\n",
      "Epoch: 144, Train_loss: 0.6018 / Val_loss: 0.7414\n",
      "Epoch: 145, Train_loss: 0.6272 / Val_loss: 0.7770\n",
      "Epoch: 146, Train_loss: 0.6154 / Val_loss: 0.7382\n",
      "Epoch: 147, Train_loss: 0.6261 / Val_loss: 0.8006\n",
      "Epoch: 148, Train_loss: 0.6186 / Val_loss: 0.7765\n",
      "Epoch: 149, Train_loss: 0.6117 / Val_loss: 0.7877\n",
      "Epoch: 150, Train_loss: 0.6182 / Val_loss: 0.7294\n",
      "Epoch: 151, Train_loss: 0.6077 / Val_loss: 0.7908\n",
      "Epoch: 152, Train_loss: 0.6085 / Val_loss: 0.7951\n",
      "Epoch: 153, Train_loss: 0.6195 / Val_loss: 0.7249\n",
      "Epoch: 154, Train_loss: 0.6201 / Val_loss: 0.7704\n",
      "Epoch: 155, Train_loss: 0.6285 / Val_loss: 0.7462\n",
      "Epoch: 156, Train_loss: 0.6126 / Val_loss: 0.7383\n",
      "Epoch: 157, Train_loss: 0.5996 / Val_loss: 0.6867\n",
      "Epoch: 158, Train_loss: 0.6128 / Val_loss: 0.7705\n",
      "Epoch: 159, Train_loss: 0.6093 / Val_loss: 0.7503\n",
      "Epoch: 160, Train_loss: 0.6005 / Val_loss: 0.7538\n",
      "Epoch: 161, Train_loss: 0.6234 / Val_loss: 0.7054\n",
      "Epoch: 162, Train_loss: 0.6041 / Val_loss: 0.7272\n",
      "Epoch: 163, Train_loss: 0.6145 / Val_loss: 0.7547\n",
      "Epoch: 164, Train_loss: 0.6359 / Val_loss: 0.7455\n",
      "Epoch: 165, Train_loss: 0.6059 / Val_loss: 0.8221\n",
      "Epoch: 166, Train_loss: 0.6094 / Val_loss: 0.7042\n",
      "Epoch: 167, Train_loss: 0.5995 / Val_loss: 0.7921\n",
      "Epoch: 168, Train_loss: 0.6343 / Val_loss: 0.7673\n",
      "Epoch: 169, Train_loss: 0.6168 / Val_loss: 0.7214\n",
      "Epoch: 170, Train_loss: 0.6239 / Val_loss: 0.7185\n",
      "Epoch: 171, Train_loss: 0.6137 / Val_loss: 0.7462\n",
      "Epoch: 172, Train_loss: 0.6056 / Val_loss: 0.7445\n",
      "Epoch: 173, Train_loss: 0.6216 / Val_loss: 0.7094\n",
      "Epoch: 174, Train_loss: 0.5956 / Val_loss: 0.8285\n",
      "Epoch: 175, Train_loss: 0.5957 / Val_loss: 0.8117\n",
      "Epoch: 176, Train_loss: 0.6442 / Val_loss: 0.7636\n",
      "Epoch: 177, Train_loss: 0.6036 / Val_loss: 0.7440\n",
      "Epoch: 178, Train_loss: 0.6171 / Val_loss: 0.7713\n",
      "Epoch: 179, Train_loss: 0.6043 / Val_loss: 0.7276\n",
      "Epoch: 180, Train_loss: 0.6048 / Val_loss: 0.8253\n",
      "Epoch: 181, Train_loss: 0.6041 / Val_loss: 0.8072\n",
      "Epoch: 182, Train_loss: 0.6147 / Val_loss: 0.7330\n",
      "Epoch: 183, Train_loss: 0.6209 / Val_loss: 0.8477\n",
      "Epoch: 184, Train_loss: 0.6236 / Val_loss: 0.7061\n",
      "Epoch: 185, Train_loss: 0.6017 / Val_loss: 0.7409\n",
      "Epoch: 186, Train_loss: 0.6259 / Val_loss: 0.7666\n",
      "Epoch: 187, Train_loss: 0.6129 / Val_loss: 0.7428\n",
      "Epoch: 188, Train_loss: 0.6208 / Val_loss: 0.7329\n",
      "Epoch: 189, Train_loss: 0.6066 / Val_loss: 0.7828\n",
      "Epoch: 190, Train_loss: 0.6033 / Val_loss: 0.8199\n",
      "Epoch: 191, Train_loss: 0.5954 / Val_loss: 0.7730\n",
      "Epoch: 192, Train_loss: 0.6182 / Val_loss: 0.8020\n",
      "Epoch: 193, Train_loss: 0.6077 / Val_loss: 0.7819\n",
      "Epoch: 194, Train_loss: 0.6034 / Val_loss: 0.8248\n",
      "Epoch: 195, Train_loss: 0.6210 / Val_loss: 0.8417\n",
      "Epoch: 196, Train_loss: 0.5862 / Val_loss: 0.7868\n",
      "Epoch: 197, Train_loss: 0.6200 / Val_loss: 0.8385\n",
      "Epoch: 198, Train_loss: 0.6114 / Val_loss: 0.7630\n",
      "Epoch: 199, Train_loss: 0.6131 / Val_loss: 0.7661\n",
      "Epoch: 200, Train_loss: 0.6022 / Val_loss: 0.8285\n",
      "Epoch: 201, Train_loss: 0.5975 / Val_loss: 0.8568\n",
      "Epoch: 202, Train_loss: 0.6121 / Val_loss: 0.8718\n",
      "Epoch: 203, Train_loss: 0.6154 / Val_loss: 0.7527\n",
      "Epoch: 204, Train_loss: 0.6125 / Val_loss: 0.7831\n",
      "Epoch: 205, Train_loss: 0.6183 / Val_loss: 0.7292\n",
      "Epoch: 206, Train_loss: 0.6114 / Val_loss: 0.8453\n",
      "Epoch: 207, Train_loss: 0.6239 / Val_loss: 0.7508\n",
      "Epoch: 208, Train_loss: 0.6076 / Val_loss: 0.7333\n",
      "Epoch: 209, Train_loss: 0.6003 / Val_loss: 0.7787\n",
      "Epoch: 210, Train_loss: 0.6069 / Val_loss: 0.7899\n",
      "Epoch: 211, Train_loss: 0.6048 / Val_loss: 0.8270\n",
      "Epoch: 212, Train_loss: 0.5851 / Val_loss: 0.8247\n",
      "Epoch: 213, Train_loss: 0.5919 / Val_loss: 0.8892\n",
      "Epoch: 214, Train_loss: 0.5947 / Val_loss: 0.7651\n",
      "Epoch: 215, Train_loss: 0.5942 / Val_loss: 0.7342\n",
      "Epoch: 216, Train_loss: 0.6037 / Val_loss: 0.7941\n",
      "Epoch: 217, Train_loss: 0.5985 / Val_loss: 0.7436\n",
      "Epoch: 218, Train_loss: 0.6069 / Val_loss: 0.7745\n",
      "Epoch: 219, Train_loss: 0.6148 / Val_loss: 0.8025\n",
      "Epoch: 220, Train_loss: 0.6245 / Val_loss: 0.7055\n",
      "Epoch: 221, Train_loss: 0.5884 / Val_loss: 0.7629\n",
      "Epoch: 222, Train_loss: 0.6084 / Val_loss: 0.8102\n",
      "Epoch: 223, Train_loss: 0.6207 / Val_loss: 0.8093\n",
      "Epoch: 224, Train_loss: 0.6056 / Val_loss: 0.8663\n",
      "Epoch: 225, Train_loss: 0.6123 / Val_loss: 0.7291\n",
      "Epoch: 226, Train_loss: 0.5954 / Val_loss: 0.7448\n",
      "Epoch: 227, Train_loss: 0.6067 / Val_loss: 0.8423\n",
      "Epoch: 228, Train_loss: 0.6254 / Val_loss: 0.7538\n",
      "Epoch: 229, Train_loss: 0.5975 / Val_loss: 0.8045\n",
      "Epoch: 230, Train_loss: 0.6091 / Val_loss: 0.7457\n",
      "Epoch: 231, Train_loss: 0.5969 / Val_loss: 0.7960\n",
      "Epoch: 232, Train_loss: 0.5927 / Val_loss: 0.7785\n",
      "Epoch: 233, Train_loss: 0.5787 / Val_loss: 0.7767\n",
      "Epoch: 234, Train_loss: 0.6048 / Val_loss: 0.7082\n",
      "Epoch: 235, Train_loss: 0.6058 / Val_loss: 0.7565\n",
      "Epoch: 236, Train_loss: 0.6022 / Val_loss: 0.8359\n",
      "Epoch: 237, Train_loss: 0.5820 / Val_loss: 0.7637\n",
      "Epoch: 238, Train_loss: 0.6027 / Val_loss: 0.8743\n",
      "Epoch: 239, Train_loss: 0.6046 / Val_loss: 0.8283\n",
      "Epoch: 240, Train_loss: 0.5990 / Val_loss: 0.8147\n",
      "Epoch: 241, Train_loss: 0.6028 / Val_loss: 0.7629\n",
      "Epoch: 242, Train_loss: 0.5978 / Val_loss: 0.7555\n",
      "Epoch: 243, Train_loss: 0.5934 / Val_loss: 0.7338\n",
      "Epoch: 244, Train_loss: 0.5981 / Val_loss: 0.7742\n",
      "Epoch: 245, Train_loss: 0.5725 / Val_loss: 0.7924\n",
      "Epoch: 246, Train_loss: 0.6025 / Val_loss: 0.7709\n",
      "Epoch: 247, Train_loss: 0.5757 / Val_loss: 0.7875\n",
      "Epoch: 248, Train_loss: 0.6144 / Val_loss: 0.7955\n",
      "Epoch: 249, Train_loss: 0.5935 / Val_loss: 0.7830\n",
      "Epoch: 250, Train_loss: 0.5842 / Val_loss: 0.7343\n",
      "Epoch: 251, Train_loss: 0.5965 / Val_loss: 0.7147\n",
      "Epoch: 252, Train_loss: 0.5792 / Val_loss: 0.7527\n",
      "Epoch: 253, Train_loss: 0.6028 / Val_loss: 0.8275\n",
      "Epoch: 254, Train_loss: 0.6009 / Val_loss: 0.7441\n",
      "Epoch: 255, Train_loss: 0.5903 / Val_loss: 0.7917\n",
      "Epoch: 256, Train_loss: 0.5831 / Val_loss: 0.8037\n",
      "Epoch: 257, Train_loss: 0.5888 / Val_loss: 0.8324\n",
      "Epoch: 258, Train_loss: 0.5871 / Val_loss: 0.7119\n",
      "Epoch: 259, Train_loss: 0.5969 / Val_loss: 0.7986\n",
      "Epoch: 260, Train_loss: 0.5936 / Val_loss: 0.8285\n",
      "Epoch: 261, Train_loss: 0.5883 / Val_loss: 0.8469\n",
      "Epoch: 262, Train_loss: 0.5843 / Val_loss: 0.7987\n",
      "Epoch: 263, Train_loss: 0.5933 / Val_loss: 0.7373\n",
      "Epoch: 264, Train_loss: 0.5883 / Val_loss: 0.7876\n",
      "Epoch: 265, Train_loss: 0.5950 / Val_loss: 0.7200\n",
      "Epoch: 266, Train_loss: 0.5972 / Val_loss: 0.7969\n",
      "Epoch: 267, Train_loss: 0.5810 / Val_loss: 0.7295\n",
      "Epoch: 268, Train_loss: 0.5747 / Val_loss: 0.7530\n",
      "Epoch: 269, Train_loss: 0.5860 / Val_loss: 0.7565\n",
      "Epoch: 270, Train_loss: 0.5974 / Val_loss: 0.7115\n",
      "Epoch: 271, Train_loss: 0.5849 / Val_loss: 0.9443\n",
      "Epoch: 272, Train_loss: 0.6329 / Val_loss: 0.7242\n",
      "Epoch: 273, Train_loss: 0.5802 / Val_loss: 0.9731\n",
      "Epoch: 274, Train_loss: 0.6195 / Val_loss: 0.7950\n",
      "Epoch: 275, Train_loss: 0.5865 / Val_loss: 0.7304\n",
      "Epoch: 276, Train_loss: 0.5969 / Val_loss: 0.8286\n",
      "Epoch: 277, Train_loss: 0.5885 / Val_loss: 0.7535\n",
      "Epoch: 278, Train_loss: 0.6011 / Val_loss: 0.8520\n",
      "Epoch: 279, Train_loss: 0.5787 / Val_loss: 0.8268\n",
      "Epoch: 280, Train_loss: 0.6034 / Val_loss: 0.7553\n",
      "Epoch: 281, Train_loss: 0.6252 / Val_loss: 0.7275\n",
      "Epoch: 282, Train_loss: 0.5873 / Val_loss: 0.8143\n",
      "Epoch: 283, Train_loss: 0.5950 / Val_loss: 0.7395\n",
      "Epoch: 284, Train_loss: 0.6069 / Val_loss: 0.8197\n",
      "Epoch: 285, Train_loss: 0.5762 / Val_loss: 0.8322\n",
      "Epoch: 286, Train_loss: 0.5817 / Val_loss: 0.8393\n",
      "Epoch: 287, Train_loss: 0.5772 / Val_loss: 0.7589\n",
      "Epoch: 288, Train_loss: 0.5796 / Val_loss: 0.7742\n",
      "Epoch: 289, Train_loss: 0.5872 / Val_loss: 0.8085\n",
      "Epoch: 290, Train_loss: 0.5884 / Val_loss: 0.8739\n",
      "Epoch: 291, Train_loss: 0.5873 / Val_loss: 0.7670\n",
      "Epoch: 292, Train_loss: 0.5900 / Val_loss: 0.7320\n",
      "Epoch: 293, Train_loss: 0.5957 / Val_loss: 0.7784\n",
      "Epoch: 294, Train_loss: 0.5894 / Val_loss: 0.8631\n",
      "Epoch: 295, Train_loss: 0.5936 / Val_loss: 0.8129\n",
      "Epoch: 296, Train_loss: 0.5771 / Val_loss: 0.8357\n",
      "Epoch: 297, Train_loss: 0.5958 / Val_loss: 0.7508\n",
      "Epoch: 298, Train_loss: 0.6002 / Val_loss: 0.8205\n",
      "Epoch: 299, Train_loss: 0.5989 / Val_loss: 0.8345\n",
      "Epoch: 300, Train_loss: 0.5904 / Val_loss: 0.7450\n",
      "Epoch: 301, Train_loss: 0.5878 / Val_loss: 0.8238\n",
      "Epoch: 302, Train_loss: 0.5738 / Val_loss: 0.7864\n",
      "Epoch: 303, Train_loss: 0.5973 / Val_loss: 0.6975\n",
      "Epoch: 304, Train_loss: 0.6062 / Val_loss: 0.7257\n",
      "Epoch: 305, Train_loss: 0.5822 / Val_loss: 0.7972\n",
      "Epoch: 306, Train_loss: 0.5935 / Val_loss: 0.8402\n",
      "Epoch: 307, Train_loss: 0.5795 / Val_loss: 0.8378\n",
      "Epoch: 308, Train_loss: 0.5802 / Val_loss: 0.8065\n",
      "Epoch: 309, Train_loss: 0.5914 / Val_loss: 0.8683\n",
      "Epoch: 310, Train_loss: 0.6183 / Val_loss: 0.8231\n",
      "Epoch: 311, Train_loss: 0.5842 / Val_loss: 0.9285\n",
      "Epoch: 312, Train_loss: 0.6033 / Val_loss: 0.7132\n",
      "Epoch: 313, Train_loss: 0.5896 / Val_loss: 0.8561\n",
      "Epoch: 314, Train_loss: 0.5793 / Val_loss: 0.8442\n",
      "Epoch: 315, Train_loss: 0.6007 / Val_loss: 0.7975\n",
      "Epoch: 316, Train_loss: 0.5799 / Val_loss: 0.8074\n",
      "Epoch: 317, Train_loss: 0.5893 / Val_loss: 0.8074\n",
      "Epoch: 318, Train_loss: 0.5685 / Val_loss: 0.9149\n",
      "Epoch: 319, Train_loss: 0.5727 / Val_loss: 0.8263\n",
      "Epoch: 320, Train_loss: 0.5831 / Val_loss: 0.7681\n",
      "Epoch: 321, Train_loss: 0.5782 / Val_loss: 0.7966\n",
      "Epoch: 322, Train_loss: 0.5810 / Val_loss: 0.7765\n",
      "Epoch: 323, Train_loss: 0.5680 / Val_loss: 0.8198\n",
      "Epoch: 324, Train_loss: 0.5856 / Val_loss: 0.7970\n",
      "Epoch: 325, Train_loss: 0.5987 / Val_loss: 0.8548\n",
      "Epoch: 326, Train_loss: 0.5746 / Val_loss: 0.8347\n",
      "Epoch: 327, Train_loss: 0.5920 / Val_loss: 0.8270\n",
      "Epoch: 328, Train_loss: 0.5681 / Val_loss: 0.8269\n",
      "Epoch: 329, Train_loss: 0.5954 / Val_loss: 0.8032\n",
      "Epoch: 330, Train_loss: 0.5781 / Val_loss: 0.7610\n",
      "Epoch: 331, Train_loss: 0.5909 / Val_loss: 0.8727\n",
      "Epoch: 332, Train_loss: 0.5802 / Val_loss: 0.8693\n",
      "Epoch: 333, Train_loss: 0.5869 / Val_loss: 0.7884\n",
      "Epoch: 334, Train_loss: 0.5769 / Val_loss: 0.8066\n",
      "Epoch: 335, Train_loss: 0.5830 / Val_loss: 0.7563\n",
      "Epoch: 336, Train_loss: 0.5790 / Val_loss: 0.9100\n",
      "Epoch: 337, Train_loss: 0.5700 / Val_loss: 0.8730\n",
      "Epoch: 338, Train_loss: 0.5912 / Val_loss: 0.8204\n",
      "Epoch: 339, Train_loss: 0.5779 / Val_loss: 0.8779\n",
      "Epoch: 340, Train_loss: 0.5714 / Val_loss: 0.8679\n",
      "Epoch: 341, Train_loss: 0.5842 / Val_loss: 0.7564\n",
      "Epoch: 342, Train_loss: 0.5888 / Val_loss: 0.7303\n",
      "Epoch: 343, Train_loss: 0.5939 / Val_loss: 0.7827\n",
      "Epoch: 344, Train_loss: 0.5808 / Val_loss: 0.7799\n",
      "Epoch: 345, Train_loss: 0.5958 / Val_loss: 0.8601\n",
      "Epoch: 346, Train_loss: 0.6003 / Val_loss: 0.8000\n",
      "Epoch: 347, Train_loss: 0.5708 / Val_loss: 0.8242\n",
      "Epoch: 348, Train_loss: 0.5921 / Val_loss: 0.8011\n",
      "Epoch: 349, Train_loss: 0.5789 / Val_loss: 0.8633\n",
      "Epoch: 350, Train_loss: 0.5724 / Val_loss: 0.7569\n",
      "Epoch: 351, Train_loss: 0.6129 / Val_loss: 0.7796\n",
      "Epoch: 352, Train_loss: 0.5903 / Val_loss: 0.8104\n",
      "Epoch: 353, Train_loss: 0.5810 / Val_loss: 0.8149\n",
      "Epoch: 354, Train_loss: 0.5724 / Val_loss: 0.7740\n",
      "Epoch: 355, Train_loss: 0.5704 / Val_loss: 0.7926\n",
      "Epoch: 356, Train_loss: 0.5804 / Val_loss: 0.8361\n",
      "Epoch: 357, Train_loss: 0.5767 / Val_loss: 0.7357\n",
      "Epoch: 358, Train_loss: 0.5901 / Val_loss: 0.8494\n",
      "Epoch: 359, Train_loss: 0.6229 / Val_loss: 0.7955\n",
      "Epoch: 360, Train_loss: 0.5763 / Val_loss: 0.8193\n",
      "Epoch: 361, Train_loss: 0.5765 / Val_loss: 0.8703\n",
      "Epoch: 362, Train_loss: 0.5948 / Val_loss: 0.8019\n",
      "Epoch: 363, Train_loss: 0.5641 / Val_loss: 0.7887\n",
      "Epoch: 364, Train_loss: 0.5873 / Val_loss: 0.7952\n",
      "Epoch: 365, Train_loss: 0.5906 / Val_loss: 0.8303\n",
      "Epoch: 366, Train_loss: 0.5844 / Val_loss: 0.8565\n",
      "Epoch: 367, Train_loss: 0.5783 / Val_loss: 0.8485\n",
      "Epoch: 368, Train_loss: 0.5863 / Val_loss: 0.7761\n",
      "Epoch: 369, Train_loss: 0.5642 / Val_loss: 0.9541\n",
      "Epoch: 370, Train_loss: 0.5750 / Val_loss: 0.7794\n",
      "Epoch: 371, Train_loss: 0.5624 / Val_loss: 0.9110\n",
      "Epoch: 372, Train_loss: 0.5640 / Val_loss: 0.8643\n",
      "Epoch: 373, Train_loss: 0.5700 / Val_loss: 0.8413\n",
      "Epoch: 374, Train_loss: 0.6001 / Val_loss: 1.0064\n",
      "Epoch: 375, Train_loss: 0.5485 / Val_loss: 0.8345\n",
      "Epoch: 376, Train_loss: 0.5767 / Val_loss: 0.8862\n",
      "Epoch: 377, Train_loss: 0.5691 / Val_loss: 0.9313\n",
      "Epoch: 378, Train_loss: 0.5697 / Val_loss: 0.8388\n",
      "Epoch: 379, Train_loss: 0.5909 / Val_loss: 0.7938\n",
      "Epoch: 380, Train_loss: 0.5639 / Val_loss: 0.8454\n",
      "Epoch: 381, Train_loss: 0.5758 / Val_loss: 0.9409\n",
      "Epoch: 382, Train_loss: 0.5661 / Val_loss: 0.8759\n",
      "Epoch: 383, Train_loss: 0.5953 / Val_loss: 0.8095\n",
      "Epoch: 384, Train_loss: 0.5946 / Val_loss: 0.8438\n",
      "Epoch: 385, Train_loss: 0.5742 / Val_loss: 0.8276\n",
      "Epoch: 386, Train_loss: 0.5791 / Val_loss: 0.7578\n",
      "Epoch: 387, Train_loss: 0.5670 / Val_loss: 0.8710\n",
      "Epoch: 388, Train_loss: 0.5814 / Val_loss: 0.8384\n",
      "Epoch: 389, Train_loss: 0.5795 / Val_loss: 0.8227\n",
      "Epoch: 390, Train_loss: 0.5716 / Val_loss: 0.7558\n",
      "Epoch: 391, Train_loss: 0.5740 / Val_loss: 0.7219\n",
      "Epoch: 392, Train_loss: 0.5890 / Val_loss: 0.8044\n",
      "Epoch: 393, Train_loss: 0.5797 / Val_loss: 0.8089\n",
      "Epoch: 394, Train_loss: 0.6033 / Val_loss: 0.8115\n",
      "Epoch: 395, Train_loss: 0.5726 / Val_loss: 0.9766\n",
      "Epoch: 396, Train_loss: 0.5870 / Val_loss: 0.8180\n",
      "Epoch: 397, Train_loss: 0.5749 / Val_loss: 0.8529\n",
      "Epoch: 398, Train_loss: 0.5873 / Val_loss: 0.7580\n",
      "Epoch: 399, Train_loss: 0.5778 / Val_loss: 0.8301\n",
      "Epoch: 400, Train_loss: 0.5950 / Val_loss: 0.8112\n",
      "Epoch: 401, Train_loss: 0.5835 / Val_loss: 0.8619\n",
      "Epoch: 402, Train_loss: 0.5426 / Val_loss: 0.8075\n",
      "Epoch: 403, Train_loss: 0.5797 / Val_loss: 0.8834\n",
      "Epoch: 404, Train_loss: 0.5661 / Val_loss: 0.7604\n",
      "Epoch: 405, Train_loss: 0.6109 / Val_loss: 0.8394\n",
      "Epoch: 406, Train_loss: 0.5647 / Val_loss: 0.8673\n",
      "Epoch: 407, Train_loss: 0.5756 / Val_loss: 0.9047\n",
      "Epoch: 408, Train_loss: 0.5577 / Val_loss: 0.8852\n",
      "Epoch: 409, Train_loss: 0.5757 / Val_loss: 0.7978\n",
      "Epoch: 410, Train_loss: 0.5705 / Val_loss: 0.8527\n",
      "Epoch: 411, Train_loss: 0.5623 / Val_loss: 0.8702\n",
      "Epoch: 412, Train_loss: 0.6018 / Val_loss: 0.9579\n",
      "Epoch: 413, Train_loss: 0.5955 / Val_loss: 0.7473\n",
      "Epoch: 414, Train_loss: 0.5621 / Val_loss: 0.9602\n",
      "Epoch: 415, Train_loss: 0.5739 / Val_loss: 0.9442\n",
      "Epoch: 416, Train_loss: 0.5567 / Val_loss: 0.7955\n",
      "Epoch: 417, Train_loss: 0.5729 / Val_loss: 0.8378\n",
      "Epoch: 418, Train_loss: 0.5772 / Val_loss: 0.9269\n",
      "Epoch: 419, Train_loss: 0.5884 / Val_loss: 0.8338\n",
      "Epoch: 420, Train_loss: 0.5581 / Val_loss: 0.8112\n",
      "Epoch: 421, Train_loss: 0.5730 / Val_loss: 0.8124\n",
      "Epoch: 422, Train_loss: 0.5540 / Val_loss: 0.9369\n",
      "Epoch: 423, Train_loss: 0.5648 / Val_loss: 0.8404\n",
      "Epoch: 424, Train_loss: 0.5680 / Val_loss: 0.8562\n",
      "Epoch: 425, Train_loss: 0.5758 / Val_loss: 0.8924\n",
      "Epoch: 426, Train_loss: 0.5632 / Val_loss: 0.7714\n",
      "Epoch: 427, Train_loss: 0.5591 / Val_loss: 0.8788\n",
      "Epoch: 428, Train_loss: 0.5684 / Val_loss: 0.7963\n",
      "Epoch: 429, Train_loss: 0.5666 / Val_loss: 0.8807\n",
      "Epoch: 430, Train_loss: 0.5670 / Val_loss: 0.9391\n",
      "Epoch: 431, Train_loss: 0.5527 / Val_loss: 0.8923\n",
      "Epoch: 432, Train_loss: 0.5736 / Val_loss: 0.8925\n",
      "Epoch: 433, Train_loss: 0.5716 / Val_loss: 0.7956\n",
      "Epoch: 434, Train_loss: 0.5557 / Val_loss: 0.8541\n",
      "Epoch: 435, Train_loss: 0.5653 / Val_loss: 0.8190\n",
      "Epoch: 436, Train_loss: 0.5741 / Val_loss: 0.8819\n",
      "Epoch: 437, Train_loss: 0.5656 / Val_loss: 0.9557\n",
      "Epoch: 438, Train_loss: 0.5649 / Val_loss: 0.9414\n",
      "Epoch: 439, Train_loss: 0.5785 / Val_loss: 0.9401\n",
      "Epoch: 440, Train_loss: 0.5735 / Val_loss: 0.7973\n",
      "Epoch: 441, Train_loss: 0.5812 / Val_loss: 0.8580\n",
      "Epoch: 442, Train_loss: 0.5651 / Val_loss: 0.9324\n",
      "Epoch: 443, Train_loss: 0.5707 / Val_loss: 0.7923\n",
      "Epoch: 444, Train_loss: 0.5675 / Val_loss: 0.8126\n",
      "Epoch: 445, Train_loss: 0.5782 / Val_loss: 0.8926\n",
      "Epoch: 446, Train_loss: 0.5691 / Val_loss: 0.8410\n",
      "Epoch: 447, Train_loss: 0.5682 / Val_loss: 0.7863\n",
      "Epoch: 448, Train_loss: 0.5572 / Val_loss: 0.9174\n",
      "Epoch: 449, Train_loss: 0.5488 / Val_loss: 0.9016\n",
      "Epoch: 450, Train_loss: 0.5571 / Val_loss: 0.8344\n",
      "Epoch: 451, Train_loss: 0.5521 / Val_loss: 0.8078\n",
      "Epoch: 452, Train_loss: 0.5561 / Val_loss: 0.9401\n",
      "Epoch: 453, Train_loss: 0.5651 / Val_loss: 0.8690\n",
      "Epoch: 454, Train_loss: 0.5712 / Val_loss: 0.7995\n",
      "Epoch: 455, Train_loss: 0.5598 / Val_loss: 0.8375\n",
      "Epoch: 456, Train_loss: 0.5634 / Val_loss: 0.8224\n",
      "Epoch: 457, Train_loss: 0.5726 / Val_loss: 0.7844\n",
      "Epoch: 458, Train_loss: 0.5608 / Val_loss: 0.7829\n",
      "Epoch: 459, Train_loss: 0.5742 / Val_loss: 0.7919\n",
      "Epoch: 460, Train_loss: 0.5782 / Val_loss: 0.9483\n",
      "Epoch: 461, Train_loss: 0.5559 / Val_loss: 0.8965\n",
      "Epoch: 462, Train_loss: 0.5682 / Val_loss: 0.8358\n",
      "Epoch: 463, Train_loss: 0.5734 / Val_loss: 0.7904\n",
      "Epoch: 464, Train_loss: 0.5736 / Val_loss: 0.9767\n",
      "Epoch: 465, Train_loss: 0.5777 / Val_loss: 0.9262\n",
      "Epoch: 466, Train_loss: 0.5629 / Val_loss: 0.8775\n",
      "Epoch: 467, Train_loss: 0.5721 / Val_loss: 0.8501\n",
      "Epoch: 468, Train_loss: 0.5554 / Val_loss: 0.9368\n",
      "Epoch: 469, Train_loss: 0.5514 / Val_loss: 0.8034\n",
      "Epoch: 470, Train_loss: 0.5596 / Val_loss: 0.9281\n",
      "Epoch: 471, Train_loss: 0.5526 / Val_loss: 0.9695\n",
      "Epoch: 472, Train_loss: 0.5639 / Val_loss: 0.8201\n",
      "Epoch: 473, Train_loss: 0.5561 / Val_loss: 0.7806\n",
      "Epoch: 474, Train_loss: 0.5513 / Val_loss: 0.8049\n",
      "Epoch: 475, Train_loss: 0.5512 / Val_loss: 0.9177\n",
      "Epoch: 476, Train_loss: 0.5530 / Val_loss: 0.9049\n",
      "Epoch: 477, Train_loss: 0.5725 / Val_loss: 0.8482\n",
      "Epoch: 478, Train_loss: 0.5562 / Val_loss: 0.8700\n",
      "Epoch: 479, Train_loss: 0.5658 / Val_loss: 0.9313\n",
      "Epoch: 480, Train_loss: 0.5628 / Val_loss: 0.8300\n",
      "Epoch: 481, Train_loss: 0.5598 / Val_loss: 0.8630\n",
      "Epoch: 482, Train_loss: 0.5742 / Val_loss: 0.8449\n",
      "Epoch: 483, Train_loss: 0.5555 / Val_loss: 0.8338\n",
      "Epoch: 484, Train_loss: 0.5600 / Val_loss: 0.8551\n",
      "Epoch: 485, Train_loss: 0.5618 / Val_loss: 0.8907\n",
      "Epoch: 486, Train_loss: 0.5500 / Val_loss: 0.8597\n",
      "Epoch: 487, Train_loss: 0.5561 / Val_loss: 0.8264\n",
      "Epoch: 488, Train_loss: 0.5527 / Val_loss: 0.9017\n",
      "Epoch: 489, Train_loss: 0.5696 / Val_loss: 0.8365\n",
      "Epoch: 490, Train_loss: 0.5700 / Val_loss: 0.9515\n",
      "Epoch: 491, Train_loss: 0.5760 / Val_loss: 0.9004\n",
      "Epoch: 492, Train_loss: 0.5711 / Val_loss: 0.8523\n",
      "Epoch: 493, Train_loss: 0.5635 / Val_loss: 0.8022\n",
      "Epoch: 494, Train_loss: 0.5519 / Val_loss: 0.9138\n",
      "Epoch: 495, Train_loss: 0.5607 / Val_loss: 0.9421\n",
      "Epoch: 496, Train_loss: 0.5708 / Val_loss: 0.9001\n",
      "Epoch: 497, Train_loss: 0.5671 / Val_loss: 0.8421\n",
      "Epoch: 498, Train_loss: 0.5492 / Val_loss: 0.8740\n",
      "Epoch: 499, Train_loss: 0.5528 / Val_loss: 0.9531\n",
      "Epoch: 500, Train_loss: 0.5665 / Val_loss: 0.9211\n",
      "Epoch: 501, Train_loss: 0.5540 / Val_loss: 0.8910\n",
      "Epoch: 502, Train_loss: 0.5557 / Val_loss: 0.8537\n",
      "Epoch: 503, Train_loss: 0.5515 / Val_loss: 0.8445\n",
      "Epoch: 504, Train_loss: 0.5591 / Val_loss: 0.9184\n",
      "Epoch: 505, Train_loss: 0.5688 / Val_loss: 0.9730\n",
      "Epoch: 506, Train_loss: 0.5705 / Val_loss: 0.6854\n",
      "Epoch: 507, Train_loss: 0.5751 / Val_loss: 0.9468\n",
      "Epoch: 508, Train_loss: 0.5686 / Val_loss: 0.8595\n",
      "Epoch: 509, Train_loss: 0.5633 / Val_loss: 0.9633\n",
      "Epoch: 510, Train_loss: 0.5574 / Val_loss: 0.8666\n",
      "Epoch: 511, Train_loss: 0.5722 / Val_loss: 0.8709\n",
      "Epoch: 512, Train_loss: 0.5497 / Val_loss: 0.8487\n",
      "Epoch: 513, Train_loss: 0.5698 / Val_loss: 0.8554\n",
      "Epoch: 514, Train_loss: 0.5516 / Val_loss: 0.9082\n",
      "Epoch: 515, Train_loss: 0.5514 / Val_loss: 0.9337\n",
      "Epoch: 516, Train_loss: 0.5551 / Val_loss: 0.7958\n",
      "Epoch: 517, Train_loss: 0.5484 / Val_loss: 0.8402\n",
      "Epoch: 518, Train_loss: 0.5524 / Val_loss: 0.9065\n",
      "Epoch: 519, Train_loss: 0.5681 / Val_loss: 0.9844\n",
      "Epoch: 520, Train_loss: 0.5898 / Val_loss: 0.8246\n",
      "Epoch: 521, Train_loss: 0.5628 / Val_loss: 0.9234\n",
      "Epoch: 522, Train_loss: 0.5634 / Val_loss: 0.8344\n",
      "Epoch: 523, Train_loss: 0.5599 / Val_loss: 1.0199\n",
      "Epoch: 524, Train_loss: 0.5512 / Val_loss: 0.9166\n",
      "Epoch: 525, Train_loss: 0.5540 / Val_loss: 0.9039\n",
      "Epoch: 526, Train_loss: 0.5637 / Val_loss: 0.7786\n",
      "Epoch: 527, Train_loss: 0.5573 / Val_loss: 1.0122\n",
      "Epoch: 528, Train_loss: 0.5529 / Val_loss: 1.1210\n",
      "Epoch: 529, Train_loss: 0.5752 / Val_loss: 0.8042\n",
      "Epoch: 530, Train_loss: 0.5663 / Val_loss: 0.9247\n",
      "Epoch: 531, Train_loss: 0.5456 / Val_loss: 0.8637\n",
      "Epoch: 532, Train_loss: 0.5582 / Val_loss: 0.9658\n",
      "Epoch: 533, Train_loss: 0.5468 / Val_loss: 0.8745\n",
      "Epoch: 534, Train_loss: 0.5729 / Val_loss: 0.8673\n",
      "Epoch: 535, Train_loss: 0.5668 / Val_loss: 0.7099\n",
      "Epoch: 536, Train_loss: 0.5569 / Val_loss: 0.9652\n",
      "Epoch: 537, Train_loss: 0.5639 / Val_loss: 0.7870\n",
      "Epoch: 538, Train_loss: 0.5524 / Val_loss: 0.7929\n",
      "Epoch: 539, Train_loss: 0.5539 / Val_loss: 0.9660\n",
      "Epoch: 540, Train_loss: 0.5470 / Val_loss: 0.8385\n",
      "Epoch: 541, Train_loss: 0.5646 / Val_loss: 0.7113\n",
      "Epoch: 542, Train_loss: 0.5460 / Val_loss: 0.8911\n",
      "Epoch: 543, Train_loss: 0.5853 / Val_loss: 0.7793\n",
      "Epoch: 544, Train_loss: 0.5568 / Val_loss: 0.8419\n",
      "Epoch: 545, Train_loss: 0.5609 / Val_loss: 0.8529\n",
      "Epoch: 546, Train_loss: 0.5581 / Val_loss: 0.7990\n",
      "Epoch: 547, Train_loss: 0.5404 / Val_loss: 0.8712\n",
      "Epoch: 548, Train_loss: 0.5532 / Val_loss: 0.8704\n",
      "Epoch: 549, Train_loss: 0.5439 / Val_loss: 0.9276\n",
      "Epoch: 550, Train_loss: 0.5588 / Val_loss: 0.7482\n",
      "Epoch: 551, Train_loss: 0.5457 / Val_loss: 0.8842\n",
      "Epoch: 552, Train_loss: 0.5597 / Val_loss: 0.8224\n",
      "Epoch: 553, Train_loss: 0.5588 / Val_loss: 0.9987\n",
      "Epoch: 554, Train_loss: 0.5499 / Val_loss: 0.9012\n",
      "Epoch: 555, Train_loss: 0.5616 / Val_loss: 0.9858\n",
      "Epoch: 556, Train_loss: 0.5632 / Val_loss: 1.0382\n",
      "Epoch: 557, Train_loss: 0.5464 / Val_loss: 0.8917\n",
      "Epoch: 558, Train_loss: 0.5527 / Val_loss: 0.8869\n",
      "Epoch: 559, Train_loss: 0.5418 / Val_loss: 0.9153\n",
      "Epoch: 560, Train_loss: 0.5656 / Val_loss: 0.8286\n",
      "Epoch: 561, Train_loss: 0.5396 / Val_loss: 0.9050\n",
      "Epoch: 562, Train_loss: 0.5514 / Val_loss: 1.0063\n",
      "Epoch: 563, Train_loss: 0.5363 / Val_loss: 0.9269\n",
      "Epoch: 564, Train_loss: 0.5382 / Val_loss: 0.9596\n",
      "Epoch: 565, Train_loss: 0.5694 / Val_loss: 0.9853\n",
      "Epoch: 566, Train_loss: 0.5542 / Val_loss: 0.7637\n",
      "Epoch: 567, Train_loss: 0.5519 / Val_loss: 0.9148\n",
      "Epoch: 568, Train_loss: 0.5525 / Val_loss: 0.9144\n",
      "Epoch: 569, Train_loss: 0.5625 / Val_loss: 0.8232\n",
      "Epoch: 570, Train_loss: 0.5428 / Val_loss: 0.9124\n",
      "Epoch: 571, Train_loss: 0.5691 / Val_loss: 0.8460\n",
      "Epoch: 572, Train_loss: 0.5590 / Val_loss: 0.9797\n",
      "Epoch: 573, Train_loss: 0.5482 / Val_loss: 0.8719\n",
      "Epoch: 574, Train_loss: 0.5533 / Val_loss: 0.9273\n",
      "Epoch: 575, Train_loss: 0.5552 / Val_loss: 1.0395\n",
      "Epoch: 576, Train_loss: 0.5485 / Val_loss: 0.9561\n",
      "Epoch: 577, Train_loss: 0.5558 / Val_loss: 0.8598\n",
      "Epoch: 578, Train_loss: 0.5506 / Val_loss: 0.9032\n",
      "Epoch: 579, Train_loss: 0.5683 / Val_loss: 0.9203\n",
      "Epoch: 580, Train_loss: 0.5405 / Val_loss: 0.9571\n",
      "Epoch: 581, Train_loss: 0.5568 / Val_loss: 0.9056\n",
      "Epoch: 582, Train_loss: 0.5714 / Val_loss: 0.8711\n",
      "Epoch: 583, Train_loss: 0.5555 / Val_loss: 0.8931\n",
      "Epoch: 584, Train_loss: 0.5423 / Val_loss: 0.9779\n",
      "Epoch: 585, Train_loss: 0.5494 / Val_loss: 0.8826\n",
      "Epoch: 586, Train_loss: 0.5590 / Val_loss: 0.8606\n",
      "Epoch: 587, Train_loss: 0.5395 / Val_loss: 0.7718\n",
      "Epoch: 588, Train_loss: 0.5404 / Val_loss: 0.8795\n",
      "Epoch: 589, Train_loss: 0.5546 / Val_loss: 0.7672\n",
      "Epoch: 590, Train_loss: 0.5454 / Val_loss: 0.8951\n",
      "Epoch: 591, Train_loss: 0.5352 / Val_loss: 0.9226\n",
      "Epoch: 592, Train_loss: 0.5575 / Val_loss: 0.8023\n",
      "Epoch: 593, Train_loss: 0.5665 / Val_loss: 1.0424\n",
      "Epoch: 594, Train_loss: 0.5522 / Val_loss: 0.9698\n",
      "Epoch: 595, Train_loss: 0.5480 / Val_loss: 1.0258\n",
      "Epoch: 596, Train_loss: 0.5680 / Val_loss: 0.9150\n",
      "Epoch: 597, Train_loss: 0.5576 / Val_loss: 0.9374\n",
      "Epoch: 598, Train_loss: 0.5661 / Val_loss: 0.8054\n",
      "Epoch: 599, Train_loss: 0.5493 / Val_loss: 0.9736\n",
      "Epoch: 600, Train_loss: 0.5537 / Val_loss: 0.7968\n",
      "Epoch: 601, Train_loss: 0.5457 / Val_loss: 0.9607\n",
      "Epoch: 602, Train_loss: 0.5572 / Val_loss: 0.9325\n",
      "Epoch: 603, Train_loss: 0.5589 / Val_loss: 1.0568\n",
      "Epoch: 604, Train_loss: 0.5627 / Val_loss: 0.9465\n",
      "Epoch: 605, Train_loss: 0.5597 / Val_loss: 0.9173\n",
      "Epoch: 606, Train_loss: 0.5498 / Val_loss: 0.9343\n",
      "Epoch: 607, Train_loss: 0.5670 / Val_loss: 0.8510\n",
      "Epoch: 608, Train_loss: 0.5607 / Val_loss: 0.8652\n",
      "Epoch: 609, Train_loss: 0.5546 / Val_loss: 0.9255\n",
      "Epoch: 610, Train_loss: 0.5561 / Val_loss: 0.9569\n",
      "Epoch: 611, Train_loss: 0.5570 / Val_loss: 0.9331\n",
      "Epoch: 612, Train_loss: 0.5587 / Val_loss: 0.8486\n",
      "Epoch: 613, Train_loss: 0.5608 / Val_loss: 0.8640\n",
      "Epoch: 614, Train_loss: 0.5565 / Val_loss: 1.0194\n",
      "Epoch: 615, Train_loss: 0.5402 / Val_loss: 0.9655\n",
      "Epoch: 616, Train_loss: 0.5593 / Val_loss: 0.9985\n",
      "Epoch: 617, Train_loss: 0.5478 / Val_loss: 0.8164\n",
      "Epoch: 618, Train_loss: 0.5604 / Val_loss: 0.8998\n",
      "Epoch: 619, Train_loss: 0.5329 / Val_loss: 1.0080\n",
      "Epoch: 620, Train_loss: 0.5298 / Val_loss: 0.9430\n",
      "Epoch: 621, Train_loss: 0.5896 / Val_loss: 0.9264\n",
      "Epoch: 622, Train_loss: 0.5330 / Val_loss: 0.7874\n",
      "Epoch: 623, Train_loss: 0.5657 / Val_loss: 0.8219\n",
      "Epoch: 624, Train_loss: 0.5378 / Val_loss: 0.8698\n",
      "Epoch: 625, Train_loss: 0.5444 / Val_loss: 0.9689\n",
      "Epoch: 626, Train_loss: 0.5508 / Val_loss: 0.9281\n",
      "Epoch: 627, Train_loss: 0.5499 / Val_loss: 0.7347\n",
      "Epoch: 628, Train_loss: 0.5427 / Val_loss: 0.8677\n",
      "Epoch: 629, Train_loss: 0.5498 / Val_loss: 0.8493\n",
      "Epoch: 630, Train_loss: 0.5431 / Val_loss: 0.9756\n",
      "Epoch: 631, Train_loss: 0.5756 / Val_loss: 0.7548\n",
      "Epoch: 632, Train_loss: 0.5463 / Val_loss: 1.0347\n",
      "Epoch: 633, Train_loss: 0.5491 / Val_loss: 1.0191\n",
      "Epoch: 634, Train_loss: 0.5262 / Val_loss: 1.0250\n",
      "Epoch: 635, Train_loss: 0.5334 / Val_loss: 0.9118\n",
      "Epoch: 636, Train_loss: 0.5638 / Val_loss: 0.8515\n",
      "Epoch: 637, Train_loss: 0.5507 / Val_loss: 0.9201\n",
      "Epoch: 638, Train_loss: 0.5382 / Val_loss: 0.9419\n",
      "Epoch: 639, Train_loss: 0.5711 / Val_loss: 1.0158\n",
      "Epoch: 640, Train_loss: 0.5549 / Val_loss: 0.8502\n",
      "Epoch: 641, Train_loss: 0.5568 / Val_loss: 0.9125\n",
      "Epoch: 642, Train_loss: 0.5444 / Val_loss: 0.8984\n",
      "Epoch: 643, Train_loss: 0.5477 / Val_loss: 0.9434\n",
      "Epoch: 644, Train_loss: 0.5624 / Val_loss: 0.9023\n",
      "Epoch: 645, Train_loss: 0.5497 / Val_loss: 0.9951\n",
      "Epoch: 646, Train_loss: 0.5466 / Val_loss: 0.9614\n",
      "Epoch: 647, Train_loss: 0.5549 / Val_loss: 0.9221\n",
      "Epoch: 648, Train_loss: 0.5604 / Val_loss: 0.8427\n",
      "Epoch: 649, Train_loss: 0.5524 / Val_loss: 0.8269\n",
      "Epoch: 650, Train_loss: 0.5563 / Val_loss: 0.9645\n",
      "Epoch: 651, Train_loss: 0.5401 / Val_loss: 0.9441\n",
      "Epoch: 652, Train_loss: 0.5528 / Val_loss: 0.8972\n",
      "Epoch: 653, Train_loss: 0.5276 / Val_loss: 0.9341\n",
      "Epoch: 654, Train_loss: 0.5309 / Val_loss: 0.9746\n",
      "Epoch: 655, Train_loss: 0.5577 / Val_loss: 0.8646\n",
      "Epoch: 656, Train_loss: 0.5430 / Val_loss: 0.8406\n",
      "Epoch: 657, Train_loss: 0.5397 / Val_loss: 0.8715\n",
      "Epoch: 658, Train_loss: 0.5525 / Val_loss: 0.8631\n",
      "Epoch: 659, Train_loss: 0.5540 / Val_loss: 0.8286\n",
      "Epoch: 660, Train_loss: 0.5358 / Val_loss: 0.8741\n",
      "Epoch: 661, Train_loss: 0.5638 / Val_loss: 0.7953\n",
      "Epoch: 662, Train_loss: 0.5386 / Val_loss: 0.9212\n",
      "Epoch: 663, Train_loss: 0.5295 / Val_loss: 0.9285\n",
      "Epoch: 664, Train_loss: 0.5431 / Val_loss: 0.9343\n",
      "Epoch: 665, Train_loss: 0.5448 / Val_loss: 1.0555\n",
      "Epoch: 666, Train_loss: 0.5331 / Val_loss: 0.8992\n",
      "Epoch: 667, Train_loss: 0.5369 / Val_loss: 1.0016\n",
      "Epoch: 668, Train_loss: 0.5507 / Val_loss: 0.9271\n",
      "Epoch: 669, Train_loss: 0.5504 / Val_loss: 0.9658\n",
      "Epoch: 670, Train_loss: 0.5428 / Val_loss: 0.8784\n",
      "Epoch: 671, Train_loss: 0.5525 / Val_loss: 1.0072\n",
      "Epoch: 672, Train_loss: 0.5729 / Val_loss: 0.9871\n",
      "Epoch: 673, Train_loss: 0.5397 / Val_loss: 0.7665\n",
      "Epoch: 674, Train_loss: 0.5520 / Val_loss: 0.8736\n",
      "Epoch: 675, Train_loss: 0.5559 / Val_loss: 0.8908\n",
      "Epoch: 676, Train_loss: 0.5370 / Val_loss: 0.9747\n",
      "Epoch: 677, Train_loss: 0.5492 / Val_loss: 0.8933\n",
      "Epoch: 678, Train_loss: 0.5461 / Val_loss: 0.8325\n",
      "Epoch: 679, Train_loss: 0.5582 / Val_loss: 0.8112\n",
      "Epoch: 680, Train_loss: 0.5397 / Val_loss: 0.9315\n",
      "Epoch: 681, Train_loss: 0.5446 / Val_loss: 1.0602\n",
      "Epoch: 682, Train_loss: 0.5489 / Val_loss: 0.9700\n",
      "Epoch: 683, Train_loss: 0.5366 / Val_loss: 0.9813\n",
      "Epoch: 684, Train_loss: 0.5320 / Val_loss: 0.9668\n",
      "Epoch: 685, Train_loss: 0.5592 / Val_loss: 0.9073\n",
      "Epoch: 686, Train_loss: 0.5262 / Val_loss: 0.8442\n",
      "Epoch: 687, Train_loss: 0.5543 / Val_loss: 0.8915\n",
      "Epoch: 688, Train_loss: 0.5422 / Val_loss: 0.8020\n",
      "Epoch: 689, Train_loss: 0.5378 / Val_loss: 0.8741\n",
      "Epoch: 690, Train_loss: 0.5420 / Val_loss: 0.9832\n",
      "Epoch: 691, Train_loss: 0.5310 / Val_loss: 0.9538\n",
      "Epoch: 692, Train_loss: 0.5572 / Val_loss: 0.9370\n",
      "Epoch: 693, Train_loss: 0.5384 / Val_loss: 0.9446\n",
      "Epoch: 694, Train_loss: 0.5516 / Val_loss: 0.9021\n",
      "Epoch: 695, Train_loss: 0.5334 / Val_loss: 0.9491\n",
      "Epoch: 696, Train_loss: 0.5248 / Val_loss: 0.9826\n",
      "Epoch: 697, Train_loss: 0.5552 / Val_loss: 0.9983\n",
      "Epoch: 698, Train_loss: 0.5442 / Val_loss: 0.9552\n",
      "Epoch: 699, Train_loss: 0.5323 / Val_loss: 0.9723\n",
      "Epoch: 700, Train_loss: 0.5582 / Val_loss: 1.0168\n",
      "Epoch: 701, Train_loss: 0.5498 / Val_loss: 0.9398\n",
      "Epoch: 702, Train_loss: 0.5402 / Val_loss: 0.8432\n",
      "Epoch: 703, Train_loss: 0.5346 / Val_loss: 0.8299\n",
      "Epoch: 704, Train_loss: 0.5301 / Val_loss: 0.9659\n",
      "Epoch: 705, Train_loss: 0.5342 / Val_loss: 0.9744\n",
      "Epoch: 706, Train_loss: 0.5436 / Val_loss: 1.0318\n",
      "Epoch: 707, Train_loss: 0.5411 / Val_loss: 1.0047\n",
      "Epoch: 708, Train_loss: 0.5413 / Val_loss: 0.8158\n",
      "Epoch: 709, Train_loss: 0.5500 / Val_loss: 0.9145\n",
      "Epoch: 710, Train_loss: 0.5481 / Val_loss: 0.9936\n",
      "Epoch: 711, Train_loss: 0.5371 / Val_loss: 1.0400\n",
      "Epoch: 712, Train_loss: 0.5360 / Val_loss: 0.9363\n",
      "Epoch: 713, Train_loss: 0.5746 / Val_loss: 1.0609\n",
      "Epoch: 714, Train_loss: 0.5658 / Val_loss: 1.0459\n",
      "Epoch: 715, Train_loss: 0.5489 / Val_loss: 0.9414\n",
      "Epoch: 716, Train_loss: 0.5387 / Val_loss: 0.9863\n",
      "Epoch: 717, Train_loss: 0.5478 / Val_loss: 1.0516\n",
      "Epoch: 718, Train_loss: 0.5384 / Val_loss: 0.8354\n",
      "Epoch: 719, Train_loss: 0.5477 / Val_loss: 0.9962\n",
      "Epoch: 720, Train_loss: 0.5458 / Val_loss: 0.8966\n",
      "Epoch: 721, Train_loss: 0.5340 / Val_loss: 0.9583\n",
      "Epoch: 722, Train_loss: 0.5420 / Val_loss: 0.9445\n",
      "Epoch: 723, Train_loss: 0.5389 / Val_loss: 0.8580\n",
      "Epoch: 724, Train_loss: 0.5391 / Val_loss: 0.9446\n",
      "Epoch: 725, Train_loss: 0.5415 / Val_loss: 0.8890\n",
      "Epoch: 726, Train_loss: 0.5361 / Val_loss: 0.9113\n",
      "Epoch: 727, Train_loss: 0.5308 / Val_loss: 0.8878\n",
      "Epoch: 728, Train_loss: 0.5525 / Val_loss: 0.8226\n",
      "Epoch: 729, Train_loss: 0.5327 / Val_loss: 0.7803\n",
      "Epoch: 730, Train_loss: 0.5338 / Val_loss: 0.9213\n",
      "Epoch: 731, Train_loss: 0.5206 / Val_loss: 0.9317\n",
      "Epoch: 732, Train_loss: 0.5419 / Val_loss: 0.8993\n",
      "Epoch: 733, Train_loss: 0.5456 / Val_loss: 0.9264\n",
      "Epoch: 734, Train_loss: 0.5475 / Val_loss: 0.8982\n",
      "Epoch: 735, Train_loss: 0.5257 / Val_loss: 1.0031\n",
      "Epoch: 736, Train_loss: 0.5341 / Val_loss: 0.9261\n",
      "Epoch: 737, Train_loss: 0.5366 / Val_loss: 1.0038\n",
      "Epoch: 738, Train_loss: 0.5547 / Val_loss: 0.9014\n",
      "Epoch: 739, Train_loss: 0.5351 / Val_loss: 1.0742\n",
      "Epoch: 740, Train_loss: 0.5377 / Val_loss: 1.0138\n",
      "Epoch: 741, Train_loss: 0.5402 / Val_loss: 0.8473\n",
      "Epoch: 742, Train_loss: 0.5547 / Val_loss: 0.7680\n",
      "Epoch: 743, Train_loss: 0.5577 / Val_loss: 0.9632\n",
      "Epoch: 744, Train_loss: 0.5374 / Val_loss: 1.0052\n",
      "Epoch: 745, Train_loss: 0.5313 / Val_loss: 0.8875\n",
      "Epoch: 746, Train_loss: 0.5443 / Val_loss: 1.0352\n",
      "Epoch: 747, Train_loss: 0.5542 / Val_loss: 0.9150\n",
      "Epoch: 748, Train_loss: 0.5305 / Val_loss: 0.9800\n",
      "Epoch: 749, Train_loss: 0.5302 / Val_loss: 0.8466\n",
      "Epoch: 750, Train_loss: 0.5324 / Val_loss: 0.9934\n",
      "Epoch: 751, Train_loss: 0.5456 / Val_loss: 0.9256\n",
      "Epoch: 752, Train_loss: 0.5365 / Val_loss: 0.9143\n",
      "Epoch: 753, Train_loss: 0.5447 / Val_loss: 0.7609\n",
      "Epoch: 754, Train_loss: 0.5429 / Val_loss: 0.9243\n",
      "Epoch: 755, Train_loss: 0.5138 / Val_loss: 0.9323\n",
      "Epoch: 756, Train_loss: 0.5681 / Val_loss: 1.0443\n",
      "Epoch: 757, Train_loss: 0.5386 / Val_loss: 0.9249\n",
      "Epoch: 758, Train_loss: 0.5345 / Val_loss: 0.9378\n",
      "Epoch: 759, Train_loss: 0.5401 / Val_loss: 0.8407\n",
      "Epoch: 760, Train_loss: 0.5402 / Val_loss: 0.9654\n",
      "Epoch: 761, Train_loss: 0.5266 / Val_loss: 0.9209\n",
      "Epoch: 762, Train_loss: 0.5359 / Val_loss: 1.0967\n",
      "Epoch: 763, Train_loss: 0.5514 / Val_loss: 0.8999\n",
      "Epoch: 764, Train_loss: 0.5415 / Val_loss: 0.9636\n",
      "Epoch: 765, Train_loss: 0.5374 / Val_loss: 0.9375\n",
      "Epoch: 766, Train_loss: 0.5192 / Val_loss: 1.0329\n",
      "Epoch: 767, Train_loss: 0.5444 / Val_loss: 1.0016\n",
      "Epoch: 768, Train_loss: 0.5319 / Val_loss: 0.9770\n",
      "Epoch: 769, Train_loss: 0.5367 / Val_loss: 0.9844\n",
      "Epoch: 770, Train_loss: 0.5407 / Val_loss: 0.8752\n",
      "Epoch: 771, Train_loss: 0.5271 / Val_loss: 1.0559\n",
      "Epoch: 772, Train_loss: 0.5208 / Val_loss: 0.9677\n",
      "Epoch: 773, Train_loss: 0.5379 / Val_loss: 1.0905\n",
      "Epoch: 774, Train_loss: 0.5299 / Val_loss: 0.8931\n",
      "Epoch: 775, Train_loss: 0.5401 / Val_loss: 1.0040\n",
      "Epoch: 776, Train_loss: 0.5337 / Val_loss: 0.9666\n",
      "Epoch: 777, Train_loss: 0.5472 / Val_loss: 0.9568\n",
      "Epoch: 778, Train_loss: 0.5598 / Val_loss: 0.9889\n",
      "Epoch: 779, Train_loss: 0.5487 / Val_loss: 0.8860\n",
      "Epoch: 780, Train_loss: 0.5257 / Val_loss: 0.9160\n",
      "Epoch: 781, Train_loss: 0.5368 / Val_loss: 0.9104\n",
      "Epoch: 782, Train_loss: 0.5338 / Val_loss: 0.9147\n",
      "Epoch: 783, Train_loss: 0.5399 / Val_loss: 0.9696\n",
      "Epoch: 784, Train_loss: 0.5366 / Val_loss: 1.0263\n",
      "Epoch: 785, Train_loss: 0.5496 / Val_loss: 0.9968\n",
      "Epoch: 786, Train_loss: 0.5392 / Val_loss: 0.9214\n",
      "Epoch: 787, Train_loss: 0.5231 / Val_loss: 0.9224\n",
      "Epoch: 788, Train_loss: 0.5495 / Val_loss: 0.9411\n",
      "Epoch: 789, Train_loss: 0.5733 / Val_loss: 0.8871\n",
      "Epoch: 790, Train_loss: 0.5361 / Val_loss: 0.8540\n",
      "Epoch: 791, Train_loss: 0.5235 / Val_loss: 0.9622\n",
      "Epoch: 792, Train_loss: 0.5304 / Val_loss: 0.8864\n",
      "Epoch: 793, Train_loss: 0.5395 / Val_loss: 1.0424\n",
      "Epoch: 794, Train_loss: 0.5281 / Val_loss: 1.0220\n",
      "Epoch: 795, Train_loss: 0.5298 / Val_loss: 0.8486\n",
      "Epoch: 796, Train_loss: 0.5416 / Val_loss: 0.9897\n",
      "Epoch: 797, Train_loss: 0.5420 / Val_loss: 0.9174\n",
      "Epoch: 798, Train_loss: 0.5420 / Val_loss: 0.9384\n",
      "Epoch: 799, Train_loss: 0.5594 / Val_loss: 0.9887\n",
      "Epoch: 800, Train_loss: 0.5276 / Val_loss: 0.9575\n",
      "Epoch: 801, Train_loss: 0.5347 / Val_loss: 1.0432\n",
      "Epoch: 802, Train_loss: 0.5277 / Val_loss: 0.9416\n",
      "Epoch: 803, Train_loss: 0.5291 / Val_loss: 1.0050\n",
      "Epoch: 804, Train_loss: 0.5383 / Val_loss: 1.1524\n",
      "Epoch: 805, Train_loss: 0.5229 / Val_loss: 0.9520\n",
      "Epoch: 806, Train_loss: 0.5366 / Val_loss: 0.9415\n",
      "Epoch: 807, Train_loss: 0.5372 / Val_loss: 0.8352\n",
      "Epoch: 808, Train_loss: 0.5283 / Val_loss: 1.0696\n",
      "Epoch: 809, Train_loss: 0.5423 / Val_loss: 0.9322\n",
      "Epoch: 810, Train_loss: 0.5540 / Val_loss: 1.1212\n",
      "Epoch: 811, Train_loss: 0.5305 / Val_loss: 0.8589\n",
      "Epoch: 812, Train_loss: 0.5332 / Val_loss: 0.9666\n",
      "Epoch: 813, Train_loss: 0.5287 / Val_loss: 0.9946\n",
      "Epoch: 814, Train_loss: 0.5484 / Val_loss: 0.8077\n",
      "Epoch: 815, Train_loss: 0.5351 / Val_loss: 0.9596\n",
      "Epoch: 816, Train_loss: 0.5381 / Val_loss: 1.0926\n",
      "Epoch: 817, Train_loss: 0.5462 / Val_loss: 0.8617\n",
      "Epoch: 818, Train_loss: 0.5285 / Val_loss: 0.8692\n",
      "Epoch: 819, Train_loss: 0.5310 / Val_loss: 0.9158\n",
      "Epoch: 820, Train_loss: 0.5397 / Val_loss: 0.9043\n",
      "Epoch: 821, Train_loss: 0.5323 / Val_loss: 0.9108\n",
      "Epoch: 822, Train_loss: 0.5423 / Val_loss: 0.9074\n",
      "Epoch: 823, Train_loss: 0.5373 / Val_loss: 0.9183\n",
      "Epoch: 824, Train_loss: 0.5282 / Val_loss: 0.8906\n",
      "Epoch: 825, Train_loss: 0.5226 / Val_loss: 1.0211\n",
      "Epoch: 826, Train_loss: 0.5292 / Val_loss: 0.8930\n",
      "Epoch: 827, Train_loss: 0.5483 / Val_loss: 1.0517\n",
      "Epoch: 828, Train_loss: 0.5312 / Val_loss: 0.8261\n",
      "Epoch: 829, Train_loss: 0.5395 / Val_loss: 1.0237\n",
      "Epoch: 830, Train_loss: 0.5401 / Val_loss: 0.9764\n",
      "Epoch: 831, Train_loss: 0.5371 / Val_loss: 0.8784\n",
      "Epoch: 832, Train_loss: 0.5674 / Val_loss: 1.1310\n",
      "Epoch: 833, Train_loss: 0.5456 / Val_loss: 1.0014\n",
      "Epoch: 834, Train_loss: 0.5308 / Val_loss: 1.0607\n",
      "Epoch: 835, Train_loss: 0.5367 / Val_loss: 0.8484\n",
      "Epoch: 836, Train_loss: 0.5412 / Val_loss: 0.8621\n",
      "Epoch: 837, Train_loss: 0.5240 / Val_loss: 0.8964\n",
      "Epoch: 838, Train_loss: 0.5374 / Val_loss: 0.9636\n",
      "Epoch: 839, Train_loss: 0.5201 / Val_loss: 1.0558\n",
      "Epoch: 840, Train_loss: 0.5271 / Val_loss: 0.9815\n",
      "Epoch: 841, Train_loss: 0.5329 / Val_loss: 0.9777\n",
      "Epoch: 842, Train_loss: 0.5212 / Val_loss: 0.9111\n",
      "Epoch: 843, Train_loss: 0.5232 / Val_loss: 0.9785\n",
      "Epoch: 844, Train_loss: 0.5340 / Val_loss: 0.9527\n",
      "Epoch: 845, Train_loss: 0.5268 / Val_loss: 1.0097\n",
      "Epoch: 846, Train_loss: 0.5395 / Val_loss: 0.8680\n",
      "Epoch: 847, Train_loss: 0.5301 / Val_loss: 0.8372\n",
      "Epoch: 848, Train_loss: 0.5160 / Val_loss: 0.8809\n",
      "Epoch: 849, Train_loss: 0.5187 / Val_loss: 1.0430\n",
      "Epoch: 850, Train_loss: 0.5481 / Val_loss: 1.0320\n",
      "Epoch: 851, Train_loss: 0.5396 / Val_loss: 1.0431\n",
      "Epoch: 852, Train_loss: 0.5340 / Val_loss: 0.8982\n",
      "Epoch: 853, Train_loss: 0.5363 / Val_loss: 0.9886\n",
      "Epoch: 854, Train_loss: 0.5369 / Val_loss: 1.0117\n",
      "Epoch: 855, Train_loss: 0.5403 / Val_loss: 0.9462\n",
      "Epoch: 856, Train_loss: 0.5455 / Val_loss: 1.0733\n",
      "Epoch: 857, Train_loss: 0.5394 / Val_loss: 0.9343\n",
      "Epoch: 858, Train_loss: 0.5520 / Val_loss: 0.9600\n",
      "Epoch: 859, Train_loss: 0.5411 / Val_loss: 0.9965\n",
      "Epoch: 860, Train_loss: 0.5526 / Val_loss: 0.9325\n",
      "Epoch: 861, Train_loss: 0.5190 / Val_loss: 0.9140\n",
      "Epoch: 862, Train_loss: 0.5333 / Val_loss: 0.8096\n",
      "Epoch: 863, Train_loss: 0.5357 / Val_loss: 0.9323\n",
      "Epoch: 864, Train_loss: 0.5451 / Val_loss: 0.9390\n",
      "Epoch: 865, Train_loss: 0.5263 / Val_loss: 0.8458\n",
      "Epoch: 866, Train_loss: 0.5343 / Val_loss: 0.9262\n",
      "Epoch: 867, Train_loss: 0.5327 / Val_loss: 0.9422\n",
      "Epoch: 868, Train_loss: 0.5293 / Val_loss: 0.9985\n",
      "Epoch: 869, Train_loss: 0.5259 / Val_loss: 1.0282\n",
      "Epoch: 870, Train_loss: 0.5179 / Val_loss: 0.8894\n",
      "Epoch: 871, Train_loss: 0.5226 / Val_loss: 0.8939\n",
      "Epoch: 872, Train_loss: 0.5101 / Val_loss: 0.9270\n",
      "Epoch: 873, Train_loss: 0.5320 / Val_loss: 0.9436\n",
      "Epoch: 874, Train_loss: 0.5540 / Val_loss: 0.9257\n",
      "Epoch: 875, Train_loss: 0.5365 / Val_loss: 1.1063\n",
      "Epoch: 876, Train_loss: 0.5322 / Val_loss: 1.0048\n",
      "Epoch: 877, Train_loss: 0.5513 / Val_loss: 1.0584\n",
      "Epoch: 878, Train_loss: 0.5321 / Val_loss: 1.1174\n",
      "Epoch: 879, Train_loss: 0.5258 / Val_loss: 0.9198\n",
      "Epoch: 880, Train_loss: 0.5358 / Val_loss: 0.9874\n",
      "Epoch: 881, Train_loss: 0.5314 / Val_loss: 1.1674\n",
      "Epoch: 882, Train_loss: 0.5272 / Val_loss: 0.9275\n",
      "Epoch: 883, Train_loss: 0.5129 / Val_loss: 1.0855\n",
      "Epoch: 884, Train_loss: 0.5337 / Val_loss: 0.9801\n",
      "Epoch: 885, Train_loss: 0.5354 / Val_loss: 1.0335\n",
      "Epoch: 886, Train_loss: 0.5157 / Val_loss: 0.9738\n",
      "Epoch: 887, Train_loss: 0.5364 / Val_loss: 1.0736\n",
      "Epoch: 888, Train_loss: 0.5297 / Val_loss: 0.9586\n",
      "Epoch: 889, Train_loss: 0.5190 / Val_loss: 0.8780\n",
      "Epoch: 890, Train_loss: 0.5340 / Val_loss: 1.1034\n",
      "Epoch: 891, Train_loss: 0.5339 / Val_loss: 0.9848\n",
      "Epoch: 892, Train_loss: 0.5499 / Val_loss: 1.2255\n",
      "Epoch: 893, Train_loss: 0.5267 / Val_loss: 0.9271\n",
      "Epoch: 894, Train_loss: 0.5199 / Val_loss: 0.9359\n",
      "Epoch: 895, Train_loss: 0.5329 / Val_loss: 0.9006\n",
      "Epoch: 896, Train_loss: 0.5250 / Val_loss: 0.9123\n",
      "Epoch: 897, Train_loss: 0.5297 / Val_loss: 1.0830\n",
      "Epoch: 898, Train_loss: 0.5370 / Val_loss: 0.9395\n",
      "Epoch: 899, Train_loss: 0.5363 / Val_loss: 0.8876\n",
      "Epoch: 900, Train_loss: 0.5493 / Val_loss: 0.9589\n",
      "Epoch: 901, Train_loss: 0.5358 / Val_loss: 0.9436\n",
      "Epoch: 902, Train_loss: 0.5258 / Val_loss: 0.9512\n",
      "Epoch: 903, Train_loss: 0.5246 / Val_loss: 0.8632\n",
      "Epoch: 904, Train_loss: 0.5358 / Val_loss: 1.0855\n",
      "Epoch: 905, Train_loss: 0.5364 / Val_loss: 0.8880\n",
      "Epoch: 906, Train_loss: 0.5316 / Val_loss: 1.0619\n",
      "Epoch: 907, Train_loss: 0.5309 / Val_loss: 1.1444\n",
      "Epoch: 908, Train_loss: 0.5116 / Val_loss: 0.9753\n",
      "Epoch: 909, Train_loss: 0.5393 / Val_loss: 1.0423\n",
      "Epoch: 910, Train_loss: 0.5377 / Val_loss: 0.9557\n",
      "Epoch: 911, Train_loss: 0.5252 / Val_loss: 0.8840\n",
      "Epoch: 912, Train_loss: 0.5231 / Val_loss: 0.9511\n",
      "Epoch: 913, Train_loss: 0.5260 / Val_loss: 1.0439\n",
      "Epoch: 914, Train_loss: 0.5223 / Val_loss: 1.0193\n",
      "Epoch: 915, Train_loss: 0.5480 / Val_loss: 0.9061\n",
      "Epoch: 916, Train_loss: 0.5343 / Val_loss: 0.9502\n",
      "Epoch: 917, Train_loss: 0.5305 / Val_loss: 0.8895\n",
      "Epoch: 918, Train_loss: 0.5480 / Val_loss: 0.9952\n",
      "Epoch: 919, Train_loss: 0.5505 / Val_loss: 1.0549\n",
      "Epoch: 920, Train_loss: 0.5296 / Val_loss: 1.0668\n",
      "Epoch: 921, Train_loss: 0.5163 / Val_loss: 0.9977\n",
      "Epoch: 922, Train_loss: 0.5481 / Val_loss: 1.0108\n",
      "Epoch: 923, Train_loss: 0.5401 / Val_loss: 0.9775\n",
      "Epoch: 924, Train_loss: 0.5221 / Val_loss: 1.0641\n",
      "Epoch: 925, Train_loss: 0.5337 / Val_loss: 0.9887\n",
      "Epoch: 926, Train_loss: 0.5227 / Val_loss: 0.9449\n",
      "Epoch: 927, Train_loss: 0.5351 / Val_loss: 0.9335\n",
      "Epoch: 928, Train_loss: 0.5199 / Val_loss: 0.9491\n",
      "Epoch: 929, Train_loss: 0.5241 / Val_loss: 0.9813\n",
      "Epoch: 930, Train_loss: 0.5294 / Val_loss: 0.8910\n",
      "Epoch: 931, Train_loss: 0.5254 / Val_loss: 0.8860\n",
      "Epoch: 932, Train_loss: 0.5294 / Val_loss: 0.8836\n",
      "Epoch: 933, Train_loss: 0.5272 / Val_loss: 1.1267\n",
      "Epoch: 934, Train_loss: 0.5241 / Val_loss: 0.9398\n",
      "Epoch: 935, Train_loss: 0.5213 / Val_loss: 0.9019\n",
      "Epoch: 936, Train_loss: 0.5339 / Val_loss: 0.9935\n",
      "Epoch: 937, Train_loss: 0.5118 / Val_loss: 0.9471\n",
      "Epoch: 938, Train_loss: 0.5282 / Val_loss: 1.1180\n",
      "Epoch: 939, Train_loss: 0.5426 / Val_loss: 0.9715\n",
      "Epoch: 940, Train_loss: 0.5359 / Val_loss: 1.0193\n",
      "Epoch: 941, Train_loss: 0.5233 / Val_loss: 1.0383\n",
      "Epoch: 942, Train_loss: 0.5336 / Val_loss: 0.8148\n",
      "Epoch: 943, Train_loss: 0.5281 / Val_loss: 0.9315\n",
      "Epoch: 944, Train_loss: 0.5558 / Val_loss: 0.8681\n",
      "Epoch: 945, Train_loss: 0.5341 / Val_loss: 1.0127\n",
      "Epoch: 946, Train_loss: 0.5242 / Val_loss: 1.1101\n",
      "Epoch: 947, Train_loss: 0.5220 / Val_loss: 0.9671\n",
      "Epoch: 948, Train_loss: 0.5263 / Val_loss: 1.1524\n",
      "Epoch: 949, Train_loss: 0.5282 / Val_loss: 1.0496\n",
      "Epoch: 950, Train_loss: 0.5327 / Val_loss: 0.9270\n",
      "Epoch: 951, Train_loss: 0.5308 / Val_loss: 0.9143\n",
      "Epoch: 952, Train_loss: 0.5140 / Val_loss: 1.0371\n",
      "Epoch: 953, Train_loss: 0.5313 / Val_loss: 0.9577\n",
      "Epoch: 954, Train_loss: 0.5343 / Val_loss: 0.9875\n",
      "Epoch: 955, Train_loss: 0.5288 / Val_loss: 1.0500\n",
      "Epoch: 956, Train_loss: 0.5145 / Val_loss: 0.9009\n",
      "Epoch: 957, Train_loss: 0.5549 / Val_loss: 1.1015\n",
      "Epoch: 958, Train_loss: 0.4975 / Val_loss: 0.9710\n",
      "Epoch: 959, Train_loss: 0.5298 / Val_loss: 1.0328\n",
      "Epoch: 960, Train_loss: 0.5308 / Val_loss: 1.0204\n",
      "Epoch: 961, Train_loss: 0.5315 / Val_loss: 1.0501\n",
      "Epoch: 962, Train_loss: 0.5360 / Val_loss: 0.9189\n",
      "Epoch: 963, Train_loss: 0.5385 / Val_loss: 1.1175\n",
      "Epoch: 964, Train_loss: 0.5335 / Val_loss: 1.1218\n",
      "Epoch: 965, Train_loss: 0.5387 / Val_loss: 1.0978\n",
      "Epoch: 966, Train_loss: 0.5378 / Val_loss: 0.8941\n",
      "Epoch: 967, Train_loss: 0.5132 / Val_loss: 0.9933\n",
      "Epoch: 968, Train_loss: 0.5358 / Val_loss: 1.1513\n",
      "Epoch: 969, Train_loss: 0.5250 / Val_loss: 1.1275\n",
      "Epoch: 970, Train_loss: 0.5210 / Val_loss: 1.0517\n",
      "Epoch: 971, Train_loss: 0.5281 / Val_loss: 1.0165\n",
      "Epoch: 972, Train_loss: 0.5369 / Val_loss: 0.8848\n",
      "Epoch: 973, Train_loss: 0.5464 / Val_loss: 0.9204\n",
      "Epoch: 974, Train_loss: 0.5240 / Val_loss: 0.9720\n",
      "Epoch: 975, Train_loss: 0.5363 / Val_loss: 0.9267\n",
      "Epoch: 976, Train_loss: 0.5316 / Val_loss: 0.9050\n",
      "Epoch: 977, Train_loss: 0.5301 / Val_loss: 1.0434\n",
      "Epoch: 978, Train_loss: 0.5137 / Val_loss: 0.9352\n",
      "Epoch: 979, Train_loss: 0.5219 / Val_loss: 0.9105\n",
      "Epoch: 980, Train_loss: 0.5239 / Val_loss: 0.9989\n",
      "Epoch: 981, Train_loss: 0.5276 / Val_loss: 1.0337\n",
      "Epoch: 982, Train_loss: 0.5226 / Val_loss: 1.0591\n",
      "Epoch: 983, Train_loss: 0.5195 / Val_loss: 0.9627\n",
      "Epoch: 984, Train_loss: 0.5154 / Val_loss: 1.0280\n",
      "Epoch: 985, Train_loss: 0.5205 / Val_loss: 0.9532\n",
      "Epoch: 986, Train_loss: 0.5271 / Val_loss: 1.0879\n",
      "Epoch: 987, Train_loss: 0.5287 / Val_loss: 1.0877\n",
      "Epoch: 988, Train_loss: 0.5305 / Val_loss: 1.0187\n",
      "Epoch: 989, Train_loss: 0.5276 / Val_loss: 0.9150\n",
      "Epoch: 990, Train_loss: 0.5368 / Val_loss: 0.9590\n",
      "Epoch: 991, Train_loss: 0.5531 / Val_loss: 1.0284\n",
      "Epoch: 992, Train_loss: 0.5391 / Val_loss: 0.9799\n",
      "Epoch: 993, Train_loss: 0.5187 / Val_loss: 0.9885\n",
      "Epoch: 994, Train_loss: 0.5079 / Val_loss: 0.9833\n",
      "Epoch: 995, Train_loss: 0.5277 / Val_loss: 0.9348\n",
      "Epoch: 996, Train_loss: 0.5221 / Val_loss: 1.0610\n",
      "Epoch: 997, Train_loss: 0.5181 / Val_loss: 0.9176\n",
      "Epoch: 998, Train_loss: 0.5371 / Val_loss: 1.0275\n",
      "Epoch: 999, Train_loss: 0.5203 / Val_loss: 1.1082\n",
      "Epoch: 1000, Train_loss: 0.5324 / Val_loss: 0.9250\n",
      "Epoch: 1001, Train_loss: 0.5334 / Val_loss: 1.0357\n",
      "Epoch: 1002, Train_loss: 0.5132 / Val_loss: 1.0891\n",
      "Epoch: 1003, Train_loss: 0.5248 / Val_loss: 0.9593\n",
      "Epoch: 1004, Train_loss: 0.5158 / Val_loss: 0.9559\n",
      "Epoch: 1005, Train_loss: 0.5207 / Val_loss: 1.0154\n",
      "Epoch: 1006, Train_loss: 0.5289 / Val_loss: 1.0803\n",
      "Epoch: 1007, Train_loss: 0.5468 / Val_loss: 1.0335\n",
      "Epoch: 1008, Train_loss: 0.5364 / Val_loss: 1.1037\n",
      "Epoch: 1009, Train_loss: 0.5197 / Val_loss: 1.1122\n",
      "Epoch: 1010, Train_loss: 0.5338 / Val_loss: 1.0157\n",
      "Epoch: 1011, Train_loss: 0.5311 / Val_loss: 0.8622\n",
      "Epoch: 1012, Train_loss: 0.5383 / Val_loss: 1.0271\n",
      "Epoch: 1013, Train_loss: 0.5251 / Val_loss: 1.0434\n",
      "Epoch: 1014, Train_loss: 0.5301 / Val_loss: 1.0701\n",
      "Epoch: 1015, Train_loss: 0.5215 / Val_loss: 1.0337\n",
      "Epoch: 1016, Train_loss: 0.5222 / Val_loss: 0.8684\n",
      "Epoch: 1017, Train_loss: 0.5232 / Val_loss: 1.0238\n",
      "Epoch: 1018, Train_loss: 0.5216 / Val_loss: 0.9893\n",
      "Epoch: 1019, Train_loss: 0.5317 / Val_loss: 0.9263\n",
      "Epoch: 1020, Train_loss: 0.5345 / Val_loss: 1.1384\n",
      "Epoch: 1021, Train_loss: 0.5136 / Val_loss: 0.9720\n",
      "Epoch: 1022, Train_loss: 0.5318 / Val_loss: 1.0298\n",
      "Epoch: 1023, Train_loss: 0.5168 / Val_loss: 1.0579\n",
      "Epoch: 1024, Train_loss: 0.5186 / Val_loss: 0.9362\n",
      "Epoch: 1025, Train_loss: 0.5247 / Val_loss: 0.8938\n",
      "Epoch: 1026, Train_loss: 0.5360 / Val_loss: 0.9023\n",
      "Epoch: 1027, Train_loss: 0.5266 / Val_loss: 0.9386\n",
      "Epoch: 1028, Train_loss: 0.5150 / Val_loss: 0.9164\n",
      "Epoch: 1029, Train_loss: 0.5129 / Val_loss: 1.0620\n",
      "Epoch: 1030, Train_loss: 0.5173 / Val_loss: 0.9577\n",
      "Epoch: 1031, Train_loss: 0.5065 / Val_loss: 1.0808\n",
      "Epoch: 1032, Train_loss: 0.5349 / Val_loss: 1.0886\n",
      "Epoch: 1033, Train_loss: 0.5276 / Val_loss: 0.9162\n",
      "Epoch: 1034, Train_loss: 0.5389 / Val_loss: 0.9506\n",
      "Epoch: 1035, Train_loss: 0.5275 / Val_loss: 1.1241\n",
      "Epoch: 1036, Train_loss: 0.5241 / Val_loss: 1.1177\n",
      "Epoch: 1037, Train_loss: 0.5213 / Val_loss: 1.0923\n",
      "Epoch: 1038, Train_loss: 0.5198 / Val_loss: 1.0213\n",
      "Epoch: 1039, Train_loss: 0.5215 / Val_loss: 1.0658\n",
      "Epoch: 1040, Train_loss: 0.5226 / Val_loss: 1.0525\n",
      "Epoch: 1041, Train_loss: 0.5190 / Val_loss: 1.0111\n",
      "Epoch: 1042, Train_loss: 0.5270 / Val_loss: 0.8994\n",
      "Epoch: 1043, Train_loss: 0.5138 / Val_loss: 0.9828\n",
      "Epoch: 1044, Train_loss: 0.5358 / Val_loss: 0.9905\n",
      "Epoch: 1045, Train_loss: 0.5385 / Val_loss: 0.9578\n",
      "Epoch: 1046, Train_loss: 0.5145 / Val_loss: 0.9929\n",
      "Epoch: 1047, Train_loss: 0.5221 / Val_loss: 1.1695\n",
      "Epoch: 1048, Train_loss: 0.5342 / Val_loss: 0.9522\n",
      "Epoch: 1049, Train_loss: 0.5060 / Val_loss: 0.9488\n",
      "Epoch: 1050, Train_loss: 0.5216 / Val_loss: 0.8164\n",
      "Epoch: 1051, Train_loss: 0.5240 / Val_loss: 1.1525\n",
      "Epoch: 1052, Train_loss: 0.5102 / Val_loss: 0.9840\n",
      "Epoch: 1053, Train_loss: 0.5202 / Val_loss: 1.1324\n",
      "Epoch: 1054, Train_loss: 0.5252 / Val_loss: 0.8873\n",
      "Epoch: 1055, Train_loss: 0.5152 / Val_loss: 1.0295\n",
      "Epoch: 1056, Train_loss: 0.5176 / Val_loss: 0.9762\n",
      "Epoch: 1057, Train_loss: 0.5304 / Val_loss: 1.0646\n",
      "Epoch: 1058, Train_loss: 0.5331 / Val_loss: 0.9184\n",
      "Epoch: 1059, Train_loss: 0.5245 / Val_loss: 1.0155\n",
      "Epoch: 1060, Train_loss: 0.5079 / Val_loss: 1.0534\n",
      "Epoch: 1061, Train_loss: 0.5186 / Val_loss: 1.1531\n",
      "Epoch: 1062, Train_loss: 0.5188 / Val_loss: 0.8629\n",
      "Epoch: 1063, Train_loss: 0.5027 / Val_loss: 0.9515\n",
      "Epoch: 1064, Train_loss: 0.5288 / Val_loss: 0.9995\n",
      "Epoch: 1065, Train_loss: 0.5169 / Val_loss: 1.0088\n",
      "Epoch: 1066, Train_loss: 0.5359 / Val_loss: 0.9763\n",
      "Epoch: 1067, Train_loss: 0.5104 / Val_loss: 1.1600\n",
      "Epoch: 1068, Train_loss: 0.5320 / Val_loss: 1.0123\n",
      "Epoch: 1069, Train_loss: 0.5281 / Val_loss: 1.0780\n",
      "Epoch: 1070, Train_loss: 0.5345 / Val_loss: 0.9509\n",
      "Epoch: 1071, Train_loss: 0.5089 / Val_loss: 1.0329\n",
      "Epoch: 1072, Train_loss: 0.5337 / Val_loss: 1.0285\n",
      "Epoch: 1073, Train_loss: 0.5235 / Val_loss: 0.9272\n",
      "Epoch: 1074, Train_loss: 0.5095 / Val_loss: 0.9883\n",
      "Epoch: 1075, Train_loss: 0.5229 / Val_loss: 0.9664\n",
      "Epoch: 1076, Train_loss: 0.5178 / Val_loss: 0.9058\n",
      "Epoch: 1077, Train_loss: 0.5213 / Val_loss: 0.9149\n",
      "Epoch: 1078, Train_loss: 0.5156 / Val_loss: 1.1347\n",
      "Epoch: 1079, Train_loss: 0.5444 / Val_loss: 0.8904\n",
      "Epoch: 1080, Train_loss: 0.5279 / Val_loss: 0.9962\n",
      "Epoch: 1081, Train_loss: 0.5098 / Val_loss: 1.0800\n",
      "Epoch: 1082, Train_loss: 0.5218 / Val_loss: 1.1733\n",
      "Epoch: 1083, Train_loss: 0.5256 / Val_loss: 0.8759\n",
      "Epoch: 1084, Train_loss: 0.5250 / Val_loss: 0.9491\n",
      "Epoch: 1085, Train_loss: 0.5204 / Val_loss: 0.9093\n",
      "Epoch: 1086, Train_loss: 0.5175 / Val_loss: 1.0211\n",
      "Epoch: 1087, Train_loss: 0.5203 / Val_loss: 1.1135\n",
      "Epoch: 1088, Train_loss: 0.5295 / Val_loss: 1.1927\n",
      "Epoch: 1089, Train_loss: 0.5162 / Val_loss: 0.8913\n",
      "Epoch: 1090, Train_loss: 0.5159 / Val_loss: 0.9622\n",
      "Epoch: 1091, Train_loss: 0.5302 / Val_loss: 1.0751\n",
      "Epoch: 1092, Train_loss: 0.5237 / Val_loss: 1.0369\n",
      "Epoch: 1093, Train_loss: 0.5114 / Val_loss: 0.9887\n",
      "Epoch: 1094, Train_loss: 0.5205 / Val_loss: 1.0387\n",
      "Epoch: 1095, Train_loss: 0.5321 / Val_loss: 0.9345\n",
      "Epoch: 1096, Train_loss: 0.5336 / Val_loss: 0.9900\n",
      "Epoch: 1097, Train_loss: 0.5197 / Val_loss: 0.9092\n",
      "Epoch: 1098, Train_loss: 0.5226 / Val_loss: 1.0824\n",
      "Epoch: 1099, Train_loss: 0.5034 / Val_loss: 0.9590\n",
      "Epoch: 1100, Train_loss: 0.5188 / Val_loss: 1.1023\n",
      "Epoch: 1101, Train_loss: 0.5113 / Val_loss: 1.1356\n",
      "Epoch: 1102, Train_loss: 0.5114 / Val_loss: 1.2809\n",
      "Epoch: 1103, Train_loss: 0.5202 / Val_loss: 1.0285\n",
      "Epoch: 1104, Train_loss: 0.5119 / Val_loss: 1.0819\n",
      "Epoch: 1105, Train_loss: 0.5193 / Val_loss: 0.9722\n",
      "Epoch: 1106, Train_loss: 0.5320 / Val_loss: 0.9500\n",
      "Epoch: 1107, Train_loss: 0.5059 / Val_loss: 1.1519\n",
      "Epoch: 1108, Train_loss: 0.5239 / Val_loss: 1.0539\n",
      "Epoch: 1109, Train_loss: 0.5035 / Val_loss: 1.0413\n",
      "Epoch: 1110, Train_loss: 0.5315 / Val_loss: 1.0468\n",
      "Epoch: 1111, Train_loss: 0.5219 / Val_loss: 1.0499\n",
      "Epoch: 1112, Train_loss: 0.5385 / Val_loss: 1.0481\n",
      "Epoch: 1113, Train_loss: 0.5063 / Val_loss: 0.9694\n",
      "Epoch: 1114, Train_loss: 0.5209 / Val_loss: 1.0672\n",
      "Epoch: 1115, Train_loss: 0.5169 / Val_loss: 1.0993\n",
      "Epoch: 1116, Train_loss: 0.5101 / Val_loss: 0.9998\n",
      "Epoch: 1117, Train_loss: 0.5113 / Val_loss: 0.9969\n",
      "Epoch: 1118, Train_loss: 0.5317 / Val_loss: 0.9928\n",
      "Epoch: 1119, Train_loss: 0.5159 / Val_loss: 1.0622\n",
      "Epoch: 1120, Train_loss: 0.5263 / Val_loss: 0.9213\n",
      "Epoch: 1121, Train_loss: 0.5112 / Val_loss: 0.8838\n",
      "Epoch: 1122, Train_loss: 0.5238 / Val_loss: 1.1230\n",
      "Epoch: 1123, Train_loss: 0.5059 / Val_loss: 1.0773\n",
      "Epoch: 1124, Train_loss: 0.5330 / Val_loss: 1.1939\n",
      "Epoch: 1125, Train_loss: 0.5138 / Val_loss: 1.0385\n",
      "Epoch: 1126, Train_loss: 0.5375 / Val_loss: 1.0606\n",
      "Epoch: 1127, Train_loss: 0.5252 / Val_loss: 0.9838\n",
      "Epoch: 1128, Train_loss: 0.5023 / Val_loss: 0.9356\n",
      "Epoch: 1129, Train_loss: 0.5137 / Val_loss: 1.0675\n",
      "Epoch: 1130, Train_loss: 0.5390 / Val_loss: 0.9616\n",
      "Epoch: 1131, Train_loss: 0.5192 / Val_loss: 1.1195\n",
      "Epoch: 1132, Train_loss: 0.5118 / Val_loss: 0.9723\n",
      "Epoch: 1133, Train_loss: 0.5596 / Val_loss: 1.0964\n",
      "Epoch: 1134, Train_loss: 0.5213 / Val_loss: 1.0164\n",
      "Epoch: 1135, Train_loss: 0.5219 / Val_loss: 1.1165\n",
      "Epoch: 1136, Train_loss: 0.5206 / Val_loss: 0.9649\n",
      "Epoch: 1137, Train_loss: 0.5194 / Val_loss: 0.8806\n",
      "Epoch: 1138, Train_loss: 0.4986 / Val_loss: 1.0261\n",
      "Epoch: 1139, Train_loss: 0.5275 / Val_loss: 0.9612\n",
      "Epoch: 1140, Train_loss: 0.5214 / Val_loss: 1.1113\n",
      "Epoch: 1141, Train_loss: 0.5191 / Val_loss: 1.1470\n",
      "Epoch: 1142, Train_loss: 0.5263 / Val_loss: 0.9967\n",
      "Epoch: 1143, Train_loss: 0.5342 / Val_loss: 1.1297\n",
      "Epoch: 1144, Train_loss: 0.5106 / Val_loss: 1.2972\n",
      "Epoch: 1145, Train_loss: 0.5360 / Val_loss: 1.0722\n",
      "Epoch: 1146, Train_loss: 0.5115 / Val_loss: 1.0535\n",
      "Epoch: 1147, Train_loss: 0.5210 / Val_loss: 1.1079\n",
      "Epoch: 1148, Train_loss: 0.5199 / Val_loss: 1.0256\n",
      "Epoch: 1149, Train_loss: 0.5369 / Val_loss: 0.9794\n",
      "Epoch: 1150, Train_loss: 0.5173 / Val_loss: 1.1006\n",
      "Epoch: 1151, Train_loss: 0.5112 / Val_loss: 0.9073\n",
      "Epoch: 1152, Train_loss: 0.5151 / Val_loss: 1.1658\n",
      "Epoch: 1153, Train_loss: 0.5156 / Val_loss: 1.1756\n",
      "Epoch: 1154, Train_loss: 0.5119 / Val_loss: 1.0588\n",
      "Epoch: 1155, Train_loss: 0.5391 / Val_loss: 1.0122\n",
      "Epoch: 1156, Train_loss: 0.5173 / Val_loss: 1.0109\n",
      "Epoch: 1157, Train_loss: 0.5272 / Val_loss: 1.0686\n",
      "Epoch: 1158, Train_loss: 0.5071 / Val_loss: 0.9275\n",
      "Epoch: 1159, Train_loss: 0.5113 / Val_loss: 0.8792\n",
      "Epoch: 1160, Train_loss: 0.5212 / Val_loss: 0.9304\n",
      "Epoch: 1161, Train_loss: 0.5238 / Val_loss: 0.9992\n",
      "Epoch: 1162, Train_loss: 0.5075 / Val_loss: 1.0415\n",
      "Epoch: 1163, Train_loss: 0.5171 / Val_loss: 1.0075\n",
      "Epoch: 1164, Train_loss: 0.5104 / Val_loss: 1.0150\n",
      "Epoch: 1165, Train_loss: 0.5055 / Val_loss: 0.9628\n",
      "Epoch: 1166, Train_loss: 0.5349 / Val_loss: 0.9709\n",
      "Epoch: 1167, Train_loss: 0.5148 / Val_loss: 0.9287\n",
      "Epoch: 1168, Train_loss: 0.5315 / Val_loss: 0.9836\n",
      "Epoch: 1169, Train_loss: 0.4987 / Val_loss: 1.0698\n",
      "Epoch: 1170, Train_loss: 0.5205 / Val_loss: 1.0854\n",
      "Epoch: 1171, Train_loss: 0.5146 / Val_loss: 1.0475\n",
      "Epoch: 1172, Train_loss: 0.5213 / Val_loss: 1.0173\n",
      "Epoch: 1173, Train_loss: 0.5302 / Val_loss: 1.2171\n",
      "Epoch: 1174, Train_loss: 0.5025 / Val_loss: 1.0370\n",
      "Epoch: 1175, Train_loss: 0.5076 / Val_loss: 1.0453\n",
      "Epoch: 1176, Train_loss: 0.5166 / Val_loss: 1.2171\n",
      "Epoch: 1177, Train_loss: 0.5203 / Val_loss: 1.0077\n",
      "Epoch: 1178, Train_loss: 0.5297 / Val_loss: 1.0192\n",
      "Epoch: 1179, Train_loss: 0.5065 / Val_loss: 1.1163\n",
      "Epoch: 1180, Train_loss: 0.5196 / Val_loss: 0.9504\n",
      "Epoch: 1181, Train_loss: 0.5277 / Val_loss: 0.9723\n",
      "Epoch: 1182, Train_loss: 0.5139 / Val_loss: 0.8969\n",
      "Epoch: 1183, Train_loss: 0.5234 / Val_loss: 0.9554\n",
      "Epoch: 1184, Train_loss: 0.4945 / Val_loss: 1.1545\n",
      "Epoch: 1185, Train_loss: 0.5229 / Val_loss: 1.0149\n",
      "Epoch: 1186, Train_loss: 0.5134 / Val_loss: 1.0322\n",
      "Epoch: 1187, Train_loss: 0.4967 / Val_loss: 1.0903\n",
      "Epoch: 1188, Train_loss: 0.5311 / Val_loss: 0.9715\n",
      "Epoch: 1189, Train_loss: 0.5191 / Val_loss: 0.9870\n",
      "Epoch: 1190, Train_loss: 0.5134 / Val_loss: 0.7892\n",
      "Epoch: 1191, Train_loss: 0.5098 / Val_loss: 0.9994\n",
      "Epoch: 1192, Train_loss: 0.5253 / Val_loss: 1.1111\n",
      "Epoch: 1193, Train_loss: 0.5268 / Val_loss: 0.9251\n",
      "Epoch: 1194, Train_loss: 0.5313 / Val_loss: 1.0440\n",
      "Epoch: 1195, Train_loss: 0.5097 / Val_loss: 0.9326\n",
      "Epoch: 1196, Train_loss: 0.5426 / Val_loss: 0.9346\n",
      "Epoch: 1197, Train_loss: 0.5063 / Val_loss: 0.8593\n",
      "Epoch: 1198, Train_loss: 0.5092 / Val_loss: 0.9960\n",
      "Epoch: 1199, Train_loss: 0.5205 / Val_loss: 1.0090\n",
      "Epoch: 1200, Train_loss: 0.5350 / Val_loss: 1.0109\n",
      "Epoch: 1201, Train_loss: 0.5034 / Val_loss: 1.0980\n",
      "Epoch: 1202, Train_loss: 0.5267 / Val_loss: 0.9386\n",
      "Epoch: 1203, Train_loss: 0.5161 / Val_loss: 1.2707\n",
      "Epoch: 1204, Train_loss: 0.5177 / Val_loss: 1.0736\n",
      "Epoch: 1205, Train_loss: 0.5061 / Val_loss: 1.0126\n",
      "Epoch: 1206, Train_loss: 0.5161 / Val_loss: 1.1155\n",
      "Epoch: 1207, Train_loss: 0.5008 / Val_loss: 0.9708\n",
      "Epoch: 1208, Train_loss: 0.5101 / Val_loss: 0.9544\n",
      "Epoch: 1209, Train_loss: 0.5111 / Val_loss: 1.0142\n",
      "Epoch: 1210, Train_loss: 0.5133 / Val_loss: 0.9829\n",
      "Epoch: 1211, Train_loss: 0.5174 / Val_loss: 1.3928\n",
      "Epoch: 1212, Train_loss: 0.5163 / Val_loss: 1.2436\n",
      "Epoch: 1213, Train_loss: 0.5152 / Val_loss: 1.2287\n",
      "Epoch: 1214, Train_loss: 0.5121 / Val_loss: 1.0053\n",
      "Epoch: 1215, Train_loss: 0.5120 / Val_loss: 1.1473\n",
      "Epoch: 1216, Train_loss: 0.4985 / Val_loss: 1.0497\n",
      "Epoch: 1217, Train_loss: 0.5129 / Val_loss: 1.1926\n",
      "Epoch: 1218, Train_loss: 0.5084 / Val_loss: 1.0740\n",
      "Epoch: 1219, Train_loss: 0.5101 / Val_loss: 1.1025\n",
      "Epoch: 1220, Train_loss: 0.5269 / Val_loss: 1.2714\n",
      "Epoch: 1221, Train_loss: 0.5211 / Val_loss: 0.9588\n",
      "Epoch: 1222, Train_loss: 0.5176 / Val_loss: 0.9761\n",
      "Epoch: 1223, Train_loss: 0.5016 / Val_loss: 0.9814\n",
      "Epoch: 1224, Train_loss: 0.5121 / Val_loss: 1.2195\n",
      "Epoch: 1225, Train_loss: 0.5075 / Val_loss: 1.0478\n",
      "Epoch: 1226, Train_loss: 0.5138 / Val_loss: 0.9514\n",
      "Epoch: 1227, Train_loss: 0.5123 / Val_loss: 0.9691\n",
      "Epoch: 1228, Train_loss: 0.5155 / Val_loss: 1.0596\n",
      "Epoch: 1229, Train_loss: 0.5098 / Val_loss: 1.0233\n",
      "Epoch: 1230, Train_loss: 0.5137 / Val_loss: 1.0872\n",
      "Epoch: 1231, Train_loss: 0.5186 / Val_loss: 1.2011\n",
      "Epoch: 1232, Train_loss: 0.5171 / Val_loss: 0.9025\n",
      "Epoch: 1233, Train_loss: 0.5094 / Val_loss: 1.1576\n",
      "Epoch: 1234, Train_loss: 0.5168 / Val_loss: 0.9303\n",
      "Epoch: 1235, Train_loss: 0.5132 / Val_loss: 1.0572\n",
      "Epoch: 1236, Train_loss: 0.5155 / Val_loss: 1.0284\n",
      "Epoch: 1237, Train_loss: 0.5187 / Val_loss: 0.9723\n",
      "Epoch: 1238, Train_loss: 0.5188 / Val_loss: 1.0216\n",
      "Epoch: 1239, Train_loss: 0.5168 / Val_loss: 1.1478\n",
      "Epoch: 1240, Train_loss: 0.5178 / Val_loss: 1.0573\n",
      "Epoch: 1241, Train_loss: 0.5117 / Val_loss: 0.9883\n",
      "Epoch: 1242, Train_loss: 0.5234 / Val_loss: 0.9460\n",
      "Epoch: 1243, Train_loss: 0.5037 / Val_loss: 0.9268\n",
      "Epoch: 1244, Train_loss: 0.5290 / Val_loss: 0.9043\n",
      "Epoch: 1245, Train_loss: 0.5271 / Val_loss: 1.0408\n",
      "Epoch: 1246, Train_loss: 0.5148 / Val_loss: 0.9088\n",
      "Epoch: 1247, Train_loss: 0.5097 / Val_loss: 1.0351\n",
      "Epoch: 1248, Train_loss: 0.5309 / Val_loss: 1.0491\n",
      "Epoch: 1249, Train_loss: 0.5053 / Val_loss: 0.9097\n",
      "Epoch: 1250, Train_loss: 0.5243 / Val_loss: 0.9810\n",
      "Epoch: 1251, Train_loss: 0.5089 / Val_loss: 1.0966\n",
      "Epoch: 1252, Train_loss: 0.5110 / Val_loss: 1.1453\n",
      "Epoch: 1253, Train_loss: 0.5164 / Val_loss: 1.0762\n",
      "Epoch: 1254, Train_loss: 0.5188 / Val_loss: 1.1319\n",
      "Epoch: 1255, Train_loss: 0.5226 / Val_loss: 1.1537\n",
      "Epoch: 1256, Train_loss: 0.5249 / Val_loss: 1.0801\n",
      "Epoch: 1257, Train_loss: 0.5201 / Val_loss: 1.1252\n",
      "Epoch: 1258, Train_loss: 0.5009 / Val_loss: 1.0470\n",
      "Epoch: 1259, Train_loss: 0.5263 / Val_loss: 0.9164\n",
      "Epoch: 1260, Train_loss: 0.5141 / Val_loss: 1.0006\n",
      "Epoch: 1261, Train_loss: 0.5102 / Val_loss: 1.1390\n",
      "Epoch: 1262, Train_loss: 0.5180 / Val_loss: 1.0696\n",
      "Epoch: 1263, Train_loss: 0.5145 / Val_loss: 1.1739\n",
      "Epoch: 1264, Train_loss: 0.5224 / Val_loss: 1.0367\n",
      "Epoch: 1265, Train_loss: 0.5129 / Val_loss: 1.1400\n",
      "Epoch: 1266, Train_loss: 0.5060 / Val_loss: 1.0145\n",
      "Epoch: 1267, Train_loss: 0.4976 / Val_loss: 0.9901\n",
      "Epoch: 1268, Train_loss: 0.5321 / Val_loss: 1.1606\n",
      "Epoch: 1269, Train_loss: 0.5223 / Val_loss: 1.0063\n",
      "Epoch: 1270, Train_loss: 0.5205 / Val_loss: 1.1359\n",
      "Epoch: 1271, Train_loss: 0.5121 / Val_loss: 1.0548\n",
      "Epoch: 1272, Train_loss: 0.5154 / Val_loss: 1.0996\n",
      "Epoch: 1273, Train_loss: 0.5209 / Val_loss: 1.1193\n",
      "Epoch: 1274, Train_loss: 0.5112 / Val_loss: 1.0579\n",
      "Epoch: 1275, Train_loss: 0.5146 / Val_loss: 1.0792\n",
      "Epoch: 1276, Train_loss: 0.5154 / Val_loss: 1.1927\n",
      "Epoch: 1277, Train_loss: 0.5165 / Val_loss: 0.9367\n",
      "Epoch: 1278, Train_loss: 0.5231 / Val_loss: 1.0171\n",
      "Epoch: 1279, Train_loss: 0.5219 / Val_loss: 1.0059\n",
      "Epoch: 1280, Train_loss: 0.5140 / Val_loss: 0.9949\n",
      "Epoch: 1281, Train_loss: 0.5009 / Val_loss: 1.0471\n",
      "Epoch: 1282, Train_loss: 0.5123 / Val_loss: 1.1171\n",
      "Epoch: 1283, Train_loss: 0.4949 / Val_loss: 1.0470\n",
      "Epoch: 1284, Train_loss: 0.5033 / Val_loss: 0.9953\n",
      "Epoch: 1285, Train_loss: 0.5105 / Val_loss: 1.1813\n",
      "Epoch: 1286, Train_loss: 0.5008 / Val_loss: 1.0284\n",
      "Epoch: 1287, Train_loss: 0.5275 / Val_loss: 1.0179\n",
      "Epoch: 1288, Train_loss: 0.5117 / Val_loss: 1.1880\n",
      "Epoch: 1289, Train_loss: 0.5062 / Val_loss: 1.1422\n",
      "Epoch: 1290, Train_loss: 0.5168 / Val_loss: 1.1097\n",
      "Epoch: 1291, Train_loss: 0.5070 / Val_loss: 1.0517\n",
      "Epoch: 1292, Train_loss: 0.5074 / Val_loss: 1.1383\n",
      "Epoch: 1293, Train_loss: 0.5140 / Val_loss: 1.2573\n",
      "Epoch: 1294, Train_loss: 0.5163 / Val_loss: 1.0255\n",
      "Epoch: 1295, Train_loss: 0.5167 / Val_loss: 0.9823\n",
      "Epoch: 1296, Train_loss: 0.5216 / Val_loss: 0.9961\n",
      "Epoch: 1297, Train_loss: 0.5040 / Val_loss: 0.9844\n",
      "Epoch: 1298, Train_loss: 0.5100 / Val_loss: 1.0974\n",
      "Epoch: 1299, Train_loss: 0.5006 / Val_loss: 1.2284\n",
      "Epoch: 1300, Train_loss: 0.5010 / Val_loss: 0.9619\n",
      "Epoch: 1301, Train_loss: 0.5030 / Val_loss: 0.9591\n",
      "Epoch: 1302, Train_loss: 0.5124 / Val_loss: 1.1767\n",
      "Epoch: 1303, Train_loss: 0.5050 / Val_loss: 1.0269\n",
      "Epoch: 1304, Train_loss: 0.4989 / Val_loss: 1.1057\n",
      "Epoch: 1305, Train_loss: 0.5015 / Val_loss: 1.0928\n",
      "Epoch: 1306, Train_loss: 0.5112 / Val_loss: 1.2318\n",
      "Epoch: 1307, Train_loss: 0.5132 / Val_loss: 1.2168\n",
      "Epoch: 1308, Train_loss: 0.5005 / Val_loss: 1.0136\n",
      "Epoch: 1309, Train_loss: 0.5257 / Val_loss: 1.0034\n",
      "Epoch: 1310, Train_loss: 0.5150 / Val_loss: 0.9768\n",
      "Epoch: 1311, Train_loss: 0.5184 / Val_loss: 1.1797\n",
      "Epoch: 1312, Train_loss: 0.5095 / Val_loss: 0.9658\n",
      "Epoch: 1313, Train_loss: 0.5145 / Val_loss: 1.0225\n",
      "Epoch: 1314, Train_loss: 0.5003 / Val_loss: 1.1803\n",
      "Epoch: 1315, Train_loss: 0.5009 / Val_loss: 1.0179\n",
      "Epoch: 1316, Train_loss: 0.5123 / Val_loss: 1.0343\n",
      "Epoch: 1317, Train_loss: 0.5014 / Val_loss: 1.0891\n",
      "Epoch: 1318, Train_loss: 0.5121 / Val_loss: 1.1133\n",
      "Epoch: 1319, Train_loss: 0.5087 / Val_loss: 0.9962\n",
      "Epoch: 1320, Train_loss: 0.5164 / Val_loss: 0.9923\n",
      "Epoch: 1321, Train_loss: 0.5063 / Val_loss: 1.0520\n",
      "Epoch: 1322, Train_loss: 0.4936 / Val_loss: 0.9918\n",
      "Epoch: 1323, Train_loss: 0.5130 / Val_loss: 1.0405\n",
      "Epoch: 1324, Train_loss: 0.5016 / Val_loss: 1.1281\n",
      "Epoch: 1325, Train_loss: 0.5129 / Val_loss: 1.0115\n",
      "Epoch: 1326, Train_loss: 0.5314 / Val_loss: 0.9738\n",
      "Epoch: 1327, Train_loss: 0.5071 / Val_loss: 1.0422\n",
      "Epoch: 1328, Train_loss: 0.4971 / Val_loss: 0.9641\n",
      "Epoch: 1329, Train_loss: 0.5127 / Val_loss: 1.1059\n",
      "Epoch: 1330, Train_loss: 0.5193 / Val_loss: 1.1341\n",
      "Epoch: 1331, Train_loss: 0.5160 / Val_loss: 1.0384\n",
      "Epoch: 1332, Train_loss: 0.4987 / Val_loss: 1.0316\n",
      "Epoch: 1333, Train_loss: 0.5123 / Val_loss: 1.0765\n",
      "Epoch: 1334, Train_loss: 0.5215 / Val_loss: 0.9532\n",
      "Epoch: 1335, Train_loss: 0.4992 / Val_loss: 0.9959\n",
      "Epoch: 1336, Train_loss: 0.5057 / Val_loss: 0.9779\n",
      "Epoch: 1337, Train_loss: 0.5047 / Val_loss: 1.1065\n",
      "Epoch: 1338, Train_loss: 0.5223 / Val_loss: 0.8131\n",
      "Epoch: 1339, Train_loss: 0.5066 / Val_loss: 1.0494\n",
      "Epoch: 1340, Train_loss: 0.4940 / Val_loss: 0.9834\n",
      "Epoch: 1341, Train_loss: 0.5075 / Val_loss: 1.0437\n",
      "Epoch: 1342, Train_loss: 0.5133 / Val_loss: 0.9585\n",
      "Epoch: 1343, Train_loss: 0.5191 / Val_loss: 1.0196\n",
      "Epoch: 1344, Train_loss: 0.4964 / Val_loss: 1.0513\n",
      "Epoch: 1345, Train_loss: 0.5049 / Val_loss: 0.9209\n",
      "Epoch: 1346, Train_loss: 0.5156 / Val_loss: 0.9762\n",
      "Epoch: 1347, Train_loss: 0.4989 / Val_loss: 1.0024\n",
      "Epoch: 1348, Train_loss: 0.5164 / Val_loss: 1.2638\n",
      "Epoch: 1349, Train_loss: 0.5136 / Val_loss: 1.0598\n",
      "Epoch: 1350, Train_loss: 0.5101 / Val_loss: 1.1637\n",
      "Epoch: 1351, Train_loss: 0.5198 / Val_loss: 1.0057\n",
      "Epoch: 1352, Train_loss: 0.5122 / Val_loss: 1.0994\n",
      "Epoch: 1353, Train_loss: 0.5051 / Val_loss: 1.0423\n",
      "Epoch: 1354, Train_loss: 0.5120 / Val_loss: 1.2580\n",
      "Epoch: 1355, Train_loss: 0.5119 / Val_loss: 1.0861\n",
      "Epoch: 1356, Train_loss: 0.5069 / Val_loss: 1.2196\n",
      "Epoch: 1357, Train_loss: 0.5040 / Val_loss: 1.0738\n",
      "Epoch: 1358, Train_loss: 0.4950 / Val_loss: 0.9597\n",
      "Epoch: 1359, Train_loss: 0.5099 / Val_loss: 0.9538\n",
      "Epoch: 1360, Train_loss: 0.5046 / Val_loss: 1.1127\n",
      "Epoch: 1361, Train_loss: 0.5186 / Val_loss: 1.1627\n",
      "Epoch: 1362, Train_loss: 0.5204 / Val_loss: 1.1889\n",
      "Epoch: 1363, Train_loss: 0.4936 / Val_loss: 0.9909\n",
      "Epoch: 1364, Train_loss: 0.5126 / Val_loss: 1.0741\n",
      "Epoch: 1365, Train_loss: 0.5147 / Val_loss: 0.9881\n",
      "Epoch: 1366, Train_loss: 0.5034 / Val_loss: 1.0035\n",
      "Epoch: 1367, Train_loss: 0.5071 / Val_loss: 1.0752\n",
      "Epoch: 1368, Train_loss: 0.5273 / Val_loss: 1.1985\n",
      "Epoch: 1369, Train_loss: 0.5027 / Val_loss: 0.9985\n",
      "Epoch: 1370, Train_loss: 0.4991 / Val_loss: 1.0489\n",
      "Epoch: 1371, Train_loss: 0.5161 / Val_loss: 1.0948\n",
      "Epoch: 1372, Train_loss: 0.5044 / Val_loss: 0.9527\n",
      "Epoch: 1373, Train_loss: 0.5227 / Val_loss: 1.1372\n",
      "Epoch: 1374, Train_loss: 0.4933 / Val_loss: 1.1512\n",
      "Epoch: 1375, Train_loss: 0.5148 / Val_loss: 1.0684\n",
      "Epoch: 1376, Train_loss: 0.5038 / Val_loss: 1.0566\n",
      "Epoch: 1377, Train_loss: 0.5112 / Val_loss: 0.9141\n",
      "Epoch: 1378, Train_loss: 0.5109 / Val_loss: 0.9504\n",
      "Epoch: 1379, Train_loss: 0.5053 / Val_loss: 0.9836\n",
      "Epoch: 1380, Train_loss: 0.4969 / Val_loss: 0.9377\n",
      "Epoch: 1381, Train_loss: 0.5050 / Val_loss: 1.1082\n",
      "Epoch: 1382, Train_loss: 0.4950 / Val_loss: 1.1450\n",
      "Epoch: 1383, Train_loss: 0.4991 / Val_loss: 1.0652\n",
      "Epoch: 1384, Train_loss: 0.5050 / Val_loss: 1.0300\n",
      "Epoch: 1385, Train_loss: 0.5081 / Val_loss: 1.1638\n",
      "Epoch: 1386, Train_loss: 0.5021 / Val_loss: 0.9584\n",
      "Epoch: 1387, Train_loss: 0.5014 / Val_loss: 0.9827\n",
      "Epoch: 1388, Train_loss: 0.5234 / Val_loss: 1.0905\n",
      "Epoch: 1389, Train_loss: 0.5154 / Val_loss: 1.1227\n",
      "Epoch: 1390, Train_loss: 0.5089 / Val_loss: 0.8315\n",
      "Epoch: 1391, Train_loss: 0.5103 / Val_loss: 1.0650\n",
      "Epoch: 1392, Train_loss: 0.5071 / Val_loss: 1.2503\n",
      "Epoch: 1393, Train_loss: 0.5018 / Val_loss: 1.2221\n",
      "Epoch: 1394, Train_loss: 0.5149 / Val_loss: 1.0012\n",
      "Epoch: 1395, Train_loss: 0.5106 / Val_loss: 1.1224\n",
      "Epoch: 1396, Train_loss: 0.5057 / Val_loss: 1.2310\n",
      "Epoch: 1397, Train_loss: 0.5002 / Val_loss: 1.0367\n",
      "Epoch: 1398, Train_loss: 0.4990 / Val_loss: 0.9973\n",
      "Epoch: 1399, Train_loss: 0.5085 / Val_loss: 1.1404\n",
      "Epoch: 1400, Train_loss: 0.5054 / Val_loss: 1.1048\n",
      "Epoch: 1401, Train_loss: 0.5101 / Val_loss: 1.0005\n",
      "Epoch: 1402, Train_loss: 0.4950 / Val_loss: 0.9547\n",
      "Epoch: 1403, Train_loss: 0.5112 / Val_loss: 1.0578\n",
      "Epoch: 1404, Train_loss: 0.5123 / Val_loss: 1.1906\n",
      "Epoch: 1405, Train_loss: 0.4900 / Val_loss: 0.9255\n",
      "Epoch: 1406, Train_loss: 0.5152 / Val_loss: 0.9204\n",
      "Epoch: 1407, Train_loss: 0.5032 / Val_loss: 1.0867\n",
      "Epoch: 1408, Train_loss: 0.5240 / Val_loss: 1.1466\n",
      "Epoch: 1409, Train_loss: 0.5031 / Val_loss: 1.1221\n",
      "Epoch: 1410, Train_loss: 0.5069 / Val_loss: 1.1502\n",
      "Epoch: 1411, Train_loss: 0.4947 / Val_loss: 1.0340\n",
      "Epoch: 1412, Train_loss: 0.5017 / Val_loss: 0.9864\n",
      "Epoch: 1413, Train_loss: 0.5105 / Val_loss: 1.0133\n",
      "Epoch: 1414, Train_loss: 0.4985 / Val_loss: 0.9073\n",
      "Epoch: 1415, Train_loss: 0.5125 / Val_loss: 1.0842\n",
      "Epoch: 1416, Train_loss: 0.5038 / Val_loss: 1.2905\n",
      "Epoch: 1417, Train_loss: 0.5023 / Val_loss: 1.0239\n",
      "Epoch: 1418, Train_loss: 0.5142 / Val_loss: 1.1580\n",
      "Epoch: 1419, Train_loss: 0.5064 / Val_loss: 1.0098\n",
      "Epoch: 1420, Train_loss: 0.5125 / Val_loss: 0.9500\n",
      "Epoch: 1421, Train_loss: 0.5148 / Val_loss: 0.9421\n",
      "Epoch: 1422, Train_loss: 0.5074 / Val_loss: 1.1649\n",
      "Epoch: 1423, Train_loss: 0.5054 / Val_loss: 1.1828\n",
      "Epoch: 1424, Train_loss: 0.5096 / Val_loss: 1.0712\n",
      "Epoch: 1425, Train_loss: 0.5066 / Val_loss: 1.0551\n",
      "Epoch: 1426, Train_loss: 0.5184 / Val_loss: 1.1300\n",
      "Epoch: 1427, Train_loss: 0.5127 / Val_loss: 1.0127\n",
      "Epoch: 1428, Train_loss: 0.5060 / Val_loss: 1.2022\n",
      "Epoch: 1429, Train_loss: 0.4977 / Val_loss: 1.0219\n",
      "Epoch: 1430, Train_loss: 0.5138 / Val_loss: 1.2010\n",
      "Epoch: 1431, Train_loss: 0.5209 / Val_loss: 1.0994\n",
      "Epoch: 1432, Train_loss: 0.5114 / Val_loss: 1.1279\n",
      "Epoch: 1433, Train_loss: 0.5136 / Val_loss: 1.0510\n",
      "Epoch: 1434, Train_loss: 0.5078 / Val_loss: 1.1234\n",
      "Epoch: 1435, Train_loss: 0.5069 / Val_loss: 0.9789\n",
      "Epoch: 1436, Train_loss: 0.5294 / Val_loss: 1.0041\n",
      "Epoch: 1437, Train_loss: 0.5171 / Val_loss: 0.9666\n",
      "Epoch: 1438, Train_loss: 0.5183 / Val_loss: 1.2379\n",
      "Epoch: 1439, Train_loss: 0.5073 / Val_loss: 1.1741\n",
      "Epoch: 1440, Train_loss: 0.5144 / Val_loss: 0.9935\n",
      "Epoch: 1441, Train_loss: 0.4998 / Val_loss: 0.9903\n",
      "Epoch: 1442, Train_loss: 0.5192 / Val_loss: 1.0992\n",
      "Epoch: 1443, Train_loss: 0.5012 / Val_loss: 1.1493\n",
      "Epoch: 1444, Train_loss: 0.4945 / Val_loss: 1.1458\n",
      "Epoch: 1445, Train_loss: 0.5179 / Val_loss: 1.0818\n",
      "Epoch: 1446, Train_loss: 0.5097 / Val_loss: 1.2838\n",
      "Epoch: 1447, Train_loss: 0.5326 / Val_loss: 1.0410\n",
      "Epoch: 1448, Train_loss: 0.5080 / Val_loss: 1.0088\n",
      "Epoch: 1449, Train_loss: 0.5256 / Val_loss: 1.2762\n",
      "Epoch: 1450, Train_loss: 0.5100 / Val_loss: 1.1078\n",
      "Epoch: 1451, Train_loss: 0.5136 / Val_loss: 1.1853\n",
      "Epoch: 1452, Train_loss: 0.5102 / Val_loss: 0.9321\n",
      "Epoch: 1453, Train_loss: 0.5017 / Val_loss: 1.1431\n",
      "Epoch: 1454, Train_loss: 0.5067 / Val_loss: 0.9849\n",
      "Epoch: 1455, Train_loss: 0.5085 / Val_loss: 0.9936\n",
      "Epoch: 1456, Train_loss: 0.4935 / Val_loss: 1.1128\n",
      "Epoch: 1457, Train_loss: 0.5091 / Val_loss: 1.0826\n",
      "Epoch: 1458, Train_loss: 0.5061 / Val_loss: 1.0386\n",
      "Epoch: 1459, Train_loss: 0.5101 / Val_loss: 1.0060\n",
      "Epoch: 1460, Train_loss: 0.4931 / Val_loss: 1.0659\n",
      "Epoch: 1461, Train_loss: 0.5105 / Val_loss: 1.1188\n",
      "Epoch: 1462, Train_loss: 0.5002 / Val_loss: 1.2242\n",
      "Epoch: 1463, Train_loss: 0.5101 / Val_loss: 1.2023\n",
      "Epoch: 1464, Train_loss: 0.5247 / Val_loss: 0.9903\n",
      "Epoch: 1465, Train_loss: 0.5234 / Val_loss: 1.0914\n",
      "Epoch: 1466, Train_loss: 0.4995 / Val_loss: 1.0117\n",
      "Epoch: 1467, Train_loss: 0.4937 / Val_loss: 1.0899\n",
      "Epoch: 1468, Train_loss: 0.5154 / Val_loss: 0.9911\n",
      "Epoch: 1469, Train_loss: 0.5059 / Val_loss: 1.0842\n",
      "Epoch: 1470, Train_loss: 0.5063 / Val_loss: 0.9643\n",
      "Epoch: 1471, Train_loss: 0.5108 / Val_loss: 1.0665\n",
      "Epoch: 1472, Train_loss: 0.5131 / Val_loss: 1.1426\n",
      "Epoch: 1473, Train_loss: 0.5025 / Val_loss: 1.1547\n",
      "Epoch: 1474, Train_loss: 0.5063 / Val_loss: 1.0497\n",
      "Epoch: 1475, Train_loss: 0.5045 / Val_loss: 1.1872\n",
      "Epoch: 1476, Train_loss: 0.5134 / Val_loss: 1.1722\n",
      "Epoch: 1477, Train_loss: 0.5110 / Val_loss: 1.1496\n",
      "Epoch: 1478, Train_loss: 0.5108 / Val_loss: 1.1505\n",
      "Epoch: 1479, Train_loss: 0.5054 / Val_loss: 1.0179\n",
      "Epoch: 1480, Train_loss: 0.5008 / Val_loss: 1.0860\n",
      "Epoch: 1481, Train_loss: 0.4886 / Val_loss: 1.1671\n",
      "Epoch: 1482, Train_loss: 0.5107 / Val_loss: 1.0863\n",
      "Epoch: 1483, Train_loss: 0.5118 / Val_loss: 1.0107\n",
      "Epoch: 1484, Train_loss: 0.4929 / Val_loss: 1.0589\n",
      "Epoch: 1485, Train_loss: 0.5060 / Val_loss: 1.1645\n",
      "Epoch: 1486, Train_loss: 0.5090 / Val_loss: 1.0982\n",
      "Epoch: 1487, Train_loss: 0.4978 / Val_loss: 1.0847\n",
      "Epoch: 1488, Train_loss: 0.5142 / Val_loss: 1.1023\n",
      "Epoch: 1489, Train_loss: 0.4966 / Val_loss: 0.9940\n",
      "Epoch: 1490, Train_loss: 0.5166 / Val_loss: 1.0195\n",
      "Epoch: 1491, Train_loss: 0.5395 / Val_loss: 1.4436\n",
      "Epoch: 1492, Train_loss: 0.5130 / Val_loss: 1.0760\n",
      "Epoch: 1493, Train_loss: 0.5064 / Val_loss: 0.9650\n",
      "Epoch: 1494, Train_loss: 0.5019 / Val_loss: 1.1301\n",
      "Epoch: 1495, Train_loss: 0.5157 / Val_loss: 1.0075\n",
      "Epoch: 1496, Train_loss: 0.5024 / Val_loss: 1.0523\n",
      "Epoch: 1497, Train_loss: 0.5125 / Val_loss: 1.1674\n",
      "Epoch: 1498, Train_loss: 0.5110 / Val_loss: 1.0215\n",
      "Epoch: 1499, Train_loss: 0.5084 / Val_loss: 1.1280\n",
      "Epoch: 1500, Train_loss: 0.5095 / Val_loss: 0.9713\n",
      "Epoch: 1501, Train_loss: 0.5042 / Val_loss: 1.0443\n",
      "Epoch: 1502, Train_loss: 0.5050 / Val_loss: 1.0171\n",
      "Epoch: 1503, Train_loss: 0.5012 / Val_loss: 1.2177\n",
      "Epoch: 1504, Train_loss: 0.5124 / Val_loss: 1.1159\n",
      "Epoch: 1505, Train_loss: 0.4941 / Val_loss: 1.0510\n",
      "Epoch: 1506, Train_loss: 0.4877 / Val_loss: 1.0758\n",
      "Epoch: 1507, Train_loss: 0.4965 / Val_loss: 1.1036\n",
      "Epoch: 1508, Train_loss: 0.5046 / Val_loss: 0.9933\n",
      "Epoch: 1509, Train_loss: 0.4918 / Val_loss: 0.9380\n",
      "Epoch: 1510, Train_loss: 0.4943 / Val_loss: 0.9938\n",
      "Epoch: 1511, Train_loss: 0.5000 / Val_loss: 0.9663\n",
      "Epoch: 1512, Train_loss: 0.4938 / Val_loss: 0.9489\n",
      "Epoch: 1513, Train_loss: 0.4908 / Val_loss: 1.1054\n",
      "Epoch: 1514, Train_loss: 0.4942 / Val_loss: 0.9345\n",
      "Epoch: 1515, Train_loss: 0.5009 / Val_loss: 1.0657\n",
      "Epoch: 1516, Train_loss: 0.5063 / Val_loss: 1.1035\n",
      "Epoch: 1517, Train_loss: 0.4924 / Val_loss: 1.2638\n",
      "Epoch: 1518, Train_loss: 0.5073 / Val_loss: 1.0044\n",
      "Epoch: 1519, Train_loss: 0.5116 / Val_loss: 1.1324\n",
      "Epoch: 1520, Train_loss: 0.5066 / Val_loss: 1.0041\n",
      "Epoch: 1521, Train_loss: 0.4948 / Val_loss: 0.9724\n",
      "Epoch: 1522, Train_loss: 0.5135 / Val_loss: 1.0093\n",
      "Epoch: 1523, Train_loss: 0.5050 / Val_loss: 0.9673\n",
      "Epoch: 1524, Train_loss: 0.5121 / Val_loss: 1.0837\n",
      "Epoch: 1525, Train_loss: 0.5014 / Val_loss: 1.1346\n",
      "Epoch: 1526, Train_loss: 0.5126 / Val_loss: 0.8897\n",
      "Epoch: 1527, Train_loss: 0.5145 / Val_loss: 1.1681\n",
      "Epoch: 1528, Train_loss: 0.5008 / Val_loss: 1.1004\n",
      "Epoch: 1529, Train_loss: 0.5097 / Val_loss: 1.1218\n",
      "Epoch: 1530, Train_loss: 0.4912 / Val_loss: 0.9959\n",
      "Epoch: 1531, Train_loss: 0.5058 / Val_loss: 1.1696\n",
      "Epoch: 1532, Train_loss: 0.4975 / Val_loss: 1.1214\n",
      "Epoch: 1533, Train_loss: 0.5115 / Val_loss: 1.2427\n",
      "Epoch: 1534, Train_loss: 0.5147 / Val_loss: 1.1122\n",
      "Epoch: 1535, Train_loss: 0.4925 / Val_loss: 0.9927\n",
      "Epoch: 1536, Train_loss: 0.5029 / Val_loss: 1.0202\n",
      "Epoch: 1537, Train_loss: 0.5077 / Val_loss: 1.0359\n",
      "Epoch: 1538, Train_loss: 0.5059 / Val_loss: 1.0231\n",
      "Epoch: 1539, Train_loss: 0.5162 / Val_loss: 0.9628\n",
      "Epoch: 1540, Train_loss: 0.5086 / Val_loss: 1.0915\n",
      "Epoch: 1541, Train_loss: 0.5239 / Val_loss: 1.0943\n",
      "Epoch: 1542, Train_loss: 0.5066 / Val_loss: 1.1056\n",
      "Epoch: 1543, Train_loss: 0.4948 / Val_loss: 0.9396\n",
      "Epoch: 1544, Train_loss: 0.5085 / Val_loss: 1.1101\n",
      "Epoch: 1545, Train_loss: 0.4987 / Val_loss: 1.1302\n",
      "Epoch: 1546, Train_loss: 0.4902 / Val_loss: 0.8659\n",
      "Epoch: 1547, Train_loss: 0.5063 / Val_loss: 1.1284\n",
      "Epoch: 1548, Train_loss: 0.4986 / Val_loss: 1.0958\n",
      "Epoch: 1549, Train_loss: 0.4969 / Val_loss: 1.0155\n",
      "Epoch: 1550, Train_loss: 0.5035 / Val_loss: 1.1404\n",
      "Epoch: 1551, Train_loss: 0.5052 / Val_loss: 1.0126\n",
      "Epoch: 1552, Train_loss: 0.5203 / Val_loss: 0.9235\n",
      "Epoch: 1553, Train_loss: 0.5011 / Val_loss: 1.2034\n",
      "Epoch: 1554, Train_loss: 0.4873 / Val_loss: 1.1154\n",
      "Epoch: 1555, Train_loss: 0.5241 / Val_loss: 1.0215\n",
      "Epoch: 1556, Train_loss: 0.4965 / Val_loss: 1.1391\n",
      "Epoch: 1557, Train_loss: 0.4962 / Val_loss: 1.1987\n",
      "Epoch: 1558, Train_loss: 0.5028 / Val_loss: 1.0866\n",
      "Epoch: 1559, Train_loss: 0.4946 / Val_loss: 0.9883\n",
      "Epoch: 1560, Train_loss: 0.4872 / Val_loss: 1.0896\n",
      "Epoch: 1561, Train_loss: 0.5082 / Val_loss: 1.0124\n",
      "Epoch: 1562, Train_loss: 0.5060 / Val_loss: 0.9440\n",
      "Epoch: 1563, Train_loss: 0.5075 / Val_loss: 1.1470\n",
      "Epoch: 1564, Train_loss: 0.4988 / Val_loss: 1.2165\n",
      "Epoch: 1565, Train_loss: 0.5044 / Val_loss: 1.0722\n",
      "Epoch: 1566, Train_loss: 0.5058 / Val_loss: 1.0872\n",
      "Epoch: 1567, Train_loss: 0.4902 / Val_loss: 1.0433\n",
      "Epoch: 1568, Train_loss: 0.5001 / Val_loss: 1.0629\n",
      "Epoch: 1569, Train_loss: 0.4901 / Val_loss: 0.9773\n",
      "Epoch: 1570, Train_loss: 0.4934 / Val_loss: 1.1088\n",
      "Epoch: 1571, Train_loss: 0.4988 / Val_loss: 0.9795\n",
      "Epoch: 1572, Train_loss: 0.5206 / Val_loss: 1.0005\n",
      "Epoch: 1573, Train_loss: 0.4932 / Val_loss: 1.0913\n",
      "Epoch: 1574, Train_loss: 0.5001 / Val_loss: 1.1877\n",
      "Epoch: 1575, Train_loss: 0.4904 / Val_loss: 1.0212\n",
      "Epoch: 1576, Train_loss: 0.5089 / Val_loss: 1.2315\n",
      "Epoch: 1577, Train_loss: 0.4904 / Val_loss: 1.1841\n",
      "Epoch: 1578, Train_loss: 0.4980 / Val_loss: 1.0945\n",
      "Epoch: 1579, Train_loss: 0.4980 / Val_loss: 1.1290\n",
      "Epoch: 1580, Train_loss: 0.4967 / Val_loss: 1.0333\n",
      "Epoch: 1581, Train_loss: 0.4897 / Val_loss: 1.1201\n",
      "Epoch: 1582, Train_loss: 0.5052 / Val_loss: 1.0354\n",
      "Epoch: 1583, Train_loss: 0.5104 / Val_loss: 1.0899\n",
      "Epoch: 1584, Train_loss: 0.5069 / Val_loss: 1.0549\n",
      "Epoch: 1585, Train_loss: 0.4848 / Val_loss: 1.0265\n",
      "Epoch: 1586, Train_loss: 0.5015 / Val_loss: 1.0074\n",
      "Epoch: 1587, Train_loss: 0.4921 / Val_loss: 1.0072\n",
      "Epoch: 1588, Train_loss: 0.4980 / Val_loss: 1.0295\n",
      "Epoch: 1589, Train_loss: 0.5017 / Val_loss: 1.0510\n",
      "Epoch: 1590, Train_loss: 0.5015 / Val_loss: 1.0678\n",
      "Epoch: 1591, Train_loss: 0.4889 / Val_loss: 1.0943\n",
      "Epoch: 1592, Train_loss: 0.4895 / Val_loss: 0.8655\n",
      "Epoch: 1593, Train_loss: 0.5027 / Val_loss: 1.0384\n",
      "Epoch: 1594, Train_loss: 0.5027 / Val_loss: 1.2260\n",
      "Epoch: 1595, Train_loss: 0.4949 / Val_loss: 1.2049\n",
      "Epoch: 1596, Train_loss: 0.5021 / Val_loss: 1.0332\n",
      "Epoch: 1597, Train_loss: 0.5304 / Val_loss: 1.2765\n",
      "Epoch: 1598, Train_loss: 0.4998 / Val_loss: 1.0876\n",
      "Epoch: 1599, Train_loss: 0.4983 / Val_loss: 1.1479\n",
      "Epoch: 1600, Train_loss: 0.4877 / Val_loss: 1.1407\n",
      "Epoch: 1601, Train_loss: 0.5031 / Val_loss: 0.7987\n",
      "Epoch: 1602, Train_loss: 0.4953 / Val_loss: 0.9724\n",
      "Epoch: 1603, Train_loss: 0.5133 / Val_loss: 0.9909\n",
      "Epoch: 1604, Train_loss: 0.4970 / Val_loss: 1.0608\n",
      "Epoch: 1605, Train_loss: 0.5108 / Val_loss: 1.0244\n",
      "Epoch: 1606, Train_loss: 0.5040 / Val_loss: 0.8942\n",
      "Epoch: 1607, Train_loss: 0.5145 / Val_loss: 0.9901\n",
      "Epoch: 1608, Train_loss: 0.4881 / Val_loss: 1.2169\n",
      "Epoch: 1609, Train_loss: 0.5017 / Val_loss: 0.9144\n",
      "Epoch: 1610, Train_loss: 0.4816 / Val_loss: 1.0434\n",
      "Epoch: 1611, Train_loss: 0.4962 / Val_loss: 1.0953\n",
      "Epoch: 1612, Train_loss: 0.4868 / Val_loss: 1.3610\n",
      "Epoch: 1613, Train_loss: 0.5181 / Val_loss: 1.0011\n",
      "Epoch: 1614, Train_loss: 0.5219 / Val_loss: 0.9183\n",
      "Epoch: 1615, Train_loss: 0.5030 / Val_loss: 0.9653\n",
      "Epoch: 1616, Train_loss: 0.5035 / Val_loss: 1.0518\n",
      "Epoch: 1617, Train_loss: 0.4895 / Val_loss: 1.0749\n",
      "Epoch: 1618, Train_loss: 0.4999 / Val_loss: 1.0639\n",
      "Epoch: 1619, Train_loss: 0.5235 / Val_loss: 0.9452\n",
      "Epoch: 1620, Train_loss: 0.4981 / Val_loss: 1.0206\n",
      "Epoch: 1621, Train_loss: 0.4987 / Val_loss: 1.0592\n",
      "Epoch: 1622, Train_loss: 0.5076 / Val_loss: 0.9926\n",
      "Epoch: 1623, Train_loss: 0.4948 / Val_loss: 1.0355\n",
      "Epoch: 1624, Train_loss: 0.5075 / Val_loss: 1.1509\n",
      "Epoch: 1625, Train_loss: 0.4815 / Val_loss: 1.1466\n",
      "Epoch: 1626, Train_loss: 0.4943 / Val_loss: 1.2639\n",
      "Epoch: 1627, Train_loss: 0.4901 / Val_loss: 1.2362\n",
      "Epoch: 1628, Train_loss: 0.5096 / Val_loss: 1.0190\n",
      "Epoch: 1629, Train_loss: 0.4785 / Val_loss: 1.0501\n",
      "Epoch: 1630, Train_loss: 0.5115 / Val_loss: 1.1186\n",
      "Epoch: 1631, Train_loss: 0.4915 / Val_loss: 1.1387\n",
      "Epoch: 1632, Train_loss: 0.5081 / Val_loss: 1.2066\n",
      "Epoch: 1633, Train_loss: 0.5024 / Val_loss: 1.2329\n",
      "Epoch: 1634, Train_loss: 0.4872 / Val_loss: 1.2291\n",
      "Epoch: 1635, Train_loss: 0.4914 / Val_loss: 1.0896\n",
      "Epoch: 1636, Train_loss: 0.4893 / Val_loss: 1.1109\n",
      "Epoch: 1637, Train_loss: 0.4921 / Val_loss: 0.9389\n",
      "Epoch: 1638, Train_loss: 0.4785 / Val_loss: 0.9988\n",
      "Epoch: 1639, Train_loss: 0.4984 / Val_loss: 1.1160\n",
      "Epoch: 1640, Train_loss: 0.5006 / Val_loss: 1.1005\n",
      "Epoch: 1641, Train_loss: 0.4980 / Val_loss: 1.0016\n",
      "Epoch: 1642, Train_loss: 0.5030 / Val_loss: 1.0690\n",
      "Epoch: 1643, Train_loss: 0.4930 / Val_loss: 0.9384\n",
      "Epoch: 1644, Train_loss: 0.4896 / Val_loss: 0.8820\n",
      "Epoch: 1645, Train_loss: 0.5033 / Val_loss: 1.0338\n",
      "Epoch: 1646, Train_loss: 0.4881 / Val_loss: 0.9411\n",
      "Epoch: 1647, Train_loss: 0.4900 / Val_loss: 0.9775\n",
      "Epoch: 1648, Train_loss: 0.4955 / Val_loss: 1.1965\n",
      "Epoch: 1649, Train_loss: 0.4872 / Val_loss: 0.9467\n",
      "Epoch: 1650, Train_loss: 0.4872 / Val_loss: 1.0297\n",
      "Epoch: 1651, Train_loss: 0.5002 / Val_loss: 0.9876\n",
      "Epoch: 1652, Train_loss: 0.4818 / Val_loss: 1.2454\n",
      "Epoch: 1653, Train_loss: 0.5161 / Val_loss: 1.0907\n",
      "Epoch: 1654, Train_loss: 0.4967 / Val_loss: 1.2593\n",
      "Epoch: 1655, Train_loss: 0.4923 / Val_loss: 1.1274\n",
      "Epoch: 1656, Train_loss: 0.4897 / Val_loss: 1.1400\n",
      "Epoch: 1657, Train_loss: 0.4935 / Val_loss: 1.0685\n",
      "Epoch: 1658, Train_loss: 0.4944 / Val_loss: 1.1891\n",
      "Epoch: 1659, Train_loss: 0.4910 / Val_loss: 1.0317\n",
      "Epoch: 1660, Train_loss: 0.5005 / Val_loss: 1.1622\n",
      "Epoch: 1661, Train_loss: 0.5115 / Val_loss: 0.9793\n",
      "Epoch: 1662, Train_loss: 0.4862 / Val_loss: 1.0581\n",
      "Epoch: 1663, Train_loss: 0.4826 / Val_loss: 0.9340\n",
      "Epoch: 1664, Train_loss: 0.4969 / Val_loss: 1.2554\n",
      "Epoch: 1665, Train_loss: 0.4939 / Val_loss: 1.0687\n",
      "Epoch: 1666, Train_loss: 0.4910 / Val_loss: 1.3687\n",
      "Epoch: 1667, Train_loss: 0.5129 / Val_loss: 1.1327\n",
      "Epoch: 1668, Train_loss: 0.5081 / Val_loss: 0.9493\n",
      "Epoch: 1669, Train_loss: 0.4792 / Val_loss: 1.0336\n",
      "Epoch: 1670, Train_loss: 0.4966 / Val_loss: 1.0590\n",
      "Epoch: 1671, Train_loss: 0.4883 / Val_loss: 1.1273\n",
      "Epoch: 1672, Train_loss: 0.4931 / Val_loss: 1.2183\n",
      "Epoch: 1673, Train_loss: 0.4960 / Val_loss: 1.2222\n",
      "Epoch: 1674, Train_loss: 0.5102 / Val_loss: 1.0817\n",
      "Epoch: 1675, Train_loss: 0.5177 / Val_loss: 1.1621\n",
      "Epoch: 1676, Train_loss: 0.4899 / Val_loss: 1.0394\n",
      "Epoch: 1677, Train_loss: 0.4929 / Val_loss: 1.1124\n",
      "Epoch: 1678, Train_loss: 0.5023 / Val_loss: 1.1525\n",
      "Epoch: 1679, Train_loss: 0.4821 / Val_loss: 1.0824\n",
      "Epoch: 1680, Train_loss: 0.5109 / Val_loss: 1.0214\n",
      "Epoch: 1681, Train_loss: 0.5100 / Val_loss: 1.1020\n",
      "Epoch: 1682, Train_loss: 0.4886 / Val_loss: 1.2029\n",
      "Epoch: 1683, Train_loss: 0.4923 / Val_loss: 0.9487\n",
      "Epoch: 1684, Train_loss: 0.5048 / Val_loss: 1.1560\n",
      "Epoch: 1685, Train_loss: 0.4890 / Val_loss: 1.1130\n",
      "Epoch: 1686, Train_loss: 0.5050 / Val_loss: 1.0857\n",
      "Epoch: 1687, Train_loss: 0.4959 / Val_loss: 1.0211\n",
      "Epoch: 1688, Train_loss: 0.5035 / Val_loss: 0.9897\n",
      "Epoch: 1689, Train_loss: 0.5015 / Val_loss: 0.8836\n",
      "Epoch: 1690, Train_loss: 0.5026 / Val_loss: 1.2467\n",
      "Epoch: 1691, Train_loss: 0.5011 / Val_loss: 0.9892\n",
      "Epoch: 1692, Train_loss: 0.4993 / Val_loss: 1.1646\n",
      "Epoch: 1693, Train_loss: 0.4870 / Val_loss: 0.9624\n",
      "Epoch: 1694, Train_loss: 0.4865 / Val_loss: 1.0761\n",
      "Epoch: 1695, Train_loss: 0.4832 / Val_loss: 1.1804\n",
      "Epoch: 1696, Train_loss: 0.4836 / Val_loss: 1.0390\n",
      "Epoch: 1697, Train_loss: 0.4854 / Val_loss: 1.1625\n",
      "Epoch: 1698, Train_loss: 0.5028 / Val_loss: 1.1741\n",
      "Epoch: 1699, Train_loss: 0.4912 / Val_loss: 1.1679\n",
      "Epoch: 1700, Train_loss: 0.5151 / Val_loss: 1.1596\n",
      "Epoch: 1701, Train_loss: 0.5036 / Val_loss: 1.1213\n",
      "Epoch: 1702, Train_loss: 0.4929 / Val_loss: 0.8871\n",
      "Epoch: 1703, Train_loss: 0.4809 / Val_loss: 1.1095\n",
      "Epoch: 1704, Train_loss: 0.4998 / Val_loss: 1.0692\n",
      "Epoch: 1705, Train_loss: 0.4877 / Val_loss: 1.2037\n",
      "Epoch: 1706, Train_loss: 0.5009 / Val_loss: 1.0897\n",
      "Epoch: 1707, Train_loss: 0.5052 / Val_loss: 1.1862\n",
      "Epoch: 1708, Train_loss: 0.4913 / Val_loss: 0.9811\n",
      "Epoch: 1709, Train_loss: 0.4851 / Val_loss: 1.1043\n",
      "Epoch: 1710, Train_loss: 0.4829 / Val_loss: 1.0072\n",
      "Epoch: 1711, Train_loss: 0.4902 / Val_loss: 1.1279\n",
      "Epoch: 1712, Train_loss: 0.4964 / Val_loss: 1.0139\n",
      "Epoch: 1713, Train_loss: 0.4909 / Val_loss: 0.9095\n",
      "Epoch: 1714, Train_loss: 0.5100 / Val_loss: 1.3158\n",
      "Epoch: 1715, Train_loss: 0.4832 / Val_loss: 1.2251\n",
      "Epoch: 1716, Train_loss: 0.5162 / Val_loss: 1.1800\n",
      "Epoch: 1717, Train_loss: 0.5044 / Val_loss: 1.0751\n",
      "Epoch: 1718, Train_loss: 0.4979 / Val_loss: 1.0217\n",
      "Epoch: 1719, Train_loss: 0.4869 / Val_loss: 1.2036\n",
      "Epoch: 1720, Train_loss: 0.4994 / Val_loss: 1.0587\n",
      "Epoch: 1721, Train_loss: 0.4971 / Val_loss: 1.1080\n",
      "Epoch: 1722, Train_loss: 0.4853 / Val_loss: 1.1486\n",
      "Epoch: 1723, Train_loss: 0.4929 / Val_loss: 0.9537\n",
      "Epoch: 1724, Train_loss: 0.5024 / Val_loss: 0.9033\n",
      "Epoch: 1725, Train_loss: 0.5087 / Val_loss: 0.9478\n",
      "Epoch: 1726, Train_loss: 0.4919 / Val_loss: 1.1203\n",
      "Epoch: 1727, Train_loss: 0.4881 / Val_loss: 1.2618\n",
      "Epoch: 1728, Train_loss: 0.4970 / Val_loss: 1.1186\n",
      "Epoch: 1729, Train_loss: 0.5037 / Val_loss: 1.0241\n",
      "Epoch: 1730, Train_loss: 0.5605 / Val_loss: 0.9931\n",
      "Epoch: 1731, Train_loss: 0.4885 / Val_loss: 0.9494\n",
      "Epoch: 1732, Train_loss: 0.5073 / Val_loss: 1.1995\n",
      "Epoch: 1733, Train_loss: 0.4995 / Val_loss: 1.2067\n",
      "Epoch: 1734, Train_loss: 0.4967 / Val_loss: 1.0767\n",
      "Epoch: 1735, Train_loss: 0.5231 / Val_loss: 1.3700\n",
      "Epoch: 1736, Train_loss: 0.4944 / Val_loss: 0.9408\n",
      "Epoch: 1737, Train_loss: 0.4798 / Val_loss: 1.2502\n",
      "Epoch: 1738, Train_loss: 0.5207 / Val_loss: 1.0333\n",
      "Epoch: 1739, Train_loss: 0.4892 / Val_loss: 1.1520\n",
      "Epoch: 1740, Train_loss: 0.4831 / Val_loss: 1.1349\n",
      "Epoch: 1741, Train_loss: 0.5029 / Val_loss: 1.0854\n",
      "Epoch: 1742, Train_loss: 0.4936 / Val_loss: 1.0969\n",
      "Epoch: 1743, Train_loss: 0.4918 / Val_loss: 1.0430\n",
      "Epoch: 1744, Train_loss: 0.4996 / Val_loss: 1.0020\n",
      "Epoch: 1745, Train_loss: 0.4915 / Val_loss: 1.1072\n",
      "Epoch: 1746, Train_loss: 0.5006 / Val_loss: 1.0311\n",
      "Epoch: 1747, Train_loss: 0.5126 / Val_loss: 1.0807\n",
      "Epoch: 1748, Train_loss: 0.5052 / Val_loss: 1.0189\n",
      "Epoch: 1749, Train_loss: 0.5064 / Val_loss: 1.0657\n",
      "Epoch: 1750, Train_loss: 0.5105 / Val_loss: 1.1410\n",
      "Epoch: 1751, Train_loss: 0.5035 / Val_loss: 0.9776\n",
      "Epoch: 1752, Train_loss: 0.4873 / Val_loss: 1.0176\n",
      "Epoch: 1753, Train_loss: 0.4868 / Val_loss: 1.0671\n",
      "Epoch: 1754, Train_loss: 0.4895 / Val_loss: 0.9748\n",
      "Epoch: 1755, Train_loss: 0.5008 / Val_loss: 1.0708\n",
      "Epoch: 1756, Train_loss: 0.4842 / Val_loss: 1.1333\n",
      "Epoch: 1757, Train_loss: 0.5038 / Val_loss: 1.0311\n",
      "Epoch: 1758, Train_loss: 0.4894 / Val_loss: 1.1552\n",
      "Epoch: 1759, Train_loss: 0.4797 / Val_loss: 1.1471\n",
      "Epoch: 1760, Train_loss: 0.4932 / Val_loss: 1.1457\n",
      "Epoch: 1761, Train_loss: 0.4890 / Val_loss: 1.1045\n",
      "Epoch: 1762, Train_loss: 0.4907 / Val_loss: 1.1714\n",
      "Epoch: 1763, Train_loss: 0.5053 / Val_loss: 1.1968\n",
      "Epoch: 1764, Train_loss: 0.4948 / Val_loss: 1.1041\n",
      "Epoch: 1765, Train_loss: 0.4853 / Val_loss: 1.0882\n",
      "Epoch: 1766, Train_loss: 0.4877 / Val_loss: 1.1261\n",
      "Epoch: 1767, Train_loss: 0.5171 / Val_loss: 0.9725\n",
      "Epoch: 1768, Train_loss: 0.4803 / Val_loss: 1.1384\n",
      "Epoch: 1769, Train_loss: 0.4820 / Val_loss: 1.1208\n",
      "Epoch: 1770, Train_loss: 0.5005 / Val_loss: 0.8946\n",
      "Epoch: 1771, Train_loss: 0.5236 / Val_loss: 1.1699\n",
      "Epoch: 1772, Train_loss: 0.4854 / Val_loss: 1.1702\n",
      "Epoch: 1773, Train_loss: 0.4920 / Val_loss: 1.1099\n",
      "Epoch: 1774, Train_loss: 0.4868 / Val_loss: 1.0193\n",
      "Epoch: 1775, Train_loss: 0.4960 / Val_loss: 1.3227\n",
      "Epoch: 1776, Train_loss: 0.4914 / Val_loss: 1.1357\n",
      "Epoch: 1777, Train_loss: 0.5039 / Val_loss: 1.3178\n",
      "Epoch: 1778, Train_loss: 0.4829 / Val_loss: 1.1483\n",
      "Epoch: 1779, Train_loss: 0.5063 / Val_loss: 1.0741\n",
      "Epoch: 1780, Train_loss: 0.4878 / Val_loss: 0.9489\n",
      "Epoch: 1781, Train_loss: 0.4919 / Val_loss: 1.0652\n",
      "Epoch: 1782, Train_loss: 0.4925 / Val_loss: 1.2054\n",
      "Epoch: 1783, Train_loss: 0.4853 / Val_loss: 1.2189\n",
      "Epoch: 1784, Train_loss: 0.4896 / Val_loss: 1.2074\n",
      "Epoch: 1785, Train_loss: 0.4739 / Val_loss: 1.0653\n",
      "Epoch: 1786, Train_loss: 0.5200 / Val_loss: 1.0456\n",
      "Epoch: 1787, Train_loss: 0.4949 / Val_loss: 1.2458\n",
      "Epoch: 1788, Train_loss: 0.5080 / Val_loss: 1.0554\n",
      "Epoch: 1789, Train_loss: 0.4997 / Val_loss: 1.0600\n",
      "Epoch: 1790, Train_loss: 0.4950 / Val_loss: 0.9839\n",
      "Epoch: 1791, Train_loss: 0.4910 / Val_loss: 1.0920\n",
      "Epoch: 1792, Train_loss: 0.5000 / Val_loss: 1.1446\n",
      "Epoch: 1793, Train_loss: 0.5106 / Val_loss: 1.0520\n",
      "Epoch: 1794, Train_loss: 0.4895 / Val_loss: 1.1563\n",
      "Epoch: 1795, Train_loss: 0.5061 / Val_loss: 1.2242\n",
      "Epoch: 1796, Train_loss: 0.5010 / Val_loss: 1.2249\n",
      "Epoch: 1797, Train_loss: 0.4993 / Val_loss: 1.0636\n",
      "Epoch: 1798, Train_loss: 0.5079 / Val_loss: 1.1871\n",
      "Epoch: 1799, Train_loss: 0.4926 / Val_loss: 1.1500\n",
      "Epoch: 1800, Train_loss: 0.4843 / Val_loss: 1.2658\n",
      "Epoch: 1801, Train_loss: 0.4834 / Val_loss: 1.1423\n",
      "Epoch: 1802, Train_loss: 0.4887 / Val_loss: 0.9779\n",
      "Epoch: 1803, Train_loss: 0.4870 / Val_loss: 0.9992\n",
      "Epoch: 1804, Train_loss: 0.4899 / Val_loss: 0.9979\n",
      "Epoch: 1805, Train_loss: 0.4766 / Val_loss: 0.9929\n",
      "Epoch: 1806, Train_loss: 0.4956 / Val_loss: 1.0717\n",
      "Epoch: 1807, Train_loss: 0.4978 / Val_loss: 1.0525\n",
      "Epoch: 1808, Train_loss: 0.4963 / Val_loss: 1.0931\n",
      "Epoch: 1809, Train_loss: 0.4976 / Val_loss: 1.2300\n",
      "Epoch: 1810, Train_loss: 0.5017 / Val_loss: 0.9744\n",
      "Epoch: 1811, Train_loss: 0.4882 / Val_loss: 1.0656\n",
      "Epoch: 1812, Train_loss: 0.4932 / Val_loss: 1.1781\n",
      "Epoch: 1813, Train_loss: 0.4824 / Val_loss: 1.0283\n",
      "Epoch: 1814, Train_loss: 0.4970 / Val_loss: 1.2214\n",
      "Epoch: 1815, Train_loss: 0.4731 / Val_loss: 1.1428\n",
      "Epoch: 1816, Train_loss: 0.4864 / Val_loss: 1.2227\n",
      "Epoch: 1817, Train_loss: 0.4746 / Val_loss: 1.2760\n",
      "Epoch: 1818, Train_loss: 0.5118 / Val_loss: 1.4376\n",
      "Epoch: 1819, Train_loss: 0.4940 / Val_loss: 1.1074\n",
      "Epoch: 1820, Train_loss: 0.5051 / Val_loss: 1.0947\n",
      "Epoch: 1821, Train_loss: 0.4891 / Val_loss: 1.1225\n",
      "Epoch: 1822, Train_loss: 0.4891 / Val_loss: 1.0896\n",
      "Epoch: 1823, Train_loss: 0.5009 / Val_loss: 1.3155\n",
      "Epoch: 1824, Train_loss: 0.4933 / Val_loss: 1.1165\n",
      "Epoch: 1825, Train_loss: 0.4890 / Val_loss: 1.1377\n",
      "Epoch: 1826, Train_loss: 0.4889 / Val_loss: 0.9672\n",
      "Epoch: 1827, Train_loss: 0.4908 / Val_loss: 1.2634\n",
      "Epoch: 1828, Train_loss: 0.4996 / Val_loss: 1.2462\n",
      "Epoch: 1829, Train_loss: 0.4866 / Val_loss: 1.2024\n",
      "Epoch: 1830, Train_loss: 0.4948 / Val_loss: 1.1662\n",
      "Epoch: 1831, Train_loss: 0.4833 / Val_loss: 0.9841\n",
      "Epoch: 1832, Train_loss: 0.5016 / Val_loss: 1.0089\n",
      "Epoch: 1833, Train_loss: 0.4907 / Val_loss: 1.0539\n",
      "Epoch: 1834, Train_loss: 0.4912 / Val_loss: 1.1349\n",
      "Epoch: 1835, Train_loss: 0.4916 / Val_loss: 0.9923\n",
      "Epoch: 1836, Train_loss: 0.5203 / Val_loss: 1.0112\n",
      "Epoch: 1837, Train_loss: 0.4949 / Val_loss: 0.8700\n",
      "Epoch: 1838, Train_loss: 0.4781 / Val_loss: 0.9177\n",
      "Epoch: 1839, Train_loss: 0.4941 / Val_loss: 0.9772\n",
      "Epoch: 1840, Train_loss: 0.4829 / Val_loss: 0.9736\n",
      "Epoch: 1841, Train_loss: 0.4849 / Val_loss: 1.1106\n",
      "Epoch: 1842, Train_loss: 0.4970 / Val_loss: 1.1551\n",
      "Epoch: 1843, Train_loss: 0.4880 / Val_loss: 1.0307\n",
      "Epoch: 1844, Train_loss: 0.4976 / Val_loss: 1.1582\n",
      "Epoch: 1845, Train_loss: 0.4870 / Val_loss: 1.1573\n",
      "Epoch: 1846, Train_loss: 0.4841 / Val_loss: 1.0971\n",
      "Epoch: 1847, Train_loss: 0.4840 / Val_loss: 1.0048\n",
      "Epoch: 1848, Train_loss: 0.4811 / Val_loss: 1.1242\n",
      "Epoch: 1849, Train_loss: 0.4865 / Val_loss: 0.9922\n",
      "Epoch: 1850, Train_loss: 0.4841 / Val_loss: 1.1608\n",
      "Epoch: 1851, Train_loss: 0.5053 / Val_loss: 1.1160\n",
      "Epoch: 1852, Train_loss: 0.4814 / Val_loss: 1.1405\n",
      "Epoch: 1853, Train_loss: 0.4871 / Val_loss: 1.0879\n",
      "Epoch: 1854, Train_loss: 0.4948 / Val_loss: 0.9971\n",
      "Epoch: 1855, Train_loss: 0.4793 / Val_loss: 0.9562\n",
      "Epoch: 1856, Train_loss: 0.4996 / Val_loss: 1.3829\n",
      "Epoch: 1857, Train_loss: 0.4938 / Val_loss: 1.2157\n",
      "Epoch: 1858, Train_loss: 0.4844 / Val_loss: 1.0883\n",
      "Epoch: 1859, Train_loss: 0.4942 / Val_loss: 1.0616\n",
      "Epoch: 1860, Train_loss: 0.4862 / Val_loss: 1.0854\n",
      "Epoch: 1861, Train_loss: 0.4895 / Val_loss: 0.9212\n",
      "Epoch: 1862, Train_loss: 0.4744 / Val_loss: 1.1464\n",
      "Epoch: 1863, Train_loss: 0.4751 / Val_loss: 1.1088\n",
      "Epoch: 1864, Train_loss: 0.4869 / Val_loss: 1.0224\n",
      "Epoch: 1865, Train_loss: 0.4766 / Val_loss: 1.1476\n",
      "Epoch: 1866, Train_loss: 0.4792 / Val_loss: 1.0867\n",
      "Epoch: 1867, Train_loss: 0.4930 / Val_loss: 1.2257\n",
      "Epoch: 1868, Train_loss: 0.4879 / Val_loss: 1.2409\n",
      "Epoch: 1869, Train_loss: 0.4802 / Val_loss: 1.2038\n",
      "Epoch: 1870, Train_loss: 0.4903 / Val_loss: 0.9999\n",
      "Epoch: 1871, Train_loss: 0.4943 / Val_loss: 1.1287\n",
      "Epoch: 1872, Train_loss: 0.4809 / Val_loss: 1.2593\n",
      "Epoch: 1873, Train_loss: 0.4897 / Val_loss: 1.1643\n",
      "Epoch: 1874, Train_loss: 0.4890 / Val_loss: 1.1198\n",
      "Epoch: 1875, Train_loss: 0.4850 / Val_loss: 1.0379\n",
      "Epoch: 1876, Train_loss: 0.4813 / Val_loss: 1.0881\n",
      "Epoch: 1877, Train_loss: 0.4875 / Val_loss: 1.1300\n",
      "Epoch: 1878, Train_loss: 0.4702 / Val_loss: 0.9443\n",
      "Epoch: 1879, Train_loss: 0.4980 / Val_loss: 1.1017\n",
      "Epoch: 1880, Train_loss: 0.4817 / Val_loss: 1.2386\n",
      "Epoch: 1881, Train_loss: 0.4786 / Val_loss: 0.9541\n",
      "Epoch: 1882, Train_loss: 0.4954 / Val_loss: 1.1535\n",
      "Epoch: 1883, Train_loss: 0.4693 / Val_loss: 1.1132\n",
      "Epoch: 1884, Train_loss: 0.4724 / Val_loss: 1.1863\n",
      "Epoch: 1885, Train_loss: 0.4987 / Val_loss: 1.1237\n",
      "Epoch: 1886, Train_loss: 0.4798 / Val_loss: 1.1130\n",
      "Epoch: 1887, Train_loss: 0.4962 / Val_loss: 1.1092\n",
      "Epoch: 1888, Train_loss: 0.4868 / Val_loss: 1.0709\n",
      "Epoch: 1889, Train_loss: 0.4890 / Val_loss: 1.1722\n",
      "Epoch: 1890, Train_loss: 0.4806 / Val_loss: 1.1156\n",
      "Epoch: 1891, Train_loss: 0.5124 / Val_loss: 0.9208\n",
      "Epoch: 1892, Train_loss: 0.4695 / Val_loss: 1.2779\n",
      "Epoch: 1893, Train_loss: 0.4912 / Val_loss: 1.1239\n",
      "Epoch: 1894, Train_loss: 0.5081 / Val_loss: 1.1005\n",
      "Epoch: 1895, Train_loss: 0.5003 / Val_loss: 0.9897\n",
      "Epoch: 1896, Train_loss: 0.4801 / Val_loss: 1.2092\n",
      "Epoch: 1897, Train_loss: 0.5021 / Val_loss: 1.3970\n",
      "Epoch: 1898, Train_loss: 0.4943 / Val_loss: 1.1146\n",
      "Epoch: 1899, Train_loss: 0.5015 / Val_loss: 1.0483\n",
      "Epoch: 1900, Train_loss: 0.4862 / Val_loss: 1.1443\n",
      "Epoch: 1901, Train_loss: 0.4770 / Val_loss: 1.1092\n",
      "Epoch: 1902, Train_loss: 0.4656 / Val_loss: 1.2546\n",
      "Epoch: 1903, Train_loss: 0.4810 / Val_loss: 0.9828\n",
      "Epoch: 1904, Train_loss: 0.4894 / Val_loss: 1.1261\n",
      "Epoch: 1905, Train_loss: 0.5040 / Val_loss: 1.1347\n",
      "Epoch: 1906, Train_loss: 0.4897 / Val_loss: 1.1602\n",
      "Epoch: 1907, Train_loss: 0.4837 / Val_loss: 1.0396\n",
      "Epoch: 1908, Train_loss: 0.4736 / Val_loss: 1.0561\n",
      "Epoch: 1909, Train_loss: 0.4798 / Val_loss: 1.2445\n",
      "Epoch: 1910, Train_loss: 0.4902 / Val_loss: 1.0498\n",
      "Epoch: 1911, Train_loss: 0.5075 / Val_loss: 1.0877\n",
      "Epoch: 1912, Train_loss: 0.4817 / Val_loss: 1.2110\n",
      "Epoch: 1913, Train_loss: 0.4953 / Val_loss: 1.0840\n",
      "Epoch: 1914, Train_loss: 0.4988 / Val_loss: 1.0299\n",
      "Epoch: 1915, Train_loss: 0.4972 / Val_loss: 1.1848\n",
      "Epoch: 1916, Train_loss: 0.4740 / Val_loss: 1.1993\n",
      "Epoch: 1917, Train_loss: 0.5127 / Val_loss: 1.1662\n",
      "Epoch: 1918, Train_loss: 0.4943 / Val_loss: 1.0636\n",
      "Epoch: 1919, Train_loss: 0.4819 / Val_loss: 1.1011\n",
      "Epoch: 1920, Train_loss: 0.4777 / Val_loss: 1.2793\n",
      "Epoch: 1921, Train_loss: 0.4902 / Val_loss: 1.2363\n",
      "Epoch: 1922, Train_loss: 0.4761 / Val_loss: 1.0722\n",
      "Epoch: 1923, Train_loss: 0.4892 / Val_loss: 1.2072\n",
      "Epoch: 1924, Train_loss: 0.4859 / Val_loss: 1.0612\n",
      "Epoch: 1925, Train_loss: 0.4930 / Val_loss: 1.0954\n",
      "Epoch: 1926, Train_loss: 0.4943 / Val_loss: 1.0141\n",
      "Epoch: 1927, Train_loss: 0.4878 / Val_loss: 1.0547\n",
      "Epoch: 1928, Train_loss: 0.4971 / Val_loss: 0.9286\n",
      "Epoch: 1929, Train_loss: 0.4827 / Val_loss: 1.1442\n",
      "Epoch: 1930, Train_loss: 0.4789 / Val_loss: 1.0577\n",
      "Epoch: 1931, Train_loss: 0.4894 / Val_loss: 0.9549\n",
      "Epoch: 1932, Train_loss: 0.4930 / Val_loss: 1.2016\n",
      "Epoch: 1933, Train_loss: 0.4997 / Val_loss: 1.0696\n",
      "Epoch: 1934, Train_loss: 0.4991 / Val_loss: 1.2681\n",
      "Epoch: 1935, Train_loss: 0.4715 / Val_loss: 1.1139\n",
      "Epoch: 1936, Train_loss: 0.4871 / Val_loss: 1.2032\n",
      "Epoch: 1937, Train_loss: 0.4811 / Val_loss: 1.2817\n",
      "Epoch: 1938, Train_loss: 0.4995 / Val_loss: 1.3827\n",
      "Epoch: 1939, Train_loss: 0.4969 / Val_loss: 1.2013\n",
      "Epoch: 1940, Train_loss: 0.4897 / Val_loss: 1.1810\n",
      "Epoch: 1941, Train_loss: 0.4835 / Val_loss: 1.1008\n",
      "Epoch: 1942, Train_loss: 0.4695 / Val_loss: 1.0645\n",
      "Epoch: 1943, Train_loss: 0.4742 / Val_loss: 1.0416\n",
      "Epoch: 1944, Train_loss: 0.4912 / Val_loss: 1.1610\n",
      "Epoch: 1945, Train_loss: 0.4840 / Val_loss: 1.0806\n",
      "Epoch: 1946, Train_loss: 0.4913 / Val_loss: 1.0892\n",
      "Epoch: 1947, Train_loss: 0.4840 / Val_loss: 1.1742\n",
      "Epoch: 1948, Train_loss: 0.4783 / Val_loss: 1.1434\n",
      "Epoch: 1949, Train_loss: 0.4910 / Val_loss: 1.0476\n",
      "Epoch: 1950, Train_loss: 0.4651 / Val_loss: 1.0537\n",
      "Epoch: 1951, Train_loss: 0.4881 / Val_loss: 1.0275\n",
      "Epoch: 1952, Train_loss: 0.5001 / Val_loss: 1.1095\n",
      "Epoch: 1953, Train_loss: 0.4818 / Val_loss: 1.0000\n",
      "Epoch: 1954, Train_loss: 0.4884 / Val_loss: 1.0553\n",
      "Epoch: 1955, Train_loss: 0.4914 / Val_loss: 1.1948\n",
      "Epoch: 1956, Train_loss: 0.5055 / Val_loss: 0.9958\n",
      "Epoch: 1957, Train_loss: 0.4887 / Val_loss: 0.9566\n",
      "Epoch: 1958, Train_loss: 0.5094 / Val_loss: 1.1507\n",
      "Epoch: 1959, Train_loss: 0.5038 / Val_loss: 1.0734\n",
      "Epoch: 1960, Train_loss: 0.4713 / Val_loss: 1.0633\n",
      "Epoch: 1961, Train_loss: 0.4929 / Val_loss: 1.1515\n",
      "Epoch: 1962, Train_loss: 0.4733 / Val_loss: 1.1632\n",
      "Epoch: 1963, Train_loss: 0.4730 / Val_loss: 1.1863\n",
      "Epoch: 1964, Train_loss: 0.5060 / Val_loss: 1.1320\n",
      "Epoch: 1965, Train_loss: 0.4872 / Val_loss: 1.1500\n",
      "Epoch: 1966, Train_loss: 0.4877 / Val_loss: 1.0868\n",
      "Epoch: 1967, Train_loss: 0.4911 / Val_loss: 1.1863\n",
      "Epoch: 1968, Train_loss: 0.4785 / Val_loss: 1.1645\n",
      "Epoch: 1969, Train_loss: 0.5070 / Val_loss: 0.9692\n",
      "Epoch: 1970, Train_loss: 0.4947 / Val_loss: 1.0507\n",
      "Epoch: 1971, Train_loss: 0.4802 / Val_loss: 1.1071\n",
      "Epoch: 1972, Train_loss: 0.4981 / Val_loss: 1.1089\n",
      "Epoch: 1973, Train_loss: 0.4897 / Val_loss: 1.0859\n",
      "Epoch: 1974, Train_loss: 0.4796 / Val_loss: 1.1243\n",
      "Epoch: 1975, Train_loss: 0.4855 / Val_loss: 1.1883\n",
      "Epoch: 1976, Train_loss: 0.4981 / Val_loss: 1.1764\n",
      "Epoch: 1977, Train_loss: 0.4819 / Val_loss: 1.2092\n",
      "Epoch: 1978, Train_loss: 0.4879 / Val_loss: 1.1720\n",
      "Epoch: 1979, Train_loss: 0.4915 / Val_loss: 1.2000\n",
      "Epoch: 1980, Train_loss: 0.4715 / Val_loss: 1.1495\n",
      "Epoch: 1981, Train_loss: 0.4810 / Val_loss: 1.2321\n",
      "Epoch: 1982, Train_loss: 0.5018 / Val_loss: 1.3233\n",
      "Epoch: 1983, Train_loss: 0.4896 / Val_loss: 1.1853\n",
      "Epoch: 1984, Train_loss: 0.4965 / Val_loss: 1.0610\n",
      "Epoch: 1985, Train_loss: 0.4865 / Val_loss: 1.1277\n",
      "Epoch: 1986, Train_loss: 0.4798 / Val_loss: 1.0701\n",
      "Epoch: 1987, Train_loss: 0.4639 / Val_loss: 1.1053\n",
      "Epoch: 1988, Train_loss: 0.4790 / Val_loss: 0.9242\n",
      "Epoch: 1989, Train_loss: 0.4819 / Val_loss: 1.1992\n",
      "Epoch: 1990, Train_loss: 0.4950 / Val_loss: 1.1032\n",
      "Epoch: 1991, Train_loss: 0.4855 / Val_loss: 1.0053\n",
      "Epoch: 1992, Train_loss: 0.4747 / Val_loss: 0.9168\n",
      "Epoch: 1993, Train_loss: 0.4757 / Val_loss: 1.0050\n",
      "Epoch: 1994, Train_loss: 0.4898 / Val_loss: 1.0663\n",
      "Epoch: 1995, Train_loss: 0.4898 / Val_loss: 0.8570\n",
      "Epoch: 1996, Train_loss: 0.4792 / Val_loss: 1.0489\n",
      "Epoch: 1997, Train_loss: 0.4849 / Val_loss: 0.9977\n",
      "Epoch: 1998, Train_loss: 0.5005 / Val_loss: 1.0006\n",
      "Epoch: 1999, Train_loss: 0.4735 / Val_loss: 1.1160\n",
      "Epoch: 2000, Train_loss: 0.4888 / Val_loss: 1.1539\n"
     ]
    }
   ],
   "source": [
    "weight = torch.Tensor([1.0, 2.5])\n",
    "log_softmax = torch.nn.LogSoftmax(dim=1)\n",
    "criterion = torch.nn.NLLLoss(weight=weight)  # Define loss criterion.\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)  # Define optimizer.\n",
    "\n",
    "losses = []\n",
    "v_losses = []\n",
    "best_v_loss = 100000\n",
    "COUNT = 2000\n",
    "val_early_stop_count = COUNT\n",
    "val_early_stop_continuous_flag = False\n",
    "\n",
    "for epoch in range(1, 2001):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    outs = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "    preds = outs[data.train_mask].squeeze()\n",
    "    loss = criterion(log_softmax(preds), data.y[data.train_mask].to(dtype=torch.long))  # Compute the loss solely based on the training nodes.\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        v_preds = outs[data.val_mask].squeeze()\n",
    "        v_loss = criterion(log_softmax(v_preds), data.y[data.val_mask].to(dtype=torch.long))\n",
    "        v_losses.append(v_loss.item())\n",
    "    print(f'Epoch: {epoch:03d}, Train_loss: {loss:.4f} / Val_loss: {v_loss:.4f}')\n",
    "    \n",
    "    if v_loss.item() < best_v_loss:\n",
    "        best_v_loss = v_loss.item()\n",
    "        val_early_stop_continuous_flag = False\n",
    "        val_early_stop_count = COUNT\n",
    "    else:\n",
    "        val_early_stop_continuous_flag = True\n",
    "        val_early_stop_count -= 1\n",
    "        if val_early_stop_count == 0:\n",
    "            print(f\"============== Early stopped at Epoch: {epoch}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.plot(v_losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Train\", \"Val\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "out = model(data.x, data.edge_index)\n",
    "pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "y_pred = pred[data.test_mask].numpy()\n",
    "y_true = data.y[data.test_mask].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5238\n",
      "Precision: 0.2609\n",
      "Recall: 0.6667\n",
      "f1 score: 0.3750\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true, y_pred, normalize=None)\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    ")\n",
    "\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred):.4f}\")\n",
    "print(f\"f1 score: {f1_score(y_true, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341,830\n",
      "GAT model number of params: 341,830\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234567)\n",
    "        self.conv1 = GATConv(data.num_features, hidden_channels)\n",
    "        self.conv2 = GATConv(hidden_channels, hidden_channels * 2)\n",
    "        self.conv3 = GATConv(hidden_channels * 2, hidden_channels * 4)\n",
    "        self.conv4 = GATConv(hidden_channels * 4, hidden_channels * 8)\n",
    "        self.conv5 = GATConv(hidden_channels * 8, hidden_channels * 4)\n",
    "        self.conv6 = GATConv(hidden_channels * 4, hidden_channels * 2)\n",
    "        self.conv7 = GATConv(hidden_channels * 2, 2)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv6(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv7(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = GAT(hidden_channels=64)\n",
    "print(f\"GAT model number of params: {count_parameters(model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train_loss: 0.7002 / Val_loss: 0.6990\n",
      "Epoch: 002, Train_loss: 0.6948 / Val_loss: 0.6903\n",
      "Epoch: 003, Train_loss: 0.6895 / Val_loss: 0.6901\n",
      "Epoch: 004, Train_loss: 0.6891 / Val_loss: 0.6888\n",
      "Epoch: 005, Train_loss: 0.6848 / Val_loss: 0.6817\n",
      "Epoch: 006, Train_loss: 0.6820 / Val_loss: 0.6784\n",
      "Epoch: 007, Train_loss: 0.6838 / Val_loss: 0.6780\n",
      "Epoch: 008, Train_loss: 0.6758 / Val_loss: 0.6709\n",
      "Epoch: 009, Train_loss: 0.6802 / Val_loss: 0.6722\n",
      "Epoch: 010, Train_loss: 0.6762 / Val_loss: 0.6653\n",
      "Epoch: 011, Train_loss: 0.6753 / Val_loss: 0.6668\n",
      "Epoch: 012, Train_loss: 0.6744 / Val_loss: 0.6656\n",
      "Epoch: 013, Train_loss: 0.6766 / Val_loss: 0.6629\n",
      "Epoch: 014, Train_loss: 0.6733 / Val_loss: 0.6671\n",
      "Epoch: 015, Train_loss: 0.6711 / Val_loss: 0.6575\n",
      "Epoch: 016, Train_loss: 0.6732 / Val_loss: 0.6539\n",
      "Epoch: 017, Train_loss: 0.6689 / Val_loss: 0.6584\n",
      "Epoch: 018, Train_loss: 0.6724 / Val_loss: 0.6458\n",
      "Epoch: 019, Train_loss: 0.6697 / Val_loss: 0.6555\n",
      "Epoch: 020, Train_loss: 0.6653 / Val_loss: 0.6594\n",
      "Epoch: 021, Train_loss: 0.6626 / Val_loss: 0.6516\n",
      "Epoch: 022, Train_loss: 0.6664 / Val_loss: 0.6519\n",
      "Epoch: 023, Train_loss: 0.6698 / Val_loss: 0.6486\n",
      "Epoch: 024, Train_loss: 0.6658 / Val_loss: 0.6479\n",
      "Epoch: 025, Train_loss: 0.6657 / Val_loss: 0.6465\n",
      "Epoch: 026, Train_loss: 0.6635 / Val_loss: 0.6403\n",
      "Epoch: 027, Train_loss: 0.6624 / Val_loss: 0.6425\n",
      "Epoch: 028, Train_loss: 0.6602 / Val_loss: 0.6453\n",
      "Epoch: 029, Train_loss: 0.6654 / Val_loss: 0.6427\n",
      "Epoch: 030, Train_loss: 0.6612 / Val_loss: 0.6439\n",
      "Epoch: 031, Train_loss: 0.6621 / Val_loss: 0.6424\n",
      "Epoch: 032, Train_loss: 0.6551 / Val_loss: 0.6418\n",
      "Epoch: 033, Train_loss: 0.6612 / Val_loss: 0.6374\n",
      "Epoch: 034, Train_loss: 0.6614 / Val_loss: 0.6509\n",
      "Epoch: 035, Train_loss: 0.6544 / Val_loss: 0.6402\n",
      "Epoch: 036, Train_loss: 0.6565 / Val_loss: 0.6376\n",
      "Epoch: 037, Train_loss: 0.6616 / Val_loss: 0.6414\n",
      "Epoch: 038, Train_loss: 0.6582 / Val_loss: 0.6383\n",
      "Epoch: 039, Train_loss: 0.6563 / Val_loss: 0.6379\n",
      "Epoch: 040, Train_loss: 0.6555 / Val_loss: 0.6453\n",
      "Epoch: 041, Train_loss: 0.6524 / Val_loss: 0.6412\n",
      "Epoch: 042, Train_loss: 0.6580 / Val_loss: 0.6369\n",
      "Epoch: 043, Train_loss: 0.6532 / Val_loss: 0.6396\n",
      "Epoch: 044, Train_loss: 0.6520 / Val_loss: 0.6473\n",
      "Epoch: 045, Train_loss: 0.6436 / Val_loss: 0.6392\n",
      "Epoch: 046, Train_loss: 0.6528 / Val_loss: 0.6381\n",
      "Epoch: 047, Train_loss: 0.6508 / Val_loss: 0.6332\n",
      "Epoch: 048, Train_loss: 0.6514 / Val_loss: 0.6401\n",
      "Epoch: 049, Train_loss: 0.6523 / Val_loss: 0.6357\n",
      "Epoch: 050, Train_loss: 0.6536 / Val_loss: 0.6402\n",
      "Epoch: 051, Train_loss: 0.6506 / Val_loss: 0.6310\n",
      "Epoch: 052, Train_loss: 0.6502 / Val_loss: 0.6362\n",
      "Epoch: 053, Train_loss: 0.6519 / Val_loss: 0.6431\n",
      "Epoch: 054, Train_loss: 0.6439 / Val_loss: 0.6382\n",
      "Epoch: 055, Train_loss: 0.6404 / Val_loss: 0.6321\n",
      "Epoch: 056, Train_loss: 0.6404 / Val_loss: 0.6377\n",
      "Epoch: 057, Train_loss: 0.6380 / Val_loss: 0.6414\n",
      "Epoch: 058, Train_loss: 0.6496 / Val_loss: 0.6364\n",
      "Epoch: 059, Train_loss: 0.6373 / Val_loss: 0.6357\n",
      "Epoch: 060, Train_loss: 0.6378 / Val_loss: 0.6286\n",
      "Epoch: 061, Train_loss: 0.6351 / Val_loss: 0.6460\n",
      "Epoch: 062, Train_loss: 0.6338 / Val_loss: 0.6438\n",
      "Epoch: 063, Train_loss: 0.6306 / Val_loss: 0.6205\n",
      "Epoch: 064, Train_loss: 0.6259 / Val_loss: 0.6319\n",
      "Epoch: 065, Train_loss: 0.6314 / Val_loss: 0.6220\n",
      "Epoch: 066, Train_loss: 0.6358 / Val_loss: 0.6418\n",
      "Epoch: 067, Train_loss: 0.6335 / Val_loss: 0.6228\n",
      "Epoch: 068, Train_loss: 0.6276 / Val_loss: 0.6329\n",
      "Epoch: 069, Train_loss: 0.6288 / Val_loss: 0.6309\n",
      "Epoch: 070, Train_loss: 0.6342 / Val_loss: 0.6239\n",
      "Epoch: 071, Train_loss: 0.6265 / Val_loss: 0.6287\n",
      "Epoch: 072, Train_loss: 0.6240 / Val_loss: 0.6321\n",
      "Epoch: 073, Train_loss: 0.6221 / Val_loss: 0.6285\n",
      "Epoch: 074, Train_loss: 0.6261 / Val_loss: 0.6562\n",
      "Epoch: 075, Train_loss: 0.6234 / Val_loss: 0.6327\n",
      "Epoch: 076, Train_loss: 0.6239 / Val_loss: 0.6380\n",
      "Epoch: 077, Train_loss: 0.6185 / Val_loss: 0.6421\n",
      "Epoch: 078, Train_loss: 0.6194 / Val_loss: 0.6509\n",
      "Epoch: 079, Train_loss: 0.6175 / Val_loss: 0.6353\n",
      "Epoch: 080, Train_loss: 0.6230 / Val_loss: 0.6511\n",
      "Epoch: 081, Train_loss: 0.6165 / Val_loss: 0.6321\n",
      "Epoch: 082, Train_loss: 0.6156 / Val_loss: 0.6477\n",
      "Epoch: 083, Train_loss: 0.6216 / Val_loss: 0.6323\n",
      "Epoch: 084, Train_loss: 0.6198 / Val_loss: 0.6657\n",
      "Epoch: 085, Train_loss: 0.6223 / Val_loss: 0.6345\n",
      "Epoch: 086, Train_loss: 0.6092 / Val_loss: 0.6589\n",
      "Epoch: 087, Train_loss: 0.6189 / Val_loss: 0.6502\n",
      "Epoch: 088, Train_loss: 0.6177 / Val_loss: 0.6443\n",
      "Epoch: 089, Train_loss: 0.6074 / Val_loss: 0.6646\n",
      "Epoch: 090, Train_loss: 0.6174 / Val_loss: 0.6784\n",
      "Epoch: 091, Train_loss: 0.6112 / Val_loss: 0.6518\n",
      "Epoch: 092, Train_loss: 0.6228 / Val_loss: 0.6549\n",
      "Epoch: 093, Train_loss: 0.6153 / Val_loss: 0.6496\n",
      "Epoch: 094, Train_loss: 0.6112 / Val_loss: 0.6846\n",
      "Epoch: 095, Train_loss: 0.6137 / Val_loss: 0.6318\n",
      "Epoch: 096, Train_loss: 0.6158 / Val_loss: 0.6568\n",
      "Epoch: 097, Train_loss: 0.6087 / Val_loss: 0.6545\n",
      "Epoch: 098, Train_loss: 0.6107 / Val_loss: 0.6670\n",
      "Epoch: 099, Train_loss: 0.6131 / Val_loss: 0.6584\n",
      "Epoch: 100, Train_loss: 0.6055 / Val_loss: 0.6526\n",
      "Epoch: 101, Train_loss: 0.6083 / Val_loss: 0.6683\n",
      "Epoch: 102, Train_loss: 0.6181 / Val_loss: 0.6452\n",
      "Epoch: 103, Train_loss: 0.5992 / Val_loss: 0.6898\n",
      "Epoch: 104, Train_loss: 0.6117 / Val_loss: 0.6501\n",
      "Epoch: 105, Train_loss: 0.5924 / Val_loss: 0.6985\n",
      "Epoch: 106, Train_loss: 0.5995 / Val_loss: 0.6834\n",
      "Epoch: 107, Train_loss: 0.6123 / Val_loss: 0.6831\n",
      "Epoch: 108, Train_loss: 0.6200 / Val_loss: 0.6922\n",
      "Epoch: 109, Train_loss: 0.6057 / Val_loss: 0.6621\n",
      "Epoch: 110, Train_loss: 0.6081 / Val_loss: 0.6981\n",
      "Epoch: 111, Train_loss: 0.6104 / Val_loss: 0.6453\n",
      "Epoch: 112, Train_loss: 0.6108 / Val_loss: 0.7260\n",
      "Epoch: 113, Train_loss: 0.6022 / Val_loss: 0.6847\n",
      "Epoch: 114, Train_loss: 0.5996 / Val_loss: 0.6845\n",
      "Epoch: 115, Train_loss: 0.6059 / Val_loss: 0.6690\n",
      "Epoch: 116, Train_loss: 0.6037 / Val_loss: 0.6968\n",
      "Epoch: 117, Train_loss: 0.5960 / Val_loss: 0.6584\n",
      "Epoch: 118, Train_loss: 0.6098 / Val_loss: 0.6864\n",
      "Epoch: 119, Train_loss: 0.6050 / Val_loss: 0.7465\n",
      "Epoch: 120, Train_loss: 0.6031 / Val_loss: 0.6940\n",
      "Epoch: 121, Train_loss: 0.6038 / Val_loss: 0.6879\n",
      "Epoch: 122, Train_loss: 0.6056 / Val_loss: 0.6577\n",
      "Epoch: 123, Train_loss: 0.6019 / Val_loss: 0.7166\n",
      "Epoch: 124, Train_loss: 0.5972 / Val_loss: 0.7231\n",
      "Epoch: 125, Train_loss: 0.6084 / Val_loss: 0.7172\n",
      "Epoch: 126, Train_loss: 0.6062 / Val_loss: 0.7014\n",
      "Epoch: 127, Train_loss: 0.6050 / Val_loss: 0.7207\n",
      "Epoch: 128, Train_loss: 0.5968 / Val_loss: 0.7145\n",
      "Epoch: 129, Train_loss: 0.6000 / Val_loss: 0.6893\n",
      "Epoch: 130, Train_loss: 0.6045 / Val_loss: 0.7008\n",
      "Epoch: 131, Train_loss: 0.5968 / Val_loss: 0.6802\n",
      "Epoch: 132, Train_loss: 0.5998 / Val_loss: 0.6989\n",
      "Epoch: 133, Train_loss: 0.6082 / Val_loss: 0.7119\n",
      "Epoch: 134, Train_loss: 0.5997 / Val_loss: 0.6772\n",
      "Epoch: 135, Train_loss: 0.5949 / Val_loss: 0.6744\n",
      "Epoch: 136, Train_loss: 0.6113 / Val_loss: 0.7030\n",
      "Epoch: 137, Train_loss: 0.5950 / Val_loss: 0.7177\n",
      "Epoch: 138, Train_loss: 0.5988 / Val_loss: 0.7128\n",
      "Epoch: 139, Train_loss: 0.5915 / Val_loss: 0.7118\n",
      "Epoch: 140, Train_loss: 0.6045 / Val_loss: 0.6609\n",
      "Epoch: 141, Train_loss: 0.5981 / Val_loss: 0.7111\n",
      "Epoch: 142, Train_loss: 0.6109 / Val_loss: 0.6565\n",
      "Epoch: 143, Train_loss: 0.5946 / Val_loss: 0.6897\n",
      "Epoch: 144, Train_loss: 0.5968 / Val_loss: 0.7007\n",
      "Epoch: 145, Train_loss: 0.5986 / Val_loss: 0.6918\n",
      "Epoch: 146, Train_loss: 0.5935 / Val_loss: 0.6965\n",
      "Epoch: 147, Train_loss: 0.5981 / Val_loss: 0.6945\n",
      "Epoch: 148, Train_loss: 0.6069 / Val_loss: 0.6621\n",
      "Epoch: 149, Train_loss: 0.5989 / Val_loss: 0.6901\n",
      "Epoch: 150, Train_loss: 0.5907 / Val_loss: 0.7070\n",
      "Epoch: 151, Train_loss: 0.5907 / Val_loss: 0.7025\n",
      "Epoch: 152, Train_loss: 0.5914 / Val_loss: 0.7200\n",
      "Epoch: 153, Train_loss: 0.5901 / Val_loss: 0.6777\n",
      "Epoch: 154, Train_loss: 0.5928 / Val_loss: 0.6878\n",
      "Epoch: 155, Train_loss: 0.5873 / Val_loss: 0.7295\n",
      "Epoch: 156, Train_loss: 0.5983 / Val_loss: 0.6922\n",
      "Epoch: 157, Train_loss: 0.5992 / Val_loss: 0.7302\n",
      "Epoch: 158, Train_loss: 0.5966 / Val_loss: 0.7829\n",
      "Epoch: 159, Train_loss: 0.5880 / Val_loss: 0.6886\n",
      "Epoch: 160, Train_loss: 0.5810 / Val_loss: 0.7129\n",
      "Epoch: 161, Train_loss: 0.5945 / Val_loss: 0.7357\n",
      "Epoch: 162, Train_loss: 0.5935 / Val_loss: 0.7046\n",
      "Epoch: 163, Train_loss: 0.5902 / Val_loss: 0.7116\n",
      "Epoch: 164, Train_loss: 0.5842 / Val_loss: 0.7232\n",
      "Epoch: 165, Train_loss: 0.5860 / Val_loss: 0.7320\n",
      "Epoch: 166, Train_loss: 0.5933 / Val_loss: 0.7060\n",
      "Epoch: 167, Train_loss: 0.5917 / Val_loss: 0.7482\n",
      "Epoch: 168, Train_loss: 0.5898 / Val_loss: 0.7682\n",
      "Epoch: 169, Train_loss: 0.5837 / Val_loss: 0.6907\n",
      "Epoch: 170, Train_loss: 0.5977 / Val_loss: 0.7808\n",
      "Epoch: 171, Train_loss: 0.5786 / Val_loss: 0.6953\n",
      "Epoch: 172, Train_loss: 0.5881 / Val_loss: 0.7301\n",
      "Epoch: 173, Train_loss: 0.5993 / Val_loss: 0.7359\n",
      "Epoch: 174, Train_loss: 0.5834 / Val_loss: 0.7162\n",
      "Epoch: 175, Train_loss: 0.5829 / Val_loss: 0.7278\n",
      "Epoch: 176, Train_loss: 0.5842 / Val_loss: 0.7973\n",
      "Epoch: 177, Train_loss: 0.5821 / Val_loss: 0.7375\n",
      "Epoch: 178, Train_loss: 0.5884 / Val_loss: 0.7439\n",
      "Epoch: 179, Train_loss: 0.5921 / Val_loss: 0.6979\n",
      "Epoch: 180, Train_loss: 0.5804 / Val_loss: 0.7204\n",
      "Epoch: 181, Train_loss: 0.5847 / Val_loss: 0.7282\n",
      "Epoch: 182, Train_loss: 0.5806 / Val_loss: 0.7430\n",
      "Epoch: 183, Train_loss: 0.5855 / Val_loss: 0.7852\n",
      "Epoch: 184, Train_loss: 0.5937 / Val_loss: 0.6965\n",
      "Epoch: 185, Train_loss: 0.6031 / Val_loss: 0.7024\n",
      "Epoch: 186, Train_loss: 0.5813 / Val_loss: 0.7710\n",
      "Epoch: 187, Train_loss: 0.5949 / Val_loss: 0.7377\n",
      "Epoch: 188, Train_loss: 0.5844 / Val_loss: 0.7363\n",
      "Epoch: 189, Train_loss: 0.5808 / Val_loss: 0.7313\n",
      "Epoch: 190, Train_loss: 0.5874 / Val_loss: 0.7155\n",
      "Epoch: 191, Train_loss: 0.5829 / Val_loss: 0.6956\n",
      "Epoch: 192, Train_loss: 0.5833 / Val_loss: 0.7353\n",
      "Epoch: 193, Train_loss: 0.5981 / Val_loss: 0.7290\n",
      "Epoch: 194, Train_loss: 0.5791 / Val_loss: 0.7575\n",
      "Epoch: 195, Train_loss: 0.5811 / Val_loss: 0.7008\n",
      "Epoch: 196, Train_loss: 0.5750 / Val_loss: 0.7412\n",
      "Epoch: 197, Train_loss: 0.5779 / Val_loss: 0.7720\n",
      "Epoch: 198, Train_loss: 0.5826 / Val_loss: 0.7408\n",
      "Epoch: 199, Train_loss: 0.5827 / Val_loss: 0.7146\n",
      "Epoch: 200, Train_loss: 0.5841 / Val_loss: 0.7405\n",
      "Epoch: 201, Train_loss: 0.5881 / Val_loss: 0.7850\n",
      "Epoch: 202, Train_loss: 0.5833 / Val_loss: 0.7473\n",
      "Epoch: 203, Train_loss: 0.5870 / Val_loss: 0.7606\n",
      "Epoch: 204, Train_loss: 0.5788 / Val_loss: 0.7406\n",
      "Epoch: 205, Train_loss: 0.5819 / Val_loss: 0.7332\n",
      "Epoch: 206, Train_loss: 0.5764 / Val_loss: 0.7271\n",
      "Epoch: 207, Train_loss: 0.5815 / Val_loss: 0.7715\n",
      "Epoch: 208, Train_loss: 0.5768 / Val_loss: 0.7422\n",
      "Epoch: 209, Train_loss: 0.5829 / Val_loss: 0.7117\n",
      "Epoch: 210, Train_loss: 0.5770 / Val_loss: 0.7479\n",
      "Epoch: 211, Train_loss: 0.5744 / Val_loss: 0.7287\n",
      "Epoch: 212, Train_loss: 0.5806 / Val_loss: 0.6950\n",
      "Epoch: 213, Train_loss: 0.5903 / Val_loss: 0.7455\n",
      "Epoch: 214, Train_loss: 0.5745 / Val_loss: 0.7581\n",
      "Epoch: 215, Train_loss: 0.5732 / Val_loss: 0.7583\n",
      "Epoch: 216, Train_loss: 0.5833 / Val_loss: 0.7673\n",
      "Epoch: 217, Train_loss: 0.5757 / Val_loss: 0.7405\n",
      "Epoch: 218, Train_loss: 0.5770 / Val_loss: 0.7166\n",
      "Epoch: 219, Train_loss: 0.5806 / Val_loss: 0.7979\n",
      "Epoch: 220, Train_loss: 0.5761 / Val_loss: 0.7469\n",
      "Epoch: 221, Train_loss: 0.5801 / Val_loss: 0.7397\n",
      "Epoch: 222, Train_loss: 0.5681 / Val_loss: 0.7782\n",
      "Epoch: 223, Train_loss: 0.5615 / Val_loss: 0.7736\n",
      "Epoch: 224, Train_loss: 0.5649 / Val_loss: 0.8049\n",
      "Epoch: 225, Train_loss: 0.5745 / Val_loss: 0.8109\n",
      "Epoch: 226, Train_loss: 0.5889 / Val_loss: 0.7628\n",
      "Epoch: 227, Train_loss: 0.5876 / Val_loss: 0.7776\n",
      "Epoch: 228, Train_loss: 0.5690 / Val_loss: 0.7445\n",
      "Epoch: 229, Train_loss: 0.5711 / Val_loss: 0.7504\n",
      "Epoch: 230, Train_loss: 0.5944 / Val_loss: 0.8297\n",
      "Epoch: 231, Train_loss: 0.5845 / Val_loss: 0.7549\n",
      "Epoch: 232, Train_loss: 0.5833 / Val_loss: 0.7689\n",
      "Epoch: 233, Train_loss: 0.5830 / Val_loss: 0.7630\n",
      "Epoch: 234, Train_loss: 0.5683 / Val_loss: 0.7498\n",
      "Epoch: 235, Train_loss: 0.5702 / Val_loss: 0.7737\n",
      "Epoch: 236, Train_loss: 0.5894 / Val_loss: 0.7737\n",
      "Epoch: 237, Train_loss: 0.5838 / Val_loss: 0.7375\n",
      "Epoch: 238, Train_loss: 0.5735 / Val_loss: 0.7860\n",
      "Epoch: 239, Train_loss: 0.5729 / Val_loss: 0.7242\n",
      "Epoch: 240, Train_loss: 0.5636 / Val_loss: 0.7850\n",
      "Epoch: 241, Train_loss: 0.5861 / Val_loss: 0.6897\n",
      "Epoch: 242, Train_loss: 0.5688 / Val_loss: 0.7703\n",
      "Epoch: 243, Train_loss: 0.5630 / Val_loss: 0.7132\n",
      "Epoch: 244, Train_loss: 0.5712 / Val_loss: 0.8081\n",
      "Epoch: 245, Train_loss: 0.5719 / Val_loss: 0.7593\n",
      "Epoch: 246, Train_loss: 0.5711 / Val_loss: 0.7844\n",
      "Epoch: 247, Train_loss: 0.5912 / Val_loss: 0.7744\n",
      "Epoch: 248, Train_loss: 0.5771 / Val_loss: 0.7573\n",
      "Epoch: 249, Train_loss: 0.5672 / Val_loss: 0.7469\n",
      "Epoch: 250, Train_loss: 0.5599 / Val_loss: 0.7958\n",
      "Epoch: 251, Train_loss: 0.5717 / Val_loss: 0.7114\n",
      "Epoch: 252, Train_loss: 0.5743 / Val_loss: 0.7868\n",
      "Epoch: 253, Train_loss: 0.5756 / Val_loss: 0.7639\n",
      "Epoch: 254, Train_loss: 0.5938 / Val_loss: 0.7864\n",
      "Epoch: 255, Train_loss: 0.5753 / Val_loss: 0.7325\n",
      "Epoch: 256, Train_loss: 0.5607 / Val_loss: 0.7778\n",
      "Epoch: 257, Train_loss: 0.5695 / Val_loss: 0.7694\n",
      "Epoch: 258, Train_loss: 0.5856 / Val_loss: 0.7691\n",
      "Epoch: 259, Train_loss: 0.5877 / Val_loss: 0.7218\n",
      "Epoch: 260, Train_loss: 0.5771 / Val_loss: 0.7808\n",
      "Epoch: 261, Train_loss: 0.5657 / Val_loss: 0.7260\n",
      "Epoch: 262, Train_loss: 0.5716 / Val_loss: 0.7807\n",
      "Epoch: 263, Train_loss: 0.5596 / Val_loss: 0.7620\n",
      "Epoch: 264, Train_loss: 0.5667 / Val_loss: 0.7810\n",
      "Epoch: 265, Train_loss: 0.5737 / Val_loss: 0.8172\n",
      "Epoch: 266, Train_loss: 0.5733 / Val_loss: 0.8598\n",
      "Epoch: 267, Train_loss: 0.5842 / Val_loss: 0.7827\n",
      "Epoch: 268, Train_loss: 0.5616 / Val_loss: 0.7751\n",
      "Epoch: 269, Train_loss: 0.5745 / Val_loss: 0.8328\n",
      "Epoch: 270, Train_loss: 0.5751 / Val_loss: 0.8397\n",
      "Epoch: 271, Train_loss: 0.5795 / Val_loss: 0.7148\n",
      "Epoch: 272, Train_loss: 0.5650 / Val_loss: 0.7347\n",
      "Epoch: 273, Train_loss: 0.5704 / Val_loss: 0.7510\n",
      "Epoch: 274, Train_loss: 0.5733 / Val_loss: 0.7890\n",
      "Epoch: 275, Train_loss: 0.5650 / Val_loss: 0.8675\n",
      "Epoch: 276, Train_loss: 0.5768 / Val_loss: 0.7460\n",
      "Epoch: 277, Train_loss: 0.5803 / Val_loss: 0.8402\n",
      "Epoch: 278, Train_loss: 0.5684 / Val_loss: 0.7557\n",
      "Epoch: 279, Train_loss: 0.5608 / Val_loss: 0.8029\n",
      "Epoch: 280, Train_loss: 0.5681 / Val_loss: 0.7294\n",
      "Epoch: 281, Train_loss: 0.5643 / Val_loss: 0.8122\n",
      "Epoch: 282, Train_loss: 0.5601 / Val_loss: 0.8018\n",
      "Epoch: 283, Train_loss: 0.5662 / Val_loss: 0.7684\n",
      "Epoch: 284, Train_loss: 0.5666 / Val_loss: 0.7618\n",
      "Epoch: 285, Train_loss: 0.5729 / Val_loss: 0.7961\n",
      "Epoch: 286, Train_loss: 0.5615 / Val_loss: 0.8650\n",
      "Epoch: 287, Train_loss: 0.5683 / Val_loss: 0.8228\n",
      "Epoch: 288, Train_loss: 0.5659 / Val_loss: 0.7777\n",
      "Epoch: 289, Train_loss: 0.5558 / Val_loss: 0.7852\n",
      "Epoch: 290, Train_loss: 0.5629 / Val_loss: 0.7863\n",
      "Epoch: 291, Train_loss: 0.5561 / Val_loss: 0.8187\n",
      "Epoch: 292, Train_loss: 0.5536 / Val_loss: 0.7953\n",
      "Epoch: 293, Train_loss: 0.5708 / Val_loss: 0.7874\n",
      "Epoch: 294, Train_loss: 0.5662 / Val_loss: 0.7545\n",
      "Epoch: 295, Train_loss: 0.5618 / Val_loss: 0.7189\n",
      "Epoch: 296, Train_loss: 0.5662 / Val_loss: 0.8400\n",
      "Epoch: 297, Train_loss: 0.5771 / Val_loss: 0.7447\n",
      "Epoch: 298, Train_loss: 0.5624 / Val_loss: 0.8695\n",
      "Epoch: 299, Train_loss: 0.5675 / Val_loss: 0.7985\n",
      "Epoch: 300, Train_loss: 0.5604 / Val_loss: 0.7797\n",
      "Epoch: 301, Train_loss: 0.5700 / Val_loss: 0.8369\n",
      "Epoch: 302, Train_loss: 0.5601 / Val_loss: 0.8606\n",
      "Epoch: 303, Train_loss: 0.5545 / Val_loss: 0.7121\n",
      "Epoch: 304, Train_loss: 0.5677 / Val_loss: 0.7825\n",
      "Epoch: 305, Train_loss: 0.5754 / Val_loss: 0.7321\n",
      "Epoch: 306, Train_loss: 0.5621 / Val_loss: 0.7727\n",
      "Epoch: 307, Train_loss: 0.5551 / Val_loss: 0.8113\n",
      "Epoch: 308, Train_loss: 0.5604 / Val_loss: 0.7729\n",
      "Epoch: 309, Train_loss: 0.5598 / Val_loss: 0.7986\n",
      "Epoch: 310, Train_loss: 0.5525 / Val_loss: 0.8341\n",
      "Epoch: 311, Train_loss: 0.5553 / Val_loss: 0.8255\n",
      "Epoch: 312, Train_loss: 0.5643 / Val_loss: 0.8515\n",
      "Epoch: 313, Train_loss: 0.5649 / Val_loss: 0.8121\n",
      "Epoch: 314, Train_loss: 0.5529 / Val_loss: 0.7698\n",
      "Epoch: 315, Train_loss: 0.5620 / Val_loss: 0.7732\n",
      "Epoch: 316, Train_loss: 0.5707 / Val_loss: 0.7700\n",
      "Epoch: 317, Train_loss: 0.5430 / Val_loss: 0.8185\n",
      "Epoch: 318, Train_loss: 0.5585 / Val_loss: 0.8401\n",
      "Epoch: 319, Train_loss: 0.5708 / Val_loss: 0.7991\n",
      "Epoch: 320, Train_loss: 0.5547 / Val_loss: 0.8618\n",
      "Epoch: 321, Train_loss: 0.5446 / Val_loss: 0.8392\n",
      "Epoch: 322, Train_loss: 0.5454 / Val_loss: 0.7238\n",
      "Epoch: 323, Train_loss: 0.5555 / Val_loss: 0.7917\n",
      "Epoch: 324, Train_loss: 0.5580 / Val_loss: 0.7937\n",
      "Epoch: 325, Train_loss: 0.5585 / Val_loss: 0.7499\n",
      "Epoch: 326, Train_loss: 0.5558 / Val_loss: 0.8699\n",
      "Epoch: 327, Train_loss: 0.5663 / Val_loss: 0.8335\n",
      "Epoch: 328, Train_loss: 0.5756 / Val_loss: 0.8255\n",
      "Epoch: 329, Train_loss: 0.5605 / Val_loss: 0.8229\n",
      "Epoch: 330, Train_loss: 0.5587 / Val_loss: 0.8778\n",
      "Epoch: 331, Train_loss: 0.5417 / Val_loss: 0.8353\n",
      "Epoch: 332, Train_loss: 0.5622 / Val_loss: 0.8198\n",
      "Epoch: 333, Train_loss: 0.5754 / Val_loss: 0.7641\n",
      "Epoch: 334, Train_loss: 0.5664 / Val_loss: 0.7728\n",
      "Epoch: 335, Train_loss: 0.5538 / Val_loss: 0.8036\n",
      "Epoch: 336, Train_loss: 0.5610 / Val_loss: 0.8304\n",
      "Epoch: 337, Train_loss: 0.5449 / Val_loss: 0.8483\n",
      "Epoch: 338, Train_loss: 0.5532 / Val_loss: 0.8356\n",
      "Epoch: 339, Train_loss: 0.5537 / Val_loss: 0.8829\n",
      "Epoch: 340, Train_loss: 0.5351 / Val_loss: 0.8507\n",
      "Epoch: 341, Train_loss: 0.5476 / Val_loss: 0.8768\n",
      "Epoch: 342, Train_loss: 0.5687 / Val_loss: 0.8166\n",
      "Epoch: 343, Train_loss: 0.5568 / Val_loss: 0.7506\n",
      "Epoch: 344, Train_loss: 0.5505 / Val_loss: 0.8508\n",
      "Epoch: 345, Train_loss: 0.5578 / Val_loss: 0.9369\n",
      "Epoch: 346, Train_loss: 0.5386 / Val_loss: 0.8390\n",
      "Epoch: 347, Train_loss: 0.5413 / Val_loss: 0.8292\n",
      "Epoch: 348, Train_loss: 0.5777 / Val_loss: 0.8112\n",
      "Epoch: 349, Train_loss: 0.5733 / Val_loss: 0.8974\n",
      "Epoch: 350, Train_loss: 0.5514 / Val_loss: 0.8245\n",
      "Epoch: 351, Train_loss: 0.5518 / Val_loss: 0.7728\n",
      "Epoch: 352, Train_loss: 0.5492 / Val_loss: 0.8938\n",
      "Epoch: 353, Train_loss: 0.5564 / Val_loss: 0.8746\n",
      "Epoch: 354, Train_loss: 0.5479 / Val_loss: 0.7670\n",
      "Epoch: 355, Train_loss: 0.5624 / Val_loss: 0.9299\n",
      "Epoch: 356, Train_loss: 0.5442 / Val_loss: 0.8662\n",
      "Epoch: 357, Train_loss: 0.5524 / Val_loss: 0.8739\n",
      "Epoch: 358, Train_loss: 0.5580 / Val_loss: 0.8807\n",
      "Epoch: 359, Train_loss: 0.5498 / Val_loss: 0.8597\n",
      "Epoch: 360, Train_loss: 0.5581 / Val_loss: 0.7568\n",
      "Epoch: 361, Train_loss: 0.5594 / Val_loss: 0.8461\n",
      "Epoch: 362, Train_loss: 0.5504 / Val_loss: 0.8256\n",
      "Epoch: 363, Train_loss: 0.5806 / Val_loss: 0.8064\n",
      "Epoch: 364, Train_loss: 0.5564 / Val_loss: 0.7536\n",
      "Epoch: 365, Train_loss: 0.5548 / Val_loss: 0.8388\n",
      "Epoch: 366, Train_loss: 0.5347 / Val_loss: 0.8795\n",
      "Epoch: 367, Train_loss: 0.5594 / Val_loss: 0.8731\n",
      "Epoch: 368, Train_loss: 0.5616 / Val_loss: 0.8990\n",
      "Epoch: 369, Train_loss: 0.5366 / Val_loss: 0.9014\n",
      "Epoch: 370, Train_loss: 0.5487 / Val_loss: 0.8376\n",
      "Epoch: 371, Train_loss: 0.5428 / Val_loss: 0.9300\n",
      "Epoch: 372, Train_loss: 0.5540 / Val_loss: 0.8263\n",
      "Epoch: 373, Train_loss: 0.5660 / Val_loss: 0.7728\n",
      "Epoch: 374, Train_loss: 0.5601 / Val_loss: 0.9865\n",
      "Epoch: 375, Train_loss: 0.5362 / Val_loss: 0.9967\n",
      "Epoch: 376, Train_loss: 0.5494 / Val_loss: 0.8784\n",
      "Epoch: 377, Train_loss: 0.5428 / Val_loss: 0.8590\n",
      "Epoch: 378, Train_loss: 0.5317 / Val_loss: 0.8234\n",
      "Epoch: 379, Train_loss: 0.5561 / Val_loss: 0.8258\n",
      "Epoch: 380, Train_loss: 0.5496 / Val_loss: 0.8476\n",
      "Epoch: 381, Train_loss: 0.5440 / Val_loss: 0.8854\n",
      "Epoch: 382, Train_loss: 0.5542 / Val_loss: 0.8600\n",
      "Epoch: 383, Train_loss: 0.5551 / Val_loss: 0.8857\n",
      "Epoch: 384, Train_loss: 0.5408 / Val_loss: 0.9977\n",
      "Epoch: 385, Train_loss: 0.5309 / Val_loss: 0.9169\n",
      "Epoch: 386, Train_loss: 0.5581 / Val_loss: 0.9213\n",
      "Epoch: 387, Train_loss: 0.5344 / Val_loss: 0.8959\n",
      "Epoch: 388, Train_loss: 0.5434 / Val_loss: 0.8949\n",
      "Epoch: 389, Train_loss: 0.5379 / Val_loss: 0.8486\n",
      "Epoch: 390, Train_loss: 0.5529 / Val_loss: 0.9123\n",
      "Epoch: 391, Train_loss: 0.5498 / Val_loss: 0.7437\n",
      "Epoch: 392, Train_loss: 0.5336 / Val_loss: 0.8517\n",
      "Epoch: 393, Train_loss: 0.5435 / Val_loss: 0.8871\n",
      "Epoch: 394, Train_loss: 0.5299 / Val_loss: 0.9016\n",
      "Epoch: 395, Train_loss: 0.5279 / Val_loss: 0.8142\n",
      "Epoch: 396, Train_loss: 0.5149 / Val_loss: 0.9906\n",
      "Epoch: 397, Train_loss: 0.5334 / Val_loss: 0.8400\n",
      "Epoch: 398, Train_loss: 0.5390 / Val_loss: 0.7847\n",
      "Epoch: 399, Train_loss: 0.5330 / Val_loss: 0.8570\n",
      "Epoch: 400, Train_loss: 0.5370 / Val_loss: 0.8450\n",
      "Epoch: 401, Train_loss: 0.5444 / Val_loss: 0.9372\n",
      "Epoch: 402, Train_loss: 0.5368 / Val_loss: 0.9365\n",
      "Epoch: 403, Train_loss: 0.5409 / Val_loss: 0.8916\n",
      "Epoch: 404, Train_loss: 0.5330 / Val_loss: 0.8326\n",
      "Epoch: 405, Train_loss: 0.5581 / Val_loss: 0.9250\n",
      "Epoch: 406, Train_loss: 0.5524 / Val_loss: 0.8644\n",
      "Epoch: 407, Train_loss: 0.5241 / Val_loss: 0.8676\n",
      "Epoch: 408, Train_loss: 0.5634 / Val_loss: 0.8264\n",
      "Epoch: 409, Train_loss: 0.5437 / Val_loss: 0.8763\n",
      "Epoch: 410, Train_loss: 0.5402 / Val_loss: 0.9943\n",
      "Epoch: 411, Train_loss: 0.5377 / Val_loss: 0.8690\n",
      "Epoch: 412, Train_loss: 0.5281 / Val_loss: 0.9669\n",
      "Epoch: 413, Train_loss: 0.5244 / Val_loss: 0.9574\n",
      "Epoch: 414, Train_loss: 0.5536 / Val_loss: 0.8241\n",
      "Epoch: 415, Train_loss: 0.5404 / Val_loss: 0.9206\n",
      "Epoch: 416, Train_loss: 0.5442 / Val_loss: 0.9049\n",
      "Epoch: 417, Train_loss: 0.5334 / Val_loss: 0.9650\n",
      "Epoch: 418, Train_loss: 0.5388 / Val_loss: 0.8885\n",
      "Epoch: 419, Train_loss: 0.5264 / Val_loss: 0.8946\n",
      "Epoch: 420, Train_loss: 0.5548 / Val_loss: 0.9445\n",
      "Epoch: 421, Train_loss: 0.5257 / Val_loss: 0.9159\n",
      "Epoch: 422, Train_loss: 0.5349 / Val_loss: 0.8405\n",
      "Epoch: 423, Train_loss: 0.5196 / Val_loss: 0.8371\n",
      "Epoch: 424, Train_loss: 0.5340 / Val_loss: 0.8998\n",
      "Epoch: 425, Train_loss: 0.5591 / Val_loss: 0.9385\n",
      "Epoch: 426, Train_loss: 0.5416 / Val_loss: 0.9659\n",
      "Epoch: 427, Train_loss: 0.5382 / Val_loss: 0.9689\n",
      "Epoch: 428, Train_loss: 0.5194 / Val_loss: 0.9625\n",
      "Epoch: 429, Train_loss: 0.5530 / Val_loss: 0.9461\n",
      "Epoch: 430, Train_loss: 0.5448 / Val_loss: 0.8636\n",
      "Epoch: 431, Train_loss: 0.5366 / Val_loss: 1.0184\n",
      "Epoch: 432, Train_loss: 0.5411 / Val_loss: 0.9322\n",
      "Epoch: 433, Train_loss: 0.5618 / Val_loss: 0.8130\n",
      "Epoch: 434, Train_loss: 0.5560 / Val_loss: 1.0682\n",
      "Epoch: 435, Train_loss: 0.5231 / Val_loss: 0.9693\n",
      "Epoch: 436, Train_loss: 0.5330 / Val_loss: 0.9044\n",
      "Epoch: 437, Train_loss: 0.5377 / Val_loss: 0.8927\n",
      "Epoch: 438, Train_loss: 0.5525 / Val_loss: 0.9305\n",
      "Epoch: 439, Train_loss: 0.5345 / Val_loss: 0.9146\n",
      "Epoch: 440, Train_loss: 0.5433 / Val_loss: 1.0975\n",
      "Epoch: 441, Train_loss: 0.5347 / Val_loss: 0.9528\n",
      "Epoch: 442, Train_loss: 0.5179 / Val_loss: 0.9158\n",
      "Epoch: 443, Train_loss: 0.5351 / Val_loss: 0.9685\n",
      "Epoch: 444, Train_loss: 0.5455 / Val_loss: 0.7936\n",
      "Epoch: 445, Train_loss: 0.5399 / Val_loss: 0.9997\n",
      "Epoch: 446, Train_loss: 0.5301 / Val_loss: 0.9116\n",
      "Epoch: 447, Train_loss: 0.5278 / Val_loss: 0.9343\n",
      "Epoch: 448, Train_loss: 0.5434 / Val_loss: 0.9568\n",
      "Epoch: 449, Train_loss: 0.5324 / Val_loss: 0.9890\n",
      "Epoch: 450, Train_loss: 0.5438 / Val_loss: 0.8790\n",
      "Epoch: 451, Train_loss: 0.5480 / Val_loss: 0.9072\n",
      "Epoch: 452, Train_loss: 0.5343 / Val_loss: 0.8788\n",
      "Epoch: 453, Train_loss: 0.5328 / Val_loss: 0.9982\n",
      "Epoch: 454, Train_loss: 0.5303 / Val_loss: 0.9807\n",
      "Epoch: 455, Train_loss: 0.5281 / Val_loss: 0.9134\n",
      "Epoch: 456, Train_loss: 0.5242 / Val_loss: 0.9037\n",
      "Epoch: 457, Train_loss: 0.5341 / Val_loss: 0.8617\n",
      "Epoch: 458, Train_loss: 0.5275 / Val_loss: 0.8392\n",
      "Epoch: 459, Train_loss: 0.5151 / Val_loss: 1.0036\n",
      "Epoch: 460, Train_loss: 0.5212 / Val_loss: 1.0582\n",
      "Epoch: 461, Train_loss: 0.5512 / Val_loss: 1.0944\n",
      "Epoch: 462, Train_loss: 0.5157 / Val_loss: 0.8786\n",
      "Epoch: 463, Train_loss: 0.5318 / Val_loss: 0.9639\n",
      "Epoch: 464, Train_loss: 0.5179 / Val_loss: 0.8879\n",
      "Epoch: 465, Train_loss: 0.5375 / Val_loss: 0.9579\n",
      "Epoch: 466, Train_loss: 0.5208 / Val_loss: 0.9393\n",
      "Epoch: 467, Train_loss: 0.5376 / Val_loss: 0.9327\n",
      "Epoch: 468, Train_loss: 0.5448 / Val_loss: 0.9420\n",
      "Epoch: 469, Train_loss: 0.5204 / Val_loss: 0.9439\n",
      "Epoch: 470, Train_loss: 0.5168 / Val_loss: 0.9515\n",
      "Epoch: 471, Train_loss: 0.5405 / Val_loss: 1.0152\n",
      "Epoch: 472, Train_loss: 0.5915 / Val_loss: 1.0337\n",
      "Epoch: 473, Train_loss: 0.5309 / Val_loss: 0.9485\n",
      "Epoch: 474, Train_loss: 0.5249 / Val_loss: 0.9065\n",
      "Epoch: 475, Train_loss: 0.5147 / Val_loss: 0.8686\n",
      "Epoch: 476, Train_loss: 0.5273 / Val_loss: 0.8411\n",
      "Epoch: 477, Train_loss: 0.5095 / Val_loss: 1.0713\n",
      "Epoch: 478, Train_loss: 0.5331 / Val_loss: 0.9819\n",
      "Epoch: 479, Train_loss: 0.5408 / Val_loss: 0.8647\n",
      "Epoch: 480, Train_loss: 0.5203 / Val_loss: 1.0344\n",
      "Epoch: 481, Train_loss: 0.5247 / Val_loss: 1.0384\n",
      "Epoch: 482, Train_loss: 0.5304 / Val_loss: 0.9113\n",
      "Epoch: 483, Train_loss: 0.5159 / Val_loss: 0.8576\n",
      "Epoch: 484, Train_loss: 0.5331 / Val_loss: 0.8200\n",
      "Epoch: 485, Train_loss: 0.5306 / Val_loss: 0.9656\n",
      "Epoch: 486, Train_loss: 0.5242 / Val_loss: 0.8692\n",
      "Epoch: 487, Train_loss: 0.5350 / Val_loss: 0.8025\n",
      "Epoch: 488, Train_loss: 0.5331 / Val_loss: 0.9117\n",
      "Epoch: 489, Train_loss: 0.5096 / Val_loss: 1.0109\n",
      "Epoch: 490, Train_loss: 0.5306 / Val_loss: 0.9690\n",
      "Epoch: 491, Train_loss: 0.5460 / Val_loss: 0.7823\n",
      "Epoch: 492, Train_loss: 0.5250 / Val_loss: 0.9104\n",
      "Epoch: 493, Train_loss: 0.5341 / Val_loss: 0.8773\n",
      "Epoch: 494, Train_loss: 0.5220 / Val_loss: 0.9766\n",
      "Epoch: 495, Train_loss: 0.5483 / Val_loss: 1.1518\n",
      "Epoch: 496, Train_loss: 0.5085 / Val_loss: 0.9752\n",
      "Epoch: 497, Train_loss: 0.5246 / Val_loss: 1.0711\n",
      "Epoch: 498, Train_loss: 0.5055 / Val_loss: 0.9198\n",
      "Epoch: 499, Train_loss: 0.5378 / Val_loss: 0.9000\n",
      "Epoch: 500, Train_loss: 0.5209 / Val_loss: 1.1152\n",
      "Epoch: 501, Train_loss: 0.5248 / Val_loss: 0.9595\n",
      "Epoch: 502, Train_loss: 0.5020 / Val_loss: 1.0961\n",
      "Epoch: 503, Train_loss: 0.5124 / Val_loss: 0.9574\n",
      "Epoch: 504, Train_loss: 0.5250 / Val_loss: 0.9903\n",
      "Epoch: 505, Train_loss: 0.5240 / Val_loss: 0.8337\n",
      "Epoch: 506, Train_loss: 0.5135 / Val_loss: 1.0467\n",
      "Epoch: 507, Train_loss: 0.5482 / Val_loss: 0.9100\n",
      "Epoch: 508, Train_loss: 0.5222 / Val_loss: 1.0631\n",
      "Epoch: 509, Train_loss: 0.5052 / Val_loss: 0.9941\n",
      "Epoch: 510, Train_loss: 0.5621 / Val_loss: 0.9137\n",
      "Epoch: 511, Train_loss: 0.5154 / Val_loss: 1.0717\n",
      "Epoch: 512, Train_loss: 0.5161 / Val_loss: 0.8380\n",
      "Epoch: 513, Train_loss: 0.5332 / Val_loss: 0.9745\n",
      "Epoch: 514, Train_loss: 0.5144 / Val_loss: 0.9578\n",
      "Epoch: 515, Train_loss: 0.5287 / Val_loss: 0.8935\n",
      "Epoch: 516, Train_loss: 0.5126 / Val_loss: 0.8946\n",
      "Epoch: 517, Train_loss: 0.5237 / Val_loss: 1.0191\n",
      "Epoch: 518, Train_loss: 0.5247 / Val_loss: 0.9029\n",
      "Epoch: 519, Train_loss: 0.5471 / Val_loss: 0.9968\n",
      "Epoch: 520, Train_loss: 0.5404 / Val_loss: 1.0482\n",
      "Epoch: 521, Train_loss: 0.5003 / Val_loss: 1.0415\n",
      "Epoch: 522, Train_loss: 0.5211 / Val_loss: 0.9992\n",
      "Epoch: 523, Train_loss: 0.5202 / Val_loss: 1.0689\n",
      "Epoch: 524, Train_loss: 0.5146 / Val_loss: 0.9653\n",
      "Epoch: 525, Train_loss: 0.5332 / Val_loss: 0.9491\n",
      "Epoch: 526, Train_loss: 0.5428 / Val_loss: 0.9327\n",
      "Epoch: 527, Train_loss: 0.5032 / Val_loss: 1.0164\n",
      "Epoch: 528, Train_loss: 0.5125 / Val_loss: 1.1422\n",
      "Epoch: 529, Train_loss: 0.5224 / Val_loss: 1.0029\n",
      "Epoch: 530, Train_loss: 0.5409 / Val_loss: 0.8483\n",
      "Epoch: 531, Train_loss: 0.4998 / Val_loss: 1.0330\n",
      "Epoch: 532, Train_loss: 0.5100 / Val_loss: 0.9585\n",
      "Epoch: 533, Train_loss: 0.5402 / Val_loss: 0.8850\n",
      "Epoch: 534, Train_loss: 0.5222 / Val_loss: 1.0754\n",
      "Epoch: 535, Train_loss: 0.5290 / Val_loss: 0.9373\n",
      "Epoch: 536, Train_loss: 0.5100 / Val_loss: 0.9399\n",
      "Epoch: 537, Train_loss: 0.5340 / Val_loss: 1.0303\n",
      "Epoch: 538, Train_loss: 0.5056 / Val_loss: 1.0957\n",
      "Epoch: 539, Train_loss: 0.5048 / Val_loss: 0.9430\n",
      "Epoch: 540, Train_loss: 0.5219 / Val_loss: 0.9020\n",
      "Epoch: 541, Train_loss: 0.5287 / Val_loss: 0.7505\n",
      "Epoch: 542, Train_loss: 0.5309 / Val_loss: 1.0008\n",
      "Epoch: 543, Train_loss: 0.4964 / Val_loss: 0.9826\n",
      "Epoch: 544, Train_loss: 0.5194 / Val_loss: 0.9081\n",
      "Epoch: 545, Train_loss: 0.5286 / Val_loss: 0.9731\n",
      "Epoch: 546, Train_loss: 0.4992 / Val_loss: 0.9648\n",
      "Epoch: 547, Train_loss: 0.5287 / Val_loss: 0.9469\n",
      "Epoch: 548, Train_loss: 0.5030 / Val_loss: 0.8981\n",
      "Epoch: 549, Train_loss: 0.4976 / Val_loss: 0.9294\n",
      "Epoch: 550, Train_loss: 0.4934 / Val_loss: 0.8672\n",
      "Epoch: 551, Train_loss: 0.5003 / Val_loss: 0.9397\n",
      "Epoch: 552, Train_loss: 0.5155 / Val_loss: 1.0437\n",
      "Epoch: 553, Train_loss: 0.4899 / Val_loss: 0.9548\n",
      "Epoch: 554, Train_loss: 0.5018 / Val_loss: 1.1366\n",
      "Epoch: 555, Train_loss: 0.4918 / Val_loss: 1.0990\n",
      "Epoch: 556, Train_loss: 0.5361 / Val_loss: 0.9436\n",
      "Epoch: 557, Train_loss: 0.4973 / Val_loss: 1.0064\n",
      "Epoch: 558, Train_loss: 0.4893 / Val_loss: 0.8658\n",
      "Epoch: 559, Train_loss: 0.5236 / Val_loss: 0.9736\n",
      "Epoch: 560, Train_loss: 0.4989 / Val_loss: 0.9326\n",
      "Epoch: 561, Train_loss: 0.5186 / Val_loss: 1.1136\n",
      "Epoch: 562, Train_loss: 0.4992 / Val_loss: 0.9407\n",
      "Epoch: 563, Train_loss: 0.5037 / Val_loss: 1.0460\n",
      "Epoch: 564, Train_loss: 0.5196 / Val_loss: 1.0817\n",
      "Epoch: 565, Train_loss: 0.5124 / Val_loss: 1.0669\n",
      "Epoch: 566, Train_loss: 0.5122 / Val_loss: 0.8596\n",
      "Epoch: 567, Train_loss: 0.5102 / Val_loss: 0.9754\n",
      "Epoch: 568, Train_loss: 0.5172 / Val_loss: 1.1225\n",
      "Epoch: 569, Train_loss: 0.5168 / Val_loss: 1.0182\n",
      "Epoch: 570, Train_loss: 0.5202 / Val_loss: 0.9451\n",
      "Epoch: 571, Train_loss: 0.5138 / Val_loss: 1.0419\n",
      "Epoch: 572, Train_loss: 0.5129 / Val_loss: 1.0116\n",
      "Epoch: 573, Train_loss: 0.5075 / Val_loss: 0.8770\n",
      "Epoch: 574, Train_loss: 0.5116 / Val_loss: 0.9309\n",
      "Epoch: 575, Train_loss: 0.5033 / Val_loss: 0.9758\n",
      "Epoch: 576, Train_loss: 0.5050 / Val_loss: 1.0213\n",
      "Epoch: 577, Train_loss: 0.5182 / Val_loss: 1.1472\n",
      "Epoch: 578, Train_loss: 0.5368 / Val_loss: 1.1976\n",
      "Epoch: 579, Train_loss: 0.5039 / Val_loss: 1.0882\n",
      "Epoch: 580, Train_loss: 0.4892 / Val_loss: 0.9581\n",
      "Epoch: 581, Train_loss: 0.5178 / Val_loss: 1.1126\n",
      "Epoch: 582, Train_loss: 0.5226 / Val_loss: 0.9794\n",
      "Epoch: 583, Train_loss: 0.5584 / Val_loss: 1.0188\n",
      "Epoch: 584, Train_loss: 0.5006 / Val_loss: 1.1488\n",
      "Epoch: 585, Train_loss: 0.5189 / Val_loss: 1.1304\n",
      "Epoch: 586, Train_loss: 0.5019 / Val_loss: 1.0174\n",
      "Epoch: 587, Train_loss: 0.5204 / Val_loss: 0.8735\n",
      "Epoch: 588, Train_loss: 0.5079 / Val_loss: 1.1466\n",
      "Epoch: 589, Train_loss: 0.5028 / Val_loss: 1.1224\n",
      "Epoch: 590, Train_loss: 0.5056 / Val_loss: 0.9600\n",
      "Epoch: 591, Train_loss: 0.4994 / Val_loss: 0.9854\n",
      "Epoch: 592, Train_loss: 0.5125 / Val_loss: 0.9856\n",
      "Epoch: 593, Train_loss: 0.5033 / Val_loss: 1.0380\n",
      "Epoch: 594, Train_loss: 0.4945 / Val_loss: 1.1002\n",
      "Epoch: 595, Train_loss: 0.5145 / Val_loss: 1.0549\n",
      "Epoch: 596, Train_loss: 0.5022 / Val_loss: 1.2117\n",
      "Epoch: 597, Train_loss: 0.4981 / Val_loss: 0.9043\n",
      "Epoch: 598, Train_loss: 0.4904 / Val_loss: 1.0250\n",
      "Epoch: 599, Train_loss: 0.5299 / Val_loss: 0.9001\n",
      "Epoch: 600, Train_loss: 0.5260 / Val_loss: 0.7929\n",
      "Epoch: 601, Train_loss: 0.5096 / Val_loss: 1.1470\n",
      "Epoch: 602, Train_loss: 0.4941 / Val_loss: 1.0595\n",
      "Epoch: 603, Train_loss: 0.4899 / Val_loss: 0.9611\n",
      "Epoch: 604, Train_loss: 0.5101 / Val_loss: 1.1872\n",
      "Epoch: 605, Train_loss: 0.4983 / Val_loss: 1.1782\n",
      "Epoch: 606, Train_loss: 0.5559 / Val_loss: 1.0131\n",
      "Epoch: 607, Train_loss: 0.5286 / Val_loss: 0.9246\n",
      "Epoch: 608, Train_loss: 0.5268 / Val_loss: 1.2615\n",
      "Epoch: 609, Train_loss: 0.5237 / Val_loss: 0.7769\n",
      "Epoch: 610, Train_loss: 0.5007 / Val_loss: 1.0273\n",
      "Epoch: 611, Train_loss: 0.5109 / Val_loss: 1.0702\n",
      "Epoch: 612, Train_loss: 0.5088 / Val_loss: 1.0006\n",
      "Epoch: 613, Train_loss: 0.5351 / Val_loss: 0.8331\n",
      "Epoch: 614, Train_loss: 0.5059 / Val_loss: 1.0710\n",
      "Epoch: 615, Train_loss: 0.4870 / Val_loss: 0.9033\n",
      "Epoch: 616, Train_loss: 0.5092 / Val_loss: 0.8567\n",
      "Epoch: 617, Train_loss: 0.4978 / Val_loss: 1.0718\n",
      "Epoch: 618, Train_loss: 0.5119 / Val_loss: 0.9273\n",
      "Epoch: 619, Train_loss: 0.5202 / Val_loss: 1.1139\n",
      "Epoch: 620, Train_loss: 0.5206 / Val_loss: 1.0037\n",
      "Epoch: 621, Train_loss: 0.5100 / Val_loss: 1.1601\n",
      "Epoch: 622, Train_loss: 0.5055 / Val_loss: 1.0082\n",
      "Epoch: 623, Train_loss: 0.5099 / Val_loss: 1.0255\n",
      "Epoch: 624, Train_loss: 0.4938 / Val_loss: 1.0701\n",
      "Epoch: 625, Train_loss: 0.5002 / Val_loss: 0.9998\n",
      "Epoch: 626, Train_loss: 0.5006 / Val_loss: 1.1390\n",
      "Epoch: 627, Train_loss: 0.4947 / Val_loss: 1.0411\n",
      "Epoch: 628, Train_loss: 0.5193 / Val_loss: 0.9146\n",
      "Epoch: 629, Train_loss: 0.5390 / Val_loss: 0.9432\n",
      "Epoch: 630, Train_loss: 0.5021 / Val_loss: 0.9872\n",
      "Epoch: 631, Train_loss: 0.5197 / Val_loss: 1.0894\n",
      "Epoch: 632, Train_loss: 0.5165 / Val_loss: 1.3056\n",
      "Epoch: 633, Train_loss: 0.4926 / Val_loss: 1.1521\n",
      "Epoch: 634, Train_loss: 0.5053 / Val_loss: 1.2810\n",
      "Epoch: 635, Train_loss: 0.5048 / Val_loss: 1.1834\n",
      "Epoch: 636, Train_loss: 0.4875 / Val_loss: 1.0761\n",
      "Epoch: 637, Train_loss: 0.5328 / Val_loss: 1.0001\n",
      "Epoch: 638, Train_loss: 0.5024 / Val_loss: 1.1810\n",
      "Epoch: 639, Train_loss: 0.4891 / Val_loss: 1.1353\n",
      "Epoch: 640, Train_loss: 0.5296 / Val_loss: 1.1152\n",
      "Epoch: 641, Train_loss: 0.4926 / Val_loss: 1.0810\n",
      "Epoch: 642, Train_loss: 0.4883 / Val_loss: 1.0611\n",
      "Epoch: 643, Train_loss: 0.5053 / Val_loss: 1.1117\n",
      "Epoch: 644, Train_loss: 0.4968 / Val_loss: 0.9687\n",
      "Epoch: 645, Train_loss: 0.5013 / Val_loss: 1.2119\n",
      "Epoch: 646, Train_loss: 0.5242 / Val_loss: 0.9740\n",
      "Epoch: 647, Train_loss: 0.4930 / Val_loss: 1.1133\n",
      "Epoch: 648, Train_loss: 0.5016 / Val_loss: 1.0426\n",
      "Epoch: 649, Train_loss: 0.4950 / Val_loss: 1.0892\n",
      "Epoch: 650, Train_loss: 0.5081 / Val_loss: 0.9560\n",
      "Epoch: 651, Train_loss: 0.4947 / Val_loss: 1.2088\n",
      "Epoch: 652, Train_loss: 0.5382 / Val_loss: 0.8709\n",
      "Epoch: 653, Train_loss: 0.4955 / Val_loss: 0.9942\n",
      "Epoch: 654, Train_loss: 0.5033 / Val_loss: 1.1183\n",
      "Epoch: 655, Train_loss: 0.5109 / Val_loss: 1.2091\n",
      "Epoch: 656, Train_loss: 0.4944 / Val_loss: 1.0140\n",
      "Epoch: 657, Train_loss: 0.5089 / Val_loss: 0.9951\n",
      "Epoch: 658, Train_loss: 0.5409 / Val_loss: 0.9379\n",
      "Epoch: 659, Train_loss: 0.5071 / Val_loss: 1.1471\n",
      "Epoch: 660, Train_loss: 0.5303 / Val_loss: 1.0182\n",
      "Epoch: 661, Train_loss: 0.5006 / Val_loss: 0.9874\n",
      "Epoch: 662, Train_loss: 0.5008 / Val_loss: 1.1143\n",
      "Epoch: 663, Train_loss: 0.4989 / Val_loss: 1.1373\n",
      "Epoch: 664, Train_loss: 0.5045 / Val_loss: 1.1874\n",
      "Epoch: 665, Train_loss: 0.5046 / Val_loss: 1.0031\n",
      "Epoch: 666, Train_loss: 0.5366 / Val_loss: 1.0360\n",
      "Epoch: 667, Train_loss: 0.5020 / Val_loss: 1.0598\n",
      "Epoch: 668, Train_loss: 0.4940 / Val_loss: 1.2837\n",
      "Epoch: 669, Train_loss: 0.5188 / Val_loss: 1.1253\n",
      "Epoch: 670, Train_loss: 0.5139 / Val_loss: 1.0213\n",
      "Epoch: 671, Train_loss: 0.5087 / Val_loss: 1.1001\n",
      "Epoch: 672, Train_loss: 0.4901 / Val_loss: 0.9290\n",
      "Epoch: 673, Train_loss: 0.5050 / Val_loss: 0.8901\n",
      "Epoch: 674, Train_loss: 0.5209 / Val_loss: 1.1989\n",
      "Epoch: 675, Train_loss: 0.5207 / Val_loss: 1.0632\n",
      "Epoch: 676, Train_loss: 0.5147 / Val_loss: 0.9389\n",
      "Epoch: 677, Train_loss: 0.5254 / Val_loss: 1.0432\n",
      "Epoch: 678, Train_loss: 0.5042 / Val_loss: 0.9640\n",
      "Epoch: 679, Train_loss: 0.4903 / Val_loss: 1.0185\n",
      "Epoch: 680, Train_loss: 0.4989 / Val_loss: 1.0204\n",
      "Epoch: 681, Train_loss: 0.5003 / Val_loss: 0.9365\n",
      "Epoch: 682, Train_loss: 0.4834 / Val_loss: 1.2833\n",
      "Epoch: 683, Train_loss: 0.5004 / Val_loss: 1.0824\n",
      "Epoch: 684, Train_loss: 0.4892 / Val_loss: 1.1873\n",
      "Epoch: 685, Train_loss: 0.4774 / Val_loss: 1.1521\n",
      "Epoch: 686, Train_loss: 0.5130 / Val_loss: 1.0273\n",
      "Epoch: 687, Train_loss: 0.5209 / Val_loss: 1.2160\n",
      "Epoch: 688, Train_loss: 0.4829 / Val_loss: 1.0164\n",
      "Epoch: 689, Train_loss: 0.5740 / Val_loss: 1.1988\n",
      "Epoch: 690, Train_loss: 0.5078 / Val_loss: 1.0762\n",
      "Epoch: 691, Train_loss: 0.4822 / Val_loss: 0.9828\n",
      "Epoch: 692, Train_loss: 0.4921 / Val_loss: 1.1351\n",
      "Epoch: 693, Train_loss: 0.5145 / Val_loss: 0.9698\n",
      "Epoch: 694, Train_loss: 0.5415 / Val_loss: 0.8451\n",
      "Epoch: 695, Train_loss: 0.5015 / Val_loss: 1.0610\n",
      "Epoch: 696, Train_loss: 0.4980 / Val_loss: 0.9543\n",
      "Epoch: 697, Train_loss: 0.5206 / Val_loss: 1.0401\n",
      "Epoch: 698, Train_loss: 0.5080 / Val_loss: 1.2202\n",
      "Epoch: 699, Train_loss: 0.4995 / Val_loss: 1.0944\n",
      "Epoch: 700, Train_loss: 0.5149 / Val_loss: 1.0934\n",
      "Epoch: 701, Train_loss: 0.4973 / Val_loss: 0.9830\n",
      "Epoch: 702, Train_loss: 0.5153 / Val_loss: 1.2007\n",
      "Epoch: 703, Train_loss: 0.5105 / Val_loss: 1.0589\n",
      "Epoch: 704, Train_loss: 0.4913 / Val_loss: 1.0972\n",
      "Epoch: 705, Train_loss: 0.5172 / Val_loss: 1.1443\n",
      "Epoch: 706, Train_loss: 0.4798 / Val_loss: 1.0435\n",
      "Epoch: 707, Train_loss: 0.4764 / Val_loss: 1.2313\n",
      "Epoch: 708, Train_loss: 0.4868 / Val_loss: 1.0551\n",
      "Epoch: 709, Train_loss: 0.5272 / Val_loss: 1.2890\n",
      "Epoch: 710, Train_loss: 0.4810 / Val_loss: 0.9331\n",
      "Epoch: 711, Train_loss: 0.5116 / Val_loss: 0.9877\n",
      "Epoch: 712, Train_loss: 0.5097 / Val_loss: 1.2223\n",
      "Epoch: 713, Train_loss: 0.5560 / Val_loss: 1.0126\n",
      "Epoch: 714, Train_loss: 0.5200 / Val_loss: 1.0632\n",
      "Epoch: 715, Train_loss: 0.4945 / Val_loss: 1.4133\n",
      "Epoch: 716, Train_loss: 0.5015 / Val_loss: 1.0443\n",
      "Epoch: 717, Train_loss: 0.4891 / Val_loss: 1.0115\n",
      "Epoch: 718, Train_loss: 0.4956 / Val_loss: 1.0192\n",
      "Epoch: 719, Train_loss: 0.5217 / Val_loss: 1.0805\n",
      "Epoch: 720, Train_loss: 0.5211 / Val_loss: 1.1503\n",
      "Epoch: 721, Train_loss: 0.5491 / Val_loss: 0.8834\n",
      "Epoch: 722, Train_loss: 0.4835 / Val_loss: 1.0480\n",
      "Epoch: 723, Train_loss: 0.5127 / Val_loss: 0.9824\n",
      "Epoch: 724, Train_loss: 0.4832 / Val_loss: 1.0201\n",
      "Epoch: 725, Train_loss: 0.4946 / Val_loss: 1.1252\n",
      "Epoch: 726, Train_loss: 0.4950 / Val_loss: 1.0705\n",
      "Epoch: 727, Train_loss: 0.4786 / Val_loss: 0.9552\n",
      "Epoch: 728, Train_loss: 0.4938 / Val_loss: 1.0668\n",
      "Epoch: 729, Train_loss: 0.4886 / Val_loss: 1.0355\n",
      "Epoch: 730, Train_loss: 0.4941 / Val_loss: 1.2572\n",
      "Epoch: 731, Train_loss: 0.4875 / Val_loss: 1.1899\n",
      "Epoch: 732, Train_loss: 0.4994 / Val_loss: 0.9976\n",
      "Epoch: 733, Train_loss: 0.5036 / Val_loss: 1.0750\n",
      "Epoch: 734, Train_loss: 0.4918 / Val_loss: 0.9857\n",
      "Epoch: 735, Train_loss: 0.5103 / Val_loss: 1.0903\n",
      "Epoch: 736, Train_loss: 0.5135 / Val_loss: 0.9814\n",
      "Epoch: 737, Train_loss: 0.5103 / Val_loss: 0.7887\n",
      "Epoch: 738, Train_loss: 0.5014 / Val_loss: 1.0126\n",
      "Epoch: 739, Train_loss: 0.4894 / Val_loss: 1.0192\n",
      "Epoch: 740, Train_loss: 0.4725 / Val_loss: 1.1328\n",
      "Epoch: 741, Train_loss: 0.4971 / Val_loss: 1.0211\n",
      "Epoch: 742, Train_loss: 0.4986 / Val_loss: 0.9957\n",
      "Epoch: 743, Train_loss: 0.4886 / Val_loss: 1.0403\n",
      "Epoch: 744, Train_loss: 0.5006 / Val_loss: 1.1205\n",
      "Epoch: 745, Train_loss: 0.4978 / Val_loss: 1.0734\n",
      "Epoch: 746, Train_loss: 0.4762 / Val_loss: 1.2007\n",
      "Epoch: 747, Train_loss: 0.4912 / Val_loss: 1.0182\n",
      "Epoch: 748, Train_loss: 0.4753 / Val_loss: 1.1634\n",
      "Epoch: 749, Train_loss: 0.5000 / Val_loss: 1.2394\n",
      "Epoch: 750, Train_loss: 0.5218 / Val_loss: 0.9872\n",
      "Epoch: 751, Train_loss: 0.4874 / Val_loss: 1.0169\n",
      "Epoch: 752, Train_loss: 0.5021 / Val_loss: 1.1650\n",
      "Epoch: 753, Train_loss: 0.4871 / Val_loss: 1.0781\n",
      "Epoch: 754, Train_loss: 0.4927 / Val_loss: 1.0546\n",
      "Epoch: 755, Train_loss: 0.4765 / Val_loss: 1.0143\n",
      "Epoch: 756, Train_loss: 0.5158 / Val_loss: 1.0506\n",
      "Epoch: 757, Train_loss: 0.5103 / Val_loss: 1.1862\n",
      "Epoch: 758, Train_loss: 0.4820 / Val_loss: 1.0794\n",
      "Epoch: 759, Train_loss: 0.5253 / Val_loss: 1.3033\n",
      "Epoch: 760, Train_loss: 0.5129 / Val_loss: 1.1322\n",
      "Epoch: 761, Train_loss: 0.4899 / Val_loss: 1.1281\n",
      "Epoch: 762, Train_loss: 0.4895 / Val_loss: 1.0844\n",
      "Epoch: 763, Train_loss: 0.4889 / Val_loss: 0.9538\n",
      "Epoch: 764, Train_loss: 0.5099 / Val_loss: 1.2575\n",
      "Epoch: 765, Train_loss: 0.5125 / Val_loss: 1.0716\n",
      "Epoch: 766, Train_loss: 0.4953 / Val_loss: 1.0751\n",
      "Epoch: 767, Train_loss: 0.4907 / Val_loss: 1.0890\n",
      "Epoch: 768, Train_loss: 0.4871 / Val_loss: 1.0922\n",
      "Epoch: 769, Train_loss: 0.4846 / Val_loss: 0.8652\n",
      "Epoch: 770, Train_loss: 0.5065 / Val_loss: 1.1777\n",
      "Epoch: 771, Train_loss: 0.4915 / Val_loss: 1.2906\n",
      "Epoch: 772, Train_loss: 0.5149 / Val_loss: 1.2112\n",
      "Epoch: 773, Train_loss: 0.5015 / Val_loss: 0.9327\n",
      "Epoch: 774, Train_loss: 0.4880 / Val_loss: 1.1499\n",
      "Epoch: 775, Train_loss: 0.4988 / Val_loss: 1.3963\n",
      "Epoch: 776, Train_loss: 0.4869 / Val_loss: 1.1358\n",
      "Epoch: 777, Train_loss: 0.4933 / Val_loss: 1.1558\n",
      "Epoch: 778, Train_loss: 0.5086 / Val_loss: 1.2373\n",
      "Epoch: 779, Train_loss: 0.5028 / Val_loss: 1.3433\n",
      "Epoch: 780, Train_loss: 0.4678 / Val_loss: 0.9019\n",
      "Epoch: 781, Train_loss: 0.5128 / Val_loss: 1.2080\n",
      "Epoch: 782, Train_loss: 0.4866 / Val_loss: 1.2436\n",
      "Epoch: 783, Train_loss: 0.4818 / Val_loss: 1.1122\n",
      "Epoch: 784, Train_loss: 0.4813 / Val_loss: 1.2035\n",
      "Epoch: 785, Train_loss: 0.4973 / Val_loss: 1.1390\n",
      "Epoch: 786, Train_loss: 0.4927 / Val_loss: 1.0408\n",
      "Epoch: 787, Train_loss: 0.4868 / Val_loss: 1.2203\n",
      "Epoch: 788, Train_loss: 0.4876 / Val_loss: 1.2167\n",
      "Epoch: 789, Train_loss: 0.5164 / Val_loss: 0.9714\n",
      "Epoch: 790, Train_loss: 0.4706 / Val_loss: 1.1954\n",
      "Epoch: 791, Train_loss: 0.4967 / Val_loss: 1.0106\n",
      "Epoch: 792, Train_loss: 0.4849 / Val_loss: 1.0243\n",
      "Epoch: 793, Train_loss: 0.5071 / Val_loss: 0.9258\n",
      "Epoch: 794, Train_loss: 0.4668 / Val_loss: 1.0727\n",
      "Epoch: 795, Train_loss: 0.5137 / Val_loss: 1.1000\n",
      "Epoch: 796, Train_loss: 0.4759 / Val_loss: 1.3662\n",
      "Epoch: 797, Train_loss: 0.5229 / Val_loss: 0.9742\n",
      "Epoch: 798, Train_loss: 0.4831 / Val_loss: 1.1367\n",
      "Epoch: 799, Train_loss: 0.4703 / Val_loss: 1.1346\n",
      "Epoch: 800, Train_loss: 0.4746 / Val_loss: 1.2868\n",
      "Epoch: 801, Train_loss: 0.4863 / Val_loss: 0.9885\n",
      "Epoch: 802, Train_loss: 0.4758 / Val_loss: 1.1797\n",
      "Epoch: 803, Train_loss: 0.4768 / Val_loss: 1.1312\n",
      "Epoch: 804, Train_loss: 0.5131 / Val_loss: 1.1706\n",
      "Epoch: 805, Train_loss: 0.4797 / Val_loss: 0.9670\n",
      "Epoch: 806, Train_loss: 0.4830 / Val_loss: 1.1710\n",
      "Epoch: 807, Train_loss: 0.5033 / Val_loss: 1.4163\n",
      "Epoch: 808, Train_loss: 0.4706 / Val_loss: 1.5077\n",
      "Epoch: 809, Train_loss: 0.4818 / Val_loss: 1.3489\n",
      "Epoch: 810, Train_loss: 0.5328 / Val_loss: 1.1684\n",
      "Epoch: 811, Train_loss: 0.4754 / Val_loss: 1.0510\n",
      "Epoch: 812, Train_loss: 0.4825 / Val_loss: 1.1115\n",
      "Epoch: 813, Train_loss: 0.4863 / Val_loss: 1.0777\n",
      "Epoch: 814, Train_loss: 0.5047 / Val_loss: 1.2328\n",
      "Epoch: 815, Train_loss: 0.4839 / Val_loss: 1.2012\n",
      "Epoch: 816, Train_loss: 0.4923 / Val_loss: 1.1057\n",
      "Epoch: 817, Train_loss: 0.4841 / Val_loss: 1.1825\n",
      "Epoch: 818, Train_loss: 0.4797 / Val_loss: 1.2758\n",
      "Epoch: 819, Train_loss: 0.4897 / Val_loss: 1.1468\n",
      "Epoch: 820, Train_loss: 0.4849 / Val_loss: 0.9438\n",
      "Epoch: 821, Train_loss: 0.4770 / Val_loss: 1.2386\n",
      "Epoch: 822, Train_loss: 0.4776 / Val_loss: 1.1090\n",
      "Epoch: 823, Train_loss: 0.4975 / Val_loss: 1.0992\n",
      "Epoch: 824, Train_loss: 0.4748 / Val_loss: 0.9740\n",
      "Epoch: 825, Train_loss: 0.4664 / Val_loss: 1.2581\n",
      "Epoch: 826, Train_loss: 0.5074 / Val_loss: 1.2817\n",
      "Epoch: 827, Train_loss: 0.4711 / Val_loss: 1.0232\n",
      "Epoch: 828, Train_loss: 0.4850 / Val_loss: 1.2036\n",
      "Epoch: 829, Train_loss: 0.4653 / Val_loss: 1.1832\n",
      "Epoch: 830, Train_loss: 0.4854 / Val_loss: 1.0611\n",
      "Epoch: 831, Train_loss: 0.4759 / Val_loss: 1.0957\n",
      "Epoch: 832, Train_loss: 0.5090 / Val_loss: 1.0428\n",
      "Epoch: 833, Train_loss: 0.4970 / Val_loss: 1.0984\n",
      "Epoch: 834, Train_loss: 0.4966 / Val_loss: 1.0673\n",
      "Epoch: 835, Train_loss: 0.4846 / Val_loss: 1.1950\n",
      "Epoch: 836, Train_loss: 0.4996 / Val_loss: 1.2756\n",
      "Epoch: 837, Train_loss: 0.4969 / Val_loss: 1.1187\n",
      "Epoch: 838, Train_loss: 0.4830 / Val_loss: 1.1254\n",
      "Epoch: 839, Train_loss: 0.4722 / Val_loss: 1.2022\n",
      "Epoch: 840, Train_loss: 0.4796 / Val_loss: 1.3523\n",
      "Epoch: 841, Train_loss: 0.5070 / Val_loss: 1.3577\n",
      "Epoch: 842, Train_loss: 0.5244 / Val_loss: 1.2044\n",
      "Epoch: 843, Train_loss: 0.4734 / Val_loss: 0.9915\n",
      "Epoch: 844, Train_loss: 0.5099 / Val_loss: 1.1814\n",
      "Epoch: 845, Train_loss: 0.4831 / Val_loss: 1.1091\n",
      "Epoch: 846, Train_loss: 0.4902 / Val_loss: 1.2867\n",
      "Epoch: 847, Train_loss: 0.4717 / Val_loss: 1.3374\n",
      "Epoch: 848, Train_loss: 0.4882 / Val_loss: 1.2076\n",
      "Epoch: 849, Train_loss: 0.4901 / Val_loss: 1.2249\n",
      "Epoch: 850, Train_loss: 0.4651 / Val_loss: 1.1266\n",
      "Epoch: 851, Train_loss: 0.4759 / Val_loss: 1.1166\n",
      "Epoch: 852, Train_loss: 0.4863 / Val_loss: 1.2532\n",
      "Epoch: 853, Train_loss: 0.5164 / Val_loss: 1.3810\n",
      "Epoch: 854, Train_loss: 0.4930 / Val_loss: 1.1918\n",
      "Epoch: 855, Train_loss: 0.5181 / Val_loss: 1.0159\n",
      "Epoch: 856, Train_loss: 0.4591 / Val_loss: 1.4594\n",
      "Epoch: 857, Train_loss: 0.4891 / Val_loss: 1.2212\n",
      "Epoch: 858, Train_loss: 0.4701 / Val_loss: 1.2015\n",
      "Epoch: 859, Train_loss: 0.5052 / Val_loss: 1.1441\n",
      "Epoch: 860, Train_loss: 0.4517 / Val_loss: 1.1271\n",
      "Epoch: 861, Train_loss: 0.5007 / Val_loss: 1.0228\n",
      "Epoch: 862, Train_loss: 0.4922 / Val_loss: 0.9677\n",
      "Epoch: 863, Train_loss: 0.4942 / Val_loss: 1.1788\n",
      "Epoch: 864, Train_loss: 0.4754 / Val_loss: 1.2124\n",
      "Epoch: 865, Train_loss: 0.4995 / Val_loss: 1.1853\n",
      "Epoch: 866, Train_loss: 0.4924 / Val_loss: 1.1695\n",
      "Epoch: 867, Train_loss: 0.5041 / Val_loss: 1.0569\n",
      "Epoch: 868, Train_loss: 0.4991 / Val_loss: 1.0962\n",
      "Epoch: 869, Train_loss: 0.4774 / Val_loss: 1.0490\n",
      "Epoch: 870, Train_loss: 0.4706 / Val_loss: 1.2080\n",
      "Epoch: 871, Train_loss: 0.4930 / Val_loss: 1.0928\n",
      "Epoch: 872, Train_loss: 0.5054 / Val_loss: 1.1330\n",
      "Epoch: 873, Train_loss: 0.5299 / Val_loss: 1.0731\n",
      "Epoch: 874, Train_loss: 0.4940 / Val_loss: 1.0294\n",
      "Epoch: 875, Train_loss: 0.5163 / Val_loss: 1.3955\n",
      "Epoch: 876, Train_loss: 0.4803 / Val_loss: 1.2201\n",
      "Epoch: 877, Train_loss: 0.4760 / Val_loss: 1.3098\n",
      "Epoch: 878, Train_loss: 0.4945 / Val_loss: 1.2726\n",
      "Epoch: 879, Train_loss: 0.4925 / Val_loss: 0.8776\n",
      "Epoch: 880, Train_loss: 0.4811 / Val_loss: 1.3042\n",
      "Epoch: 881, Train_loss: 0.4819 / Val_loss: 1.1537\n",
      "Epoch: 882, Train_loss: 0.4891 / Val_loss: 1.3709\n",
      "Epoch: 883, Train_loss: 0.4705 / Val_loss: 1.2803\n",
      "Epoch: 884, Train_loss: 0.4751 / Val_loss: 1.2669\n",
      "Epoch: 885, Train_loss: 0.4902 / Val_loss: 1.2906\n",
      "Epoch: 886, Train_loss: 0.5042 / Val_loss: 1.1616\n",
      "Epoch: 887, Train_loss: 0.4895 / Val_loss: 1.3381\n",
      "Epoch: 888, Train_loss: 0.4796 / Val_loss: 1.2458\n",
      "Epoch: 889, Train_loss: 0.4808 / Val_loss: 1.0906\n",
      "Epoch: 890, Train_loss: 0.5011 / Val_loss: 1.2344\n",
      "Epoch: 891, Train_loss: 0.4843 / Val_loss: 1.2186\n",
      "Epoch: 892, Train_loss: 0.4859 / Val_loss: 1.2767\n",
      "Epoch: 893, Train_loss: 0.4904 / Val_loss: 1.2222\n",
      "Epoch: 894, Train_loss: 0.5035 / Val_loss: 1.2750\n",
      "Epoch: 895, Train_loss: 0.4852 / Val_loss: 1.2462\n",
      "Epoch: 896, Train_loss: 0.4724 / Val_loss: 1.0644\n",
      "Epoch: 897, Train_loss: 0.4745 / Val_loss: 1.0947\n",
      "Epoch: 898, Train_loss: 0.4656 / Val_loss: 1.2650\n",
      "Epoch: 899, Train_loss: 0.5050 / Val_loss: 1.1424\n",
      "Epoch: 900, Train_loss: 0.5110 / Val_loss: 0.8394\n",
      "Epoch: 901, Train_loss: 0.4875 / Val_loss: 1.1832\n",
      "Epoch: 902, Train_loss: 0.4778 / Val_loss: 1.1624\n",
      "Epoch: 903, Train_loss: 0.4870 / Val_loss: 1.0900\n",
      "Epoch: 904, Train_loss: 0.4974 / Val_loss: 0.9803\n",
      "Epoch: 905, Train_loss: 0.5031 / Val_loss: 1.0948\n",
      "Epoch: 906, Train_loss: 0.4549 / Val_loss: 1.2640\n",
      "Epoch: 907, Train_loss: 0.5003 / Val_loss: 1.1005\n",
      "Epoch: 908, Train_loss: 0.4840 / Val_loss: 1.0239\n",
      "Epoch: 909, Train_loss: 0.4843 / Val_loss: 1.1402\n",
      "Epoch: 910, Train_loss: 0.4887 / Val_loss: 1.1773\n",
      "Epoch: 911, Train_loss: 0.4803 / Val_loss: 1.2341\n",
      "Epoch: 912, Train_loss: 0.4714 / Val_loss: 1.1817\n",
      "Epoch: 913, Train_loss: 0.4805 / Val_loss: 1.1137\n",
      "Epoch: 914, Train_loss: 0.4973 / Val_loss: 1.1524\n",
      "Epoch: 915, Train_loss: 0.4623 / Val_loss: 1.2312\n",
      "Epoch: 916, Train_loss: 0.4863 / Val_loss: 1.3920\n",
      "Epoch: 917, Train_loss: 0.4792 / Val_loss: 0.9906\n",
      "Epoch: 918, Train_loss: 0.4661 / Val_loss: 1.0820\n",
      "Epoch: 919, Train_loss: 0.4594 / Val_loss: 1.0855\n",
      "Epoch: 920, Train_loss: 0.4747 / Val_loss: 0.9747\n",
      "Epoch: 921, Train_loss: 0.4748 / Val_loss: 1.2668\n",
      "Epoch: 922, Train_loss: 0.4617 / Val_loss: 1.4974\n",
      "Epoch: 923, Train_loss: 0.4808 / Val_loss: 1.2995\n",
      "Epoch: 924, Train_loss: 0.4990 / Val_loss: 1.4060\n",
      "Epoch: 925, Train_loss: 0.5011 / Val_loss: 0.9863\n",
      "Epoch: 926, Train_loss: 0.4922 / Val_loss: 1.2457\n",
      "Epoch: 927, Train_loss: 0.4656 / Val_loss: 1.4502\n",
      "Epoch: 928, Train_loss: 0.4676 / Val_loss: 1.2314\n",
      "Epoch: 929, Train_loss: 0.4798 / Val_loss: 1.0974\n",
      "Epoch: 930, Train_loss: 0.4751 / Val_loss: 1.1956\n",
      "Epoch: 931, Train_loss: 0.4872 / Val_loss: 1.1455\n",
      "Epoch: 932, Train_loss: 0.4783 / Val_loss: 1.2244\n",
      "Epoch: 933, Train_loss: 0.4773 / Val_loss: 1.1909\n",
      "Epoch: 934, Train_loss: 0.4739 / Val_loss: 1.1378\n",
      "Epoch: 935, Train_loss: 0.4857 / Val_loss: 1.2572\n",
      "Epoch: 936, Train_loss: 0.4756 / Val_loss: 1.2659\n",
      "Epoch: 937, Train_loss: 0.5256 / Val_loss: 1.1005\n",
      "Epoch: 938, Train_loss: 0.4731 / Val_loss: 1.2356\n",
      "Epoch: 939, Train_loss: 0.5049 / Val_loss: 1.3305\n",
      "Epoch: 940, Train_loss: 0.4603 / Val_loss: 1.1915\n",
      "Epoch: 941, Train_loss: 0.4731 / Val_loss: 1.0668\n",
      "Epoch: 942, Train_loss: 0.4928 / Val_loss: 1.0898\n",
      "Epoch: 943, Train_loss: 0.5016 / Val_loss: 1.0317\n",
      "Epoch: 944, Train_loss: 0.4963 / Val_loss: 0.9995\n",
      "Epoch: 945, Train_loss: 0.4761 / Val_loss: 1.2690\n",
      "Epoch: 946, Train_loss: 0.4717 / Val_loss: 1.1052\n",
      "Epoch: 947, Train_loss: 0.4964 / Val_loss: 1.4542\n",
      "Epoch: 948, Train_loss: 0.4848 / Val_loss: 1.0389\n",
      "Epoch: 949, Train_loss: 0.4909 / Val_loss: 1.3000\n",
      "Epoch: 950, Train_loss: 0.4795 / Val_loss: 1.2443\n",
      "Epoch: 951, Train_loss: 0.4920 / Val_loss: 1.1116\n",
      "Epoch: 952, Train_loss: 0.5145 / Val_loss: 1.2953\n",
      "Epoch: 953, Train_loss: 0.4914 / Val_loss: 1.3335\n",
      "Epoch: 954, Train_loss: 0.4898 / Val_loss: 1.1098\n",
      "Epoch: 955, Train_loss: 0.5022 / Val_loss: 1.1944\n",
      "Epoch: 956, Train_loss: 0.4679 / Val_loss: 1.1927\n",
      "Epoch: 957, Train_loss: 0.4775 / Val_loss: 1.2008\n",
      "Epoch: 958, Train_loss: 0.4756 / Val_loss: 1.1545\n",
      "Epoch: 959, Train_loss: 0.4830 / Val_loss: 1.0437\n",
      "Epoch: 960, Train_loss: 0.4945 / Val_loss: 1.4811\n",
      "Epoch: 961, Train_loss: 0.4752 / Val_loss: 1.1550\n",
      "Epoch: 962, Train_loss: 0.4915 / Val_loss: 1.0575\n",
      "Epoch: 963, Train_loss: 0.4784 / Val_loss: 1.0894\n",
      "Epoch: 964, Train_loss: 0.4708 / Val_loss: 1.3292\n",
      "Epoch: 965, Train_loss: 0.4822 / Val_loss: 1.1041\n",
      "Epoch: 966, Train_loss: 0.5206 / Val_loss: 1.3508\n",
      "Epoch: 967, Train_loss: 0.4810 / Val_loss: 1.2309\n",
      "Epoch: 968, Train_loss: 0.4877 / Val_loss: 1.1066\n",
      "Epoch: 969, Train_loss: 0.4683 / Val_loss: 1.5120\n",
      "Epoch: 970, Train_loss: 0.4883 / Val_loss: 0.9434\n",
      "Epoch: 971, Train_loss: 0.4629 / Val_loss: 1.2175\n",
      "Epoch: 972, Train_loss: 0.4817 / Val_loss: 1.2140\n",
      "Epoch: 973, Train_loss: 0.4760 / Val_loss: 1.1403\n",
      "Epoch: 974, Train_loss: 0.4745 / Val_loss: 1.0116\n",
      "Epoch: 975, Train_loss: 0.4608 / Val_loss: 1.1620\n",
      "Epoch: 976, Train_loss: 0.4685 / Val_loss: 1.0300\n",
      "Epoch: 977, Train_loss: 0.4632 / Val_loss: 1.3088\n",
      "Epoch: 978, Train_loss: 0.4853 / Val_loss: 1.0803\n",
      "Epoch: 979, Train_loss: 0.4845 / Val_loss: 1.2275\n",
      "Epoch: 980, Train_loss: 0.4818 / Val_loss: 1.3959\n",
      "Epoch: 981, Train_loss: 0.5201 / Val_loss: 1.1561\n",
      "Epoch: 982, Train_loss: 0.4981 / Val_loss: 1.0201\n",
      "Epoch: 983, Train_loss: 0.4818 / Val_loss: 1.2590\n",
      "Epoch: 984, Train_loss: 0.4701 / Val_loss: 1.3122\n",
      "Epoch: 985, Train_loss: 0.4751 / Val_loss: 1.1707\n",
      "Epoch: 986, Train_loss: 0.4568 / Val_loss: 1.1614\n",
      "Epoch: 987, Train_loss: 0.4798 / Val_loss: 1.1264\n",
      "Epoch: 988, Train_loss: 0.5236 / Val_loss: 1.1310\n",
      "Epoch: 989, Train_loss: 0.4832 / Val_loss: 1.2292\n",
      "Epoch: 990, Train_loss: 0.4874 / Val_loss: 1.1343\n",
      "Epoch: 991, Train_loss: 0.4769 / Val_loss: 1.2080\n",
      "Epoch: 992, Train_loss: 0.4663 / Val_loss: 1.1586\n",
      "Epoch: 993, Train_loss: 0.4746 / Val_loss: 1.1398\n",
      "Epoch: 994, Train_loss: 0.4714 / Val_loss: 1.5611\n",
      "Epoch: 995, Train_loss: 0.5028 / Val_loss: 1.2748\n",
      "Epoch: 996, Train_loss: 0.4672 / Val_loss: 1.3112\n",
      "Epoch: 997, Train_loss: 0.4834 / Val_loss: 1.2488\n",
      "Epoch: 998, Train_loss: 0.4682 / Val_loss: 1.4464\n",
      "Epoch: 999, Train_loss: 0.4622 / Val_loss: 1.2966\n",
      "Epoch: 1000, Train_loss: 0.4571 / Val_loss: 1.2807\n",
      "Epoch: 1001, Train_loss: 0.4572 / Val_loss: 1.1869\n",
      "Epoch: 1002, Train_loss: 0.4675 / Val_loss: 1.3480\n",
      "Epoch: 1003, Train_loss: 0.4896 / Val_loss: 1.1119\n",
      "Epoch: 1004, Train_loss: 0.4749 / Val_loss: 1.3672\n",
      "Epoch: 1005, Train_loss: 0.4740 / Val_loss: 0.9917\n",
      "Epoch: 1006, Train_loss: 0.4826 / Val_loss: 1.0250\n",
      "Epoch: 1007, Train_loss: 0.4811 / Val_loss: 1.0754\n",
      "Epoch: 1008, Train_loss: 0.4729 / Val_loss: 1.2777\n",
      "Epoch: 1009, Train_loss: 0.4848 / Val_loss: 0.9257\n",
      "Epoch: 1010, Train_loss: 0.4619 / Val_loss: 1.1825\n",
      "Epoch: 1011, Train_loss: 0.4909 / Val_loss: 1.2299\n",
      "Epoch: 1012, Train_loss: 0.4689 / Val_loss: 1.2536\n",
      "Epoch: 1013, Train_loss: 0.4679 / Val_loss: 1.2711\n",
      "Epoch: 1014, Train_loss: 0.4745 / Val_loss: 1.3046\n",
      "Epoch: 1015, Train_loss: 0.4537 / Val_loss: 1.0998\n",
      "Epoch: 1016, Train_loss: 0.5039 / Val_loss: 1.2881\n",
      "Epoch: 1017, Train_loss: 0.4611 / Val_loss: 1.3123\n",
      "Epoch: 1018, Train_loss: 0.4849 / Val_loss: 1.3000\n",
      "Epoch: 1019, Train_loss: 0.5027 / Val_loss: 1.2566\n",
      "Epoch: 1020, Train_loss: 0.4876 / Val_loss: 1.1094\n",
      "Epoch: 1021, Train_loss: 0.4711 / Val_loss: 1.2111\n",
      "Epoch: 1022, Train_loss: 0.4797 / Val_loss: 1.4817\n",
      "Epoch: 1023, Train_loss: 0.4800 / Val_loss: 1.2323\n",
      "Epoch: 1024, Train_loss: 0.4966 / Val_loss: 1.1148\n",
      "Epoch: 1025, Train_loss: 0.4888 / Val_loss: 1.3002\n",
      "Epoch: 1026, Train_loss: 0.4726 / Val_loss: 1.1461\n",
      "Epoch: 1027, Train_loss: 0.4865 / Val_loss: 1.3972\n",
      "Epoch: 1028, Train_loss: 0.4966 / Val_loss: 1.1199\n",
      "Epoch: 1029, Train_loss: 0.4808 / Val_loss: 1.0921\n",
      "Epoch: 1030, Train_loss: 0.4680 / Val_loss: 1.2896\n",
      "Epoch: 1031, Train_loss: 0.4810 / Val_loss: 1.1150\n",
      "Epoch: 1032, Train_loss: 0.4742 / Val_loss: 1.1741\n",
      "Epoch: 1033, Train_loss: 0.4623 / Val_loss: 1.3115\n",
      "Epoch: 1034, Train_loss: 0.4744 / Val_loss: 1.1873\n",
      "Epoch: 1035, Train_loss: 0.4888 / Val_loss: 1.1169\n",
      "Epoch: 1036, Train_loss: 0.4990 / Val_loss: 1.3953\n",
      "Epoch: 1037, Train_loss: 0.4973 / Val_loss: 1.5216\n",
      "Epoch: 1038, Train_loss: 0.4720 / Val_loss: 1.3053\n",
      "Epoch: 1039, Train_loss: 0.4924 / Val_loss: 1.0221\n",
      "Epoch: 1040, Train_loss: 0.4681 / Val_loss: 1.1739\n",
      "Epoch: 1041, Train_loss: 0.4599 / Val_loss: 1.1844\n",
      "Epoch: 1042, Train_loss: 0.5090 / Val_loss: 1.1993\n",
      "Epoch: 1043, Train_loss: 0.4945 / Val_loss: 1.1714\n",
      "Epoch: 1044, Train_loss: 0.4813 / Val_loss: 1.2004\n",
      "Epoch: 1045, Train_loss: 0.4594 / Val_loss: 1.0947\n",
      "Epoch: 1046, Train_loss: 0.4873 / Val_loss: 1.0783\n",
      "Epoch: 1047, Train_loss: 0.4631 / Val_loss: 1.4904\n",
      "Epoch: 1048, Train_loss: 0.4959 / Val_loss: 1.0735\n",
      "Epoch: 1049, Train_loss: 0.4793 / Val_loss: 1.1503\n",
      "Epoch: 1050, Train_loss: 0.4863 / Val_loss: 0.8714\n",
      "Epoch: 1051, Train_loss: 0.4777 / Val_loss: 1.3151\n",
      "Epoch: 1052, Train_loss: 0.4683 / Val_loss: 1.0062\n",
      "Epoch: 1053, Train_loss: 0.4891 / Val_loss: 1.3400\n",
      "Epoch: 1054, Train_loss: 0.4720 / Val_loss: 0.7968\n",
      "Epoch: 1055, Train_loss: 0.4835 / Val_loss: 1.2291\n",
      "Epoch: 1056, Train_loss: 0.4529 / Val_loss: 1.1361\n",
      "Epoch: 1057, Train_loss: 0.4790 / Val_loss: 1.1066\n",
      "Epoch: 1058, Train_loss: 0.5429 / Val_loss: 1.4812\n",
      "Epoch: 1059, Train_loss: 0.4914 / Val_loss: 1.0542\n",
      "Epoch: 1060, Train_loss: 0.4970 / Val_loss: 1.2256\n",
      "Epoch: 1061, Train_loss: 0.4700 / Val_loss: 1.2579\n",
      "Epoch: 1062, Train_loss: 0.4783 / Val_loss: 1.0322\n",
      "Epoch: 1063, Train_loss: 0.4776 / Val_loss: 1.0905\n",
      "Epoch: 1064, Train_loss: 0.4771 / Val_loss: 1.3579\n",
      "Epoch: 1065, Train_loss: 0.4658 / Val_loss: 1.2236\n",
      "Epoch: 1066, Train_loss: 0.4624 / Val_loss: 0.9908\n",
      "Epoch: 1067, Train_loss: 0.4892 / Val_loss: 1.3199\n",
      "Epoch: 1068, Train_loss: 0.4855 / Val_loss: 1.2122\n",
      "Epoch: 1069, Train_loss: 0.4770 / Val_loss: 1.1271\n",
      "Epoch: 1070, Train_loss: 0.4616 / Val_loss: 1.1415\n",
      "Epoch: 1071, Train_loss: 0.4530 / Val_loss: 1.2481\n",
      "Epoch: 1072, Train_loss: 0.4689 / Val_loss: 1.3231\n",
      "Epoch: 1073, Train_loss: 0.4676 / Val_loss: 1.2866\n",
      "Epoch: 1074, Train_loss: 0.4764 / Val_loss: 1.4767\n",
      "Epoch: 1075, Train_loss: 0.4688 / Val_loss: 1.2343\n",
      "Epoch: 1076, Train_loss: 0.4349 / Val_loss: 1.2081\n",
      "Epoch: 1077, Train_loss: 0.4769 / Val_loss: 1.2807\n",
      "Epoch: 1078, Train_loss: 0.4853 / Val_loss: 1.2387\n",
      "Epoch: 1079, Train_loss: 0.4656 / Val_loss: 1.2052\n",
      "Epoch: 1080, Train_loss: 0.4417 / Val_loss: 1.1576\n",
      "Epoch: 1081, Train_loss: 0.4808 / Val_loss: 1.2784\n",
      "Epoch: 1082, Train_loss: 0.4874 / Val_loss: 1.3088\n",
      "Epoch: 1083, Train_loss: 0.4601 / Val_loss: 1.1304\n",
      "Epoch: 1084, Train_loss: 0.4717 / Val_loss: 1.1849\n",
      "Epoch: 1085, Train_loss: 0.4772 / Val_loss: 1.1364\n",
      "Epoch: 1086, Train_loss: 0.4573 / Val_loss: 1.2296\n",
      "Epoch: 1087, Train_loss: 0.4695 / Val_loss: 1.2569\n",
      "Epoch: 1088, Train_loss: 0.4750 / Val_loss: 1.3037\n",
      "Epoch: 1089, Train_loss: 0.4573 / Val_loss: 1.3557\n",
      "Epoch: 1090, Train_loss: 0.4592 / Val_loss: 1.1350\n",
      "Epoch: 1091, Train_loss: 0.4802 / Val_loss: 1.2995\n",
      "Epoch: 1092, Train_loss: 0.4659 / Val_loss: 1.1603\n",
      "Epoch: 1093, Train_loss: 0.4802 / Val_loss: 1.2053\n",
      "Epoch: 1094, Train_loss: 0.4638 / Val_loss: 1.2816\n",
      "Epoch: 1095, Train_loss: 0.4455 / Val_loss: 1.3763\n",
      "Epoch: 1096, Train_loss: 0.4540 / Val_loss: 1.1605\n",
      "Epoch: 1097, Train_loss: 0.4682 / Val_loss: 1.4064\n",
      "Epoch: 1098, Train_loss: 0.4494 / Val_loss: 1.1997\n",
      "Epoch: 1099, Train_loss: 0.4642 / Val_loss: 1.1382\n",
      "Epoch: 1100, Train_loss: 0.4906 / Val_loss: 1.2725\n",
      "Epoch: 1101, Train_loss: 0.4662 / Val_loss: 1.1133\n",
      "Epoch: 1102, Train_loss: 0.4595 / Val_loss: 1.2354\n",
      "Epoch: 1103, Train_loss: 0.4678 / Val_loss: 1.3644\n",
      "Epoch: 1104, Train_loss: 0.4876 / Val_loss: 1.4917\n",
      "Epoch: 1105, Train_loss: 0.4886 / Val_loss: 1.5637\n",
      "Epoch: 1106, Train_loss: 0.4520 / Val_loss: 1.2052\n",
      "Epoch: 1107, Train_loss: 0.4664 / Val_loss: 1.0147\n",
      "Epoch: 1108, Train_loss: 0.4743 / Val_loss: 1.0136\n",
      "Epoch: 1109, Train_loss: 0.4406 / Val_loss: 1.5049\n",
      "Epoch: 1110, Train_loss: 0.4676 / Val_loss: 1.2111\n",
      "Epoch: 1111, Train_loss: 0.5066 / Val_loss: 1.1774\n",
      "Epoch: 1112, Train_loss: 0.4430 / Val_loss: 1.2494\n",
      "Epoch: 1113, Train_loss: 0.4747 / Val_loss: 1.1792\n",
      "Epoch: 1114, Train_loss: 0.4726 / Val_loss: 0.8265\n",
      "Epoch: 1115, Train_loss: 0.4721 / Val_loss: 1.1447\n",
      "Epoch: 1116, Train_loss: 0.4587 / Val_loss: 1.3344\n",
      "Epoch: 1117, Train_loss: 0.4641 / Val_loss: 1.4347\n",
      "Epoch: 1118, Train_loss: 0.4693 / Val_loss: 1.3310\n",
      "Epoch: 1119, Train_loss: 0.4873 / Val_loss: 1.1659\n",
      "Epoch: 1120, Train_loss: 0.4725 / Val_loss: 1.4398\n",
      "Epoch: 1121, Train_loss: 0.4746 / Val_loss: 1.3672\n",
      "Epoch: 1122, Train_loss: 0.4660 / Val_loss: 1.2607\n",
      "Epoch: 1123, Train_loss: 0.4744 / Val_loss: 1.1613\n",
      "Epoch: 1124, Train_loss: 0.4591 / Val_loss: 1.1561\n",
      "Epoch: 1125, Train_loss: 0.4519 / Val_loss: 1.2341\n",
      "Epoch: 1126, Train_loss: 0.4673 / Val_loss: 1.2018\n",
      "Epoch: 1127, Train_loss: 0.4728 / Val_loss: 1.3975\n",
      "Epoch: 1128, Train_loss: 0.4942 / Val_loss: 1.1857\n",
      "Epoch: 1129, Train_loss: 0.4733 / Val_loss: 1.2647\n",
      "Epoch: 1130, Train_loss: 0.4617 / Val_loss: 1.1448\n",
      "Epoch: 1131, Train_loss: 0.4779 / Val_loss: 1.5078\n",
      "Epoch: 1132, Train_loss: 0.4710 / Val_loss: 1.2069\n",
      "Epoch: 1133, Train_loss: 0.4831 / Val_loss: 1.3233\n",
      "Epoch: 1134, Train_loss: 0.4563 / Val_loss: 1.0040\n",
      "Epoch: 1135, Train_loss: 0.4546 / Val_loss: 1.2069\n",
      "Epoch: 1136, Train_loss: 0.4749 / Val_loss: 1.1704\n",
      "Epoch: 1137, Train_loss: 0.5025 / Val_loss: 1.2691\n",
      "Epoch: 1138, Train_loss: 0.4912 / Val_loss: 1.1932\n",
      "Epoch: 1139, Train_loss: 0.4700 / Val_loss: 1.1838\n",
      "Epoch: 1140, Train_loss: 0.4411 / Val_loss: 1.0146\n",
      "Epoch: 1141, Train_loss: 0.4641 / Val_loss: 1.1720\n",
      "Epoch: 1142, Train_loss: 0.5012 / Val_loss: 1.3452\n",
      "Epoch: 1143, Train_loss: 0.4623 / Val_loss: 1.2124\n",
      "Epoch: 1144, Train_loss: 0.4509 / Val_loss: 1.0491\n",
      "Epoch: 1145, Train_loss: 0.4600 / Val_loss: 1.1524\n",
      "Epoch: 1146, Train_loss: 0.4679 / Val_loss: 1.0588\n",
      "Epoch: 1147, Train_loss: 0.4703 / Val_loss: 1.1359\n",
      "Epoch: 1148, Train_loss: 0.4684 / Val_loss: 1.0468\n",
      "Epoch: 1149, Train_loss: 0.4991 / Val_loss: 1.1697\n",
      "Epoch: 1150, Train_loss: 0.4781 / Val_loss: 1.4223\n",
      "Epoch: 1151, Train_loss: 0.4710 / Val_loss: 1.2174\n",
      "Epoch: 1152, Train_loss: 0.4908 / Val_loss: 1.0446\n",
      "Epoch: 1153, Train_loss: 0.4692 / Val_loss: 1.4202\n",
      "Epoch: 1154, Train_loss: 0.4679 / Val_loss: 1.1235\n",
      "Epoch: 1155, Train_loss: 0.4617 / Val_loss: 1.1563\n",
      "Epoch: 1156, Train_loss: 0.4528 / Val_loss: 1.2746\n",
      "Epoch: 1157, Train_loss: 0.4839 / Val_loss: 1.0431\n",
      "Epoch: 1158, Train_loss: 0.4810 / Val_loss: 1.0355\n",
      "Epoch: 1159, Train_loss: 0.4615 / Val_loss: 1.3138\n",
      "Epoch: 1160, Train_loss: 0.4741 / Val_loss: 1.0195\n",
      "Epoch: 1161, Train_loss: 0.4455 / Val_loss: 1.2518\n",
      "Epoch: 1162, Train_loss: 0.4696 / Val_loss: 1.2046\n",
      "Epoch: 1163, Train_loss: 0.4517 / Val_loss: 1.1854\n",
      "Epoch: 1164, Train_loss: 0.4696 / Val_loss: 1.4788\n",
      "Epoch: 1165, Train_loss: 0.4740 / Val_loss: 1.1562\n",
      "Epoch: 1166, Train_loss: 0.4635 / Val_loss: 1.5195\n",
      "Epoch: 1167, Train_loss: 0.4662 / Val_loss: 1.0096\n",
      "Epoch: 1168, Train_loss: 0.4733 / Val_loss: 1.4125\n",
      "Epoch: 1169, Train_loss: 0.4405 / Val_loss: 1.4264\n",
      "Epoch: 1170, Train_loss: 0.4539 / Val_loss: 1.0892\n",
      "Epoch: 1171, Train_loss: 0.4931 / Val_loss: 1.3112\n",
      "Epoch: 1172, Train_loss: 0.5071 / Val_loss: 1.2994\n",
      "Epoch: 1173, Train_loss: 0.4621 / Val_loss: 1.2888\n",
      "Epoch: 1174, Train_loss: 0.4644 / Val_loss: 1.4546\n",
      "Epoch: 1175, Train_loss: 0.4542 / Val_loss: 1.3334\n",
      "Epoch: 1176, Train_loss: 0.4711 / Val_loss: 1.1950\n",
      "Epoch: 1177, Train_loss: 0.4618 / Val_loss: 1.3638\n",
      "Epoch: 1178, Train_loss: 0.4546 / Val_loss: 1.5082\n",
      "Epoch: 1179, Train_loss: 0.4442 / Val_loss: 1.2448\n",
      "Epoch: 1180, Train_loss: 0.4705 / Val_loss: 1.3184\n",
      "Epoch: 1181, Train_loss: 0.4531 / Val_loss: 1.4701\n",
      "Epoch: 1182, Train_loss: 0.4610 / Val_loss: 1.2815\n",
      "Epoch: 1183, Train_loss: 0.4664 / Val_loss: 1.5107\n",
      "Epoch: 1184, Train_loss: 0.4554 / Val_loss: 1.4830\n",
      "Epoch: 1185, Train_loss: 0.5342 / Val_loss: 1.3809\n",
      "Epoch: 1186, Train_loss: 0.4614 / Val_loss: 1.4418\n",
      "Epoch: 1187, Train_loss: 0.4613 / Val_loss: 1.3121\n",
      "Epoch: 1188, Train_loss: 0.4773 / Val_loss: 1.1778\n",
      "Epoch: 1189, Train_loss: 0.4688 / Val_loss: 1.3403\n",
      "Epoch: 1190, Train_loss: 0.4545 / Val_loss: 1.2558\n",
      "Epoch: 1191, Train_loss: 0.4432 / Val_loss: 1.3886\n",
      "Epoch: 1192, Train_loss: 0.4593 / Val_loss: 1.5716\n",
      "Epoch: 1193, Train_loss: 0.4481 / Val_loss: 1.4212\n",
      "Epoch: 1194, Train_loss: 0.4712 / Val_loss: 1.3293\n",
      "Epoch: 1195, Train_loss: 0.4790 / Val_loss: 1.5195\n",
      "Epoch: 1196, Train_loss: 0.4834 / Val_loss: 1.4503\n",
      "Epoch: 1197, Train_loss: 0.4779 / Val_loss: 1.2183\n",
      "Epoch: 1198, Train_loss: 0.4606 / Val_loss: 0.9190\n",
      "Epoch: 1199, Train_loss: 0.4907 / Val_loss: 1.2509\n",
      "Epoch: 1200, Train_loss: 0.5000 / Val_loss: 1.3017\n",
      "Epoch: 1201, Train_loss: 0.4536 / Val_loss: 1.1851\n",
      "Epoch: 1202, Train_loss: 0.4625 / Val_loss: 1.3817\n",
      "Epoch: 1203, Train_loss: 0.4521 / Val_loss: 1.3331\n",
      "Epoch: 1204, Train_loss: 0.4678 / Val_loss: 1.0652\n",
      "Epoch: 1205, Train_loss: 0.4790 / Val_loss: 1.2427\n",
      "Epoch: 1206, Train_loss: 0.4635 / Val_loss: 1.0461\n",
      "Epoch: 1207, Train_loss: 0.4598 / Val_loss: 1.1958\n",
      "Epoch: 1208, Train_loss: 0.5053 / Val_loss: 1.1735\n",
      "Epoch: 1209, Train_loss: 0.4712 / Val_loss: 1.0627\n",
      "Epoch: 1210, Train_loss: 0.4715 / Val_loss: 1.3656\n",
      "Epoch: 1211, Train_loss: 0.4819 / Val_loss: 1.1097\n",
      "Epoch: 1212, Train_loss: 0.4657 / Val_loss: 1.3044\n",
      "Epoch: 1213, Train_loss: 0.4369 / Val_loss: 1.2005\n",
      "Epoch: 1214, Train_loss: 0.4591 / Val_loss: 1.5336\n",
      "Epoch: 1215, Train_loss: 0.4941 / Val_loss: 1.3371\n",
      "Epoch: 1216, Train_loss: 0.4636 / Val_loss: 1.2215\n",
      "Epoch: 1217, Train_loss: 0.4407 / Val_loss: 0.9495\n",
      "Epoch: 1218, Train_loss: 0.4640 / Val_loss: 1.4486\n",
      "Epoch: 1219, Train_loss: 0.4619 / Val_loss: 1.1383\n",
      "Epoch: 1220, Train_loss: 0.4711 / Val_loss: 1.1277\n",
      "Epoch: 1221, Train_loss: 0.4442 / Val_loss: 1.0134\n",
      "Epoch: 1222, Train_loss: 0.4493 / Val_loss: 1.1941\n",
      "Epoch: 1223, Train_loss: 0.4890 / Val_loss: 1.5466\n",
      "Epoch: 1224, Train_loss: 0.4717 / Val_loss: 1.3006\n",
      "Epoch: 1225, Train_loss: 0.4970 / Val_loss: 1.4368\n",
      "Epoch: 1226, Train_loss: 0.4590 / Val_loss: 1.3626\n",
      "Epoch: 1227, Train_loss: 0.4728 / Val_loss: 1.3546\n",
      "Epoch: 1228, Train_loss: 0.4549 / Val_loss: 1.3182\n",
      "Epoch: 1229, Train_loss: 0.4580 / Val_loss: 1.2173\n",
      "Epoch: 1230, Train_loss: 0.4872 / Val_loss: 1.0253\n",
      "Epoch: 1231, Train_loss: 0.4606 / Val_loss: 1.1552\n",
      "Epoch: 1232, Train_loss: 0.4761 / Val_loss: 1.1915\n",
      "Epoch: 1233, Train_loss: 0.4886 / Val_loss: 1.0440\n",
      "Epoch: 1234, Train_loss: 0.4462 / Val_loss: 1.2904\n",
      "Epoch: 1235, Train_loss: 0.4640 / Val_loss: 1.2250\n",
      "Epoch: 1236, Train_loss: 0.4738 / Val_loss: 1.2945\n",
      "Epoch: 1237, Train_loss: 0.4474 / Val_loss: 1.1574\n",
      "Epoch: 1238, Train_loss: 0.4674 / Val_loss: 1.1443\n",
      "Epoch: 1239, Train_loss: 0.4721 / Val_loss: 1.1202\n",
      "Epoch: 1240, Train_loss: 0.4724 / Val_loss: 1.0451\n",
      "Epoch: 1241, Train_loss: 0.4789 / Val_loss: 1.2838\n",
      "Epoch: 1242, Train_loss: 0.4887 / Val_loss: 1.3370\n",
      "Epoch: 1243, Train_loss: 0.4657 / Val_loss: 1.4168\n",
      "Epoch: 1244, Train_loss: 0.4638 / Val_loss: 1.0496\n",
      "Epoch: 1245, Train_loss: 0.4619 / Val_loss: 1.2233\n",
      "Epoch: 1246, Train_loss: 0.4664 / Val_loss: 1.2922\n",
      "Epoch: 1247, Train_loss: 0.4728 / Val_loss: 1.1749\n",
      "Epoch: 1248, Train_loss: 0.5032 / Val_loss: 1.4200\n",
      "Epoch: 1249, Train_loss: 0.4572 / Val_loss: 1.4528\n",
      "Epoch: 1250, Train_loss: 0.4625 / Val_loss: 1.1517\n",
      "Epoch: 1251, Train_loss: 0.4691 / Val_loss: 1.4292\n",
      "Epoch: 1252, Train_loss: 0.4490 / Val_loss: 1.3373\n",
      "Epoch: 1253, Train_loss: 0.4502 / Val_loss: 1.5563\n",
      "Epoch: 1254, Train_loss: 0.4615 / Val_loss: 1.4340\n",
      "Epoch: 1255, Train_loss: 0.4692 / Val_loss: 1.3179\n",
      "Epoch: 1256, Train_loss: 0.4662 / Val_loss: 1.0763\n",
      "Epoch: 1257, Train_loss: 0.4742 / Val_loss: 1.3360\n",
      "Epoch: 1258, Train_loss: 0.4721 / Val_loss: 1.1914\n",
      "Epoch: 1259, Train_loss: 0.4578 / Val_loss: 1.4404\n",
      "Epoch: 1260, Train_loss: 0.4590 / Val_loss: 0.9802\n",
      "Epoch: 1261, Train_loss: 0.4562 / Val_loss: 0.9799\n",
      "Epoch: 1262, Train_loss: 0.4452 / Val_loss: 1.1505\n",
      "Epoch: 1263, Train_loss: 0.4800 / Val_loss: 0.9512\n",
      "Epoch: 1264, Train_loss: 0.4702 / Val_loss: 1.4079\n",
      "Epoch: 1265, Train_loss: 0.4538 / Val_loss: 1.0219\n",
      "Epoch: 1266, Train_loss: 0.4636 / Val_loss: 1.4945\n",
      "Epoch: 1267, Train_loss: 0.4634 / Val_loss: 1.3452\n",
      "Epoch: 1268, Train_loss: 0.4661 / Val_loss: 1.1682\n",
      "Epoch: 1269, Train_loss: 0.4533 / Val_loss: 1.2903\n",
      "Epoch: 1270, Train_loss: 0.4604 / Val_loss: 1.2706\n",
      "Epoch: 1271, Train_loss: 0.4541 / Val_loss: 1.4416\n",
      "Epoch: 1272, Train_loss: 0.4882 / Val_loss: 1.1464\n",
      "Epoch: 1273, Train_loss: 0.4514 / Val_loss: 1.1528\n",
      "Epoch: 1274, Train_loss: 0.4513 / Val_loss: 1.2801\n",
      "Epoch: 1275, Train_loss: 0.4472 / Val_loss: 1.0911\n",
      "Epoch: 1276, Train_loss: 0.4566 / Val_loss: 1.1273\n",
      "Epoch: 1277, Train_loss: 0.4612 / Val_loss: 1.4874\n",
      "Epoch: 1278, Train_loss: 0.4594 / Val_loss: 1.3654\n",
      "Epoch: 1279, Train_loss: 0.4419 / Val_loss: 1.4164\n",
      "Epoch: 1280, Train_loss: 0.4519 / Val_loss: 1.4524\n",
      "Epoch: 1281, Train_loss: 0.4589 / Val_loss: 1.3713\n",
      "Epoch: 1282, Train_loss: 0.4526 / Val_loss: 1.5039\n",
      "Epoch: 1283, Train_loss: 0.4816 / Val_loss: 1.3297\n",
      "Epoch: 1284, Train_loss: 0.4651 / Val_loss: 1.2670\n",
      "Epoch: 1285, Train_loss: 0.4640 / Val_loss: 1.2824\n",
      "Epoch: 1286, Train_loss: 0.4426 / Val_loss: 1.3142\n",
      "Epoch: 1287, Train_loss: 0.4767 / Val_loss: 1.3410\n",
      "Epoch: 1288, Train_loss: 0.4796 / Val_loss: 0.9646\n",
      "Epoch: 1289, Train_loss: 0.4469 / Val_loss: 1.2698\n",
      "Epoch: 1290, Train_loss: 0.4629 / Val_loss: 0.9844\n",
      "Epoch: 1291, Train_loss: 0.4515 / Val_loss: 1.1438\n",
      "Epoch: 1292, Train_loss: 0.4529 / Val_loss: 1.1477\n",
      "Epoch: 1293, Train_loss: 0.4648 / Val_loss: 1.4937\n",
      "Epoch: 1294, Train_loss: 0.4573 / Val_loss: 1.2525\n",
      "Epoch: 1295, Train_loss: 0.4417 / Val_loss: 1.3011\n",
      "Epoch: 1296, Train_loss: 0.4646 / Val_loss: 1.2463\n",
      "Epoch: 1297, Train_loss: 0.4497 / Val_loss: 1.2300\n",
      "Epoch: 1298, Train_loss: 0.4707 / Val_loss: 1.2943\n",
      "Epoch: 1299, Train_loss: 0.4610 / Val_loss: 1.2249\n",
      "Epoch: 1300, Train_loss: 0.4606 / Val_loss: 1.5095\n",
      "Epoch: 1301, Train_loss: 0.4413 / Val_loss: 1.4654\n",
      "Epoch: 1302, Train_loss: 0.4664 / Val_loss: 1.1045\n",
      "Epoch: 1303, Train_loss: 0.4658 / Val_loss: 1.3284\n",
      "Epoch: 1304, Train_loss: 0.4486 / Val_loss: 1.3718\n",
      "Epoch: 1305, Train_loss: 0.4525 / Val_loss: 1.2688\n",
      "Epoch: 1306, Train_loss: 0.4667 / Val_loss: 1.5001\n",
      "Epoch: 1307, Train_loss: 0.4671 / Val_loss: 1.2628\n",
      "Epoch: 1308, Train_loss: 0.4760 / Val_loss: 1.0030\n",
      "Epoch: 1309, Train_loss: 0.4629 / Val_loss: 1.3557\n",
      "Epoch: 1310, Train_loss: 0.4546 / Val_loss: 1.3296\n",
      "Epoch: 1311, Train_loss: 0.4846 / Val_loss: 1.1215\n",
      "Epoch: 1312, Train_loss: 0.4846 / Val_loss: 1.1483\n",
      "Epoch: 1313, Train_loss: 0.4743 / Val_loss: 1.2517\n",
      "Epoch: 1314, Train_loss: 0.4336 / Val_loss: 1.2168\n",
      "Epoch: 1315, Train_loss: 0.4456 / Val_loss: 1.1930\n",
      "Epoch: 1316, Train_loss: 0.4545 / Val_loss: 1.3541\n",
      "Epoch: 1317, Train_loss: 0.4610 / Val_loss: 1.4655\n",
      "Epoch: 1318, Train_loss: 0.4503 / Val_loss: 1.3114\n",
      "Epoch: 1319, Train_loss: 0.4772 / Val_loss: 1.3631\n",
      "Epoch: 1320, Train_loss: 0.4468 / Val_loss: 1.2249\n",
      "Epoch: 1321, Train_loss: 0.4493 / Val_loss: 1.4172\n",
      "Epoch: 1322, Train_loss: 0.4682 / Val_loss: 1.3199\n",
      "Epoch: 1323, Train_loss: 0.4671 / Val_loss: 1.2545\n",
      "Epoch: 1324, Train_loss: 0.4391 / Val_loss: 1.3370\n",
      "Epoch: 1325, Train_loss: 0.4818 / Val_loss: 1.2287\n",
      "Epoch: 1326, Train_loss: 0.4447 / Val_loss: 1.1525\n",
      "Epoch: 1327, Train_loss: 0.4623 / Val_loss: 1.5192\n",
      "Epoch: 1328, Train_loss: 0.4609 / Val_loss: 0.9576\n",
      "Epoch: 1329, Train_loss: 0.4483 / Val_loss: 1.4846\n",
      "Epoch: 1330, Train_loss: 0.4582 / Val_loss: 1.2533\n",
      "Epoch: 1331, Train_loss: 0.4696 / Val_loss: 1.3444\n",
      "Epoch: 1332, Train_loss: 0.4381 / Val_loss: 1.0290\n",
      "Epoch: 1333, Train_loss: 0.4680 / Val_loss: 1.1792\n",
      "Epoch: 1334, Train_loss: 0.4425 / Val_loss: 1.4427\n",
      "Epoch: 1335, Train_loss: 0.4328 / Val_loss: 1.4887\n",
      "Epoch: 1336, Train_loss: 0.4434 / Val_loss: 1.2937\n",
      "Epoch: 1337, Train_loss: 0.4432 / Val_loss: 1.1954\n",
      "Epoch: 1338, Train_loss: 0.4511 / Val_loss: 1.3449\n",
      "Epoch: 1339, Train_loss: 0.4708 / Val_loss: 1.1227\n",
      "Epoch: 1340, Train_loss: 0.4660 / Val_loss: 1.2115\n",
      "Epoch: 1341, Train_loss: 0.4464 / Val_loss: 1.4467\n",
      "Epoch: 1342, Train_loss: 0.4527 / Val_loss: 1.2880\n",
      "Epoch: 1343, Train_loss: 0.4382 / Val_loss: 1.3568\n",
      "Epoch: 1344, Train_loss: 0.4621 / Val_loss: 1.0770\n",
      "Epoch: 1345, Train_loss: 0.4322 / Val_loss: 1.5099\n",
      "Epoch: 1346, Train_loss: 0.4665 / Val_loss: 1.4113\n",
      "Epoch: 1347, Train_loss: 0.4486 / Val_loss: 1.3067\n",
      "Epoch: 1348, Train_loss: 0.4665 / Val_loss: 1.2530\n",
      "Epoch: 1349, Train_loss: 0.4494 / Val_loss: 1.2139\n",
      "Epoch: 1350, Train_loss: 0.4604 / Val_loss: 1.5691\n",
      "Epoch: 1351, Train_loss: 0.4351 / Val_loss: 1.2638\n",
      "Epoch: 1352, Train_loss: 0.4884 / Val_loss: 1.3505\n",
      "Epoch: 1353, Train_loss: 0.4595 / Val_loss: 1.2327\n",
      "Epoch: 1354, Train_loss: 0.4932 / Val_loss: 1.3642\n",
      "Epoch: 1355, Train_loss: 0.4553 / Val_loss: 1.2463\n",
      "Epoch: 1356, Train_loss: 0.4573 / Val_loss: 1.0856\n",
      "Epoch: 1357, Train_loss: 0.4402 / Val_loss: 1.2567\n",
      "Epoch: 1358, Train_loss: 0.4928 / Val_loss: 1.0809\n",
      "Epoch: 1359, Train_loss: 0.4663 / Val_loss: 1.1310\n",
      "Epoch: 1360, Train_loss: 0.4662 / Val_loss: 1.0502\n",
      "Epoch: 1361, Train_loss: 0.4424 / Val_loss: 1.2755\n",
      "Epoch: 1362, Train_loss: 0.4851 / Val_loss: 1.1873\n",
      "Epoch: 1363, Train_loss: 0.4617 / Val_loss: 1.1140\n",
      "Epoch: 1364, Train_loss: 0.4661 / Val_loss: 1.1110\n",
      "Epoch: 1365, Train_loss: 0.4545 / Val_loss: 1.4826\n",
      "Epoch: 1366, Train_loss: 0.4434 / Val_loss: 0.9958\n",
      "Epoch: 1367, Train_loss: 0.4629 / Val_loss: 1.4822\n",
      "Epoch: 1368, Train_loss: 0.4523 / Val_loss: 1.2242\n",
      "Epoch: 1369, Train_loss: 0.4679 / Val_loss: 1.5719\n",
      "Epoch: 1370, Train_loss: 0.4673 / Val_loss: 1.2536\n",
      "Epoch: 1371, Train_loss: 0.4746 / Val_loss: 1.2702\n",
      "Epoch: 1372, Train_loss: 0.4573 / Val_loss: 1.5037\n",
      "Epoch: 1373, Train_loss: 0.4437 / Val_loss: 1.2096\n",
      "Epoch: 1374, Train_loss: 0.4514 / Val_loss: 1.3413\n",
      "Epoch: 1375, Train_loss: 0.4841 / Val_loss: 1.4463\n",
      "Epoch: 1376, Train_loss: 0.4674 / Val_loss: 1.3509\n",
      "Epoch: 1377, Train_loss: 0.4439 / Val_loss: 1.3420\n",
      "Epoch: 1378, Train_loss: 0.4484 / Val_loss: 1.1855\n",
      "Epoch: 1379, Train_loss: 0.4347 / Val_loss: 1.3088\n",
      "Epoch: 1380, Train_loss: 0.4660 / Val_loss: 1.4419\n",
      "Epoch: 1381, Train_loss: 0.4914 / Val_loss: 1.2846\n",
      "Epoch: 1382, Train_loss: 0.4553 / Val_loss: 1.4169\n",
      "Epoch: 1383, Train_loss: 0.4452 / Val_loss: 1.3880\n",
      "Epoch: 1384, Train_loss: 0.4360 / Val_loss: 1.4363\n",
      "Epoch: 1385, Train_loss: 0.4456 / Val_loss: 1.2534\n",
      "Epoch: 1386, Train_loss: 0.4447 / Val_loss: 1.2452\n",
      "Epoch: 1387, Train_loss: 0.4519 / Val_loss: 1.4034\n",
      "Epoch: 1388, Train_loss: 0.4651 / Val_loss: 1.4748\n",
      "Epoch: 1389, Train_loss: 0.4834 / Val_loss: 1.5227\n",
      "Epoch: 1390, Train_loss: 0.4525 / Val_loss: 1.4784\n",
      "Epoch: 1391, Train_loss: 0.4580 / Val_loss: 1.1197\n",
      "Epoch: 1392, Train_loss: 0.4537 / Val_loss: 1.2475\n",
      "Epoch: 1393, Train_loss: 0.4399 / Val_loss: 1.2703\n",
      "Epoch: 1394, Train_loss: 0.4379 / Val_loss: 1.5106\n",
      "Epoch: 1395, Train_loss: 0.4340 / Val_loss: 1.2021\n",
      "Epoch: 1396, Train_loss: 0.4692 / Val_loss: 1.5465\n",
      "Epoch: 1397, Train_loss: 0.4786 / Val_loss: 1.2880\n",
      "Epoch: 1398, Train_loss: 0.4578 / Val_loss: 1.2584\n",
      "Epoch: 1399, Train_loss: 0.4625 / Val_loss: 1.0334\n",
      "Epoch: 1400, Train_loss: 0.4357 / Val_loss: 1.3100\n",
      "Epoch: 1401, Train_loss: 0.4600 / Val_loss: 1.2762\n",
      "Epoch: 1402, Train_loss: 0.4453 / Val_loss: 1.4095\n",
      "Epoch: 1403, Train_loss: 0.4396 / Val_loss: 1.4473\n",
      "Epoch: 1404, Train_loss: 0.4517 / Val_loss: 1.4186\n",
      "Epoch: 1405, Train_loss: 0.4594 / Val_loss: 1.3747\n",
      "Epoch: 1406, Train_loss: 0.4334 / Val_loss: 1.3276\n",
      "Epoch: 1407, Train_loss: 0.4436 / Val_loss: 1.3001\n",
      "Epoch: 1408, Train_loss: 0.4528 / Val_loss: 1.3626\n",
      "Epoch: 1409, Train_loss: 0.4481 / Val_loss: 1.1487\n",
      "Epoch: 1410, Train_loss: 0.4498 / Val_loss: 0.9885\n",
      "Epoch: 1411, Train_loss: 0.4493 / Val_loss: 1.4576\n",
      "Epoch: 1412, Train_loss: 0.4578 / Val_loss: 1.4431\n",
      "Epoch: 1413, Train_loss: 0.4733 / Val_loss: 1.3200\n",
      "Epoch: 1414, Train_loss: 0.4355 / Val_loss: 1.2424\n",
      "Epoch: 1415, Train_loss: 0.4689 / Val_loss: 1.1939\n",
      "Epoch: 1416, Train_loss: 0.4401 / Val_loss: 1.3630\n",
      "Epoch: 1417, Train_loss: 0.4549 / Val_loss: 1.3591\n",
      "Epoch: 1418, Train_loss: 0.4548 / Val_loss: 1.4158\n",
      "Epoch: 1419, Train_loss: 0.4368 / Val_loss: 1.3533\n",
      "Epoch: 1420, Train_loss: 0.4422 / Val_loss: 1.2642\n",
      "Epoch: 1421, Train_loss: 0.4383 / Val_loss: 1.0893\n",
      "Epoch: 1422, Train_loss: 0.4651 / Val_loss: 1.4309\n",
      "Epoch: 1423, Train_loss: 0.5035 / Val_loss: 1.1134\n",
      "Epoch: 1424, Train_loss: 0.4610 / Val_loss: 1.1168\n",
      "Epoch: 1425, Train_loss: 0.4798 / Val_loss: 1.3255\n",
      "Epoch: 1426, Train_loss: 0.4821 / Val_loss: 1.4702\n",
      "Epoch: 1427, Train_loss: 0.4689 / Val_loss: 1.3722\n",
      "Epoch: 1428, Train_loss: 0.4494 / Val_loss: 1.1454\n",
      "Epoch: 1429, Train_loss: 0.4720 / Val_loss: 1.3026\n",
      "Epoch: 1430, Train_loss: 0.4522 / Val_loss: 1.4124\n",
      "Epoch: 1431, Train_loss: 0.4539 / Val_loss: 1.2553\n",
      "Epoch: 1432, Train_loss: 0.4529 / Val_loss: 1.1811\n",
      "Epoch: 1433, Train_loss: 0.4301 / Val_loss: 1.1498\n",
      "Epoch: 1434, Train_loss: 0.4515 / Val_loss: 1.2837\n",
      "Epoch: 1435, Train_loss: 0.4369 / Val_loss: 1.6020\n",
      "Epoch: 1436, Train_loss: 0.4243 / Val_loss: 1.3412\n",
      "Epoch: 1437, Train_loss: 0.4866 / Val_loss: 1.1134\n",
      "Epoch: 1438, Train_loss: 0.4649 / Val_loss: 1.2820\n",
      "Epoch: 1439, Train_loss: 0.4325 / Val_loss: 1.3979\n",
      "Epoch: 1440, Train_loss: 0.4437 / Val_loss: 1.2897\n",
      "Epoch: 1441, Train_loss: 0.4504 / Val_loss: 1.2207\n",
      "Epoch: 1442, Train_loss: 0.4710 / Val_loss: 1.2046\n",
      "Epoch: 1443, Train_loss: 0.4367 / Val_loss: 1.3163\n",
      "Epoch: 1444, Train_loss: 0.4587 / Val_loss: 1.5448\n",
      "Epoch: 1445, Train_loss: 0.4702 / Val_loss: 1.0529\n",
      "Epoch: 1446, Train_loss: 0.4618 / Val_loss: 1.0574\n",
      "Epoch: 1447, Train_loss: 0.4582 / Val_loss: 1.2802\n",
      "Epoch: 1448, Train_loss: 0.4520 / Val_loss: 1.1723\n",
      "Epoch: 1449, Train_loss: 0.4752 / Val_loss: 1.3168\n",
      "Epoch: 1450, Train_loss: 0.4567 / Val_loss: 1.2434\n",
      "Epoch: 1451, Train_loss: 0.4513 / Val_loss: 1.2529\n",
      "Epoch: 1452, Train_loss: 0.4668 / Val_loss: 1.0829\n",
      "Epoch: 1453, Train_loss: 0.4352 / Val_loss: 1.1057\n",
      "Epoch: 1454, Train_loss: 0.4611 / Val_loss: 1.4038\n",
      "Epoch: 1455, Train_loss: 0.4751 / Val_loss: 1.4172\n",
      "Epoch: 1456, Train_loss: 0.4819 / Val_loss: 1.1957\n",
      "Epoch: 1457, Train_loss: 0.4474 / Val_loss: 1.3816\n",
      "Epoch: 1458, Train_loss: 0.4351 / Val_loss: 1.3483\n",
      "Epoch: 1459, Train_loss: 0.4493 / Val_loss: 1.3518\n",
      "Epoch: 1460, Train_loss: 0.4647 / Val_loss: 1.1274\n",
      "Epoch: 1461, Train_loss: 0.4617 / Val_loss: 1.4995\n",
      "Epoch: 1462, Train_loss: 0.4383 / Val_loss: 1.3607\n",
      "Epoch: 1463, Train_loss: 0.4577 / Val_loss: 1.1793\n",
      "Epoch: 1464, Train_loss: 0.4522 / Val_loss: 1.3503\n",
      "Epoch: 1465, Train_loss: 0.4594 / Val_loss: 1.4572\n",
      "Epoch: 1466, Train_loss: 0.4732 / Val_loss: 1.1350\n",
      "Epoch: 1467, Train_loss: 0.4671 / Val_loss: 1.0497\n",
      "Epoch: 1468, Train_loss: 0.4485 / Val_loss: 1.0913\n",
      "Epoch: 1469, Train_loss: 0.4310 / Val_loss: 1.2649\n",
      "Epoch: 1470, Train_loss: 0.4597 / Val_loss: 1.0112\n",
      "Epoch: 1471, Train_loss: 0.4617 / Val_loss: 1.2192\n",
      "Epoch: 1472, Train_loss: 0.4647 / Val_loss: 1.5789\n",
      "Epoch: 1473, Train_loss: 0.4550 / Val_loss: 1.4616\n",
      "Epoch: 1474, Train_loss: 0.4600 / Val_loss: 1.4596\n",
      "Epoch: 1475, Train_loss: 0.4284 / Val_loss: 1.2778\n",
      "Epoch: 1476, Train_loss: 0.4184 / Val_loss: 1.3318\n",
      "Epoch: 1477, Train_loss: 0.4392 / Val_loss: 0.9336\n",
      "Epoch: 1478, Train_loss: 0.4666 / Val_loss: 1.3496\n",
      "Epoch: 1479, Train_loss: 0.4464 / Val_loss: 1.3646\n",
      "Epoch: 1480, Train_loss: 0.4411 / Val_loss: 1.4399\n",
      "Epoch: 1481, Train_loss: 0.4936 / Val_loss: 1.1174\n",
      "Epoch: 1482, Train_loss: 0.4862 / Val_loss: 1.2912\n",
      "Epoch: 1483, Train_loss: 0.4720 / Val_loss: 1.3481\n",
      "Epoch: 1484, Train_loss: 0.4424 / Val_loss: 1.5500\n",
      "Epoch: 1485, Train_loss: 0.4511 / Val_loss: 1.1046\n",
      "Epoch: 1486, Train_loss: 0.4558 / Val_loss: 1.0842\n",
      "Epoch: 1487, Train_loss: 0.4574 / Val_loss: 1.3317\n",
      "Epoch: 1488, Train_loss: 0.4849 / Val_loss: 1.2063\n",
      "Epoch: 1489, Train_loss: 0.4633 / Val_loss: 1.3083\n",
      "Epoch: 1490, Train_loss: 0.4734 / Val_loss: 1.1930\n",
      "Epoch: 1491, Train_loss: 0.4734 / Val_loss: 1.3100\n",
      "Epoch: 1492, Train_loss: 0.4728 / Val_loss: 1.2358\n",
      "Epoch: 1493, Train_loss: 0.4393 / Val_loss: 1.2197\n",
      "Epoch: 1494, Train_loss: 0.4666 / Val_loss: 1.1718\n",
      "Epoch: 1495, Train_loss: 0.4446 / Val_loss: 1.1363\n",
      "Epoch: 1496, Train_loss: 0.4605 / Val_loss: 1.3409\n",
      "Epoch: 1497, Train_loss: 0.4381 / Val_loss: 1.1984\n",
      "Epoch: 1498, Train_loss: 0.5106 / Val_loss: 1.4573\n",
      "Epoch: 1499, Train_loss: 0.4543 / Val_loss: 1.1178\n",
      "Epoch: 1500, Train_loss: 0.4325 / Val_loss: 1.4735\n",
      "Epoch: 1501, Train_loss: 0.4500 / Val_loss: 1.5013\n",
      "Epoch: 1502, Train_loss: 0.4550 / Val_loss: 1.0217\n",
      "Epoch: 1503, Train_loss: 0.4305 / Val_loss: 1.1960\n",
      "Epoch: 1504, Train_loss: 0.4445 / Val_loss: 1.0939\n",
      "Epoch: 1505, Train_loss: 0.4861 / Val_loss: 1.5432\n",
      "Epoch: 1506, Train_loss: 0.4462 / Val_loss: 1.2847\n",
      "Epoch: 1507, Train_loss: 0.4648 / Val_loss: 1.1779\n",
      "Epoch: 1508, Train_loss: 0.4313 / Val_loss: 1.0083\n",
      "Epoch: 1509, Train_loss: 0.4409 / Val_loss: 1.2509\n",
      "Epoch: 1510, Train_loss: 0.4635 / Val_loss: 1.1838\n",
      "Epoch: 1511, Train_loss: 0.4515 / Val_loss: 1.2246\n",
      "Epoch: 1512, Train_loss: 0.4403 / Val_loss: 1.0357\n",
      "Epoch: 1513, Train_loss: 0.4529 / Val_loss: 1.2921\n",
      "Epoch: 1514, Train_loss: 0.4552 / Val_loss: 1.2973\n",
      "Epoch: 1515, Train_loss: 0.4491 / Val_loss: 1.2741\n",
      "Epoch: 1516, Train_loss: 0.4208 / Val_loss: 1.6554\n",
      "Epoch: 1517, Train_loss: 0.4584 / Val_loss: 1.2850\n",
      "Epoch: 1518, Train_loss: 0.4627 / Val_loss: 1.4030\n",
      "Epoch: 1519, Train_loss: 0.4498 / Val_loss: 1.4816\n",
      "Epoch: 1520, Train_loss: 0.4465 / Val_loss: 1.4464\n",
      "Epoch: 1521, Train_loss: 0.4484 / Val_loss: 1.3335\n",
      "Epoch: 1522, Train_loss: 0.4505 / Val_loss: 1.1241\n",
      "Epoch: 1523, Train_loss: 0.4256 / Val_loss: 1.2789\n",
      "Epoch: 1524, Train_loss: 0.4491 / Val_loss: 1.3908\n",
      "Epoch: 1525, Train_loss: 0.4542 / Val_loss: 1.2507\n",
      "Epoch: 1526, Train_loss: 0.4413 / Val_loss: 1.3289\n",
      "Epoch: 1527, Train_loss: 0.4597 / Val_loss: 1.6056\n",
      "Epoch: 1528, Train_loss: 0.4521 / Val_loss: 1.1903\n",
      "Epoch: 1529, Train_loss: 0.4508 / Val_loss: 1.2717\n",
      "Epoch: 1530, Train_loss: 0.4575 / Val_loss: 1.2744\n",
      "Epoch: 1531, Train_loss: 0.4397 / Val_loss: 1.5101\n",
      "Epoch: 1532, Train_loss: 0.4226 / Val_loss: 1.2079\n",
      "Epoch: 1533, Train_loss: 0.4320 / Val_loss: 1.3334\n",
      "Epoch: 1534, Train_loss: 0.4674 / Val_loss: 1.3977\n",
      "Epoch: 1535, Train_loss: 0.4375 / Val_loss: 1.4191\n",
      "Epoch: 1536, Train_loss: 0.4377 / Val_loss: 1.3933\n",
      "Epoch: 1537, Train_loss: 0.4436 / Val_loss: 1.4262\n",
      "Epoch: 1538, Train_loss: 0.4380 / Val_loss: 1.3632\n",
      "Epoch: 1539, Train_loss: 0.4369 / Val_loss: 1.3829\n",
      "Epoch: 1540, Train_loss: 0.4360 / Val_loss: 1.3082\n",
      "Epoch: 1541, Train_loss: 0.4357 / Val_loss: 1.1974\n",
      "Epoch: 1542, Train_loss: 0.4444 / Val_loss: 1.6947\n",
      "Epoch: 1543, Train_loss: 0.4513 / Val_loss: 1.2503\n",
      "Epoch: 1544, Train_loss: 0.4628 / Val_loss: 1.2119\n",
      "Epoch: 1545, Train_loss: 0.4418 / Val_loss: 1.2754\n",
      "Epoch: 1546, Train_loss: 0.4353 / Val_loss: 1.3075\n",
      "Epoch: 1547, Train_loss: 0.4269 / Val_loss: 1.3692\n",
      "Epoch: 1548, Train_loss: 0.4435 / Val_loss: 1.0776\n",
      "Epoch: 1549, Train_loss: 0.4262 / Val_loss: 1.4650\n",
      "Epoch: 1550, Train_loss: 0.4481 / Val_loss: 1.4122\n",
      "Epoch: 1551, Train_loss: 0.4456 / Val_loss: 1.1291\n",
      "Epoch: 1552, Train_loss: 0.4239 / Val_loss: 1.2414\n",
      "Epoch: 1553, Train_loss: 0.4531 / Val_loss: 1.3690\n",
      "Epoch: 1554, Train_loss: 0.4389 / Val_loss: 1.4240\n",
      "Epoch: 1555, Train_loss: 0.4425 / Val_loss: 1.5770\n",
      "Epoch: 1556, Train_loss: 0.4771 / Val_loss: 1.3777\n",
      "Epoch: 1557, Train_loss: 0.4426 / Val_loss: 1.5128\n",
      "Epoch: 1558, Train_loss: 0.4579 / Val_loss: 1.4269\n",
      "Epoch: 1559, Train_loss: 0.4507 / Val_loss: 1.5156\n",
      "Epoch: 1560, Train_loss: 0.4253 / Val_loss: 1.2962\n",
      "Epoch: 1561, Train_loss: 0.4697 / Val_loss: 1.4235\n",
      "Epoch: 1562, Train_loss: 0.4315 / Val_loss: 1.3480\n",
      "Epoch: 1563, Train_loss: 0.4324 / Val_loss: 1.4742\n",
      "Epoch: 1564, Train_loss: 0.4257 / Val_loss: 1.6027\n",
      "Epoch: 1565, Train_loss: 0.4532 / Val_loss: 1.5342\n",
      "Epoch: 1566, Train_loss: 0.4388 / Val_loss: 1.3118\n",
      "Epoch: 1567, Train_loss: 0.5093 / Val_loss: 1.4273\n",
      "Epoch: 1568, Train_loss: 0.4688 / Val_loss: 1.6152\n",
      "Epoch: 1569, Train_loss: 0.4380 / Val_loss: 1.1384\n",
      "Epoch: 1570, Train_loss: 0.4347 / Val_loss: 1.2421\n",
      "Epoch: 1571, Train_loss: 0.4511 / Val_loss: 1.3296\n",
      "Epoch: 1572, Train_loss: 0.4411 / Val_loss: 1.2416\n",
      "Epoch: 1573, Train_loss: 0.4423 / Val_loss: 1.2099\n",
      "Epoch: 1574, Train_loss: 0.4413 / Val_loss: 1.3635\n",
      "Epoch: 1575, Train_loss: 0.4389 / Val_loss: 1.4206\n",
      "Epoch: 1576, Train_loss: 0.4523 / Val_loss: 1.2937\n",
      "Epoch: 1577, Train_loss: 0.4574 / Val_loss: 1.3938\n",
      "Epoch: 1578, Train_loss: 0.4530 / Val_loss: 1.3483\n",
      "Epoch: 1579, Train_loss: 0.4635 / Val_loss: 1.2272\n",
      "Epoch: 1580, Train_loss: 0.4346 / Val_loss: 1.2539\n",
      "Epoch: 1581, Train_loss: 0.4637 / Val_loss: 1.4153\n",
      "Epoch: 1582, Train_loss: 0.4781 / Val_loss: 1.4829\n",
      "Epoch: 1583, Train_loss: 0.4380 / Val_loss: 1.4424\n",
      "Epoch: 1584, Train_loss: 0.4514 / Val_loss: 1.3408\n",
      "Epoch: 1585, Train_loss: 0.4298 / Val_loss: 1.3032\n",
      "Epoch: 1586, Train_loss: 0.4314 / Val_loss: 1.1394\n",
      "Epoch: 1587, Train_loss: 0.4313 / Val_loss: 1.3163\n",
      "Epoch: 1588, Train_loss: 0.4500 / Val_loss: 1.5089\n",
      "Epoch: 1589, Train_loss: 0.4285 / Val_loss: 1.2586\n",
      "Epoch: 1590, Train_loss: 0.4428 / Val_loss: 1.1094\n",
      "Epoch: 1591, Train_loss: 0.4777 / Val_loss: 1.2231\n",
      "Epoch: 1592, Train_loss: 0.4358 / Val_loss: 1.4461\n",
      "Epoch: 1593, Train_loss: 0.4287 / Val_loss: 1.1891\n",
      "Epoch: 1594, Train_loss: 0.4378 / Val_loss: 1.3634\n",
      "Epoch: 1595, Train_loss: 0.4473 / Val_loss: 1.5328\n",
      "Epoch: 1596, Train_loss: 0.4430 / Val_loss: 1.5032\n",
      "Epoch: 1597, Train_loss: 0.4666 / Val_loss: 1.1836\n",
      "Epoch: 1598, Train_loss: 0.4556 / Val_loss: 1.3482\n",
      "Epoch: 1599, Train_loss: 0.4499 / Val_loss: 1.3741\n",
      "Epoch: 1600, Train_loss: 0.4433 / Val_loss: 1.2074\n",
      "Epoch: 1601, Train_loss: 0.4379 / Val_loss: 1.1809\n",
      "Epoch: 1602, Train_loss: 0.4214 / Val_loss: 1.2946\n",
      "Epoch: 1603, Train_loss: 0.4753 / Val_loss: 1.1754\n",
      "Epoch: 1604, Train_loss: 0.4416 / Val_loss: 1.3662\n",
      "Epoch: 1605, Train_loss: 0.4267 / Val_loss: 1.0821\n",
      "Epoch: 1606, Train_loss: 0.4250 / Val_loss: 1.4299\n",
      "Epoch: 1607, Train_loss: 0.4408 / Val_loss: 1.4435\n",
      "Epoch: 1608, Train_loss: 0.4299 / Val_loss: 1.4132\n",
      "Epoch: 1609, Train_loss: 0.4184 / Val_loss: 1.3191\n",
      "Epoch: 1610, Train_loss: 0.4736 / Val_loss: 1.3406\n",
      "Epoch: 1611, Train_loss: 0.4754 / Val_loss: 1.2011\n",
      "Epoch: 1612, Train_loss: 0.4477 / Val_loss: 1.3639\n",
      "Epoch: 1613, Train_loss: 0.4267 / Val_loss: 1.4549\n",
      "Epoch: 1614, Train_loss: 0.4455 / Val_loss: 1.5471\n",
      "Epoch: 1615, Train_loss: 0.4364 / Val_loss: 1.3008\n",
      "Epoch: 1616, Train_loss: 0.4345 / Val_loss: 1.4835\n",
      "Epoch: 1617, Train_loss: 0.4338 / Val_loss: 1.2578\n",
      "Epoch: 1618, Train_loss: 0.4536 / Val_loss: 1.3875\n",
      "Epoch: 1619, Train_loss: 0.4604 / Val_loss: 1.3329\n",
      "Epoch: 1620, Train_loss: 0.4547 / Val_loss: 1.4262\n",
      "Epoch: 1621, Train_loss: 0.4456 / Val_loss: 1.2689\n",
      "Epoch: 1622, Train_loss: 0.4543 / Val_loss: 1.3834\n",
      "Epoch: 1623, Train_loss: 0.4453 / Val_loss: 1.2940\n",
      "Epoch: 1624, Train_loss: 0.4324 / Val_loss: 1.5047\n",
      "Epoch: 1625, Train_loss: 0.4384 / Val_loss: 1.2380\n",
      "Epoch: 1626, Train_loss: 0.4428 / Val_loss: 1.8179\n",
      "Epoch: 1627, Train_loss: 0.4785 / Val_loss: 1.4813\n",
      "Epoch: 1628, Train_loss: 0.4344 / Val_loss: 1.3578\n",
      "Epoch: 1629, Train_loss: 0.4282 / Val_loss: 1.4628\n",
      "Epoch: 1630, Train_loss: 0.4456 / Val_loss: 1.4268\n",
      "Epoch: 1631, Train_loss: 0.4367 / Val_loss: 1.5541\n",
      "Epoch: 1632, Train_loss: 0.4428 / Val_loss: 1.4733\n",
      "Epoch: 1633, Train_loss: 0.4356 / Val_loss: 1.4887\n",
      "Epoch: 1634, Train_loss: 0.4211 / Val_loss: 1.4370\n",
      "Epoch: 1635, Train_loss: 0.4136 / Val_loss: 1.4847\n",
      "Epoch: 1636, Train_loss: 0.4240 / Val_loss: 1.3742\n",
      "Epoch: 1637, Train_loss: 0.4466 / Val_loss: 1.3434\n",
      "Epoch: 1638, Train_loss: 0.4237 / Val_loss: 1.2667\n",
      "Epoch: 1639, Train_loss: 0.4437 / Val_loss: 1.2165\n",
      "Epoch: 1640, Train_loss: 0.4498 / Val_loss: 1.4309\n",
      "Epoch: 1641, Train_loss: 0.4346 / Val_loss: 1.0824\n",
      "Epoch: 1642, Train_loss: 0.4561 / Val_loss: 1.2684\n",
      "Epoch: 1643, Train_loss: 0.4502 / Val_loss: 1.1672\n",
      "Epoch: 1644, Train_loss: 0.4567 / Val_loss: 1.5087\n",
      "Epoch: 1645, Train_loss: 0.4484 / Val_loss: 1.0582\n",
      "Epoch: 1646, Train_loss: 0.4425 / Val_loss: 1.5810\n",
      "Epoch: 1647, Train_loss: 0.4435 / Val_loss: 1.3396\n",
      "Epoch: 1648, Train_loss: 0.4180 / Val_loss: 1.1618\n",
      "Epoch: 1649, Train_loss: 0.4311 / Val_loss: 1.6874\n",
      "Epoch: 1650, Train_loss: 0.4632 / Val_loss: 1.3167\n",
      "Epoch: 1651, Train_loss: 0.4850 / Val_loss: 1.1309\n",
      "Epoch: 1652, Train_loss: 0.4880 / Val_loss: 1.0515\n",
      "Epoch: 1653, Train_loss: 0.4424 / Val_loss: 1.2847\n",
      "Epoch: 1654, Train_loss: 0.4316 / Val_loss: 1.2946\n",
      "Epoch: 1655, Train_loss: 0.4406 / Val_loss: 1.1701\n",
      "Epoch: 1656, Train_loss: 0.4457 / Val_loss: 1.4533\n",
      "Epoch: 1657, Train_loss: 0.4371 / Val_loss: 1.3004\n",
      "Epoch: 1658, Train_loss: 0.4294 / Val_loss: 1.2953\n",
      "Epoch: 1659, Train_loss: 0.4266 / Val_loss: 1.4501\n",
      "Epoch: 1660, Train_loss: 0.4382 / Val_loss: 1.6049\n",
      "Epoch: 1661, Train_loss: 0.4446 / Val_loss: 1.7330\n",
      "Epoch: 1662, Train_loss: 0.4271 / Val_loss: 1.4884\n",
      "Epoch: 1663, Train_loss: 0.4505 / Val_loss: 1.3768\n",
      "Epoch: 1664, Train_loss: 0.4384 / Val_loss: 1.2385\n",
      "Epoch: 1665, Train_loss: 0.4262 / Val_loss: 1.2013\n",
      "Epoch: 1666, Train_loss: 0.4445 / Val_loss: 1.5762\n",
      "Epoch: 1667, Train_loss: 0.4666 / Val_loss: 1.3227\n",
      "Epoch: 1668, Train_loss: 0.4526 / Val_loss: 1.1661\n",
      "Epoch: 1669, Train_loss: 0.4264 / Val_loss: 1.1991\n",
      "Epoch: 1670, Train_loss: 0.4928 / Val_loss: 1.2395\n",
      "Epoch: 1671, Train_loss: 0.4577 / Val_loss: 1.4334\n",
      "Epoch: 1672, Train_loss: 0.4323 / Val_loss: 1.1026\n",
      "Epoch: 1673, Train_loss: 0.4747 / Val_loss: 1.1039\n",
      "Epoch: 1674, Train_loss: 0.4442 / Val_loss: 1.3116\n",
      "Epoch: 1675, Train_loss: 0.4456 / Val_loss: 1.8531\n",
      "Epoch: 1676, Train_loss: 0.4797 / Val_loss: 1.2513\n",
      "Epoch: 1677, Train_loss: 0.4575 / Val_loss: 1.0076\n",
      "Epoch: 1678, Train_loss: 0.4624 / Val_loss: 1.3311\n",
      "Epoch: 1679, Train_loss: 0.4370 / Val_loss: 1.2981\n",
      "Epoch: 1680, Train_loss: 0.4462 / Val_loss: 1.3740\n",
      "Epoch: 1681, Train_loss: 0.4215 / Val_loss: 1.2272\n",
      "Epoch: 1682, Train_loss: 0.4153 / Val_loss: 1.3828\n",
      "Epoch: 1683, Train_loss: 0.4279 / Val_loss: 1.0462\n",
      "Epoch: 1684, Train_loss: 0.4444 / Val_loss: 1.5896\n",
      "Epoch: 1685, Train_loss: 0.4361 / Val_loss: 1.4219\n",
      "Epoch: 1686, Train_loss: 0.4383 / Val_loss: 1.3954\n",
      "Epoch: 1687, Train_loss: 0.4378 / Val_loss: 1.6392\n",
      "Epoch: 1688, Train_loss: 0.4534 / Val_loss: 1.5524\n",
      "Epoch: 1689, Train_loss: 0.4255 / Val_loss: 1.5409\n",
      "Epoch: 1690, Train_loss: 0.4492 / Val_loss: 1.5052\n",
      "Epoch: 1691, Train_loss: 0.4355 / Val_loss: 1.3089\n",
      "Epoch: 1692, Train_loss: 0.4603 / Val_loss: 1.4040\n",
      "Epoch: 1693, Train_loss: 0.4492 / Val_loss: 1.3570\n",
      "Epoch: 1694, Train_loss: 0.4197 / Val_loss: 1.4168\n",
      "Epoch: 1695, Train_loss: 0.4523 / Val_loss: 1.4370\n",
      "Epoch: 1696, Train_loss: 0.4433 / Val_loss: 1.2603\n",
      "Epoch: 1697, Train_loss: 0.4384 / Val_loss: 1.3083\n",
      "Epoch: 1698, Train_loss: 0.4351 / Val_loss: 1.1843\n",
      "Epoch: 1699, Train_loss: 0.4371 / Val_loss: 1.3305\n",
      "Epoch: 1700, Train_loss: 0.4350 / Val_loss: 1.1996\n",
      "Epoch: 1701, Train_loss: 0.4359 / Val_loss: 1.1665\n",
      "Epoch: 1702, Train_loss: 0.4600 / Val_loss: 1.2271\n",
      "Epoch: 1703, Train_loss: 0.4260 / Val_loss: 1.4324\n",
      "Epoch: 1704, Train_loss: 0.4371 / Val_loss: 1.4611\n",
      "Epoch: 1705, Train_loss: 0.4428 / Val_loss: 1.3542\n",
      "Epoch: 1706, Train_loss: 0.4239 / Val_loss: 1.2744\n",
      "Epoch: 1707, Train_loss: 0.4249 / Val_loss: 1.4140\n",
      "Epoch: 1708, Train_loss: 0.4349 / Val_loss: 1.4435\n",
      "Epoch: 1709, Train_loss: 0.4111 / Val_loss: 1.3436\n",
      "Epoch: 1710, Train_loss: 0.4282 / Val_loss: 1.4839\n",
      "Epoch: 1711, Train_loss: 0.4620 / Val_loss: 1.4208\n",
      "Epoch: 1712, Train_loss: 0.4639 / Val_loss: 1.4857\n",
      "Epoch: 1713, Train_loss: 0.4196 / Val_loss: 1.4072\n",
      "Epoch: 1714, Train_loss: 0.4444 / Val_loss: 1.5490\n",
      "Epoch: 1715, Train_loss: 0.4412 / Val_loss: 1.6955\n",
      "Epoch: 1716, Train_loss: 0.4311 / Val_loss: 1.2853\n",
      "Epoch: 1717, Train_loss: 0.4457 / Val_loss: 1.3004\n",
      "Epoch: 1718, Train_loss: 0.4549 / Val_loss: 1.4664\n",
      "Epoch: 1719, Train_loss: 0.4371 / Val_loss: 1.2662\n",
      "Epoch: 1720, Train_loss: 0.4417 / Val_loss: 1.2381\n",
      "Epoch: 1721, Train_loss: 0.4732 / Val_loss: 1.4247\n",
      "Epoch: 1722, Train_loss: 0.4314 / Val_loss: 1.2018\n",
      "Epoch: 1723, Train_loss: 0.4556 / Val_loss: 1.4384\n",
      "Epoch: 1724, Train_loss: 0.4482 / Val_loss: 1.5261\n",
      "Epoch: 1725, Train_loss: 0.4557 / Val_loss: 1.1430\n",
      "Epoch: 1726, Train_loss: 0.4173 / Val_loss: 1.3578\n",
      "Epoch: 1727, Train_loss: 0.4349 / Val_loss: 1.0804\n",
      "Epoch: 1728, Train_loss: 0.4119 / Val_loss: 1.4886\n",
      "Epoch: 1729, Train_loss: 0.4259 / Val_loss: 1.3541\n",
      "Epoch: 1730, Train_loss: 0.4051 / Val_loss: 1.3765\n",
      "Epoch: 1731, Train_loss: 0.4137 / Val_loss: 1.4549\n",
      "Epoch: 1732, Train_loss: 0.4161 / Val_loss: 1.3116\n",
      "Epoch: 1733, Train_loss: 0.4890 / Val_loss: 1.1946\n",
      "Epoch: 1734, Train_loss: 0.4133 / Val_loss: 1.5941\n",
      "Epoch: 1735, Train_loss: 0.4265 / Val_loss: 1.3505\n",
      "Epoch: 1736, Train_loss: 0.4554 / Val_loss: 1.3150\n",
      "Epoch: 1737, Train_loss: 0.4193 / Val_loss: 1.5024\n",
      "Epoch: 1738, Train_loss: 0.4293 / Val_loss: 1.3317\n",
      "Epoch: 1739, Train_loss: 0.4166 / Val_loss: 1.4432\n",
      "Epoch: 1740, Train_loss: 0.4289 / Val_loss: 1.3214\n",
      "Epoch: 1741, Train_loss: 0.4398 / Val_loss: 1.2286\n",
      "Epoch: 1742, Train_loss: 0.4817 / Val_loss: 1.5142\n",
      "Epoch: 1743, Train_loss: 0.4404 / Val_loss: 1.4330\n",
      "Epoch: 1744, Train_loss: 0.4455 / Val_loss: 1.5748\n",
      "Epoch: 1745, Train_loss: 0.4352 / Val_loss: 1.6734\n",
      "Epoch: 1746, Train_loss: 0.4241 / Val_loss: 1.4528\n",
      "Epoch: 1747, Train_loss: 0.4243 / Val_loss: 1.2833\n",
      "Epoch: 1748, Train_loss: 0.4410 / Val_loss: 1.0741\n",
      "Epoch: 1749, Train_loss: 0.4221 / Val_loss: 1.2829\n",
      "Epoch: 1750, Train_loss: 0.4233 / Val_loss: 1.5096\n",
      "Epoch: 1751, Train_loss: 0.4323 / Val_loss: 1.1291\n",
      "Epoch: 1752, Train_loss: 0.4326 / Val_loss: 1.0876\n",
      "Epoch: 1753, Train_loss: 0.4702 / Val_loss: 1.4386\n",
      "Epoch: 1754, Train_loss: 0.4442 / Val_loss: 1.0355\n",
      "Epoch: 1755, Train_loss: 0.4401 / Val_loss: 1.3088\n",
      "Epoch: 1756, Train_loss: 0.4234 / Val_loss: 1.2332\n",
      "Epoch: 1757, Train_loss: 0.4273 / Val_loss: 1.2649\n",
      "Epoch: 1758, Train_loss: 0.4292 / Val_loss: 1.2032\n",
      "Epoch: 1759, Train_loss: 0.4615 / Val_loss: 1.2615\n",
      "Epoch: 1760, Train_loss: 0.4733 / Val_loss: 1.2402\n",
      "Epoch: 1761, Train_loss: 0.4332 / Val_loss: 1.5528\n",
      "Epoch: 1762, Train_loss: 0.4264 / Val_loss: 1.3727\n",
      "Epoch: 1763, Train_loss: 0.4308 / Val_loss: 1.4267\n",
      "Epoch: 1764, Train_loss: 0.4138 / Val_loss: 1.4925\n",
      "Epoch: 1765, Train_loss: 0.4629 / Val_loss: 1.4043\n",
      "Epoch: 1766, Train_loss: 0.4545 / Val_loss: 1.0078\n",
      "Epoch: 1767, Train_loss: 0.4150 / Val_loss: 1.4810\n",
      "Epoch: 1768, Train_loss: 0.4183 / Val_loss: 1.5818\n",
      "Epoch: 1769, Train_loss: 0.4444 / Val_loss: 1.1049\n",
      "Epoch: 1770, Train_loss: 0.4294 / Val_loss: 1.0644\n",
      "Epoch: 1771, Train_loss: 0.4745 / Val_loss: 1.5281\n",
      "Epoch: 1772, Train_loss: 0.4422 / Val_loss: 1.4832\n",
      "Epoch: 1773, Train_loss: 0.4485 / Val_loss: 1.3191\n",
      "Epoch: 1774, Train_loss: 0.4382 / Val_loss: 1.5960\n",
      "Epoch: 1775, Train_loss: 0.4317 / Val_loss: 1.6112\n",
      "Epoch: 1776, Train_loss: 0.4362 / Val_loss: 1.3046\n",
      "Epoch: 1777, Train_loss: 0.4272 / Val_loss: 1.4433\n",
      "Epoch: 1778, Train_loss: 0.4303 / Val_loss: 1.1314\n",
      "Epoch: 1779, Train_loss: 0.4556 / Val_loss: 1.2551\n",
      "Epoch: 1780, Train_loss: 0.4097 / Val_loss: 1.4972\n",
      "Epoch: 1781, Train_loss: 0.4179 / Val_loss: 1.3324\n",
      "Epoch: 1782, Train_loss: 0.4515 / Val_loss: 1.5214\n",
      "Epoch: 1783, Train_loss: 0.4218 / Val_loss: 1.3104\n",
      "Epoch: 1784, Train_loss: 0.4184 / Val_loss: 1.3274\n",
      "Epoch: 1785, Train_loss: 0.4264 / Val_loss: 1.3579\n",
      "Epoch: 1786, Train_loss: 0.4248 / Val_loss: 1.1738\n",
      "Epoch: 1787, Train_loss: 0.4428 / Val_loss: 1.3547\n",
      "Epoch: 1788, Train_loss: 0.4550 / Val_loss: 1.6809\n",
      "Epoch: 1789, Train_loss: 0.4237 / Val_loss: 1.5906\n",
      "Epoch: 1790, Train_loss: 0.4314 / Val_loss: 1.4314\n",
      "Epoch: 1791, Train_loss: 0.3981 / Val_loss: 1.2154\n",
      "Epoch: 1792, Train_loss: 0.4385 / Val_loss: 1.3919\n",
      "Epoch: 1793, Train_loss: 0.4424 / Val_loss: 1.5304\n",
      "Epoch: 1794, Train_loss: 0.4550 / Val_loss: 1.2469\n",
      "Epoch: 1795, Train_loss: 0.4560 / Val_loss: 1.2974\n",
      "Epoch: 1796, Train_loss: 0.4139 / Val_loss: 1.2261\n",
      "Epoch: 1797, Train_loss: 0.4358 / Val_loss: 1.5623\n",
      "Epoch: 1798, Train_loss: 0.4360 / Val_loss: 1.3220\n",
      "Epoch: 1799, Train_loss: 0.4386 / Val_loss: 1.3743\n",
      "Epoch: 1800, Train_loss: 0.4209 / Val_loss: 1.4739\n",
      "Epoch: 1801, Train_loss: 0.4539 / Val_loss: 1.4228\n",
      "Epoch: 1802, Train_loss: 0.4296 / Val_loss: 1.4046\n",
      "Epoch: 1803, Train_loss: 0.4398 / Val_loss: 1.1295\n",
      "Epoch: 1804, Train_loss: 0.4420 / Val_loss: 1.2548\n",
      "Epoch: 1805, Train_loss: 0.4505 / Val_loss: 1.6589\n",
      "Epoch: 1806, Train_loss: 0.4269 / Val_loss: 1.1301\n",
      "Epoch: 1807, Train_loss: 0.4414 / Val_loss: 1.0279\n",
      "Epoch: 1808, Train_loss: 0.4671 / Val_loss: 1.3672\n",
      "Epoch: 1809, Train_loss: 0.4516 / Val_loss: 1.3165\n",
      "Epoch: 1810, Train_loss: 0.4499 / Val_loss: 1.6154\n",
      "Epoch: 1811, Train_loss: 0.4240 / Val_loss: 1.3891\n",
      "Epoch: 1812, Train_loss: 0.4586 / Val_loss: 1.3067\n",
      "Epoch: 1813, Train_loss: 0.4284 / Val_loss: 1.2645\n",
      "Epoch: 1814, Train_loss: 0.4361 / Val_loss: 1.4102\n",
      "Epoch: 1815, Train_loss: 0.4317 / Val_loss: 1.2995\n",
      "Epoch: 1816, Train_loss: 0.4468 / Val_loss: 1.1998\n",
      "Epoch: 1817, Train_loss: 0.4152 / Val_loss: 1.1654\n",
      "Epoch: 1818, Train_loss: 0.4164 / Val_loss: 1.3822\n",
      "Epoch: 1819, Train_loss: 0.4233 / Val_loss: 0.9876\n",
      "Epoch: 1820, Train_loss: 0.4325 / Val_loss: 1.3278\n",
      "Epoch: 1821, Train_loss: 0.4182 / Val_loss: 1.1941\n",
      "Epoch: 1822, Train_loss: 0.4363 / Val_loss: 1.3998\n",
      "Epoch: 1823, Train_loss: 0.4428 / Val_loss: 1.4531\n",
      "Epoch: 1824, Train_loss: 0.4240 / Val_loss: 1.7134\n",
      "Epoch: 1825, Train_loss: 0.4407 / Val_loss: 1.1725\n",
      "Epoch: 1826, Train_loss: 0.4253 / Val_loss: 1.6454\n",
      "Epoch: 1827, Train_loss: 0.4317 / Val_loss: 1.2181\n",
      "Epoch: 1828, Train_loss: 0.4201 / Val_loss: 1.3956\n",
      "Epoch: 1829, Train_loss: 0.4106 / Val_loss: 1.3881\n",
      "Epoch: 1830, Train_loss: 0.4659 / Val_loss: 1.3360\n",
      "Epoch: 1831, Train_loss: 0.4211 / Val_loss: 1.3138\n",
      "Epoch: 1832, Train_loss: 0.4364 / Val_loss: 1.1830\n",
      "Epoch: 1833, Train_loss: 0.4321 / Val_loss: 1.6607\n",
      "Epoch: 1834, Train_loss: 0.4140 / Val_loss: 1.5326\n",
      "Epoch: 1835, Train_loss: 0.4211 / Val_loss: 1.4639\n",
      "Epoch: 1836, Train_loss: 0.4258 / Val_loss: 1.3190\n",
      "Epoch: 1837, Train_loss: 0.4256 / Val_loss: 1.2080\n",
      "Epoch: 1838, Train_loss: 0.4305 / Val_loss: 1.5752\n",
      "Epoch: 1839, Train_loss: 0.4382 / Val_loss: 1.4613\n",
      "Epoch: 1840, Train_loss: 0.4247 / Val_loss: 1.5094\n",
      "Epoch: 1841, Train_loss: 0.4019 / Val_loss: 1.2587\n",
      "Epoch: 1842, Train_loss: 0.4213 / Val_loss: 1.2414\n",
      "Epoch: 1843, Train_loss: 0.4337 / Val_loss: 1.1822\n",
      "Epoch: 1844, Train_loss: 0.4174 / Val_loss: 1.0911\n",
      "Epoch: 1845, Train_loss: 0.4319 / Val_loss: 1.3981\n",
      "Epoch: 1846, Train_loss: 0.4192 / Val_loss: 1.4774\n",
      "Epoch: 1847, Train_loss: 0.4337 / Val_loss: 1.6342\n",
      "Epoch: 1848, Train_loss: 0.4197 / Val_loss: 1.4257\n",
      "Epoch: 1849, Train_loss: 0.4538 / Val_loss: 1.4528\n",
      "Epoch: 1850, Train_loss: 0.4159 / Val_loss: 1.0248\n",
      "Epoch: 1851, Train_loss: 0.4362 / Val_loss: 1.2940\n",
      "Epoch: 1852, Train_loss: 0.4478 / Val_loss: 1.2553\n",
      "Epoch: 1853, Train_loss: 0.4322 / Val_loss: 1.3913\n",
      "Epoch: 1854, Train_loss: 0.4665 / Val_loss: 1.4676\n",
      "Epoch: 1855, Train_loss: 0.4322 / Val_loss: 1.3053\n",
      "Epoch: 1856, Train_loss: 0.4336 / Val_loss: 1.5064\n",
      "Epoch: 1857, Train_loss: 0.4259 / Val_loss: 1.1896\n",
      "Epoch: 1858, Train_loss: 0.4278 / Val_loss: 1.1906\n",
      "Epoch: 1859, Train_loss: 0.4087 / Val_loss: 1.4154\n",
      "Epoch: 1860, Train_loss: 0.4645 / Val_loss: 1.8870\n",
      "Epoch: 1861, Train_loss: 0.4287 / Val_loss: 1.4325\n",
      "Epoch: 1862, Train_loss: 0.4399 / Val_loss: 1.1472\n",
      "Epoch: 1863, Train_loss: 0.4404 / Val_loss: 1.2384\n",
      "Epoch: 1864, Train_loss: 0.4190 / Val_loss: 1.4265\n",
      "Epoch: 1865, Train_loss: 0.4795 / Val_loss: 1.2999\n",
      "Epoch: 1866, Train_loss: 0.4279 / Val_loss: 1.4165\n",
      "Epoch: 1867, Train_loss: 0.4425 / Val_loss: 1.3668\n",
      "Epoch: 1868, Train_loss: 0.4437 / Val_loss: 1.3874\n",
      "Epoch: 1869, Train_loss: 0.4350 / Val_loss: 1.2965\n",
      "Epoch: 1870, Train_loss: 0.4213 / Val_loss: 1.3965\n",
      "Epoch: 1871, Train_loss: 0.4173 / Val_loss: 1.3588\n",
      "Epoch: 1872, Train_loss: 0.4195 / Val_loss: 1.4842\n",
      "Epoch: 1873, Train_loss: 0.4197 / Val_loss: 1.3997\n",
      "Epoch: 1874, Train_loss: 0.4400 / Val_loss: 1.0640\n",
      "Epoch: 1875, Train_loss: 0.4295 / Val_loss: 1.2953\n",
      "Epoch: 1876, Train_loss: 0.4625 / Val_loss: 1.2524\n",
      "Epoch: 1877, Train_loss: 0.4309 / Val_loss: 1.2862\n",
      "Epoch: 1878, Train_loss: 0.4808 / Val_loss: 1.3907\n",
      "Epoch: 1879, Train_loss: 0.4464 / Val_loss: 1.3277\n",
      "Epoch: 1880, Train_loss: 0.4277 / Val_loss: 1.4470\n",
      "Epoch: 1881, Train_loss: 0.4196 / Val_loss: 1.3413\n",
      "Epoch: 1882, Train_loss: 0.4216 / Val_loss: 1.3419\n",
      "Epoch: 1883, Train_loss: 0.4443 / Val_loss: 1.4804\n",
      "Epoch: 1884, Train_loss: 0.4307 / Val_loss: 1.5531\n",
      "Epoch: 1885, Train_loss: 0.4172 / Val_loss: 1.5495\n",
      "Epoch: 1886, Train_loss: 0.4543 / Val_loss: 1.1775\n",
      "Epoch: 1887, Train_loss: 0.4524 / Val_loss: 1.3155\n",
      "Epoch: 1888, Train_loss: 0.4206 / Val_loss: 1.3062\n",
      "Epoch: 1889, Train_loss: 0.4444 / Val_loss: 1.3583\n",
      "Epoch: 1890, Train_loss: 0.4292 / Val_loss: 1.2177\n",
      "Epoch: 1891, Train_loss: 0.4162 / Val_loss: 1.0351\n",
      "Epoch: 1892, Train_loss: 0.4634 / Val_loss: 1.4012\n",
      "Epoch: 1893, Train_loss: 0.4079 / Val_loss: 1.2041\n",
      "Epoch: 1894, Train_loss: 0.4205 / Val_loss: 1.0832\n",
      "Epoch: 1895, Train_loss: 0.4059 / Val_loss: 1.3052\n",
      "Epoch: 1896, Train_loss: 0.4111 / Val_loss: 1.2895\n",
      "Epoch: 1897, Train_loss: 0.4406 / Val_loss: 1.3814\n",
      "Epoch: 1898, Train_loss: 0.4440 / Val_loss: 1.0848\n",
      "Epoch: 1899, Train_loss: 0.4109 / Val_loss: 1.2135\n",
      "Epoch: 1900, Train_loss: 0.4123 / Val_loss: 1.4895\n",
      "Epoch: 1901, Train_loss: 0.4309 / Val_loss: 1.1942\n",
      "Epoch: 1902, Train_loss: 0.4450 / Val_loss: 1.3804\n",
      "Epoch: 1903, Train_loss: 0.4302 / Val_loss: 1.3907\n",
      "Epoch: 1904, Train_loss: 0.4375 / Val_loss: 1.4686\n",
      "Epoch: 1905, Train_loss: 0.4408 / Val_loss: 1.8046\n",
      "Epoch: 1906, Train_loss: 0.4158 / Val_loss: 1.3121\n",
      "Epoch: 1907, Train_loss: 0.4230 / Val_loss: 1.5167\n",
      "Epoch: 1908, Train_loss: 0.4733 / Val_loss: 1.3032\n",
      "Epoch: 1909, Train_loss: 0.4239 / Val_loss: 1.2835\n",
      "Epoch: 1910, Train_loss: 0.3993 / Val_loss: 1.5827\n",
      "Epoch: 1911, Train_loss: 0.4186 / Val_loss: 1.7177\n",
      "Epoch: 1912, Train_loss: 0.4503 / Val_loss: 1.2475\n",
      "Epoch: 1913, Train_loss: 0.4169 / Val_loss: 1.3649\n",
      "Epoch: 1914, Train_loss: 0.3971 / Val_loss: 1.4520\n",
      "Epoch: 1915, Train_loss: 0.4178 / Val_loss: 1.5760\n",
      "Epoch: 1916, Train_loss: 0.4277 / Val_loss: 1.5159\n",
      "Epoch: 1917, Train_loss: 0.4184 / Val_loss: 1.1602\n",
      "Epoch: 1918, Train_loss: 0.4155 / Val_loss: 1.7672\n",
      "Epoch: 1919, Train_loss: 0.4293 / Val_loss: 1.3112\n",
      "Epoch: 1920, Train_loss: 0.4059 / Val_loss: 1.5254\n",
      "Epoch: 1921, Train_loss: 0.4443 / Val_loss: 1.4166\n",
      "Epoch: 1922, Train_loss: 0.4134 / Val_loss: 1.6957\n",
      "Epoch: 1923, Train_loss: 0.4321 / Val_loss: 1.3458\n",
      "Epoch: 1924, Train_loss: 0.4126 / Val_loss: 1.3585\n",
      "Epoch: 1925, Train_loss: 0.4308 / Val_loss: 1.6993\n",
      "Epoch: 1926, Train_loss: 0.4226 / Val_loss: 1.3614\n",
      "Epoch: 1927, Train_loss: 0.4365 / Val_loss: 1.4061\n",
      "Epoch: 1928, Train_loss: 0.4004 / Val_loss: 1.1907\n",
      "Epoch: 1929, Train_loss: 0.4355 / Val_loss: 1.2127\n",
      "Epoch: 1930, Train_loss: 0.4289 / Val_loss: 1.2652\n",
      "Epoch: 1931, Train_loss: 0.4304 / Val_loss: 1.4473\n",
      "Epoch: 1932, Train_loss: 0.4089 / Val_loss: 1.6142\n",
      "Epoch: 1933, Train_loss: 0.4714 / Val_loss: 1.4698\n",
      "Epoch: 1934, Train_loss: 0.4275 / Val_loss: 1.3822\n",
      "Epoch: 1935, Train_loss: 0.4349 / Val_loss: 1.5272\n",
      "Epoch: 1936, Train_loss: 0.4471 / Val_loss: 1.4329\n",
      "Epoch: 1937, Train_loss: 0.4172 / Val_loss: 1.4409\n",
      "Epoch: 1938, Train_loss: 0.4178 / Val_loss: 1.4924\n",
      "Epoch: 1939, Train_loss: 0.4302 / Val_loss: 1.5012\n",
      "Epoch: 1940, Train_loss: 0.3998 / Val_loss: 1.2300\n",
      "Epoch: 1941, Train_loss: 0.4309 / Val_loss: 1.6011\n",
      "Epoch: 1942, Train_loss: 0.4094 / Val_loss: 1.4317\n",
      "Epoch: 1943, Train_loss: 0.4157 / Val_loss: 1.2244\n",
      "Epoch: 1944, Train_loss: 0.4209 / Val_loss: 1.2030\n",
      "Epoch: 1945, Train_loss: 0.4357 / Val_loss: 1.4885\n",
      "Epoch: 1946, Train_loss: 0.3969 / Val_loss: 1.1546\n",
      "Epoch: 1947, Train_loss: 0.4140 / Val_loss: 1.2421\n",
      "Epoch: 1948, Train_loss: 0.4199 / Val_loss: 1.4273\n",
      "Epoch: 1949, Train_loss: 0.4443 / Val_loss: 1.0917\n",
      "Epoch: 1950, Train_loss: 0.4119 / Val_loss: 1.3823\n",
      "Epoch: 1951, Train_loss: 0.4106 / Val_loss: 1.3492\n",
      "Epoch: 1952, Train_loss: 0.4058 / Val_loss: 1.2941\n",
      "Epoch: 1953, Train_loss: 0.4211 / Val_loss: 1.3125\n",
      "Epoch: 1954, Train_loss: 0.4229 / Val_loss: 1.4568\n",
      "Epoch: 1955, Train_loss: 0.4404 / Val_loss: 1.2420\n",
      "Epoch: 1956, Train_loss: 0.4298 / Val_loss: 1.4350\n",
      "Epoch: 1957, Train_loss: 0.4327 / Val_loss: 1.5504\n",
      "Epoch: 1958, Train_loss: 0.4367 / Val_loss: 1.6302\n",
      "Epoch: 1959, Train_loss: 0.4103 / Val_loss: 1.6814\n",
      "Epoch: 1960, Train_loss: 0.4303 / Val_loss: 1.4177\n",
      "Epoch: 1961, Train_loss: 0.4377 / Val_loss: 1.1844\n",
      "Epoch: 1962, Train_loss: 0.4248 / Val_loss: 1.5279\n",
      "Epoch: 1963, Train_loss: 0.4121 / Val_loss: 1.6283\n",
      "Epoch: 1964, Train_loss: 0.4040 / Val_loss: 1.5445\n",
      "Epoch: 1965, Train_loss: 0.4170 / Val_loss: 1.4948\n",
      "Epoch: 1966, Train_loss: 0.4544 / Val_loss: 1.3055\n",
      "Epoch: 1967, Train_loss: 0.4199 / Val_loss: 1.2096\n",
      "Epoch: 1968, Train_loss: 0.4231 / Val_loss: 1.3735\n",
      "Epoch: 1969, Train_loss: 0.4319 / Val_loss: 1.3344\n",
      "Epoch: 1970, Train_loss: 0.4279 / Val_loss: 1.4696\n",
      "Epoch: 1971, Train_loss: 0.3973 / Val_loss: 1.4102\n",
      "Epoch: 1972, Train_loss: 0.4120 / Val_loss: 1.2808\n",
      "Epoch: 1973, Train_loss: 0.4378 / Val_loss: 1.4912\n",
      "Epoch: 1974, Train_loss: 0.4197 / Val_loss: 1.7037\n",
      "Epoch: 1975, Train_loss: 0.3908 / Val_loss: 1.6128\n",
      "Epoch: 1976, Train_loss: 0.4428 / Val_loss: 1.2425\n",
      "Epoch: 1977, Train_loss: 0.3974 / Val_loss: 1.3955\n",
      "Epoch: 1978, Train_loss: 0.4256 / Val_loss: 1.2901\n",
      "Epoch: 1979, Train_loss: 0.4455 / Val_loss: 1.2147\n",
      "Epoch: 1980, Train_loss: 0.4253 / Val_loss: 1.5367\n",
      "Epoch: 1981, Train_loss: 0.4129 / Val_loss: 1.5447\n",
      "Epoch: 1982, Train_loss: 0.4241 / Val_loss: 1.7127\n",
      "Epoch: 1983, Train_loss: 0.4024 / Val_loss: 1.6676\n",
      "Epoch: 1984, Train_loss: 0.4237 / Val_loss: 1.2927\n",
      "Epoch: 1985, Train_loss: 0.4459 / Val_loss: 1.2745\n",
      "Epoch: 1986, Train_loss: 0.4190 / Val_loss: 1.4634\n",
      "Epoch: 1987, Train_loss: 0.4143 / Val_loss: 1.7035\n",
      "Epoch: 1988, Train_loss: 0.4102 / Val_loss: 1.4440\n",
      "Epoch: 1989, Train_loss: 0.4219 / Val_loss: 1.8114\n",
      "Epoch: 1990, Train_loss: 0.4381 / Val_loss: 1.5524\n",
      "Epoch: 1991, Train_loss: 0.3955 / Val_loss: 1.3933\n",
      "Epoch: 1992, Train_loss: 0.4012 / Val_loss: 1.6388\n",
      "Epoch: 1993, Train_loss: 0.4202 / Val_loss: 1.4687\n",
      "Epoch: 1994, Train_loss: 0.4074 / Val_loss: 1.5716\n",
      "Epoch: 1995, Train_loss: 0.4081 / Val_loss: 1.0947\n",
      "Epoch: 1996, Train_loss: 0.4251 / Val_loss: 1.4846\n",
      "Epoch: 1997, Train_loss: 0.4202 / Val_loss: 1.4157\n",
      "Epoch: 1998, Train_loss: 0.4410 / Val_loss: 1.7348\n",
      "Epoch: 1999, Train_loss: 0.4019 / Val_loss: 1.3312\n",
      "Epoch: 2000, Train_loss: 0.4494 / Val_loss: 1.2976\n"
     ]
    }
   ],
   "source": [
    "weight = torch.Tensor([1.0, 2.5])\n",
    "log_softmax = torch.nn.LogSoftmax(dim=1)\n",
    "criterion = torch.nn.NLLLoss(weight=weight)  # Define loss criterion.\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)  # Define optimizer.\n",
    "\n",
    "losses = []\n",
    "v_losses = []\n",
    "best_v_loss = 100000\n",
    "COUNT = 2000\n",
    "val_early_stop_count = COUNT\n",
    "val_early_stop_continuous_flag = False\n",
    "\n",
    "for epoch in range(1, 2001):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    outs = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "    preds = outs[data.train_mask].squeeze()\n",
    "    loss = criterion(log_softmax(preds), data.y[data.train_mask].to(dtype=torch.long))  # Compute the loss solely based on the training nodes.\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        v_preds = outs[data.val_mask].squeeze()\n",
    "        v_loss = criterion(log_softmax(v_preds), data.y[data.val_mask].to(dtype=torch.long))\n",
    "        v_losses.append(v_loss.item())\n",
    "    print(f'Epoch: {epoch:03d}, Train_loss: {loss:.4f} / Val_loss: {v_loss:.4f}')\n",
    "    \n",
    "    if v_loss.item() < best_v_loss:\n",
    "        best_v_loss = v_loss.item()\n",
    "        val_early_stop_continuous_flag = False\n",
    "        val_early_stop_count = COUNT\n",
    "    else:\n",
    "        val_early_stop_continuous_flag = True\n",
    "        val_early_stop_count -= 1\n",
    "        if val_early_stop_count == 0:\n",
    "            print(f\"============== Early stopped at Epoch: {epoch}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.plot(v_losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Train\", \"Val\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "out = model(data.x, data.edge_index)\n",
    "pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "y_pred = pred[data.test_mask].numpy()\n",
    "y_true = data.y[data.test_mask].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5238\n",
      "Precision: 0.2250\n",
      "Recall: 0.5000\n",
      "f1 score: 0.3103\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true, y_pred, normalize=None)\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    ")\n",
    "\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred):.4f}\")\n",
    "print(f\"f1 score: {f1_score(y_true, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 외곽선에 걸친 샘플 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "BORDER_COL = 'M.P. border boundary length'\n",
    "df_inside = df[df[BORDER_COL] == 0]\n",
    "df_inside = df_inside.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_included = df_inside[\"merged ID\"].tolist()\n",
    "\n",
    "edges_2 = []\n",
    "edge_info_2 = df_inside[EDGE_COL].map(lambda x: list(map(int, x.split(\",\"))))\n",
    "for i, e_list in enumerate(edge_info_2):\n",
    "    for e in e_list:\n",
    "        if e in indices_included:\n",
    "            idx = df_inside.index[df_inside[\"merged ID\"] == e].tolist()[0]\n",
    "            new = [i, idx]\n",
    "            edges_2.append(new)\n",
    "        \n",
    "edge_index_2 = torch.Tensor(edges_2).to(dtype=torch.long).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   1,  ..., 480, 480, 480],\n",
       "        [  1, 389,   0,  ..., 380, 475, 477]])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(edge_index_2.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(d.apply(lambda x: set(x), axis=1).value_counts() != 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (~df_inside[\"Percent of grain that twinned\"].isna()).map(int).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_indices) = 336\n",
      "len(val_indices) = 72\n",
      "len(test_indices) = 73\n",
      "split done!\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1105)\n",
    "\n",
    "train_ratio = 0.7\n",
    "\n",
    "pos_indices = np.where(y == 1)[0]\n",
    "pos_indices_train, pos_indices_others = train_test_split(\n",
    "    pos_indices,\n",
    "    train_size=train_ratio\n",
    ")\n",
    "pos_indices_val, pos_indices_test = train_test_split(\n",
    "    pos_indices_others,\n",
    "    train_size=0.5\n",
    ")\n",
    "assert len(pos_indices) == len(pos_indices_train) + len(pos_indices_val) + len(pos_indices_test)\n",
    "assert set(pos_indices.tolist()) == set(pos_indices_train.tolist()) | set(pos_indices_val.tolist()) | set(pos_indices_test.tolist())\n",
    "assert len(set(pos_indices_train.tolist()).intersection(set(pos_indices_val.tolist())).intersection(set(pos_indices_test.tolist()))) == 0\n",
    "\n",
    "neg_indices = np.where(y == 0)[0]\n",
    "neg_indices_train, neg_indices_others = train_test_split(\n",
    "    neg_indices,\n",
    "    train_size=train_ratio\n",
    ")\n",
    "neg_indices_val, neg_indices_test = train_test_split(\n",
    "    neg_indices_others,\n",
    "    train_size=0.5\n",
    ")\n",
    "assert len(neg_indices) == len(neg_indices_train) + len(neg_indices_val) + len(neg_indices_test)\n",
    "assert set(neg_indices.tolist()) == set(neg_indices_train.tolist()) | set(neg_indices_val.tolist()) | set(neg_indices_test.tolist())\n",
    "assert len(set(neg_indices_train.tolist()).intersection(set(neg_indices_val.tolist())).intersection(set(neg_indices_test.tolist()))) == 0\n",
    "\n",
    "train_indices = pos_indices_train.tolist() + neg_indices_train.tolist()\n",
    "val_indices = pos_indices_val.tolist() + neg_indices_val.tolist()\n",
    "test_indices = pos_indices_test.tolist() + neg_indices_test.tolist()\n",
    "\n",
    "print(f\"{len(train_indices) = }\")\n",
    "print(f\"{len(val_indices) = }\")\n",
    "print(f\"{len(test_indices) = }\")\n",
    "\n",
    "print(\"split done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_train_mask = np.zeros_like(y)\n",
    "for i in train_indices:\n",
    "    tmp_train_mask[i-1] = 1\n",
    "train_mask = torch.Tensor(tmp_train_mask).to(dtype=bool)\n",
    "\n",
    "tmp_val_mask = np.zeros_like(y)\n",
    "for i in val_indices:\n",
    "    tmp_val_mask[i-1] = 1\n",
    "val_mask = torch.Tensor(tmp_val_mask).to(dtype=bool)\n",
    "\n",
    "tmp_test_mask = np.zeros_like(y)\n",
    "for i in test_indices:\n",
    "    tmp_test_mask[i-1] = 1\n",
    "test_mask = torch.Tensor(tmp_test_mask).to(dtype=bool)\n",
    "\n",
    "assert (train_mask.to(dtype=torch.int16) + val_mask.to(dtype=torch.int16) + test_mask.to(dtype=torch.int16) == 1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (336, 26) / (72, 26) / (73, 26)\n",
      "y_train.shape = (336,) / (72,) / (73,)\n"
     ]
    }
   ],
   "source": [
    "X_train = df_inside.loc[train_mask.numpy(), FEATURE_COLS]\n",
    "X_val = df_inside.loc[val_mask.numpy(), FEATURE_COLS]\n",
    "X_test = df_inside.loc[test_mask.numpy(), FEATURE_COLS]\n",
    "y_train = y[train_mask.numpy()]\n",
    "y_val = y[val_mask.numpy()]\n",
    "y_test = y[test_mask.numpy()]\n",
    "\n",
    "print(f\"{X_train.shape = } / {X_val.shape} / {X_test.shape}\")\n",
    "print(f\"{y_train.shape = } / {y_val.shape} / {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_norm = scaler.transform(X_train)\n",
    "X_val_norm = scaler.transform(X_val)\n",
    "X_test_norm = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros_like(df_inside[FEATURE_COLS])\n",
    "X[train_mask.numpy(), :] = X_train_norm\n",
    "X[val_mask.numpy(), :] = X_val_norm\n",
    "X[test_mask.numpy(), :] = X_test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(\n",
    "    x=torch.Tensor(X),\n",
    "    y=torch.Tensor(y),\n",
    "    edge_index=edge_index_2,\n",
    "    train_mask=train_mask,\n",
    "    val_mask=val_mask,\n",
    "    test_mask=test_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[481, 26], edge_index=[2, 2420], y=[481], train_mask=[481], val_mask=[481], test_mask=[481])"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merged parent area</th>\n",
       "      <th>M.P. major axis</th>\n",
       "      <th>M.P. aspect ratio</th>\n",
       "      <th>GOS</th>\n",
       "      <th>Schmid for Var1</th>\n",
       "      <th>Schmid for Var2</th>\n",
       "      <th>Schmid for Var3</th>\n",
       "      <th>Schmid for Var4</th>\n",
       "      <th>Schmid for Var5</th>\n",
       "      <th>Schmid for Var6</th>\n",
       "      <th>...</th>\n",
       "      <th>Schmid SF3</th>\n",
       "      <th>Schmid SF4</th>\n",
       "      <th>Schmid SF5</th>\n",
       "      <th>Schmid SF6</th>\n",
       "      <th>Taylor TF1</th>\n",
       "      <th>Taylor TF2</th>\n",
       "      <th>Taylor TF3</th>\n",
       "      <th>Taylor TF4</th>\n",
       "      <th>Taylor TF5</th>\n",
       "      <th>Taylor TF6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>481.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>481.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.051675</td>\n",
       "      <td>0.056287</td>\n",
       "      <td>0.014602</td>\n",
       "      <td>0.065761</td>\n",
       "      <td>-0.068053</td>\n",
       "      <td>-0.068871</td>\n",
       "      <td>-0.038275</td>\n",
       "      <td>-0.039614</td>\n",
       "      <td>-0.063793</td>\n",
       "      <td>-0.060608</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005043</td>\n",
       "      <td>-0.018380</td>\n",
       "      <td>-0.029685</td>\n",
       "      <td>0.020217</td>\n",
       "      <td>0.034459</td>\n",
       "      <td>-0.026234</td>\n",
       "      <td>-0.012887</td>\n",
       "      <td>-0.000475</td>\n",
       "      <td>-0.027544</td>\n",
       "      <td>-0.000475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.160957</td>\n",
       "      <td>1.096437</td>\n",
       "      <td>1.042331</td>\n",
       "      <td>1.071293</td>\n",
       "      <td>0.984204</td>\n",
       "      <td>0.981220</td>\n",
       "      <td>0.960567</td>\n",
       "      <td>0.960851</td>\n",
       "      <td>0.977547</td>\n",
       "      <td>0.976719</td>\n",
       "      <td>...</td>\n",
       "      <td>1.001958</td>\n",
       "      <td>1.000100</td>\n",
       "      <td>1.027037</td>\n",
       "      <td>0.995778</td>\n",
       "      <td>1.013476</td>\n",
       "      <td>0.969551</td>\n",
       "      <td>1.003859</td>\n",
       "      <td>1.019893</td>\n",
       "      <td>0.994575</td>\n",
       "      <td>1.019893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.444032</td>\n",
       "      <td>-0.930698</td>\n",
       "      <td>-0.756616</td>\n",
       "      <td>-0.674776</td>\n",
       "      <td>-1.856827</td>\n",
       "      <td>-1.847090</td>\n",
       "      <td>-1.537449</td>\n",
       "      <td>-1.544332</td>\n",
       "      <td>-2.149953</td>\n",
       "      <td>-2.229914</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.423593</td>\n",
       "      <td>-1.972551</td>\n",
       "      <td>-2.686199</td>\n",
       "      <td>-2.645639</td>\n",
       "      <td>-1.280158</td>\n",
       "      <td>-1.502252</td>\n",
       "      <td>-1.810494</td>\n",
       "      <td>-3.974721</td>\n",
       "      <td>-1.942829</td>\n",
       "      <td>-3.974721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.389650</td>\n",
       "      <td>-0.604446</td>\n",
       "      <td>-0.429439</td>\n",
       "      <td>-0.500579</td>\n",
       "      <td>-0.862927</td>\n",
       "      <td>-0.856619</td>\n",
       "      <td>-0.887019</td>\n",
       "      <td>-0.891115</td>\n",
       "      <td>-0.677592</td>\n",
       "      <td>-0.648619</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.769632</td>\n",
       "      <td>-0.889969</td>\n",
       "      <td>-0.771405</td>\n",
       "      <td>-0.765064</td>\n",
       "      <td>-0.567027</td>\n",
       "      <td>-0.800843</td>\n",
       "      <td>-0.885758</td>\n",
       "      <td>-0.525523</td>\n",
       "      <td>-0.869314</td>\n",
       "      <td>-0.525523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.270690</td>\n",
       "      <td>-0.231602</td>\n",
       "      <td>-0.221137</td>\n",
       "      <td>-0.405004</td>\n",
       "      <td>-0.012317</td>\n",
       "      <td>0.021075</td>\n",
       "      <td>-0.058941</td>\n",
       "      <td>-0.064036</td>\n",
       "      <td>-0.015855</td>\n",
       "      <td>-0.024202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179622</td>\n",
       "      <td>0.112454</td>\n",
       "      <td>0.228769</td>\n",
       "      <td>0.118833</td>\n",
       "      <td>-0.433828</td>\n",
       "      <td>-0.237781</td>\n",
       "      <td>-0.323943</td>\n",
       "      <td>-0.009961</td>\n",
       "      <td>-0.306065</td>\n",
       "      <td>-0.009961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.002180</td>\n",
       "      <td>0.351596</td>\n",
       "      <td>0.124486</td>\n",
       "      <td>-0.093494</td>\n",
       "      <td>0.652407</td>\n",
       "      <td>0.662274</td>\n",
       "      <td>0.643735</td>\n",
       "      <td>0.639252</td>\n",
       "      <td>0.395085</td>\n",
       "      <td>0.404812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.874513</td>\n",
       "      <td>0.803447</td>\n",
       "      <td>0.853427</td>\n",
       "      <td>0.959748</td>\n",
       "      <td>0.364962</td>\n",
       "      <td>0.711490</td>\n",
       "      <td>0.892147</td>\n",
       "      <td>0.741166</td>\n",
       "      <td>0.858450</td>\n",
       "      <td>0.741166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.965936</td>\n",
       "      <td>10.731805</td>\n",
       "      <td>10.893488</td>\n",
       "      <td>6.321528</td>\n",
       "      <td>2.034974</td>\n",
       "      <td>1.993670</td>\n",
       "      <td>2.161261</td>\n",
       "      <td>2.134987</td>\n",
       "      <td>2.393950</td>\n",
       "      <td>2.453829</td>\n",
       "      <td>...</td>\n",
       "      <td>1.266005</td>\n",
       "      <td>1.578006</td>\n",
       "      <td>1.227104</td>\n",
       "      <td>1.333607</td>\n",
       "      <td>4.065437</td>\n",
       "      <td>2.780073</td>\n",
       "      <td>2.129937</td>\n",
       "      <td>1.667139</td>\n",
       "      <td>2.071183</td>\n",
       "      <td>1.667139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       merged parent area  M.P. major axis  M.P. aspect ratio         GOS  \\\n",
       "count          481.000000       481.000000         481.000000  481.000000   \n",
       "mean             0.051675         0.056287           0.014602    0.065761   \n",
       "std              1.160957         1.096437           1.042331    1.071293   \n",
       "min             -0.444032        -0.930698          -0.756616   -0.674776   \n",
       "25%             -0.389650        -0.604446          -0.429439   -0.500579   \n",
       "50%             -0.270690        -0.231602          -0.221137   -0.405004   \n",
       "75%             -0.002180         0.351596           0.124486   -0.093494   \n",
       "max             10.965936        10.731805          10.893488    6.321528   \n",
       "\n",
       "       Schmid for Var1  Schmid for Var2  Schmid for Var3  Schmid for Var4  \\\n",
       "count       481.000000       481.000000       481.000000       481.000000   \n",
       "mean         -0.068053        -0.068871        -0.038275        -0.039614   \n",
       "std           0.984204         0.981220         0.960567         0.960851   \n",
       "min          -1.856827        -1.847090        -1.537449        -1.544332   \n",
       "25%          -0.862927        -0.856619        -0.887019        -0.891115   \n",
       "50%          -0.012317         0.021075        -0.058941        -0.064036   \n",
       "75%           0.652407         0.662274         0.643735         0.639252   \n",
       "max           2.034974         1.993670         2.161261         2.134987   \n",
       "\n",
       "       Schmid for Var5  Schmid for Var6  ...  Schmid SF3  Schmid SF4  \\\n",
       "count       481.000000       481.000000  ...  481.000000  481.000000   \n",
       "mean         -0.063793        -0.060608  ...   -0.005043   -0.018380   \n",
       "std           0.977547         0.976719  ...    1.001958    1.000100   \n",
       "min          -2.149953        -2.229914  ...   -2.423593   -1.972551   \n",
       "25%          -0.677592        -0.648619  ...   -0.769632   -0.889969   \n",
       "50%          -0.015855        -0.024202  ...    0.179622    0.112454   \n",
       "75%           0.395085         0.404812  ...    0.874513    0.803447   \n",
       "max           2.393950         2.453829  ...    1.266005    1.578006   \n",
       "\n",
       "       Schmid SF5  Schmid SF6  Taylor TF1  Taylor TF2  Taylor TF3  Taylor TF4  \\\n",
       "count  481.000000  481.000000  481.000000  481.000000  481.000000  481.000000   \n",
       "mean    -0.029685    0.020217    0.034459   -0.026234   -0.012887   -0.000475   \n",
       "std      1.027037    0.995778    1.013476    0.969551    1.003859    1.019893   \n",
       "min     -2.686199   -2.645639   -1.280158   -1.502252   -1.810494   -3.974721   \n",
       "25%     -0.771405   -0.765064   -0.567027   -0.800843   -0.885758   -0.525523   \n",
       "50%      0.228769    0.118833   -0.433828   -0.237781   -0.323943   -0.009961   \n",
       "75%      0.853427    0.959748    0.364962    0.711490    0.892147    0.741166   \n",
       "max      1.227104    1.333607    4.065437    2.780073    2.129937    1.667139   \n",
       "\n",
       "       Taylor TF5  Taylor TF6  \n",
       "count  481.000000  481.000000  \n",
       "mean    -0.027544   -0.000475  \n",
       "std      0.994575    1.019893  \n",
       "min     -1.942829   -3.974721  \n",
       "25%     -0.869314   -0.525523  \n",
       "50%     -0.306065   -0.009961  \n",
       "75%      0.858450    0.741166  \n",
       "max      2.071183    1.667139  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X, columns=FEATURE_COLS).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\msi\\Desktop\\workspace\\042_materials_GNN\\01_src\\gnn_node_classification\\.venv_gnn\\lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=5,\n",
    "    max_depth=50,\n",
    "    random_state=1105\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train_norm, y[train_mask])\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_true = y[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2603\n",
      "Precision: 0.1695\n",
      "Recall: 0.6667\n",
      "f1 score: 0.2703\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true, y_pred, normalize=None)\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    ")\n",
    "\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred):.4f}\")\n",
    "print(f\"f1 score: {f1_score(y_true, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\msi\\Desktop\\workspace\\042_materials_GNN\\01_src\\gnn_node_classification\\.venv_gnn\\lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(\n",
    "    random_state=1105\n",
    ")\n",
    "\n",
    "lr_model.fit(X_train_norm, y[train_mask])\n",
    "y_pred = lr_model.predict(X_test)\n",
    "y_true = y[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5342\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "f1 score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true, y_pred, normalize=None)\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    ")\n",
    "\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred):.4f}\")\n",
    "print(f\"f1 score: {f1_score(y_true, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\msi\\Desktop\\workspace\\042_materials_GNN\\01_src\\gnn_node_classification\\.venv_gnn\\lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but LinearSVC was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "class_weight = {\n",
    "    0: 1.0,\n",
    "    1: 4.0\n",
    "}\n",
    "svc_model = LinearSVC(\n",
    "    class_weight=class_weight,\n",
    "    random_state=1105\n",
    ")\n",
    "\n",
    "svc_model.fit(X_train_norm, y[train_mask])\n",
    "y_pred = svc_model.predict(X_test)\n",
    "y_true = y[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5616\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "f1 score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true, y_pred, normalize=None)\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    ")\n",
    "\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred):.4f}\")\n",
    "print(f\"f1 score: {f1_score(y_true, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(params):\n",
    "    num = sum(p.numel() for p in params if p.requires_grad)\n",
    "    print(f\"{num:,}\")\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339,138\n",
      "MLP model number of params: 339,138\n"
     ]
    }
   ],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.lin1 = Linear(data.num_features, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, hidden_channels * 2)\n",
    "        self.lin3 = Linear(hidden_channels * 2, hidden_channels * 4)\n",
    "        self.lin4 = Linear(hidden_channels * 4, hidden_channels * 8)\n",
    "        self.lin5 = Linear(hidden_channels * 8, hidden_channels * 4)\n",
    "        self.lin6 = Linear(hidden_channels * 4, hidden_channels * 2)\n",
    "        self.lin7 = Linear(hidden_channels * 2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin3(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin4(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin5(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin6(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin7(x)\n",
    "        return x\n",
    "    \n",
    "model = MLP(hidden_channels=64)\n",
    "print(f\"MLP model number of params: {count_parameters(model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train_loss: 0.6851 / Val_loss: 0.6853\n",
      "Epoch: 002, Train_loss: 0.6845 / Val_loss: 0.6836\n",
      "Epoch: 003, Train_loss: 0.6813 / Val_loss: 0.6820\n",
      "Epoch: 004, Train_loss: 0.6795 / Val_loss: 0.6803\n",
      "Epoch: 005, Train_loss: 0.6778 / Val_loss: 0.6786\n",
      "Epoch: 006, Train_loss: 0.6759 / Val_loss: 0.6768\n",
      "Epoch: 007, Train_loss: 0.6724 / Val_loss: 0.6749\n",
      "Epoch: 008, Train_loss: 0.6676 / Val_loss: 0.6729\n",
      "Epoch: 009, Train_loss: 0.6672 / Val_loss: 0.6707\n",
      "Epoch: 010, Train_loss: 0.6621 / Val_loss: 0.6684\n",
      "Epoch: 011, Train_loss: 0.6647 / Val_loss: 0.6661\n",
      "Epoch: 012, Train_loss: 0.6593 / Val_loss: 0.6637\n",
      "Epoch: 013, Train_loss: 0.6578 / Val_loss: 0.6612\n",
      "Epoch: 014, Train_loss: 0.6599 / Val_loss: 0.6589\n",
      "Epoch: 015, Train_loss: 0.6648 / Val_loss: 0.6568\n",
      "Epoch: 016, Train_loss: 0.6550 / Val_loss: 0.6548\n",
      "Epoch: 017, Train_loss: 0.6499 / Val_loss: 0.6529\n",
      "Epoch: 018, Train_loss: 0.6512 / Val_loss: 0.6511\n",
      "Epoch: 019, Train_loss: 0.6548 / Val_loss: 0.6494\n",
      "Epoch: 020, Train_loss: 0.6594 / Val_loss: 0.6481\n",
      "Epoch: 021, Train_loss: 0.6580 / Val_loss: 0.6470\n",
      "Epoch: 022, Train_loss: 0.6481 / Val_loss: 0.6459\n",
      "Epoch: 023, Train_loss: 0.6543 / Val_loss: 0.6448\n",
      "Epoch: 024, Train_loss: 0.6510 / Val_loss: 0.6439\n",
      "Epoch: 025, Train_loss: 0.6431 / Val_loss: 0.6429\n",
      "Epoch: 026, Train_loss: 0.6369 / Val_loss: 0.6416\n",
      "Epoch: 027, Train_loss: 0.6348 / Val_loss: 0.6399\n",
      "Epoch: 028, Train_loss: 0.6415 / Val_loss: 0.6379\n",
      "Epoch: 029, Train_loss: 0.6477 / Val_loss: 0.6360\n",
      "Epoch: 030, Train_loss: 0.6406 / Val_loss: 0.6338\n",
      "Epoch: 031, Train_loss: 0.6471 / Val_loss: 0.6318\n",
      "Epoch: 032, Train_loss: 0.6350 / Val_loss: 0.6294\n",
      "Epoch: 033, Train_loss: 0.6303 / Val_loss: 0.6266\n",
      "Epoch: 034, Train_loss: 0.6391 / Val_loss: 0.6239\n",
      "Epoch: 035, Train_loss: 0.6439 / Val_loss: 0.6214\n",
      "Epoch: 036, Train_loss: 0.6321 / Val_loss: 0.6187\n",
      "Epoch: 037, Train_loss: 0.6343 / Val_loss: 0.6161\n",
      "Epoch: 038, Train_loss: 0.6250 / Val_loss: 0.6135\n",
      "Epoch: 039, Train_loss: 0.6299 / Val_loss: 0.6105\n",
      "Epoch: 040, Train_loss: 0.6153 / Val_loss: 0.6069\n",
      "Epoch: 041, Train_loss: 0.6345 / Val_loss: 0.6040\n",
      "Epoch: 042, Train_loss: 0.6227 / Val_loss: 0.6009\n",
      "Epoch: 043, Train_loss: 0.6247 / Val_loss: 0.5981\n",
      "Epoch: 044, Train_loss: 0.6319 / Val_loss: 0.5962\n",
      "Epoch: 045, Train_loss: 0.6159 / Val_loss: 0.5939\n",
      "Epoch: 046, Train_loss: 0.6251 / Val_loss: 0.5923\n",
      "Epoch: 047, Train_loss: 0.6077 / Val_loss: 0.5904\n",
      "Epoch: 048, Train_loss: 0.6165 / Val_loss: 0.5887\n",
      "Epoch: 049, Train_loss: 0.6133 / Val_loss: 0.5872\n",
      "Epoch: 050, Train_loss: 0.6094 / Val_loss: 0.5857\n",
      "Epoch: 051, Train_loss: 0.6206 / Val_loss: 0.5848\n",
      "Epoch: 052, Train_loss: 0.6192 / Val_loss: 0.5842\n",
      "Epoch: 053, Train_loss: 0.6149 / Val_loss: 0.5834\n",
      "Epoch: 054, Train_loss: 0.6056 / Val_loss: 0.5825\n",
      "Epoch: 055, Train_loss: 0.5952 / Val_loss: 0.5805\n",
      "Epoch: 056, Train_loss: 0.6180 / Val_loss: 0.5792\n",
      "Epoch: 057, Train_loss: 0.6060 / Val_loss: 0.5774\n",
      "Epoch: 058, Train_loss: 0.6003 / Val_loss: 0.5751\n",
      "Epoch: 059, Train_loss: 0.6125 / Val_loss: 0.5734\n",
      "Epoch: 060, Train_loss: 0.6154 / Val_loss: 0.5730\n",
      "Epoch: 061, Train_loss: 0.6087 / Val_loss: 0.5727\n",
      "Epoch: 062, Train_loss: 0.5828 / Val_loss: 0.5712\n",
      "Epoch: 063, Train_loss: 0.6023 / Val_loss: 0.5696\n",
      "Epoch: 064, Train_loss: 0.5901 / Val_loss: 0.5675\n",
      "Epoch: 065, Train_loss: 0.5819 / Val_loss: 0.5645\n",
      "Epoch: 066, Train_loss: 0.5870 / Val_loss: 0.5616\n",
      "Epoch: 067, Train_loss: 0.5804 / Val_loss: 0.5586\n",
      "Epoch: 068, Train_loss: 0.5899 / Val_loss: 0.5557\n",
      "Epoch: 069, Train_loss: 0.5663 / Val_loss: 0.5525\n",
      "Epoch: 070, Train_loss: 0.5633 / Val_loss: 0.5489\n",
      "Epoch: 071, Train_loss: 0.5881 / Val_loss: 0.5467\n",
      "Epoch: 072, Train_loss: 0.5993 / Val_loss: 0.5455\n",
      "Epoch: 073, Train_loss: 0.5848 / Val_loss: 0.5456\n",
      "Epoch: 074, Train_loss: 0.5737 / Val_loss: 0.5459\n",
      "Epoch: 075, Train_loss: 0.5770 / Val_loss: 0.5469\n",
      "Epoch: 076, Train_loss: 0.5928 / Val_loss: 0.5487\n",
      "Epoch: 077, Train_loss: 0.5603 / Val_loss: 0.5500\n",
      "Epoch: 078, Train_loss: 0.5647 / Val_loss: 0.5504\n",
      "Epoch: 079, Train_loss: 0.5617 / Val_loss: 0.5496\n",
      "Epoch: 080, Train_loss: 0.5743 / Val_loss: 0.5485\n",
      "Epoch: 081, Train_loss: 0.5486 / Val_loss: 0.5456\n",
      "Epoch: 082, Train_loss: 0.5462 / Val_loss: 0.5417\n",
      "Epoch: 083, Train_loss: 0.5748 / Val_loss: 0.5387\n",
      "Epoch: 084, Train_loss: 0.5495 / Val_loss: 0.5359\n",
      "Epoch: 085, Train_loss: 0.5401 / Val_loss: 0.5327\n",
      "Epoch: 086, Train_loss: 0.5709 / Val_loss: 0.5315\n",
      "Epoch: 087, Train_loss: 0.5560 / Val_loss: 0.5311\n",
      "Epoch: 088, Train_loss: 0.5923 / Val_loss: 0.5332\n",
      "Epoch: 089, Train_loss: 0.5711 / Val_loss: 0.5366\n",
      "Epoch: 090, Train_loss: 0.5318 / Val_loss: 0.5385\n",
      "Epoch: 091, Train_loss: 0.5541 / Val_loss: 0.5404\n",
      "Epoch: 092, Train_loss: 0.5625 / Val_loss: 0.5427\n",
      "Epoch: 093, Train_loss: 0.5265 / Val_loss: 0.5433\n",
      "Epoch: 094, Train_loss: 0.5401 / Val_loss: 0.5427\n",
      "Epoch: 095, Train_loss: 0.5220 / Val_loss: 0.5404\n",
      "Epoch: 096, Train_loss: 0.5236 / Val_loss: 0.5362\n",
      "Epoch: 097, Train_loss: 0.5106 / Val_loss: 0.5304\n",
      "Epoch: 098, Train_loss: 0.5261 / Val_loss: 0.5257\n",
      "Epoch: 099, Train_loss: 0.4991 / Val_loss: 0.5210\n",
      "Epoch: 100, Train_loss: 0.5366 / Val_loss: 0.5185\n",
      "Epoch: 101, Train_loss: 0.5539 / Val_loss: 0.5173\n",
      "Epoch: 102, Train_loss: 0.5157 / Val_loss: 0.5162\n",
      "Epoch: 103, Train_loss: 0.5010 / Val_loss: 0.5162\n",
      "Epoch: 104, Train_loss: 0.4847 / Val_loss: 0.5152\n",
      "Epoch: 105, Train_loss: 0.5255 / Val_loss: 0.5149\n",
      "Epoch: 106, Train_loss: 0.4860 / Val_loss: 0.5141\n",
      "Epoch: 107, Train_loss: 0.4747 / Val_loss: 0.5135\n",
      "Epoch: 108, Train_loss: 0.5440 / Val_loss: 0.5149\n",
      "Epoch: 109, Train_loss: 0.5081 / Val_loss: 0.5151\n",
      "Epoch: 110, Train_loss: 0.4645 / Val_loss: 0.5135\n",
      "Epoch: 111, Train_loss: 0.4924 / Val_loss: 0.5124\n",
      "Epoch: 112, Train_loss: 0.5247 / Val_loss: 0.5117\n",
      "Epoch: 113, Train_loss: 0.4911 / Val_loss: 0.5118\n",
      "Epoch: 114, Train_loss: 0.4900 / Val_loss: 0.5124\n",
      "Epoch: 115, Train_loss: 0.4616 / Val_loss: 0.5118\n",
      "Epoch: 116, Train_loss: 0.4700 / Val_loss: 0.5102\n",
      "Epoch: 117, Train_loss: 0.5145 / Val_loss: 0.5102\n",
      "Epoch: 118, Train_loss: 0.4588 / Val_loss: 0.5096\n",
      "Epoch: 119, Train_loss: 0.5409 / Val_loss: 0.5116\n",
      "Epoch: 120, Train_loss: 0.5161 / Val_loss: 0.5144\n",
      "Epoch: 121, Train_loss: 0.4968 / Val_loss: 0.5177\n",
      "Epoch: 122, Train_loss: 0.4726 / Val_loss: 0.5224\n",
      "Epoch: 123, Train_loss: 0.4559 / Val_loss: 0.5250\n",
      "Epoch: 124, Train_loss: 0.5112 / Val_loss: 0.5287\n",
      "Epoch: 125, Train_loss: 0.4898 / Val_loss: 0.5344\n",
      "Epoch: 126, Train_loss: 0.4643 / Val_loss: 0.5375\n",
      "Epoch: 127, Train_loss: 0.4528 / Val_loss: 0.5398\n",
      "Epoch: 128, Train_loss: 0.4259 / Val_loss: 0.5381\n",
      "Epoch: 129, Train_loss: 0.4597 / Val_loss: 0.5362\n",
      "Epoch: 130, Train_loss: 0.4338 / Val_loss: 0.5339\n",
      "Epoch: 131, Train_loss: 0.4704 / Val_loss: 0.5331\n",
      "Epoch: 132, Train_loss: 0.4965 / Val_loss: 0.5366\n",
      "Epoch: 133, Train_loss: 0.4420 / Val_loss: 0.5410\n",
      "Epoch: 134, Train_loss: 0.4327 / Val_loss: 0.5445\n",
      "Epoch: 135, Train_loss: 0.4679 / Val_loss: 0.5481\n",
      "Epoch: 136, Train_loss: 0.4540 / Val_loss: 0.5509\n",
      "Epoch: 137, Train_loss: 0.4431 / Val_loss: 0.5551\n",
      "Epoch: 138, Train_loss: 0.4654 / Val_loss: 0.5596\n",
      "Epoch: 139, Train_loss: 0.4411 / Val_loss: 0.5654\n",
      "Epoch: 140, Train_loss: 0.4288 / Val_loss: 0.5714\n",
      "Epoch: 141, Train_loss: 0.3925 / Val_loss: 0.5720\n",
      "Epoch: 142, Train_loss: 0.4561 / Val_loss: 0.5717\n",
      "Epoch: 143, Train_loss: 0.4154 / Val_loss: 0.5700\n",
      "Epoch: 144, Train_loss: 0.3966 / Val_loss: 0.5675\n",
      "Epoch: 145, Train_loss: 0.4100 / Val_loss: 0.5654\n",
      "Epoch: 146, Train_loss: 0.4449 / Val_loss: 0.5635\n",
      "Epoch: 147, Train_loss: 0.4419 / Val_loss: 0.5611\n",
      "Epoch: 148, Train_loss: 0.4399 / Val_loss: 0.5609\n",
      "Epoch: 149, Train_loss: 0.4062 / Val_loss: 0.5637\n",
      "Epoch: 150, Train_loss: 0.4546 / Val_loss: 0.5682\n",
      "Epoch: 151, Train_loss: 0.3638 / Val_loss: 0.5699\n",
      "Epoch: 152, Train_loss: 0.4089 / Val_loss: 0.5729\n",
      "Epoch: 153, Train_loss: 0.4415 / Val_loss: 0.5783\n",
      "Epoch: 154, Train_loss: 0.4566 / Val_loss: 0.5839\n",
      "Epoch: 155, Train_loss: 0.3968 / Val_loss: 0.5895\n",
      "Epoch: 156, Train_loss: 0.3485 / Val_loss: 0.5915\n",
      "Epoch: 157, Train_loss: 0.4389 / Val_loss: 0.5891\n",
      "Epoch: 158, Train_loss: 0.3942 / Val_loss: 0.5862\n",
      "Epoch: 159, Train_loss: 0.4199 / Val_loss: 0.5830\n",
      "Epoch: 160, Train_loss: 0.4142 / Val_loss: 0.5787\n",
      "Epoch: 161, Train_loss: 0.4203 / Val_loss: 0.5757\n",
      "Epoch: 162, Train_loss: 0.4088 / Val_loss: 0.5711\n",
      "Epoch: 163, Train_loss: 0.4176 / Val_loss: 0.5648\n",
      "Epoch: 164, Train_loss: 0.4132 / Val_loss: 0.5577\n",
      "Epoch: 165, Train_loss: 0.3769 / Val_loss: 0.5542\n",
      "Epoch: 166, Train_loss: 0.4003 / Val_loss: 0.5530\n",
      "Epoch: 167, Train_loss: 0.3975 / Val_loss: 0.5539\n",
      "Epoch: 168, Train_loss: 0.4539 / Val_loss: 0.5567\n",
      "Epoch: 169, Train_loss: 0.3703 / Val_loss: 0.5590\n",
      "Epoch: 170, Train_loss: 0.4290 / Val_loss: 0.5598\n",
      "Epoch: 171, Train_loss: 0.3921 / Val_loss: 0.5602\n",
      "Epoch: 172, Train_loss: 0.3964 / Val_loss: 0.5605\n",
      "Epoch: 173, Train_loss: 0.3897 / Val_loss: 0.5597\n",
      "Epoch: 174, Train_loss: 0.4189 / Val_loss: 0.5593\n",
      "Epoch: 175, Train_loss: 0.4089 / Val_loss: 0.5586\n",
      "Epoch: 176, Train_loss: 0.3888 / Val_loss: 0.5579\n",
      "Epoch: 177, Train_loss: 0.3887 / Val_loss: 0.5560\n",
      "Epoch: 178, Train_loss: 0.4169 / Val_loss: 0.5546\n",
      "Epoch: 179, Train_loss: 0.3673 / Val_loss: 0.5532\n",
      "Epoch: 180, Train_loss: 0.3939 / Val_loss: 0.5490\n",
      "Epoch: 181, Train_loss: 0.4276 / Val_loss: 0.5474\n",
      "Epoch: 182, Train_loss: 0.3645 / Val_loss: 0.5458\n",
      "Epoch: 183, Train_loss: 0.4579 / Val_loss: 0.5461\n",
      "Epoch: 184, Train_loss: 0.4036 / Val_loss: 0.5491\n",
      "Epoch: 185, Train_loss: 0.3427 / Val_loss: 0.5513\n",
      "Epoch: 186, Train_loss: 0.4000 / Val_loss: 0.5538\n",
      "Epoch: 187, Train_loss: 0.3847 / Val_loss: 0.5559\n",
      "Epoch: 188, Train_loss: 0.3866 / Val_loss: 0.5565\n",
      "Epoch: 189, Train_loss: 0.3933 / Val_loss: 0.5560\n",
      "Epoch: 190, Train_loss: 0.3833 / Val_loss: 0.5556\n",
      "Epoch: 191, Train_loss: 0.3860 / Val_loss: 0.5542\n",
      "Epoch: 192, Train_loss: 0.3523 / Val_loss: 0.5534\n",
      "Epoch: 193, Train_loss: 0.3909 / Val_loss: 0.5529\n",
      "Epoch: 194, Train_loss: 0.3859 / Val_loss: 0.5546\n",
      "Epoch: 195, Train_loss: 0.4064 / Val_loss: 0.5576\n",
      "Epoch: 196, Train_loss: 0.3422 / Val_loss: 0.5585\n",
      "Epoch: 197, Train_loss: 0.4010 / Val_loss: 0.5597\n",
      "Epoch: 198, Train_loss: 0.4146 / Val_loss: 0.5618\n",
      "Epoch: 199, Train_loss: 0.3489 / Val_loss: 0.5642\n",
      "Epoch: 200, Train_loss: 0.3581 / Val_loss: 0.5675\n",
      "Epoch: 201, Train_loss: 0.3538 / Val_loss: 0.5717\n",
      "Epoch: 202, Train_loss: 0.3561 / Val_loss: 0.5763\n",
      "Epoch: 203, Train_loss: 0.3620 / Val_loss: 0.5810\n",
      "Epoch: 204, Train_loss: 0.3942 / Val_loss: 0.5860\n",
      "Epoch: 205, Train_loss: 0.3898 / Val_loss: 0.5902\n",
      "Epoch: 206, Train_loss: 0.4236 / Val_loss: 0.5912\n",
      "Epoch: 207, Train_loss: 0.3855 / Val_loss: 0.5919\n",
      "Epoch: 208, Train_loss: 0.3434 / Val_loss: 0.5914\n",
      "Epoch: 209, Train_loss: 0.3979 / Val_loss: 0.5903\n",
      "Epoch: 210, Train_loss: 0.3484 / Val_loss: 0.5889\n",
      "Epoch: 211, Train_loss: 0.3436 / Val_loss: 0.5878\n",
      "Epoch: 212, Train_loss: 0.3598 / Val_loss: 0.5875\n",
      "Epoch: 213, Train_loss: 0.3671 / Val_loss: 0.5868\n",
      "Epoch: 214, Train_loss: 0.3963 / Val_loss: 0.5861\n",
      "Epoch: 215, Train_loss: 0.3291 / Val_loss: 0.5854\n",
      "Epoch: 216, Train_loss: 0.3666 / Val_loss: 0.5847\n",
      "Epoch: 217, Train_loss: 0.3567 / Val_loss: 0.5851\n",
      "Epoch: 218, Train_loss: 0.3989 / Val_loss: 0.5848\n",
      "Epoch: 219, Train_loss: 0.3455 / Val_loss: 0.5848\n",
      "Epoch: 220, Train_loss: 0.3435 / Val_loss: 0.5863\n",
      "Epoch: 221, Train_loss: 0.3541 / Val_loss: 0.5873\n",
      "Epoch: 222, Train_loss: 0.3327 / Val_loss: 0.5895\n",
      "Epoch: 223, Train_loss: 0.3540 / Val_loss: 0.5928\n",
      "Epoch: 224, Train_loss: 0.3248 / Val_loss: 0.5968\n",
      "Epoch: 225, Train_loss: 0.3695 / Val_loss: 0.5996\n",
      "Epoch: 226, Train_loss: 0.3519 / Val_loss: 0.6005\n",
      "Epoch: 227, Train_loss: 0.3316 / Val_loss: 0.6017\n",
      "Epoch: 228, Train_loss: 0.3933 / Val_loss: 0.6023\n",
      "Epoch: 229, Train_loss: 0.3919 / Val_loss: 0.6015\n",
      "Epoch: 230, Train_loss: 0.3292 / Val_loss: 0.6004\n",
      "Epoch: 231, Train_loss: 0.3545 / Val_loss: 0.6013\n",
      "Epoch: 232, Train_loss: 0.3853 / Val_loss: 0.6005\n",
      "Epoch: 233, Train_loss: 0.3413 / Val_loss: 0.6017\n",
      "Epoch: 234, Train_loss: 0.3215 / Val_loss: 0.6036\n",
      "Epoch: 235, Train_loss: 0.3708 / Val_loss: 0.6050\n",
      "Epoch: 236, Train_loss: 0.3597 / Val_loss: 0.6065\n",
      "Epoch: 237, Train_loss: 0.3683 / Val_loss: 0.6079\n",
      "Epoch: 238, Train_loss: 0.3522 / Val_loss: 0.6089\n",
      "Epoch: 239, Train_loss: 0.3174 / Val_loss: 0.6101\n",
      "Epoch: 240, Train_loss: 0.4107 / Val_loss: 0.6109\n",
      "Epoch: 241, Train_loss: 0.3652 / Val_loss: 0.6124\n",
      "Epoch: 242, Train_loss: 0.3033 / Val_loss: 0.6146\n",
      "Epoch: 243, Train_loss: 0.3334 / Val_loss: 0.6164\n",
      "Epoch: 244, Train_loss: 0.3264 / Val_loss: 0.6189\n",
      "Epoch: 245, Train_loss: 0.3363 / Val_loss: 0.6201\n",
      "Epoch: 246, Train_loss: 0.3454 / Val_loss: 0.6202\n",
      "Epoch: 247, Train_loss: 0.3584 / Val_loss: 0.6200\n",
      "Epoch: 248, Train_loss: 0.3425 / Val_loss: 0.6207\n",
      "Epoch: 249, Train_loss: 0.3571 / Val_loss: 0.6216\n",
      "Epoch: 250, Train_loss: 0.3482 / Val_loss: 0.6231\n",
      "Epoch: 251, Train_loss: 0.3240 / Val_loss: 0.6260\n",
      "Epoch: 252, Train_loss: 0.3244 / Val_loss: 0.6297\n",
      "Epoch: 253, Train_loss: 0.3203 / Val_loss: 0.6334\n",
      "Epoch: 254, Train_loss: 0.3489 / Val_loss: 0.6369\n",
      "Epoch: 255, Train_loss: 0.3096 / Val_loss: 0.6411\n",
      "Epoch: 256, Train_loss: 0.3320 / Val_loss: 0.6450\n",
      "Epoch: 257, Train_loss: 0.3395 / Val_loss: 0.6494\n",
      "Epoch: 258, Train_loss: 0.3325 / Val_loss: 0.6540\n",
      "Epoch: 259, Train_loss: 0.3377 / Val_loss: 0.6588\n",
      "Epoch: 260, Train_loss: 0.3636 / Val_loss: 0.6640\n",
      "Epoch: 261, Train_loss: 0.2991 / Val_loss: 0.6682\n",
      "Epoch: 262, Train_loss: 0.3031 / Val_loss: 0.6724\n",
      "Epoch: 263, Train_loss: 0.3230 / Val_loss: 0.6761\n",
      "Epoch: 264, Train_loss: 0.3110 / Val_loss: 0.6779\n",
      "Epoch: 265, Train_loss: 0.3068 / Val_loss: 0.6800\n",
      "Epoch: 266, Train_loss: 0.3054 / Val_loss: 0.6818\n",
      "Epoch: 267, Train_loss: 0.3839 / Val_loss: 0.6824\n",
      "Epoch: 268, Train_loss: 0.3023 / Val_loss: 0.6835\n",
      "Epoch: 269, Train_loss: 0.2992 / Val_loss: 0.6846\n",
      "Epoch: 270, Train_loss: 0.3120 / Val_loss: 0.6853\n",
      "Epoch: 271, Train_loss: 0.3274 / Val_loss: 0.6871\n",
      "Epoch: 272, Train_loss: 0.3363 / Val_loss: 0.6877\n",
      "Epoch: 273, Train_loss: 0.3294 / Val_loss: 0.6878\n",
      "Epoch: 274, Train_loss: 0.3020 / Val_loss: 0.6863\n",
      "Epoch: 275, Train_loss: 0.3238 / Val_loss: 0.6860\n",
      "Epoch: 276, Train_loss: 0.3212 / Val_loss: 0.6861\n",
      "Epoch: 277, Train_loss: 0.2918 / Val_loss: 0.6876\n",
      "Epoch: 278, Train_loss: 0.3120 / Val_loss: 0.6893\n",
      "Epoch: 279, Train_loss: 0.3417 / Val_loss: 0.6887\n",
      "Epoch: 280, Train_loss: 0.3096 / Val_loss: 0.6882\n",
      "Epoch: 281, Train_loss: 0.3550 / Val_loss: 0.6874\n",
      "Epoch: 282, Train_loss: 0.3213 / Val_loss: 0.6871\n",
      "Epoch: 283, Train_loss: 0.3584 / Val_loss: 0.6860\n",
      "Epoch: 284, Train_loss: 0.3427 / Val_loss: 0.6845\n",
      "Epoch: 285, Train_loss: 0.3796 / Val_loss: 0.6812\n",
      "Epoch: 286, Train_loss: 0.3223 / Val_loss: 0.6781\n",
      "Epoch: 287, Train_loss: 0.2795 / Val_loss: 0.6751\n",
      "Epoch: 288, Train_loss: 0.3060 / Val_loss: 0.6729\n",
      "Epoch: 289, Train_loss: 0.3406 / Val_loss: 0.6714\n",
      "Epoch: 290, Train_loss: 0.2991 / Val_loss: 0.6699\n",
      "Epoch: 291, Train_loss: 0.3042 / Val_loss: 0.6698\n",
      "Epoch: 292, Train_loss: 0.3980 / Val_loss: 0.6698\n",
      "Epoch: 293, Train_loss: 0.2922 / Val_loss: 0.6697\n",
      "Epoch: 294, Train_loss: 0.3009 / Val_loss: 0.6714\n",
      "Epoch: 295, Train_loss: 0.2928 / Val_loss: 0.6742\n",
      "Epoch: 296, Train_loss: 0.3152 / Val_loss: 0.6768\n",
      "Epoch: 297, Train_loss: 0.2762 / Val_loss: 0.6816\n",
      "Epoch: 298, Train_loss: 0.2959 / Val_loss: 0.6875\n",
      "Epoch: 299, Train_loss: 0.3238 / Val_loss: 0.6916\n",
      "Epoch: 300, Train_loss: 0.3339 / Val_loss: 0.6944\n",
      "Epoch: 301, Train_loss: 0.2591 / Val_loss: 0.6983\n",
      "Epoch: 302, Train_loss: 0.3096 / Val_loss: 0.7020\n",
      "Epoch: 303, Train_loss: 0.3305 / Val_loss: 0.7055\n",
      "Epoch: 304, Train_loss: 0.2806 / Val_loss: 0.7094\n",
      "Epoch: 305, Train_loss: 0.3291 / Val_loss: 0.7151\n",
      "Epoch: 306, Train_loss: 0.3056 / Val_loss: 0.7190\n",
      "Epoch: 307, Train_loss: 0.3071 / Val_loss: 0.7246\n",
      "Epoch: 308, Train_loss: 0.2875 / Val_loss: 0.7315\n",
      "Epoch: 309, Train_loss: 0.3091 / Val_loss: 0.7388\n",
      "Epoch: 310, Train_loss: 0.3074 / Val_loss: 0.7429\n",
      "Epoch: 311, Train_loss: 0.3116 / Val_loss: 0.7436\n",
      "Epoch: 312, Train_loss: 0.2886 / Val_loss: 0.7444\n",
      "Epoch: 313, Train_loss: 0.3432 / Val_loss: 0.7427\n",
      "Epoch: 314, Train_loss: 0.3255 / Val_loss: 0.7396\n",
      "Epoch: 315, Train_loss: 0.3294 / Val_loss: 0.7352\n",
      "Epoch: 316, Train_loss: 0.2379 / Val_loss: 0.7341\n",
      "Epoch: 317, Train_loss: 0.3262 / Val_loss: 0.7338\n",
      "Epoch: 318, Train_loss: 0.2847 / Val_loss: 0.7355\n",
      "Epoch: 319, Train_loss: 0.3051 / Val_loss: 0.7368\n",
      "Epoch: 320, Train_loss: 0.2654 / Val_loss: 0.7396\n",
      "Epoch: 321, Train_loss: 0.2394 / Val_loss: 0.7422\n",
      "Epoch: 322, Train_loss: 0.3057 / Val_loss: 0.7457\n",
      "Epoch: 323, Train_loss: 0.3189 / Val_loss: 0.7485\n",
      "Epoch: 324, Train_loss: 0.2858 / Val_loss: 0.7516\n",
      "Epoch: 325, Train_loss: 0.2459 / Val_loss: 0.7574\n",
      "Epoch: 326, Train_loss: 0.2862 / Val_loss: 0.7639\n",
      "Epoch: 327, Train_loss: 0.2639 / Val_loss: 0.7711\n",
      "Epoch: 328, Train_loss: 0.2702 / Val_loss: 0.7778\n",
      "Epoch: 329, Train_loss: 0.2708 / Val_loss: 0.7858\n",
      "Epoch: 330, Train_loss: 0.2911 / Val_loss: 0.7932\n",
      "Epoch: 331, Train_loss: 0.2141 / Val_loss: 0.8021\n",
      "Epoch: 332, Train_loss: 0.2255 / Val_loss: 0.8114\n",
      "Epoch: 333, Train_loss: 0.2929 / Val_loss: 0.8202\n",
      "Epoch: 334, Train_loss: 0.2495 / Val_loss: 0.8299\n",
      "Epoch: 335, Train_loss: 0.2580 / Val_loss: 0.8399\n",
      "Epoch: 336, Train_loss: 0.2599 / Val_loss: 0.8483\n",
      "Epoch: 337, Train_loss: 0.2901 / Val_loss: 0.8552\n",
      "Epoch: 338, Train_loss: 0.2268 / Val_loss: 0.8627\n",
      "Epoch: 339, Train_loss: 0.2721 / Val_loss: 0.8678\n",
      "Epoch: 340, Train_loss: 0.2999 / Val_loss: 0.8705\n",
      "Epoch: 341, Train_loss: 0.2663 / Val_loss: 0.8738\n",
      "Epoch: 342, Train_loss: 0.2791 / Val_loss: 0.8752\n",
      "Epoch: 343, Train_loss: 0.2570 / Val_loss: 0.8767\n",
      "Epoch: 344, Train_loss: 0.2660 / Val_loss: 0.8767\n",
      "Epoch: 345, Train_loss: 0.2457 / Val_loss: 0.8773\n",
      "Epoch: 346, Train_loss: 0.2875 / Val_loss: 0.8750\n",
      "Epoch: 347, Train_loss: 0.3037 / Val_loss: 0.8707\n",
      "Epoch: 348, Train_loss: 0.2634 / Val_loss: 0.8674\n",
      "Epoch: 349, Train_loss: 0.2707 / Val_loss: 0.8639\n",
      "Epoch: 350, Train_loss: 0.2937 / Val_loss: 0.8606\n",
      "Epoch: 351, Train_loss: 0.3364 / Val_loss: 0.8558\n",
      "Epoch: 352, Train_loss: 0.2750 / Val_loss: 0.8498\n",
      "Epoch: 353, Train_loss: 0.2592 / Val_loss: 0.8467\n",
      "Epoch: 354, Train_loss: 0.2773 / Val_loss: 0.8429\n",
      "Epoch: 355, Train_loss: 0.2448 / Val_loss: 0.8420\n",
      "Epoch: 356, Train_loss: 0.2545 / Val_loss: 0.8410\n",
      "Epoch: 357, Train_loss: 0.2420 / Val_loss: 0.8434\n",
      "Epoch: 358, Train_loss: 0.2771 / Val_loss: 0.8468\n",
      "Epoch: 359, Train_loss: 0.2862 / Val_loss: 0.8507\n",
      "Epoch: 360, Train_loss: 0.2250 / Val_loss: 0.8573\n",
      "Epoch: 361, Train_loss: 0.2435 / Val_loss: 0.8650\n",
      "Epoch: 362, Train_loss: 0.2689 / Val_loss: 0.8725\n",
      "Epoch: 363, Train_loss: 0.2692 / Val_loss: 0.8807\n",
      "Epoch: 364, Train_loss: 0.2245 / Val_loss: 0.8887\n",
      "Epoch: 365, Train_loss: 0.2672 / Val_loss: 0.8962\n",
      "Epoch: 366, Train_loss: 0.2359 / Val_loss: 0.9038\n",
      "Epoch: 367, Train_loss: 0.3262 / Val_loss: 0.9076\n",
      "Epoch: 368, Train_loss: 0.2712 / Val_loss: 0.9100\n",
      "Epoch: 369, Train_loss: 0.2448 / Val_loss: 0.9099\n",
      "Epoch: 370, Train_loss: 0.2560 / Val_loss: 0.9084\n",
      "Epoch: 371, Train_loss: 0.2528 / Val_loss: 0.9055\n",
      "Epoch: 372, Train_loss: 0.2954 / Val_loss: 0.8996\n",
      "Epoch: 373, Train_loss: 0.2215 / Val_loss: 0.8976\n",
      "Epoch: 374, Train_loss: 0.2071 / Val_loss: 0.8982\n",
      "Epoch: 375, Train_loss: 0.2597 / Val_loss: 0.8998\n",
      "Epoch: 376, Train_loss: 0.2297 / Val_loss: 0.9016\n",
      "Epoch: 377, Train_loss: 0.2575 / Val_loss: 0.9035\n",
      "Epoch: 378, Train_loss: 0.2266 / Val_loss: 0.9077\n",
      "Epoch: 379, Train_loss: 0.2628 / Val_loss: 0.9125\n",
      "Epoch: 380, Train_loss: 0.2491 / Val_loss: 0.9143\n",
      "Epoch: 381, Train_loss: 0.2276 / Val_loss: 0.9161\n",
      "Epoch: 382, Train_loss: 0.2221 / Val_loss: 0.9188\n",
      "Epoch: 383, Train_loss: 0.2603 / Val_loss: 0.9216\n",
      "Epoch: 384, Train_loss: 0.2686 / Val_loss: 0.9238\n",
      "Epoch: 385, Train_loss: 0.2543 / Val_loss: 0.9259\n",
      "Epoch: 386, Train_loss: 0.2026 / Val_loss: 0.9288\n",
      "Epoch: 387, Train_loss: 0.2719 / Val_loss: 0.9290\n",
      "Epoch: 388, Train_loss: 0.2669 / Val_loss: 0.9285\n",
      "Epoch: 389, Train_loss: 0.2689 / Val_loss: 0.9287\n",
      "Epoch: 390, Train_loss: 0.2906 / Val_loss: 0.9271\n",
      "Epoch: 391, Train_loss: 0.2838 / Val_loss: 0.9229\n",
      "Epoch: 392, Train_loss: 0.2287 / Val_loss: 0.9204\n",
      "Epoch: 393, Train_loss: 0.2900 / Val_loss: 0.9148\n",
      "Epoch: 394, Train_loss: 0.2487 / Val_loss: 0.9112\n",
      "Epoch: 395, Train_loss: 0.2196 / Val_loss: 0.9099\n",
      "Epoch: 396, Train_loss: 0.2194 / Val_loss: 0.9122\n",
      "Epoch: 397, Train_loss: 0.3168 / Val_loss: 0.9087\n",
      "Epoch: 398, Train_loss: 0.2503 / Val_loss: 0.9078\n",
      "Epoch: 399, Train_loss: 0.2548 / Val_loss: 0.9097\n",
      "Epoch: 400, Train_loss: 0.2424 / Val_loss: 0.9132\n",
      "Epoch: 401, Train_loss: 0.2553 / Val_loss: 0.9178\n",
      "Epoch: 402, Train_loss: 0.2763 / Val_loss: 0.9239\n",
      "Epoch: 403, Train_loss: 0.2459 / Val_loss: 0.9302\n",
      "Epoch: 404, Train_loss: 0.2393 / Val_loss: 0.9380\n",
      "Epoch: 405, Train_loss: 0.2405 / Val_loss: 0.9463\n",
      "Epoch: 406, Train_loss: 0.2407 / Val_loss: 0.9511\n",
      "Epoch: 407, Train_loss: 0.2196 / Val_loss: 0.9550\n",
      "Epoch: 408, Train_loss: 0.2023 / Val_loss: 0.9609\n",
      "Epoch: 409, Train_loss: 0.2463 / Val_loss: 0.9639\n",
      "Epoch: 410, Train_loss: 0.2525 / Val_loss: 0.9660\n",
      "Epoch: 411, Train_loss: 0.2943 / Val_loss: 0.9630\n",
      "Epoch: 412, Train_loss: 0.1955 / Val_loss: 0.9647\n",
      "Epoch: 413, Train_loss: 0.2258 / Val_loss: 0.9660\n",
      "Epoch: 414, Train_loss: 0.2139 / Val_loss: 0.9691\n",
      "Epoch: 415, Train_loss: 0.2397 / Val_loss: 0.9713\n",
      "Epoch: 416, Train_loss: 0.2599 / Val_loss: 0.9711\n",
      "Epoch: 417, Train_loss: 0.2325 / Val_loss: 0.9697\n",
      "Epoch: 418, Train_loss: 0.1898 / Val_loss: 0.9706\n",
      "Epoch: 419, Train_loss: 0.2612 / Val_loss: 0.9696\n",
      "Epoch: 420, Train_loss: 0.2740 / Val_loss: 0.9679\n",
      "Epoch: 421, Train_loss: 0.2006 / Val_loss: 0.9696\n",
      "Epoch: 422, Train_loss: 0.2720 / Val_loss: 0.9683\n",
      "Epoch: 423, Train_loss: 0.2246 / Val_loss: 0.9676\n",
      "Epoch: 424, Train_loss: 0.1962 / Val_loss: 0.9683\n",
      "Epoch: 425, Train_loss: 0.2134 / Val_loss: 0.9713\n",
      "Epoch: 426, Train_loss: 0.2431 / Val_loss: 0.9746\n",
      "Epoch: 427, Train_loss: 0.1930 / Val_loss: 0.9814\n",
      "Epoch: 428, Train_loss: 0.2535 / Val_loss: 0.9861\n",
      "Epoch: 429, Train_loss: 0.2519 / Val_loss: 0.9894\n",
      "Epoch: 430, Train_loss: 0.2095 / Val_loss: 0.9948\n",
      "Epoch: 431, Train_loss: 0.2625 / Val_loss: 0.9972\n",
      "Epoch: 432, Train_loss: 0.2507 / Val_loss: 0.9988\n",
      "Epoch: 433, Train_loss: 0.2457 / Val_loss: 1.0025\n",
      "Epoch: 434, Train_loss: 0.2265 / Val_loss: 1.0083\n",
      "Epoch: 435, Train_loss: 0.2227 / Val_loss: 1.0144\n",
      "Epoch: 436, Train_loss: 0.2394 / Val_loss: 1.0171\n",
      "Epoch: 437, Train_loss: 0.1759 / Val_loss: 1.0247\n",
      "Epoch: 438, Train_loss: 0.2005 / Val_loss: 1.0322\n",
      "Epoch: 439, Train_loss: 0.1980 / Val_loss: 1.0445\n",
      "Epoch: 440, Train_loss: 0.2528 / Val_loss: 1.0525\n",
      "Epoch: 441, Train_loss: 0.1933 / Val_loss: 1.0658\n",
      "Epoch: 442, Train_loss: 0.1942 / Val_loss: 1.0813\n",
      "Epoch: 443, Train_loss: 0.1613 / Val_loss: 1.0991\n",
      "Epoch: 444, Train_loss: 0.1941 / Val_loss: 1.1196\n",
      "Epoch: 445, Train_loss: 0.2652 / Val_loss: 1.1327\n",
      "Epoch: 446, Train_loss: 0.2542 / Val_loss: 1.1447\n",
      "Epoch: 447, Train_loss: 0.2408 / Val_loss: 1.1531\n",
      "Epoch: 448, Train_loss: 0.1864 / Val_loss: 1.1651\n",
      "Epoch: 449, Train_loss: 0.1985 / Val_loss: 1.1763\n",
      "Epoch: 450, Train_loss: 0.1943 / Val_loss: 1.1894\n",
      "Epoch: 451, Train_loss: 0.2406 / Val_loss: 1.1940\n",
      "Epoch: 452, Train_loss: 0.2216 / Val_loss: 1.1962\n",
      "Epoch: 453, Train_loss: 0.1785 / Val_loss: 1.2013\n",
      "Epoch: 454, Train_loss: 0.2016 / Val_loss: 1.2068\n",
      "Epoch: 455, Train_loss: 0.1838 / Val_loss: 1.2152\n",
      "Epoch: 456, Train_loss: 0.2298 / Val_loss: 1.2225\n",
      "Epoch: 457, Train_loss: 0.2391 / Val_loss: 1.2256\n",
      "Epoch: 458, Train_loss: 0.2208 / Val_loss: 1.2236\n",
      "Epoch: 459, Train_loss: 0.2068 / Val_loss: 1.2226\n",
      "Epoch: 460, Train_loss: 0.1933 / Val_loss: 1.2227\n",
      "Epoch: 461, Train_loss: 0.2112 / Val_loss: 1.2221\n",
      "Epoch: 462, Train_loss: 0.2115 / Val_loss: 1.2207\n",
      "Epoch: 463, Train_loss: 0.2681 / Val_loss: 1.2019\n",
      "Epoch: 464, Train_loss: 0.2090 / Val_loss: 1.1828\n",
      "Epoch: 465, Train_loss: 0.2112 / Val_loss: 1.1631\n",
      "Epoch: 466, Train_loss: 0.2256 / Val_loss: 1.1415\n",
      "Epoch: 467, Train_loss: 0.2170 / Val_loss: 1.1219\n",
      "Epoch: 468, Train_loss: 0.2114 / Val_loss: 1.1072\n",
      "Epoch: 469, Train_loss: 0.1866 / Val_loss: 1.1006\n",
      "Epoch: 470, Train_loss: 0.2004 / Val_loss: 1.0972\n",
      "Epoch: 471, Train_loss: 0.2150 / Val_loss: 1.0937\n",
      "Epoch: 472, Train_loss: 0.2073 / Val_loss: 1.0918\n",
      "Epoch: 473, Train_loss: 0.1998 / Val_loss: 1.0921\n",
      "Epoch: 474, Train_loss: 0.2178 / Val_loss: 1.0934\n",
      "Epoch: 475, Train_loss: 0.1904 / Val_loss: 1.0974\n",
      "Epoch: 476, Train_loss: 0.2536 / Val_loss: 1.0984\n",
      "Epoch: 477, Train_loss: 0.1782 / Val_loss: 1.1013\n",
      "Epoch: 478, Train_loss: 0.2640 / Val_loss: 1.1027\n",
      "Epoch: 479, Train_loss: 0.1911 / Val_loss: 1.1068\n",
      "Epoch: 480, Train_loss: 0.2091 / Val_loss: 1.1150\n",
      "Epoch: 481, Train_loss: 0.1908 / Val_loss: 1.1254\n",
      "Epoch: 482, Train_loss: 0.2342 / Val_loss: 1.1308\n",
      "Epoch: 483, Train_loss: 0.2005 / Val_loss: 1.1387\n",
      "Epoch: 484, Train_loss: 0.1949 / Val_loss: 1.1470\n",
      "Epoch: 485, Train_loss: 0.2097 / Val_loss: 1.1559\n",
      "Epoch: 486, Train_loss: 0.2225 / Val_loss: 1.1591\n",
      "Epoch: 487, Train_loss: 0.2256 / Val_loss: 1.1659\n",
      "Epoch: 488, Train_loss: 0.2232 / Val_loss: 1.1704\n",
      "Epoch: 489, Train_loss: 0.1915 / Val_loss: 1.1761\n",
      "Epoch: 490, Train_loss: 0.1865 / Val_loss: 1.1834\n",
      "Epoch: 491, Train_loss: 0.2299 / Val_loss: 1.1896\n",
      "Epoch: 492, Train_loss: 0.2369 / Val_loss: 1.1933\n",
      "Epoch: 493, Train_loss: 0.1861 / Val_loss: 1.1993\n",
      "Epoch: 494, Train_loss: 0.2316 / Val_loss: 1.2044\n",
      "Epoch: 495, Train_loss: 0.2028 / Val_loss: 1.2108\n",
      "Epoch: 496, Train_loss: 0.1553 / Val_loss: 1.2221\n",
      "Epoch: 497, Train_loss: 0.2075 / Val_loss: 1.2334\n",
      "Epoch: 498, Train_loss: 0.1782 / Val_loss: 1.2443\n",
      "Epoch: 499, Train_loss: 0.2658 / Val_loss: 1.2467\n",
      "Epoch: 500, Train_loss: 0.2195 / Val_loss: 1.2418\n",
      "Epoch: 501, Train_loss: 0.2144 / Val_loss: 1.2363\n",
      "Epoch: 502, Train_loss: 0.2103 / Val_loss: 1.2216\n",
      "Epoch: 503, Train_loss: 0.2785 / Val_loss: 1.2024\n",
      "Epoch: 504, Train_loss: 0.1556 / Val_loss: 1.1892\n",
      "Epoch: 505, Train_loss: 0.2234 / Val_loss: 1.1732\n",
      "Epoch: 506, Train_loss: 0.2473 / Val_loss: 1.1580\n",
      "Epoch: 507, Train_loss: 0.2041 / Val_loss: 1.1461\n",
      "Epoch: 508, Train_loss: 0.1983 / Val_loss: 1.1392\n",
      "Epoch: 509, Train_loss: 0.2138 / Val_loss: 1.1348\n",
      "Epoch: 510, Train_loss: 0.1927 / Val_loss: 1.1332\n",
      "Epoch: 511, Train_loss: 0.1808 / Val_loss: 1.1347\n",
      "Epoch: 512, Train_loss: 0.1757 / Val_loss: 1.1379\n",
      "Epoch: 513, Train_loss: 0.1899 / Val_loss: 1.1429\n",
      "Epoch: 514, Train_loss: 0.2494 / Val_loss: 1.1454\n",
      "Epoch: 515, Train_loss: 0.1749 / Val_loss: 1.1532\n",
      "Epoch: 516, Train_loss: 0.1868 / Val_loss: 1.1643\n",
      "Epoch: 517, Train_loss: 0.2003 / Val_loss: 1.1745\n",
      "Epoch: 518, Train_loss: 0.2195 / Val_loss: 1.1823\n",
      "Epoch: 519, Train_loss: 0.1938 / Val_loss: 1.1912\n",
      "Epoch: 520, Train_loss: 0.2336 / Val_loss: 1.1911\n",
      "Epoch: 521, Train_loss: 0.1913 / Val_loss: 1.1959\n",
      "Epoch: 522, Train_loss: 0.1562 / Val_loss: 1.2045\n",
      "Epoch: 523, Train_loss: 0.1913 / Val_loss: 1.2069\n",
      "Epoch: 524, Train_loss: 0.2137 / Val_loss: 1.2056\n",
      "Epoch: 525, Train_loss: 0.1778 / Val_loss: 1.2034\n",
      "Epoch: 526, Train_loss: 0.1931 / Val_loss: 1.2038\n",
      "Epoch: 527, Train_loss: 0.1896 / Val_loss: 1.2069\n",
      "Epoch: 528, Train_loss: 0.1733 / Val_loss: 1.2140\n",
      "Epoch: 529, Train_loss: 0.1635 / Val_loss: 1.2222\n",
      "Epoch: 530, Train_loss: 0.1989 / Val_loss: 1.2290\n",
      "Epoch: 531, Train_loss: 0.1780 / Val_loss: 1.2346\n",
      "Epoch: 532, Train_loss: 0.1491 / Val_loss: 1.2415\n",
      "Epoch: 533, Train_loss: 0.2265 / Val_loss: 1.2445\n",
      "Epoch: 534, Train_loss: 0.1889 / Val_loss: 1.2492\n",
      "Epoch: 535, Train_loss: 0.1780 / Val_loss: 1.2547\n",
      "Epoch: 536, Train_loss: 0.1596 / Val_loss: 1.2634\n",
      "Epoch: 537, Train_loss: 0.1769 / Val_loss: 1.2741\n",
      "Epoch: 538, Train_loss: 0.1768 / Val_loss: 1.2864\n",
      "Epoch: 539, Train_loss: 0.1860 / Val_loss: 1.2954\n",
      "Epoch: 540, Train_loss: 0.1640 / Val_loss: 1.3082\n",
      "Epoch: 541, Train_loss: 0.1594 / Val_loss: 1.3213\n",
      "Epoch: 542, Train_loss: 0.1990 / Val_loss: 1.3302\n",
      "Epoch: 543, Train_loss: 0.1797 / Val_loss: 1.3429\n",
      "Epoch: 544, Train_loss: 0.1652 / Val_loss: 1.3497\n",
      "Epoch: 545, Train_loss: 0.2011 / Val_loss: 1.3546\n",
      "Epoch: 546, Train_loss: 0.1836 / Val_loss: 1.3616\n",
      "Epoch: 547, Train_loss: 0.1873 / Val_loss: 1.3663\n",
      "Epoch: 548, Train_loss: 0.1732 / Val_loss: 1.3728\n",
      "Epoch: 549, Train_loss: 0.1738 / Val_loss: 1.3790\n",
      "Epoch: 550, Train_loss: 0.1501 / Val_loss: 1.3861\n",
      "Epoch: 551, Train_loss: 0.1945 / Val_loss: 1.3870\n",
      "Epoch: 552, Train_loss: 0.1874 / Val_loss: 1.3870\n",
      "Epoch: 553, Train_loss: 0.1989 / Val_loss: 1.3862\n",
      "Epoch: 554, Train_loss: 0.1841 / Val_loss: 1.3842\n",
      "Epoch: 555, Train_loss: 0.1920 / Val_loss: 1.3836\n",
      "Epoch: 556, Train_loss: 0.1752 / Val_loss: 1.3817\n",
      "Epoch: 557, Train_loss: 0.1404 / Val_loss: 1.3844\n",
      "Epoch: 558, Train_loss: 0.1654 / Val_loss: 1.3860\n",
      "Epoch: 559, Train_loss: 0.1556 / Val_loss: 1.3916\n",
      "Epoch: 560, Train_loss: 0.1349 / Val_loss: 1.4032\n",
      "Epoch: 561, Train_loss: 0.1519 / Val_loss: 1.4151\n",
      "Epoch: 562, Train_loss: 0.2037 / Val_loss: 1.4196\n",
      "Epoch: 563, Train_loss: 0.1970 / Val_loss: 1.4255\n",
      "Epoch: 564, Train_loss: 0.1740 / Val_loss: 1.4309\n",
      "Epoch: 565, Train_loss: 0.1921 / Val_loss: 1.4362\n",
      "Epoch: 566, Train_loss: 0.1893 / Val_loss: 1.4359\n",
      "Epoch: 567, Train_loss: 0.1706 / Val_loss: 1.4354\n",
      "Epoch: 568, Train_loss: 0.1874 / Val_loss: 1.4360\n",
      "Epoch: 569, Train_loss: 0.1678 / Val_loss: 1.4336\n",
      "Epoch: 570, Train_loss: 0.1770 / Val_loss: 1.4320\n",
      "Epoch: 571, Train_loss: 0.1644 / Val_loss: 1.4342\n",
      "Epoch: 572, Train_loss: 0.1854 / Val_loss: 1.4288\n",
      "Epoch: 573, Train_loss: 0.1416 / Val_loss: 1.4321\n",
      "Epoch: 574, Train_loss: 0.1491 / Val_loss: 1.4398\n",
      "Epoch: 575, Train_loss: 0.1471 / Val_loss: 1.4536\n",
      "Epoch: 576, Train_loss: 0.1975 / Val_loss: 1.4641\n",
      "Epoch: 577, Train_loss: 0.1543 / Val_loss: 1.4761\n",
      "Epoch: 578, Train_loss: 0.1507 / Val_loss: 1.4896\n",
      "Epoch: 579, Train_loss: 0.1859 / Val_loss: 1.4955\n",
      "Epoch: 580, Train_loss: 0.1908 / Val_loss: 1.4987\n",
      "Epoch: 581, Train_loss: 0.1343 / Val_loss: 1.5080\n",
      "Epoch: 582, Train_loss: 0.1620 / Val_loss: 1.5128\n",
      "Epoch: 583, Train_loss: 0.2095 / Val_loss: 1.5127\n",
      "Epoch: 584, Train_loss: 0.1582 / Val_loss: 1.5109\n",
      "Epoch: 585, Train_loss: 0.1899 / Val_loss: 1.5072\n",
      "Epoch: 586, Train_loss: 0.1852 / Val_loss: 1.5038\n",
      "Epoch: 587, Train_loss: 0.1344 / Val_loss: 1.5050\n",
      "Epoch: 588, Train_loss: 0.1479 / Val_loss: 1.5091\n",
      "Epoch: 589, Train_loss: 0.1655 / Val_loss: 1.5166\n",
      "Epoch: 590, Train_loss: 0.1793 / Val_loss: 1.5236\n",
      "Epoch: 591, Train_loss: 0.2086 / Val_loss: 1.5183\n",
      "Epoch: 592, Train_loss: 0.1909 / Val_loss: 1.5090\n",
      "Epoch: 593, Train_loss: 0.1733 / Val_loss: 1.5026\n",
      "Epoch: 594, Train_loss: 0.1494 / Val_loss: 1.4994\n",
      "Epoch: 595, Train_loss: 0.2009 / Val_loss: 1.4983\n",
      "Epoch: 596, Train_loss: 0.1677 / Val_loss: 1.4987\n",
      "Epoch: 597, Train_loss: 0.1574 / Val_loss: 1.5017\n",
      "Epoch: 598, Train_loss: 0.1584 / Val_loss: 1.5110\n",
      "Epoch: 599, Train_loss: 0.1726 / Val_loss: 1.5197\n",
      "Epoch: 600, Train_loss: 0.1810 / Val_loss: 1.5330\n",
      "Epoch: 601, Train_loss: 0.1680 / Val_loss: 1.5476\n",
      "Epoch: 602, Train_loss: 0.1430 / Val_loss: 1.5660\n",
      "Epoch: 603, Train_loss: 0.1302 / Val_loss: 1.5896\n",
      "Epoch: 604, Train_loss: 0.1951 / Val_loss: 1.6089\n",
      "Epoch: 605, Train_loss: 0.1628 / Val_loss: 1.6291\n",
      "Epoch: 606, Train_loss: 0.1416 / Val_loss: 1.6524\n",
      "Epoch: 607, Train_loss: 0.1561 / Val_loss: 1.6773\n",
      "Epoch: 608, Train_loss: 0.2042 / Val_loss: 1.6978\n",
      "Epoch: 609, Train_loss: 0.1750 / Val_loss: 1.7133\n",
      "Epoch: 610, Train_loss: 0.1716 / Val_loss: 1.7231\n",
      "Epoch: 611, Train_loss: 0.1639 / Val_loss: 1.7236\n",
      "Epoch: 612, Train_loss: 0.1477 / Val_loss: 1.7210\n",
      "Epoch: 613, Train_loss: 0.1351 / Val_loss: 1.7207\n",
      "Epoch: 614, Train_loss: 0.2069 / Val_loss: 1.7153\n",
      "Epoch: 615, Train_loss: 0.1283 / Val_loss: 1.7141\n",
      "Epoch: 616, Train_loss: 0.1596 / Val_loss: 1.7098\n",
      "Epoch: 617, Train_loss: 0.1583 / Val_loss: 1.7107\n",
      "Epoch: 618, Train_loss: 0.1570 / Val_loss: 1.7138\n",
      "Epoch: 619, Train_loss: 0.1639 / Val_loss: 1.7181\n",
      "Epoch: 620, Train_loss: 0.1393 / Val_loss: 1.7268\n",
      "Epoch: 621, Train_loss: 0.1579 / Val_loss: 1.7360\n",
      "Epoch: 622, Train_loss: 0.1662 / Val_loss: 1.7439\n",
      "Epoch: 623, Train_loss: 0.1849 / Val_loss: 1.7497\n",
      "Epoch: 624, Train_loss: 0.1555 / Val_loss: 1.7547\n",
      "Epoch: 625, Train_loss: 0.2220 / Val_loss: 1.7502\n",
      "Epoch: 626, Train_loss: 0.1398 / Val_loss: 1.7467\n",
      "Epoch: 627, Train_loss: 0.2021 / Val_loss: 1.7373\n",
      "Epoch: 628, Train_loss: 0.2234 / Val_loss: 1.7200\n",
      "Epoch: 629, Train_loss: 0.1883 / Val_loss: 1.6968\n",
      "Epoch: 630, Train_loss: 0.1403 / Val_loss: 1.6809\n",
      "Epoch: 631, Train_loss: 0.1562 / Val_loss: 1.6702\n",
      "Epoch: 632, Train_loss: 0.1653 / Val_loss: 1.6635\n",
      "Epoch: 633, Train_loss: 0.1770 / Val_loss: 1.6608\n",
      "Epoch: 634, Train_loss: 0.1720 / Val_loss: 1.6543\n",
      "Epoch: 635, Train_loss: 0.1624 / Val_loss: 1.6478\n",
      "Epoch: 636, Train_loss: 0.1443 / Val_loss: 1.6479\n",
      "Epoch: 637, Train_loss: 0.1549 / Val_loss: 1.6526\n",
      "Epoch: 638, Train_loss: 0.1803 / Val_loss: 1.6580\n",
      "Epoch: 639, Train_loss: 0.1604 / Val_loss: 1.6697\n",
      "Epoch: 640, Train_loss: 0.1743 / Val_loss: 1.6767\n",
      "Epoch: 641, Train_loss: 0.1494 / Val_loss: 1.6885\n",
      "Epoch: 642, Train_loss: 0.2034 / Val_loss: 1.6908\n",
      "Epoch: 643, Train_loss: 0.1419 / Val_loss: 1.6973\n",
      "Epoch: 644, Train_loss: 0.1384 / Val_loss: 1.7083\n",
      "Epoch: 645, Train_loss: 0.1940 / Val_loss: 1.7142\n",
      "Epoch: 646, Train_loss: 0.1726 / Val_loss: 1.7218\n",
      "Epoch: 647, Train_loss: 0.1231 / Val_loss: 1.7386\n",
      "Epoch: 648, Train_loss: 0.1350 / Val_loss: 1.7619\n",
      "Epoch: 649, Train_loss: 0.1201 / Val_loss: 1.7876\n",
      "Epoch: 650, Train_loss: 0.1587 / Val_loss: 1.8146\n",
      "Epoch: 651, Train_loss: 0.1571 / Val_loss: 1.8382\n",
      "Epoch: 652, Train_loss: 0.1384 / Val_loss: 1.8564\n",
      "Epoch: 653, Train_loss: 0.1370 / Val_loss: 1.8784\n",
      "Epoch: 654, Train_loss: 0.1701 / Val_loss: 1.8910\n",
      "Epoch: 655, Train_loss: 0.1780 / Val_loss: 1.9047\n",
      "Epoch: 656, Train_loss: 0.1485 / Val_loss: 1.9124\n",
      "Epoch: 657, Train_loss: 0.1638 / Val_loss: 1.9168\n",
      "Epoch: 658, Train_loss: 0.1544 / Val_loss: 1.9254\n",
      "Epoch: 659, Train_loss: 0.1431 / Val_loss: 1.9315\n",
      "Epoch: 660, Train_loss: 0.2739 / Val_loss: 1.9131\n",
      "Epoch: 661, Train_loss: 0.1426 / Val_loss: 1.8970\n",
      "Epoch: 662, Train_loss: 0.1451 / Val_loss: 1.8821\n",
      "Epoch: 663, Train_loss: 0.1684 / Val_loss: 1.8657\n",
      "Epoch: 664, Train_loss: 0.1117 / Val_loss: 1.8548\n",
      "Epoch: 665, Train_loss: 0.1354 / Val_loss: 1.8515\n",
      "Epoch: 666, Train_loss: 0.1807 / Val_loss: 1.8365\n",
      "Epoch: 667, Train_loss: 0.1643 / Val_loss: 1.8238\n",
      "Epoch: 668, Train_loss: 0.1524 / Val_loss: 1.8066\n",
      "Epoch: 669, Train_loss: 0.1474 / Val_loss: 1.7859\n",
      "Epoch: 670, Train_loss: 0.1454 / Val_loss: 1.7737\n",
      "Epoch: 671, Train_loss: 0.1457 / Val_loss: 1.7681\n",
      "Epoch: 672, Train_loss: 0.1204 / Val_loss: 1.7721\n",
      "Epoch: 673, Train_loss: 0.1974 / Val_loss: 1.7736\n",
      "Epoch: 674, Train_loss: 0.1375 / Val_loss: 1.7824\n",
      "Epoch: 675, Train_loss: 0.1426 / Val_loss: 1.7989\n",
      "Epoch: 676, Train_loss: 0.1565 / Val_loss: 1.8166\n",
      "Epoch: 677, Train_loss: 0.1411 / Val_loss: 1.8361\n",
      "Epoch: 678, Train_loss: 0.1614 / Val_loss: 1.8593\n",
      "Epoch: 679, Train_loss: 0.1358 / Val_loss: 1.8802\n",
      "Epoch: 680, Train_loss: 0.1758 / Val_loss: 1.8943\n",
      "Epoch: 681, Train_loss: 0.1692 / Val_loss: 1.9007\n",
      "Epoch: 682, Train_loss: 0.1739 / Val_loss: 1.8985\n",
      "Epoch: 683, Train_loss: 0.1849 / Val_loss: 1.8876\n",
      "Epoch: 684, Train_loss: 0.2067 / Val_loss: 1.8693\n",
      "Epoch: 685, Train_loss: 0.1622 / Val_loss: 1.8479\n",
      "Epoch: 686, Train_loss: 0.1486 / Val_loss: 1.8336\n",
      "Epoch: 687, Train_loss: 0.1325 / Val_loss: 1.8297\n",
      "Epoch: 688, Train_loss: 0.1578 / Val_loss: 1.8316\n",
      "Epoch: 689, Train_loss: 0.1643 / Val_loss: 1.8381\n",
      "Epoch: 690, Train_loss: 0.1851 / Val_loss: 1.8496\n",
      "Epoch: 691, Train_loss: 0.1428 / Val_loss: 1.8572\n",
      "Epoch: 692, Train_loss: 0.1493 / Val_loss: 1.8659\n",
      "Epoch: 693, Train_loss: 0.1410 / Val_loss: 1.8815\n",
      "Epoch: 694, Train_loss: 0.1332 / Val_loss: 1.8963\n",
      "Epoch: 695, Train_loss: 0.1092 / Val_loss: 1.9169\n",
      "Epoch: 696, Train_loss: 0.1401 / Val_loss: 1.9374\n",
      "Epoch: 697, Train_loss: 0.1532 / Val_loss: 1.9625\n",
      "Epoch: 698, Train_loss: 0.1416 / Val_loss: 1.9860\n",
      "Epoch: 699, Train_loss: 0.1338 / Val_loss: 2.0180\n",
      "Epoch: 700, Train_loss: 0.1213 / Val_loss: 2.0557\n",
      "Epoch: 701, Train_loss: 0.1438 / Val_loss: 2.0852\n",
      "Epoch: 702, Train_loss: 0.1495 / Val_loss: 2.1130\n",
      "Epoch: 703, Train_loss: 0.1178 / Val_loss: 2.1389\n",
      "Epoch: 704, Train_loss: 0.1166 / Val_loss: 2.1678\n",
      "Epoch: 705, Train_loss: 0.1499 / Val_loss: 2.1901\n",
      "Epoch: 706, Train_loss: 0.1502 / Val_loss: 2.2005\n",
      "Epoch: 707, Train_loss: 0.1612 / Val_loss: 2.2086\n",
      "Epoch: 708, Train_loss: 0.1312 / Val_loss: 2.2230\n",
      "Epoch: 709, Train_loss: 0.1352 / Val_loss: 2.2317\n",
      "Epoch: 710, Train_loss: 0.1553 / Val_loss: 2.2273\n",
      "Epoch: 711, Train_loss: 0.1503 / Val_loss: 2.2244\n",
      "Epoch: 712, Train_loss: 0.1415 / Val_loss: 2.2107\n",
      "Epoch: 713, Train_loss: 0.1425 / Val_loss: 2.1936\n",
      "Epoch: 714, Train_loss: 0.1443 / Val_loss: 2.1816\n",
      "Epoch: 715, Train_loss: 0.1349 / Val_loss: 2.1599\n",
      "Epoch: 716, Train_loss: 0.1772 / Val_loss: 2.1374\n",
      "Epoch: 717, Train_loss: 0.1540 / Val_loss: 2.1207\n",
      "Epoch: 718, Train_loss: 0.1215 / Val_loss: 2.1117\n",
      "Epoch: 719, Train_loss: 0.1278 / Val_loss: 2.0877\n",
      "Epoch: 720, Train_loss: 0.0990 / Val_loss: 2.0738\n",
      "Epoch: 721, Train_loss: 0.1474 / Val_loss: 2.0584\n",
      "Epoch: 722, Train_loss: 0.1273 / Val_loss: 2.0484\n",
      "Epoch: 723, Train_loss: 0.1641 / Val_loss: 2.0356\n",
      "Epoch: 724, Train_loss: 0.1586 / Val_loss: 2.0273\n",
      "Epoch: 725, Train_loss: 0.1573 / Val_loss: 2.0286\n",
      "Epoch: 726, Train_loss: 0.1524 / Val_loss: 2.0292\n",
      "Epoch: 727, Train_loss: 0.1368 / Val_loss: 2.0405\n",
      "Epoch: 728, Train_loss: 0.1336 / Val_loss: 2.0520\n",
      "Epoch: 729, Train_loss: 0.1263 / Val_loss: 2.0570\n",
      "Epoch: 730, Train_loss: 0.1461 / Val_loss: 2.0584\n",
      "Epoch: 731, Train_loss: 0.1477 / Val_loss: 2.0657\n",
      "Epoch: 732, Train_loss: 0.1320 / Val_loss: 2.0734\n",
      "Epoch: 733, Train_loss: 0.1304 / Val_loss: 2.0813\n",
      "Epoch: 734, Train_loss: 0.1490 / Val_loss: 2.0791\n",
      "Epoch: 735, Train_loss: 0.0971 / Val_loss: 2.0842\n",
      "Epoch: 736, Train_loss: 0.1653 / Val_loss: 2.0885\n",
      "Epoch: 737, Train_loss: 0.1437 / Val_loss: 2.0966\n",
      "Epoch: 738, Train_loss: 0.1209 / Val_loss: 2.1104\n",
      "Epoch: 739, Train_loss: 0.1357 / Val_loss: 2.1359\n",
      "Epoch: 740, Train_loss: 0.1718 / Val_loss: 2.1538\n",
      "Epoch: 741, Train_loss: 0.1071 / Val_loss: 2.1779\n",
      "Epoch: 742, Train_loss: 0.1137 / Val_loss: 2.2094\n",
      "Epoch: 743, Train_loss: 0.1524 / Val_loss: 2.2322\n",
      "Epoch: 744, Train_loss: 0.1447 / Val_loss: 2.2556\n",
      "Epoch: 745, Train_loss: 0.1067 / Val_loss: 2.2805\n",
      "Epoch: 746, Train_loss: 0.1219 / Val_loss: 2.3010\n",
      "Epoch: 747, Train_loss: 0.1234 / Val_loss: 2.3200\n",
      "Epoch: 748, Train_loss: 0.1390 / Val_loss: 2.3422\n",
      "Epoch: 749, Train_loss: 0.1504 / Val_loss: 2.3625\n",
      "Epoch: 750, Train_loss: 0.1292 / Val_loss: 2.3798\n",
      "Epoch: 751, Train_loss: 0.1276 / Val_loss: 2.4043\n",
      "Epoch: 752, Train_loss: 0.1603 / Val_loss: 2.4209\n",
      "Epoch: 753, Train_loss: 0.1034 / Val_loss: 2.4257\n",
      "Epoch: 754, Train_loss: 0.1278 / Val_loss: 2.4240\n",
      "Epoch: 755, Train_loss: 0.1172 / Val_loss: 2.4231\n",
      "Epoch: 756, Train_loss: 0.1158 / Val_loss: 2.4207\n",
      "Epoch: 757, Train_loss: 0.1512 / Val_loss: 2.4130\n",
      "Epoch: 758, Train_loss: 0.1505 / Val_loss: 2.3980\n",
      "Epoch: 759, Train_loss: 0.1416 / Val_loss: 2.3882\n",
      "Epoch: 760, Train_loss: 0.1313 / Val_loss: 2.3823\n",
      "Epoch: 761, Train_loss: 0.1402 / Val_loss: 2.3827\n",
      "Epoch: 762, Train_loss: 0.1423 / Val_loss: 2.3737\n",
      "Epoch: 763, Train_loss: 0.1376 / Val_loss: 2.3653\n",
      "Epoch: 764, Train_loss: 0.1365 / Val_loss: 2.3595\n",
      "Epoch: 765, Train_loss: 0.1582 / Val_loss: 2.3492\n",
      "Epoch: 766, Train_loss: 0.0938 / Val_loss: 2.3526\n",
      "Epoch: 767, Train_loss: 0.1204 / Val_loss: 2.3568\n",
      "Epoch: 768, Train_loss: 0.1288 / Val_loss: 2.3624\n",
      "Epoch: 769, Train_loss: 0.1095 / Val_loss: 2.3839\n",
      "Epoch: 770, Train_loss: 0.1322 / Val_loss: 2.4008\n",
      "Epoch: 771, Train_loss: 0.1416 / Val_loss: 2.4076\n",
      "Epoch: 772, Train_loss: 0.1155 / Val_loss: 2.4236\n",
      "Epoch: 773, Train_loss: 0.1333 / Val_loss: 2.4364\n",
      "Epoch: 774, Train_loss: 0.1191 / Val_loss: 2.4556\n",
      "Epoch: 775, Train_loss: 0.1395 / Val_loss: 2.4707\n",
      "Epoch: 776, Train_loss: 0.1303 / Val_loss: 2.4873\n",
      "Epoch: 777, Train_loss: 0.0970 / Val_loss: 2.5055\n",
      "Epoch: 778, Train_loss: 0.1496 / Val_loss: 2.5201\n",
      "Epoch: 779, Train_loss: 0.1027 / Val_loss: 2.5401\n",
      "Epoch: 780, Train_loss: 0.0994 / Val_loss: 2.5583\n",
      "Epoch: 781, Train_loss: 0.1291 / Val_loss: 2.5642\n",
      "Epoch: 782, Train_loss: 0.1237 / Val_loss: 2.5694\n",
      "Epoch: 783, Train_loss: 0.1184 / Val_loss: 2.5758\n",
      "Epoch: 784, Train_loss: 0.1379 / Val_loss: 2.5719\n",
      "Epoch: 785, Train_loss: 0.1249 / Val_loss: 2.5742\n",
      "Epoch: 786, Train_loss: 0.1100 / Val_loss: 2.5843\n",
      "Epoch: 787, Train_loss: 0.1526 / Val_loss: 2.5929\n",
      "Epoch: 788, Train_loss: 0.1148 / Val_loss: 2.6082\n",
      "Epoch: 789, Train_loss: 0.0999 / Val_loss: 2.6270\n",
      "Epoch: 790, Train_loss: 0.1130 / Val_loss: 2.6474\n",
      "Epoch: 791, Train_loss: 0.1614 / Val_loss: 2.6501\n",
      "Epoch: 792, Train_loss: 0.1271 / Val_loss: 2.6358\n",
      "Epoch: 793, Train_loss: 0.1594 / Val_loss: 2.6067\n",
      "Epoch: 794, Train_loss: 0.0954 / Val_loss: 2.5827\n",
      "Epoch: 795, Train_loss: 0.0999 / Val_loss: 2.5663\n",
      "Epoch: 796, Train_loss: 0.1405 / Val_loss: 2.5485\n",
      "Epoch: 797, Train_loss: 0.1232 / Val_loss: 2.5353\n",
      "Epoch: 798, Train_loss: 0.1102 / Val_loss: 2.5384\n",
      "Epoch: 799, Train_loss: 0.1387 / Val_loss: 2.5435\n",
      "Epoch: 800, Train_loss: 0.1230 / Val_loss: 2.5478\n",
      "Epoch: 801, Train_loss: 0.1147 / Val_loss: 2.5551\n",
      "Epoch: 802, Train_loss: 0.1540 / Val_loss: 2.5512\n",
      "Epoch: 803, Train_loss: 0.1177 / Val_loss: 2.5486\n",
      "Epoch: 804, Train_loss: 0.1279 / Val_loss: 2.5450\n",
      "Epoch: 805, Train_loss: 0.1486 / Val_loss: 2.5317\n",
      "Epoch: 806, Train_loss: 0.1064 / Val_loss: 2.5184\n",
      "Epoch: 807, Train_loss: 0.1341 / Val_loss: 2.4885\n",
      "Epoch: 808, Train_loss: 0.1164 / Val_loss: 2.4631\n",
      "Epoch: 809, Train_loss: 0.1100 / Val_loss: 2.4409\n",
      "Epoch: 810, Train_loss: 0.1068 / Val_loss: 2.4266\n",
      "Epoch: 811, Train_loss: 0.0828 / Val_loss: 2.4259\n",
      "Epoch: 812, Train_loss: 0.1195 / Val_loss: 2.4252\n",
      "Epoch: 813, Train_loss: 0.1179 / Val_loss: 2.4220\n",
      "Epoch: 814, Train_loss: 0.1298 / Val_loss: 2.4255\n",
      "Epoch: 815, Train_loss: 0.1517 / Val_loss: 2.4191\n",
      "Epoch: 816, Train_loss: 0.0710 / Val_loss: 2.4232\n",
      "Epoch: 817, Train_loss: 0.1429 / Val_loss: 2.4166\n",
      "Epoch: 818, Train_loss: 0.1396 / Val_loss: 2.4104\n",
      "Epoch: 819, Train_loss: 0.1235 / Val_loss: 2.4067\n",
      "Epoch: 820, Train_loss: 0.1074 / Val_loss: 2.4075\n",
      "Epoch: 821, Train_loss: 0.1456 / Val_loss: 2.4098\n",
      "Epoch: 822, Train_loss: 0.1043 / Val_loss: 2.4196\n",
      "Epoch: 823, Train_loss: 0.1160 / Val_loss: 2.4344\n",
      "Epoch: 824, Train_loss: 0.1234 / Val_loss: 2.4446\n",
      "Epoch: 825, Train_loss: 0.1310 / Val_loss: 2.4485\n",
      "Epoch: 826, Train_loss: 0.1005 / Val_loss: 2.4518\n",
      "Epoch: 827, Train_loss: 0.0841 / Val_loss: 2.4589\n",
      "Epoch: 828, Train_loss: 0.1020 / Val_loss: 2.4721\n",
      "Epoch: 829, Train_loss: 0.1089 / Val_loss: 2.4896\n",
      "Epoch: 830, Train_loss: 0.1184 / Val_loss: 2.5088\n",
      "Epoch: 831, Train_loss: 0.1239 / Val_loss: 2.5352\n",
      "Epoch: 832, Train_loss: 0.1007 / Val_loss: 2.5644\n",
      "Epoch: 833, Train_loss: 0.1164 / Val_loss: 2.5935\n",
      "Epoch: 834, Train_loss: 0.1327 / Val_loss: 2.6229\n",
      "Epoch: 835, Train_loss: 0.1192 / Val_loss: 2.6493\n",
      "Epoch: 836, Train_loss: 0.0986 / Val_loss: 2.6688\n",
      "Epoch: 837, Train_loss: 0.1215 / Val_loss: 2.6748\n",
      "Epoch: 838, Train_loss: 0.1043 / Val_loss: 2.6815\n",
      "Epoch: 839, Train_loss: 0.1151 / Val_loss: 2.6913\n",
      "Epoch: 840, Train_loss: 0.1294 / Val_loss: 2.7053\n",
      "Epoch: 841, Train_loss: 0.1057 / Val_loss: 2.7152\n",
      "Epoch: 842, Train_loss: 0.1037 / Val_loss: 2.7246\n",
      "Epoch: 843, Train_loss: 0.0991 / Val_loss: 2.7336\n",
      "Epoch: 844, Train_loss: 0.1485 / Val_loss: 2.7355\n",
      "Epoch: 845, Train_loss: 0.0959 / Val_loss: 2.7470\n",
      "Epoch: 846, Train_loss: 0.1071 / Val_loss: 2.7475\n",
      "Epoch: 847, Train_loss: 0.1359 / Val_loss: 2.7507\n",
      "Epoch: 848, Train_loss: 0.0940 / Val_loss: 2.7641\n",
      "Epoch: 849, Train_loss: 0.0976 / Val_loss: 2.7770\n",
      "Epoch: 850, Train_loss: 0.1352 / Val_loss: 2.7877\n",
      "Epoch: 851, Train_loss: 0.1142 / Val_loss: 2.7871\n",
      "Epoch: 852, Train_loss: 0.0815 / Val_loss: 2.7957\n",
      "Epoch: 853, Train_loss: 0.1143 / Val_loss: 2.8066\n",
      "Epoch: 854, Train_loss: 0.0948 / Val_loss: 2.8177\n",
      "Epoch: 855, Train_loss: 0.1283 / Val_loss: 2.8340\n",
      "Epoch: 856, Train_loss: 0.0976 / Val_loss: 2.8542\n",
      "Epoch: 857, Train_loss: 0.1232 / Val_loss: 2.8804\n",
      "Epoch: 858, Train_loss: 0.1093 / Val_loss: 2.9056\n",
      "Epoch: 859, Train_loss: 0.1406 / Val_loss: 2.8991\n",
      "Epoch: 860, Train_loss: 0.0805 / Val_loss: 2.9040\n",
      "Epoch: 861, Train_loss: 0.1572 / Val_loss: 2.8871\n",
      "Epoch: 862, Train_loss: 0.0879 / Val_loss: 2.8755\n",
      "Epoch: 863, Train_loss: 0.0741 / Val_loss: 2.8763\n",
      "Epoch: 864, Train_loss: 0.1162 / Val_loss: 2.8689\n",
      "Epoch: 865, Train_loss: 0.1219 / Val_loss: 2.8687\n",
      "Epoch: 866, Train_loss: 0.1410 / Val_loss: 2.8634\n",
      "Epoch: 867, Train_loss: 0.1257 / Val_loss: 2.8601\n",
      "Epoch: 868, Train_loss: 0.1591 / Val_loss: 2.8478\n",
      "Epoch: 869, Train_loss: 0.1106 / Val_loss: 2.8454\n",
      "Epoch: 870, Train_loss: 0.0858 / Val_loss: 2.8537\n",
      "Epoch: 871, Train_loss: 0.1074 / Val_loss: 2.8563\n",
      "Epoch: 872, Train_loss: 0.1104 / Val_loss: 2.8571\n",
      "Epoch: 873, Train_loss: 0.1076 / Val_loss: 2.8711\n",
      "Epoch: 874, Train_loss: 0.1042 / Val_loss: 2.8895\n",
      "Epoch: 875, Train_loss: 0.1014 / Val_loss: 2.9187\n",
      "Epoch: 876, Train_loss: 0.1322 / Val_loss: 2.9475\n",
      "Epoch: 877, Train_loss: 0.0775 / Val_loss: 2.9868\n",
      "Epoch: 878, Train_loss: 0.0987 / Val_loss: 3.0212\n",
      "Epoch: 879, Train_loss: 0.0840 / Val_loss: 3.0617\n",
      "Epoch: 880, Train_loss: 0.1156 / Val_loss: 3.0927\n",
      "Epoch: 881, Train_loss: 0.0772 / Val_loss: 3.1330\n",
      "Epoch: 882, Train_loss: 0.1027 / Val_loss: 3.1710\n",
      "Epoch: 883, Train_loss: 0.1000 / Val_loss: 3.2109\n",
      "Epoch: 884, Train_loss: 0.0725 / Val_loss: 3.2424\n",
      "Epoch: 885, Train_loss: 0.0942 / Val_loss: 3.2627\n",
      "Epoch: 886, Train_loss: 0.1059 / Val_loss: 3.2797\n",
      "Epoch: 887, Train_loss: 0.1320 / Val_loss: 3.2742\n",
      "Epoch: 888, Train_loss: 0.1484 / Val_loss: 3.2635\n",
      "Epoch: 889, Train_loss: 0.1537 / Val_loss: 3.2334\n",
      "Epoch: 890, Train_loss: 0.0927 / Val_loss: 3.1940\n",
      "Epoch: 891, Train_loss: 0.1078 / Val_loss: 3.1559\n",
      "Epoch: 892, Train_loss: 0.1030 / Val_loss: 3.1179\n",
      "Epoch: 893, Train_loss: 0.0888 / Val_loss: 3.0821\n",
      "Epoch: 894, Train_loss: 0.1017 / Val_loss: 3.0474\n",
      "Epoch: 895, Train_loss: 0.1101 / Val_loss: 3.0289\n",
      "Epoch: 896, Train_loss: 0.1156 / Val_loss: 3.0204\n",
      "Epoch: 897, Train_loss: 0.0826 / Val_loss: 3.0179\n",
      "Epoch: 898, Train_loss: 0.0915 / Val_loss: 3.0281\n",
      "Epoch: 899, Train_loss: 0.1015 / Val_loss: 3.0542\n",
      "Epoch: 900, Train_loss: 0.1077 / Val_loss: 3.0849\n",
      "Epoch: 901, Train_loss: 0.1473 / Val_loss: 3.0919\n",
      "Epoch: 902, Train_loss: 0.0938 / Val_loss: 3.1095\n",
      "Epoch: 903, Train_loss: 0.0798 / Val_loss: 3.1284\n",
      "Epoch: 904, Train_loss: 0.0828 / Val_loss: 3.1470\n",
      "Epoch: 905, Train_loss: 0.1073 / Val_loss: 3.1636\n",
      "Epoch: 906, Train_loss: 0.1251 / Val_loss: 3.1520\n",
      "Epoch: 907, Train_loss: 0.1246 / Val_loss: 3.1358\n",
      "Epoch: 908, Train_loss: 0.1629 / Val_loss: 3.1070\n",
      "Epoch: 909, Train_loss: 0.1041 / Val_loss: 3.0829\n",
      "Epoch: 910, Train_loss: 0.0884 / Val_loss: 3.0735\n",
      "Epoch: 911, Train_loss: 0.0987 / Val_loss: 3.0541\n",
      "Epoch: 912, Train_loss: 0.1522 / Val_loss: 3.0191\n",
      "Epoch: 913, Train_loss: 0.1391 / Val_loss: 2.9901\n",
      "Epoch: 914, Train_loss: 0.1130 / Val_loss: 2.9587\n",
      "Epoch: 915, Train_loss: 0.1372 / Val_loss: 2.9298\n",
      "Epoch: 916, Train_loss: 0.0718 / Val_loss: 2.9149\n",
      "Epoch: 917, Train_loss: 0.0659 / Val_loss: 2.9118\n",
      "Epoch: 918, Train_loss: 0.1025 / Val_loss: 2.9020\n",
      "Epoch: 919, Train_loss: 0.0885 / Val_loss: 2.8944\n",
      "Epoch: 920, Train_loss: 0.1222 / Val_loss: 2.8869\n",
      "Epoch: 921, Train_loss: 0.0661 / Val_loss: 2.8847\n",
      "Epoch: 922, Train_loss: 0.0839 / Val_loss: 2.8928\n",
      "Epoch: 923, Train_loss: 0.1075 / Val_loss: 2.9100\n",
      "Epoch: 924, Train_loss: 0.0684 / Val_loss: 2.9342\n",
      "Epoch: 925, Train_loss: 0.0752 / Val_loss: 2.9678\n",
      "Epoch: 926, Train_loss: 0.1214 / Val_loss: 2.9964\n",
      "Epoch: 927, Train_loss: 0.0582 / Val_loss: 3.0293\n",
      "Epoch: 928, Train_loss: 0.0924 / Val_loss: 3.0744\n",
      "Epoch: 929, Train_loss: 0.1294 / Val_loss: 3.1068\n",
      "Epoch: 930, Train_loss: 0.1012 / Val_loss: 3.1406\n",
      "Epoch: 931, Train_loss: 0.1113 / Val_loss: 3.1683\n",
      "Epoch: 932, Train_loss: 0.0927 / Val_loss: 3.1889\n",
      "Epoch: 933, Train_loss: 0.0906 / Val_loss: 3.2087\n",
      "Epoch: 934, Train_loss: 0.1166 / Val_loss: 3.2170\n",
      "Epoch: 935, Train_loss: 0.1150 / Val_loss: 3.2111\n",
      "Epoch: 936, Train_loss: 0.1063 / Val_loss: 3.2089\n",
      "Epoch: 937, Train_loss: 0.1051 / Val_loss: 3.2170\n",
      "Epoch: 938, Train_loss: 0.0957 / Val_loss: 3.2239\n",
      "Epoch: 939, Train_loss: 0.0802 / Val_loss: 3.2406\n",
      "Epoch: 940, Train_loss: 0.1122 / Val_loss: 3.2537\n",
      "Epoch: 941, Train_loss: 0.0717 / Val_loss: 3.2692\n",
      "Epoch: 942, Train_loss: 0.1536 / Val_loss: 3.2576\n",
      "Epoch: 943, Train_loss: 0.1126 / Val_loss: 3.2299\n",
      "Epoch: 944, Train_loss: 0.0949 / Val_loss: 3.2092\n",
      "Epoch: 945, Train_loss: 0.1142 / Val_loss: 3.1812\n",
      "Epoch: 946, Train_loss: 0.0966 / Val_loss: 3.1468\n",
      "Epoch: 947, Train_loss: 0.0853 / Val_loss: 3.1189\n",
      "Epoch: 948, Train_loss: 0.0942 / Val_loss: 3.1023\n",
      "Epoch: 949, Train_loss: 0.1273 / Val_loss: 3.0756\n",
      "Epoch: 950, Train_loss: 0.0948 / Val_loss: 3.0541\n",
      "Epoch: 951, Train_loss: 0.1102 / Val_loss: 3.0343\n",
      "Epoch: 952, Train_loss: 0.1343 / Val_loss: 3.0162\n",
      "Epoch: 953, Train_loss: 0.0952 / Val_loss: 3.0125\n",
      "Epoch: 954, Train_loss: 0.1217 / Val_loss: 3.0111\n",
      "Epoch: 955, Train_loss: 0.0954 / Val_loss: 3.0139\n",
      "Epoch: 956, Train_loss: 0.1124 / Val_loss: 3.0104\n",
      "Epoch: 957, Train_loss: 0.0928 / Val_loss: 3.0207\n",
      "Epoch: 958, Train_loss: 0.1081 / Val_loss: 3.0304\n",
      "Epoch: 959, Train_loss: 0.1016 / Val_loss: 3.0466\n",
      "Epoch: 960, Train_loss: 0.1244 / Val_loss: 3.0490\n",
      "Epoch: 961, Train_loss: 0.1451 / Val_loss: 3.0443\n",
      "Epoch: 962, Train_loss: 0.0844 / Val_loss: 3.0457\n",
      "Epoch: 963, Train_loss: 0.0982 / Val_loss: 3.0459\n",
      "Epoch: 964, Train_loss: 0.0958 / Val_loss: 3.0525\n",
      "Epoch: 965, Train_loss: 0.0920 / Val_loss: 3.0693\n",
      "Epoch: 966, Train_loss: 0.1001 / Val_loss: 3.0909\n",
      "Epoch: 967, Train_loss: 0.0657 / Val_loss: 3.1238\n",
      "Epoch: 968, Train_loss: 0.1004 / Val_loss: 3.1607\n",
      "Epoch: 969, Train_loss: 0.0718 / Val_loss: 3.2053\n",
      "Epoch: 970, Train_loss: 0.1127 / Val_loss: 3.2478\n",
      "Epoch: 971, Train_loss: 0.0994 / Val_loss: 3.2936\n",
      "Epoch: 972, Train_loss: 0.0907 / Val_loss: 3.3197\n",
      "Epoch: 973, Train_loss: 0.1119 / Val_loss: 3.3650\n",
      "Epoch: 974, Train_loss: 0.0786 / Val_loss: 3.4154\n",
      "Epoch: 975, Train_loss: 0.1163 / Val_loss: 3.4542\n",
      "Epoch: 976, Train_loss: 0.0662 / Val_loss: 3.4929\n",
      "Epoch: 977, Train_loss: 0.0870 / Val_loss: 3.5159\n",
      "Epoch: 978, Train_loss: 0.0737 / Val_loss: 3.5460\n",
      "Epoch: 979, Train_loss: 0.1142 / Val_loss: 3.5578\n",
      "Epoch: 980, Train_loss: 0.1064 / Val_loss: 3.5690\n",
      "Epoch: 981, Train_loss: 0.1080 / Val_loss: 3.5749\n",
      "Epoch: 982, Train_loss: 0.0932 / Val_loss: 3.5797\n",
      "Epoch: 983, Train_loss: 0.0818 / Val_loss: 3.5894\n",
      "Epoch: 984, Train_loss: 0.0558 / Val_loss: 3.6190\n",
      "Epoch: 985, Train_loss: 0.0888 / Val_loss: 3.6532\n",
      "Epoch: 986, Train_loss: 0.0528 / Val_loss: 3.6974\n",
      "Epoch: 987, Train_loss: 0.0694 / Val_loss: 3.7321\n",
      "Epoch: 988, Train_loss: 0.0982 / Val_loss: 3.7832\n",
      "Epoch: 989, Train_loss: 0.0658 / Val_loss: 3.8391\n",
      "Epoch: 990, Train_loss: 0.0748 / Val_loss: 3.8754\n",
      "Epoch: 991, Train_loss: 0.1179 / Val_loss: 3.8765\n",
      "Epoch: 992, Train_loss: 0.1264 / Val_loss: 3.8665\n",
      "Epoch: 993, Train_loss: 0.1069 / Val_loss: 3.8728\n",
      "Epoch: 994, Train_loss: 0.0991 / Val_loss: 3.8716\n",
      "Epoch: 995, Train_loss: 0.0768 / Val_loss: 3.8815\n",
      "Epoch: 996, Train_loss: 0.0772 / Val_loss: 3.9052\n",
      "Epoch: 997, Train_loss: 0.0810 / Val_loss: 3.9312\n",
      "Epoch: 998, Train_loss: 0.1015 / Val_loss: 3.9425\n",
      "Epoch: 999, Train_loss: 0.1586 / Val_loss: 3.8817\n",
      "Epoch: 1000, Train_loss: 0.1084 / Val_loss: 3.8062\n",
      "Epoch: 1001, Train_loss: 0.0786 / Val_loss: 3.7447\n",
      "Epoch: 1002, Train_loss: 0.0546 / Val_loss: 3.6977\n",
      "Epoch: 1003, Train_loss: 0.0930 / Val_loss: 3.6619\n",
      "Epoch: 1004, Train_loss: 0.0785 / Val_loss: 3.6351\n",
      "Epoch: 1005, Train_loss: 0.0679 / Val_loss: 3.6140\n",
      "Epoch: 1006, Train_loss: 0.0915 / Val_loss: 3.6043\n",
      "Epoch: 1007, Train_loss: 0.0590 / Val_loss: 3.6063\n",
      "Epoch: 1008, Train_loss: 0.0854 / Val_loss: 3.6194\n",
      "Epoch: 1009, Train_loss: 0.0843 / Val_loss: 3.6307\n",
      "Epoch: 1010, Train_loss: 0.0864 / Val_loss: 3.6429\n",
      "Epoch: 1011, Train_loss: 0.1063 / Val_loss: 3.6481\n",
      "Epoch: 1012, Train_loss: 0.0943 / Val_loss: 3.6467\n",
      "Epoch: 1013, Train_loss: 0.0747 / Val_loss: 3.6494\n",
      "Epoch: 1014, Train_loss: 0.0880 / Val_loss: 3.6377\n",
      "Epoch: 1015, Train_loss: 0.1255 / Val_loss: 3.6091\n",
      "Epoch: 1016, Train_loss: 0.0724 / Val_loss: 3.5941\n",
      "Epoch: 1017, Train_loss: 0.0727 / Val_loss: 3.5896\n",
      "Epoch: 1018, Train_loss: 0.0888 / Val_loss: 3.5726\n",
      "Epoch: 1019, Train_loss: 0.1005 / Val_loss: 3.5624\n",
      "Epoch: 1020, Train_loss: 0.0798 / Val_loss: 3.5522\n",
      "Epoch: 1021, Train_loss: 0.0817 / Val_loss: 3.5578\n",
      "Epoch: 1022, Train_loss: 0.0444 / Val_loss: 3.5739\n",
      "Epoch: 1023, Train_loss: 0.0829 / Val_loss: 3.5765\n",
      "Epoch: 1024, Train_loss: 0.0909 / Val_loss: 3.5825\n",
      "Epoch: 1025, Train_loss: 0.0575 / Val_loss: 3.5916\n",
      "Epoch: 1026, Train_loss: 0.0960 / Val_loss: 3.6049\n",
      "Epoch: 1027, Train_loss: 0.0842 / Val_loss: 3.6211\n",
      "Epoch: 1028, Train_loss: 0.1122 / Val_loss: 3.6250\n",
      "Epoch: 1029, Train_loss: 0.0854 / Val_loss: 3.6392\n",
      "Epoch: 1030, Train_loss: 0.1075 / Val_loss: 3.6605\n",
      "Epoch: 1031, Train_loss: 0.1163 / Val_loss: 3.6709\n",
      "Epoch: 1032, Train_loss: 0.1449 / Val_loss: 3.6685\n",
      "Epoch: 1033, Train_loss: 0.1189 / Val_loss: 3.6513\n",
      "Epoch: 1034, Train_loss: 0.0613 / Val_loss: 3.6419\n",
      "Epoch: 1035, Train_loss: 0.0873 / Val_loss: 3.6274\n",
      "Epoch: 1036, Train_loss: 0.1046 / Val_loss: 3.6197\n",
      "Epoch: 1037, Train_loss: 0.0950 / Val_loss: 3.5999\n",
      "Epoch: 1038, Train_loss: 0.0830 / Val_loss: 3.5890\n",
      "Epoch: 1039, Train_loss: 0.1073 / Val_loss: 3.5803\n",
      "Epoch: 1040, Train_loss: 0.0634 / Val_loss: 3.5814\n",
      "Epoch: 1041, Train_loss: 0.0718 / Val_loss: 3.5840\n",
      "Epoch: 1042, Train_loss: 0.0805 / Val_loss: 3.5869\n",
      "Epoch: 1043, Train_loss: 0.0579 / Val_loss: 3.6051\n",
      "Epoch: 1044, Train_loss: 0.0631 / Val_loss: 3.6286\n",
      "Epoch: 1045, Train_loss: 0.0585 / Val_loss: 3.6566\n",
      "Epoch: 1046, Train_loss: 0.0792 / Val_loss: 3.6863\n",
      "Epoch: 1047, Train_loss: 0.0625 / Val_loss: 3.7156\n",
      "Epoch: 1048, Train_loss: 0.0927 / Val_loss: 3.7555\n",
      "Epoch: 1049, Train_loss: 0.0692 / Val_loss: 3.7955\n",
      "Epoch: 1050, Train_loss: 0.0646 / Val_loss: 3.8477\n",
      "Epoch: 1051, Train_loss: 0.1015 / Val_loss: 3.8910\n",
      "Epoch: 1052, Train_loss: 0.0830 / Val_loss: 3.9263\n",
      "Epoch: 1053, Train_loss: 0.1290 / Val_loss: 3.9195\n",
      "Epoch: 1054, Train_loss: 0.0841 / Val_loss: 3.9133\n",
      "Epoch: 1055, Train_loss: 0.0889 / Val_loss: 3.9184\n",
      "Epoch: 1056, Train_loss: 0.0796 / Val_loss: 3.9357\n",
      "Epoch: 1057, Train_loss: 0.0818 / Val_loss: 3.9684\n",
      "Epoch: 1058, Train_loss: 0.0533 / Val_loss: 4.0144\n",
      "Epoch: 1059, Train_loss: 0.0686 / Val_loss: 4.0392\n",
      "Epoch: 1060, Train_loss: 0.0931 / Val_loss: 4.0692\n",
      "Epoch: 1061, Train_loss: 0.1312 / Val_loss: 4.0757\n",
      "Epoch: 1062, Train_loss: 0.0830 / Val_loss: 4.0896\n",
      "Epoch: 1063, Train_loss: 0.0766 / Val_loss: 4.1023\n",
      "Epoch: 1064, Train_loss: 0.1409 / Val_loss: 4.1022\n",
      "Epoch: 1065, Train_loss: 0.0920 / Val_loss: 4.1050\n",
      "Epoch: 1066, Train_loss: 0.0753 / Val_loss: 4.1078\n",
      "Epoch: 1067, Train_loss: 0.0826 / Val_loss: 4.1084\n",
      "Epoch: 1068, Train_loss: 0.0962 / Val_loss: 4.1204\n",
      "Epoch: 1069, Train_loss: 0.0911 / Val_loss: 4.0940\n",
      "Epoch: 1070, Train_loss: 0.0667 / Val_loss: 4.0709\n",
      "Epoch: 1071, Train_loss: 0.0720 / Val_loss: 4.0592\n",
      "Epoch: 1072, Train_loss: 0.0851 / Val_loss: 4.0464\n",
      "Epoch: 1073, Train_loss: 0.0722 / Val_loss: 4.0206\n",
      "Epoch: 1074, Train_loss: 0.0639 / Val_loss: 4.0030\n",
      "Epoch: 1075, Train_loss: 0.0734 / Val_loss: 3.9938\n",
      "Epoch: 1076, Train_loss: 0.0633 / Val_loss: 3.9962\n",
      "Epoch: 1077, Train_loss: 0.1147 / Val_loss: 3.9750\n",
      "Epoch: 1078, Train_loss: 0.0729 / Val_loss: 3.9697\n",
      "Epoch: 1079, Train_loss: 0.0959 / Val_loss: 3.9724\n",
      "Epoch: 1080, Train_loss: 0.0980 / Val_loss: 3.9681\n",
      "Epoch: 1081, Train_loss: 0.0713 / Val_loss: 3.9820\n",
      "Epoch: 1082, Train_loss: 0.0994 / Val_loss: 3.9812\n",
      "Epoch: 1083, Train_loss: 0.0914 / Val_loss: 3.9978\n",
      "Epoch: 1084, Train_loss: 0.1310 / Val_loss: 3.9985\n",
      "Epoch: 1085, Train_loss: 0.0995 / Val_loss: 4.0022\n",
      "Epoch: 1086, Train_loss: 0.0767 / Val_loss: 4.0041\n",
      "Epoch: 1087, Train_loss: 0.0956 / Val_loss: 4.0047\n",
      "Epoch: 1088, Train_loss: 0.1183 / Val_loss: 4.0022\n",
      "Epoch: 1089, Train_loss: 0.0943 / Val_loss: 4.0065\n",
      "Epoch: 1090, Train_loss: 0.0804 / Val_loss: 4.0005\n",
      "Epoch: 1091, Train_loss: 0.0806 / Val_loss: 3.9948\n",
      "Epoch: 1092, Train_loss: 0.0728 / Val_loss: 4.0028\n",
      "Epoch: 1093, Train_loss: 0.0603 / Val_loss: 4.0147\n",
      "Epoch: 1094, Train_loss: 0.0701 / Val_loss: 4.0358\n",
      "Epoch: 1095, Train_loss: 0.0616 / Val_loss: 4.0605\n",
      "Epoch: 1096, Train_loss: 0.0856 / Val_loss: 4.0933\n",
      "Epoch: 1097, Train_loss: 0.0828 / Val_loss: 4.1175\n",
      "Epoch: 1098, Train_loss: 0.0770 / Val_loss: 4.1460\n",
      "Epoch: 1099, Train_loss: 0.0322 / Val_loss: 4.1897\n",
      "Epoch: 1100, Train_loss: 0.0822 / Val_loss: 4.2299\n",
      "Epoch: 1101, Train_loss: 0.0734 / Val_loss: 4.2692\n",
      "Epoch: 1102, Train_loss: 0.0809 / Val_loss: 4.3158\n",
      "Epoch: 1103, Train_loss: 0.0498 / Val_loss: 4.3721\n",
      "Epoch: 1104, Train_loss: 0.0780 / Val_loss: 4.4307\n",
      "Epoch: 1105, Train_loss: 0.0523 / Val_loss: 4.4896\n",
      "Epoch: 1106, Train_loss: 0.0561 / Val_loss: 4.5489\n",
      "Epoch: 1107, Train_loss: 0.0479 / Val_loss: 4.6014\n",
      "Epoch: 1108, Train_loss: 0.0486 / Val_loss: 4.6379\n",
      "Epoch: 1109, Train_loss: 0.0615 / Val_loss: 4.6825\n",
      "Epoch: 1110, Train_loss: 0.0471 / Val_loss: 4.7325\n",
      "Epoch: 1111, Train_loss: 0.0758 / Val_loss: 4.7900\n",
      "Epoch: 1112, Train_loss: 0.0854 / Val_loss: 4.8402\n",
      "Epoch: 1113, Train_loss: 0.1161 / Val_loss: 4.8362\n",
      "Epoch: 1114, Train_loss: 0.0923 / Val_loss: 4.7993\n",
      "Epoch: 1115, Train_loss: 0.0684 / Val_loss: 4.7748\n",
      "Epoch: 1116, Train_loss: 0.0660 / Val_loss: 4.7629\n",
      "Epoch: 1117, Train_loss: 0.0559 / Val_loss: 4.7518\n",
      "Epoch: 1118, Train_loss: 0.0824 / Val_loss: 4.7318\n",
      "Epoch: 1119, Train_loss: 0.1060 / Val_loss: 4.6772\n",
      "Epoch: 1120, Train_loss: 0.0762 / Val_loss: 4.6122\n",
      "Epoch: 1121, Train_loss: 0.0805 / Val_loss: 4.5573\n",
      "Epoch: 1122, Train_loss: 0.0689 / Val_loss: 4.5022\n",
      "Epoch: 1123, Train_loss: 0.0529 / Val_loss: 4.4820\n",
      "Epoch: 1124, Train_loss: 0.0723 / Val_loss: 4.4931\n",
      "Epoch: 1125, Train_loss: 0.0825 / Val_loss: 4.5068\n",
      "Epoch: 1126, Train_loss: 0.0700 / Val_loss: 4.5196\n",
      "Epoch: 1127, Train_loss: 0.1113 / Val_loss: 4.5059\n",
      "Epoch: 1128, Train_loss: 0.0848 / Val_loss: 4.5002\n",
      "Epoch: 1129, Train_loss: 0.1054 / Val_loss: 4.4804\n",
      "Epoch: 1130, Train_loss: 0.1241 / Val_loss: 4.4212\n",
      "Epoch: 1131, Train_loss: 0.1076 / Val_loss: 4.3444\n",
      "Epoch: 1132, Train_loss: 0.0768 / Val_loss: 4.2935\n",
      "Epoch: 1133, Train_loss: 0.0974 / Val_loss: 4.2356\n",
      "Epoch: 1134, Train_loss: 0.0796 / Val_loss: 4.1921\n",
      "Epoch: 1135, Train_loss: 0.0933 / Val_loss: 4.1552\n",
      "Epoch: 1136, Train_loss: 0.0979 / Val_loss: 4.1320\n",
      "Epoch: 1137, Train_loss: 0.0607 / Val_loss: 4.1253\n",
      "Epoch: 1138, Train_loss: 0.0666 / Val_loss: 4.1293\n",
      "Epoch: 1139, Train_loss: 0.0585 / Val_loss: 4.1368\n",
      "Epoch: 1140, Train_loss: 0.0618 / Val_loss: 4.1467\n",
      "Epoch: 1141, Train_loss: 0.0610 / Val_loss: 4.1622\n",
      "Epoch: 1142, Train_loss: 0.1072 / Val_loss: 4.1934\n",
      "Epoch: 1143, Train_loss: 0.0755 / Val_loss: 4.2301\n",
      "Epoch: 1144, Train_loss: 0.0923 / Val_loss: 4.2907\n",
      "Epoch: 1145, Train_loss: 0.0687 / Val_loss: 4.3501\n",
      "Epoch: 1146, Train_loss: 0.0890 / Val_loss: 4.4058\n",
      "Epoch: 1147, Train_loss: 0.1098 / Val_loss: 4.4339\n",
      "Epoch: 1148, Train_loss: 0.0683 / Val_loss: 4.4741\n",
      "Epoch: 1149, Train_loss: 0.1144 / Val_loss: 4.4890\n",
      "Epoch: 1150, Train_loss: 0.0844 / Val_loss: 4.4997\n",
      "Epoch: 1151, Train_loss: 0.0716 / Val_loss: 4.5092\n",
      "Epoch: 1152, Train_loss: 0.0706 / Val_loss: 4.5315\n",
      "Epoch: 1153, Train_loss: 0.0581 / Val_loss: 4.5514\n",
      "Epoch: 1154, Train_loss: 0.0945 / Val_loss: 4.5731\n",
      "Epoch: 1155, Train_loss: 0.0618 / Val_loss: 4.5998\n",
      "Epoch: 1156, Train_loss: 0.0552 / Val_loss: 4.6283\n",
      "Epoch: 1157, Train_loss: 0.0875 / Val_loss: 4.6353\n",
      "Epoch: 1158, Train_loss: 0.0752 / Val_loss: 4.6309\n",
      "Epoch: 1159, Train_loss: 0.0853 / Val_loss: 4.6180\n",
      "Epoch: 1160, Train_loss: 0.0809 / Val_loss: 4.6094\n",
      "Epoch: 1161, Train_loss: 0.0738 / Val_loss: 4.5961\n",
      "Epoch: 1162, Train_loss: 0.0751 / Val_loss: 4.5847\n",
      "Epoch: 1163, Train_loss: 0.0858 / Val_loss: 4.5683\n",
      "Epoch: 1164, Train_loss: 0.0626 / Val_loss: 4.5525\n",
      "Epoch: 1165, Train_loss: 0.0492 / Val_loss: 4.5551\n",
      "Epoch: 1166, Train_loss: 0.0907 / Val_loss: 4.5347\n",
      "Epoch: 1167, Train_loss: 0.0748 / Val_loss: 4.5266\n",
      "Epoch: 1168, Train_loss: 0.0801 / Val_loss: 4.5209\n",
      "Epoch: 1169, Train_loss: 0.0484 / Val_loss: 4.5305\n",
      "Epoch: 1170, Train_loss: 0.0676 / Val_loss: 4.5464\n",
      "Epoch: 1171, Train_loss: 0.0857 / Val_loss: 4.5597\n",
      "Epoch: 1172, Train_loss: 0.0659 / Val_loss: 4.5814\n",
      "Epoch: 1173, Train_loss: 0.0477 / Val_loss: 4.6055\n",
      "Epoch: 1174, Train_loss: 0.0613 / Val_loss: 4.6269\n",
      "Epoch: 1175, Train_loss: 0.0376 / Val_loss: 4.6659\n",
      "Epoch: 1176, Train_loss: 0.0611 / Val_loss: 4.7201\n",
      "Epoch: 1177, Train_loss: 0.0542 / Val_loss: 4.7809\n",
      "Epoch: 1178, Train_loss: 0.0568 / Val_loss: 4.8358\n",
      "Epoch: 1179, Train_loss: 0.0602 / Val_loss: 4.8665\n",
      "Epoch: 1180, Train_loss: 0.0625 / Val_loss: 4.8831\n",
      "Epoch: 1181, Train_loss: 0.0742 / Val_loss: 4.8905\n",
      "Epoch: 1182, Train_loss: 0.0595 / Val_loss: 4.9081\n",
      "Epoch: 1183, Train_loss: 0.0807 / Val_loss: 4.9269\n",
      "Epoch: 1184, Train_loss: 0.0731 / Val_loss: 4.9083\n",
      "Epoch: 1185, Train_loss: 0.0592 / Val_loss: 4.8987\n",
      "Epoch: 1186, Train_loss: 0.0538 / Val_loss: 4.8889\n",
      "Epoch: 1187, Train_loss: 0.1076 / Val_loss: 4.8655\n",
      "Epoch: 1188, Train_loss: 0.0786 / Val_loss: 4.8554\n",
      "Epoch: 1189, Train_loss: 0.0717 / Val_loss: 4.8495\n",
      "Epoch: 1190, Train_loss: 0.0813 / Val_loss: 4.8035\n",
      "Epoch: 1191, Train_loss: 0.0512 / Val_loss: 4.7743\n",
      "Epoch: 1192, Train_loss: 0.0754 / Val_loss: 4.7221\n",
      "Epoch: 1193, Train_loss: 0.0430 / Val_loss: 4.6787\n",
      "Epoch: 1194, Train_loss: 0.0358 / Val_loss: 4.6599\n",
      "Epoch: 1195, Train_loss: 0.0632 / Val_loss: 4.6374\n",
      "Epoch: 1196, Train_loss: 0.1118 / Val_loss: 4.6000\n",
      "Epoch: 1197, Train_loss: 0.0456 / Val_loss: 4.5811\n",
      "Epoch: 1198, Train_loss: 0.0636 / Val_loss: 4.5622\n",
      "Epoch: 1199, Train_loss: 0.0742 / Val_loss: 4.5527\n",
      "Epoch: 1200, Train_loss: 0.0572 / Val_loss: 4.5479\n",
      "Epoch: 1201, Train_loss: 0.0604 / Val_loss: 4.5444\n",
      "Epoch: 1202, Train_loss: 0.0611 / Val_loss: 4.5428\n",
      "Epoch: 1203, Train_loss: 0.0692 / Val_loss: 4.5471\n",
      "Epoch: 1204, Train_loss: 0.0365 / Val_loss: 4.5401\n",
      "Epoch: 1205, Train_loss: 0.0754 / Val_loss: 4.5159\n",
      "Epoch: 1206, Train_loss: 0.0390 / Val_loss: 4.4999\n",
      "Epoch: 1207, Train_loss: 0.0857 / Val_loss: 4.4824\n",
      "Epoch: 1208, Train_loss: 0.0549 / Val_loss: 4.4749\n",
      "Epoch: 1209, Train_loss: 0.0523 / Val_loss: 4.4712\n",
      "Epoch: 1210, Train_loss: 0.0663 / Val_loss: 4.4863\n",
      "Epoch: 1211, Train_loss: 0.0559 / Val_loss: 4.4962\n",
      "Epoch: 1212, Train_loss: 0.0897 / Val_loss: 4.5033\n",
      "Epoch: 1213, Train_loss: 0.1040 / Val_loss: 4.5066\n",
      "Epoch: 1214, Train_loss: 0.0566 / Val_loss: 4.5014\n",
      "Epoch: 1215, Train_loss: 0.0822 / Val_loss: 4.5015\n",
      "Epoch: 1216, Train_loss: 0.0701 / Val_loss: 4.4934\n",
      "Epoch: 1217, Train_loss: 0.0699 / Val_loss: 4.4899\n",
      "Epoch: 1218, Train_loss: 0.0595 / Val_loss: 4.4876\n",
      "Epoch: 1219, Train_loss: 0.0725 / Val_loss: 4.4824\n",
      "Epoch: 1220, Train_loss: 0.0642 / Val_loss: 4.4824\n",
      "Epoch: 1221, Train_loss: 0.0486 / Val_loss: 4.4950\n",
      "Epoch: 1222, Train_loss: 0.0877 / Val_loss: 4.5164\n",
      "Epoch: 1223, Train_loss: 0.0792 / Val_loss: 4.5338\n",
      "Epoch: 1224, Train_loss: 0.0691 / Val_loss: 4.5512\n",
      "Epoch: 1225, Train_loss: 0.0761 / Val_loss: 4.5713\n",
      "Epoch: 1226, Train_loss: 0.0421 / Val_loss: 4.6028\n",
      "Epoch: 1227, Train_loss: 0.0723 / Val_loss: 4.6294\n",
      "Epoch: 1228, Train_loss: 0.0642 / Val_loss: 4.6661\n",
      "Epoch: 1229, Train_loss: 0.0596 / Val_loss: 4.7006\n",
      "Epoch: 1230, Train_loss: 0.0714 / Val_loss: 4.7305\n",
      "Epoch: 1231, Train_loss: 0.0621 / Val_loss: 4.7507\n",
      "Epoch: 1232, Train_loss: 0.0919 / Val_loss: 4.7318\n",
      "Epoch: 1233, Train_loss: 0.0517 / Val_loss: 4.7109\n",
      "Epoch: 1234, Train_loss: 0.0512 / Val_loss: 4.6996\n",
      "Epoch: 1235, Train_loss: 0.0739 / Val_loss: 4.6997\n",
      "Epoch: 1236, Train_loss: 0.0811 / Val_loss: 4.6914\n",
      "Epoch: 1237, Train_loss: 0.0539 / Val_loss: 4.6972\n",
      "Epoch: 1238, Train_loss: 0.0583 / Val_loss: 4.7019\n",
      "Epoch: 1239, Train_loss: 0.0799 / Val_loss: 4.7201\n",
      "Epoch: 1240, Train_loss: 0.0466 / Val_loss: 4.7440\n",
      "Epoch: 1241, Train_loss: 0.0782 / Val_loss: 4.7821\n",
      "Epoch: 1242, Train_loss: 0.0665 / Val_loss: 4.8235\n",
      "Epoch: 1243, Train_loss: 0.0693 / Val_loss: 4.8513\n",
      "Epoch: 1244, Train_loss: 0.0865 / Val_loss: 4.8499\n",
      "Epoch: 1245, Train_loss: 0.0727 / Val_loss: 4.8593\n",
      "Epoch: 1246, Train_loss: 0.0594 / Val_loss: 4.8680\n",
      "Epoch: 1247, Train_loss: 0.0400 / Val_loss: 4.8874\n",
      "Epoch: 1248, Train_loss: 0.0471 / Val_loss: 4.9120\n",
      "Epoch: 1249, Train_loss: 0.0591 / Val_loss: 4.9346\n",
      "Epoch: 1250, Train_loss: 0.0561 / Val_loss: 4.9624\n",
      "Epoch: 1251, Train_loss: 0.0731 / Val_loss: 4.9757\n",
      "Epoch: 1252, Train_loss: 0.0689 / Val_loss: 5.0004\n",
      "Epoch: 1253, Train_loss: 0.0936 / Val_loss: 5.0296\n",
      "Epoch: 1254, Train_loss: 0.0664 / Val_loss: 5.0443\n",
      "Epoch: 1255, Train_loss: 0.0780 / Val_loss: 5.0508\n",
      "Epoch: 1256, Train_loss: 0.0394 / Val_loss: 5.0757\n",
      "Epoch: 1257, Train_loss: 0.0685 / Val_loss: 5.0979\n",
      "Epoch: 1258, Train_loss: 0.0608 / Val_loss: 5.1035\n",
      "Epoch: 1259, Train_loss: 0.0704 / Val_loss: 5.1327\n",
      "Epoch: 1260, Train_loss: 0.0601 / Val_loss: 5.1714\n",
      "Epoch: 1261, Train_loss: 0.0690 / Val_loss: 5.1862\n",
      "Epoch: 1262, Train_loss: 0.0720 / Val_loss: 5.1987\n",
      "Epoch: 1263, Train_loss: 0.0660 / Val_loss: 5.2216\n",
      "Epoch: 1264, Train_loss: 0.0756 / Val_loss: 5.2283\n",
      "Epoch: 1265, Train_loss: 0.0692 / Val_loss: 5.2595\n",
      "Epoch: 1266, Train_loss: 0.0446 / Val_loss: 5.3051\n",
      "Epoch: 1267, Train_loss: 0.0519 / Val_loss: 5.3530\n",
      "Epoch: 1268, Train_loss: 0.0387 / Val_loss: 5.4081\n",
      "Epoch: 1269, Train_loss: 0.0583 / Val_loss: 5.4729\n",
      "Epoch: 1270, Train_loss: 0.0658 / Val_loss: 5.5334\n",
      "Epoch: 1271, Train_loss: 0.0466 / Val_loss: 5.6036\n",
      "Epoch: 1272, Train_loss: 0.0542 / Val_loss: 5.6798\n",
      "Epoch: 1273, Train_loss: 0.0707 / Val_loss: 5.7320\n",
      "Epoch: 1274, Train_loss: 0.0473 / Val_loss: 5.7669\n",
      "Epoch: 1275, Train_loss: 0.0450 / Val_loss: 5.8101\n",
      "Epoch: 1276, Train_loss: 0.0479 / Val_loss: 5.8559\n",
      "Epoch: 1277, Train_loss: 0.0375 / Val_loss: 5.9091\n",
      "Epoch: 1278, Train_loss: 0.0435 / Val_loss: 5.9545\n",
      "Epoch: 1279, Train_loss: 0.0496 / Val_loss: 6.0059\n",
      "Epoch: 1280, Train_loss: 0.0881 / Val_loss: 6.0654\n",
      "Epoch: 1281, Train_loss: 0.0589 / Val_loss: 6.1205\n",
      "Epoch: 1282, Train_loss: 0.0411 / Val_loss: 6.1914\n",
      "Epoch: 1283, Train_loss: 0.0706 / Val_loss: 6.2431\n",
      "Epoch: 1284, Train_loss: 0.0829 / Val_loss: 6.2710\n",
      "Epoch: 1285, Train_loss: 0.0678 / Val_loss: 6.2563\n",
      "Epoch: 1286, Train_loss: 0.0411 / Val_loss: 6.2505\n",
      "Epoch: 1287, Train_loss: 0.0329 / Val_loss: 6.2212\n",
      "Epoch: 1288, Train_loss: 0.0535 / Val_loss: 6.1866\n",
      "Epoch: 1289, Train_loss: 0.0701 / Val_loss: 6.1670\n",
      "Epoch: 1290, Train_loss: 0.0697 / Val_loss: 6.1423\n",
      "Epoch: 1291, Train_loss: 0.0856 / Val_loss: 6.0924\n",
      "Epoch: 1292, Train_loss: 0.0844 / Val_loss: 6.0137\n",
      "Epoch: 1293, Train_loss: 0.0851 / Val_loss: 5.9081\n",
      "Epoch: 1294, Train_loss: 0.0633 / Val_loss: 5.8234\n",
      "Epoch: 1295, Train_loss: 0.0654 / Val_loss: 5.7511\n",
      "Epoch: 1296, Train_loss: 0.0483 / Val_loss: 5.7078\n",
      "Epoch: 1297, Train_loss: 0.0465 / Val_loss: 5.6732\n",
      "Epoch: 1298, Train_loss: 0.0688 / Val_loss: 5.6397\n",
      "Epoch: 1299, Train_loss: 0.1095 / Val_loss: 5.5628\n",
      "Epoch: 1300, Train_loss: 0.0421 / Val_loss: 5.5086\n",
      "Epoch: 1301, Train_loss: 0.0576 / Val_loss: 5.4742\n",
      "Epoch: 1302, Train_loss: 0.0838 / Val_loss: 5.4432\n",
      "Epoch: 1303, Train_loss: 0.0588 / Val_loss: 5.4386\n",
      "Epoch: 1304, Train_loss: 0.0572 / Val_loss: 5.4433\n",
      "Epoch: 1305, Train_loss: 0.0961 / Val_loss: 5.4512\n",
      "Epoch: 1306, Train_loss: 0.0332 / Val_loss: 5.4776\n",
      "Epoch: 1307, Train_loss: 0.0525 / Val_loss: 5.4950\n",
      "Epoch: 1308, Train_loss: 0.0705 / Val_loss: 5.4903\n",
      "Epoch: 1309, Train_loss: 0.0458 / Val_loss: 5.4880\n",
      "Epoch: 1310, Train_loss: 0.0614 / Val_loss: 5.4987\n",
      "Epoch: 1311, Train_loss: 0.0514 / Val_loss: 5.5235\n",
      "Epoch: 1312, Train_loss: 0.0639 / Val_loss: 5.5496\n",
      "Epoch: 1313, Train_loss: 0.0926 / Val_loss: 5.5648\n",
      "Epoch: 1314, Train_loss: 0.0516 / Val_loss: 5.5846\n",
      "Epoch: 1315, Train_loss: 0.0548 / Val_loss: 5.6148\n",
      "Epoch: 1316, Train_loss: 0.0640 / Val_loss: 5.6235\n",
      "Epoch: 1317, Train_loss: 0.0519 / Val_loss: 5.6402\n",
      "Epoch: 1318, Train_loss: 0.0668 / Val_loss: 5.6235\n",
      "Epoch: 1319, Train_loss: 0.0496 / Val_loss: 5.5584\n",
      "Epoch: 1320, Train_loss: 0.1089 / Val_loss: 5.4673\n",
      "Epoch: 1321, Train_loss: 0.0566 / Val_loss: 5.3965\n",
      "Epoch: 1322, Train_loss: 0.0450 / Val_loss: 5.3379\n",
      "Epoch: 1323, Train_loss: 0.0451 / Val_loss: 5.3040\n",
      "Epoch: 1324, Train_loss: 0.0580 / Val_loss: 5.2898\n",
      "Epoch: 1325, Train_loss: 0.0589 / Val_loss: 5.2899\n",
      "Epoch: 1326, Train_loss: 0.0793 / Val_loss: 5.2659\n",
      "Epoch: 1327, Train_loss: 0.0908 / Val_loss: 5.2661\n",
      "Epoch: 1328, Train_loss: 0.0586 / Val_loss: 5.2795\n",
      "Epoch: 1329, Train_loss: 0.0685 / Val_loss: 5.3168\n",
      "Epoch: 1330, Train_loss: 0.0342 / Val_loss: 5.3652\n",
      "Epoch: 1331, Train_loss: 0.0271 / Val_loss: 5.4241\n",
      "Epoch: 1332, Train_loss: 0.0701 / Val_loss: 5.4869\n",
      "Epoch: 1333, Train_loss: 0.0803 / Val_loss: 5.5496\n",
      "Epoch: 1334, Train_loss: 0.0606 / Val_loss: 5.5899\n",
      "Epoch: 1335, Train_loss: 0.0728 / Val_loss: 5.6162\n",
      "Epoch: 1336, Train_loss: 0.0691 / Val_loss: 5.6333\n",
      "Epoch: 1337, Train_loss: 0.0627 / Val_loss: 5.6257\n",
      "Epoch: 1338, Train_loss: 0.0530 / Val_loss: 5.6004\n",
      "Epoch: 1339, Train_loss: 0.0518 / Val_loss: 5.5839\n",
      "Epoch: 1340, Train_loss: 0.0383 / Val_loss: 5.5675\n",
      "Epoch: 1341, Train_loss: 0.0471 / Val_loss: 5.5953\n",
      "Epoch: 1342, Train_loss: 0.0462 / Val_loss: 5.6208\n",
      "Epoch: 1343, Train_loss: 0.0313 / Val_loss: 5.6475\n",
      "Epoch: 1344, Train_loss: 0.0613 / Val_loss: 5.6775\n",
      "Epoch: 1345, Train_loss: 0.0578 / Val_loss: 5.7204\n",
      "Epoch: 1346, Train_loss: 0.0348 / Val_loss: 5.7604\n",
      "Epoch: 1347, Train_loss: 0.0667 / Val_loss: 5.7859\n",
      "Epoch: 1348, Train_loss: 0.0558 / Val_loss: 5.7903\n",
      "Epoch: 1349, Train_loss: 0.0632 / Val_loss: 5.7954\n",
      "Epoch: 1350, Train_loss: 0.0829 / Val_loss: 5.8215\n",
      "Epoch: 1351, Train_loss: 0.0557 / Val_loss: 5.8705\n",
      "Epoch: 1352, Train_loss: 0.0706 / Val_loss: 5.8980\n",
      "Epoch: 1353, Train_loss: 0.0598 / Val_loss: 5.8826\n",
      "Epoch: 1354, Train_loss: 0.0501 / Val_loss: 5.8756\n",
      "Epoch: 1355, Train_loss: 0.0758 / Val_loss: 5.8686\n",
      "Epoch: 1356, Train_loss: 0.0373 / Val_loss: 5.8648\n",
      "Epoch: 1357, Train_loss: 0.0744 / Val_loss: 5.8405\n",
      "Epoch: 1358, Train_loss: 0.0630 / Val_loss: 5.8178\n",
      "Epoch: 1359, Train_loss: 0.0729 / Val_loss: 5.7535\n",
      "Epoch: 1360, Train_loss: 0.0797 / Val_loss: 5.7142\n",
      "Epoch: 1361, Train_loss: 0.0642 / Val_loss: 5.6832\n",
      "Epoch: 1362, Train_loss: 0.0438 / Val_loss: 5.6673\n",
      "Epoch: 1363, Train_loss: 0.0698 / Val_loss: 5.6563\n",
      "Epoch: 1364, Train_loss: 0.0660 / Val_loss: 5.5951\n",
      "Epoch: 1365, Train_loss: 0.0765 / Val_loss: 5.5461\n",
      "Epoch: 1366, Train_loss: 0.0397 / Val_loss: 5.5085\n",
      "Epoch: 1367, Train_loss: 0.0384 / Val_loss: 5.4831\n",
      "Epoch: 1368, Train_loss: 0.0536 / Val_loss: 5.4505\n",
      "Epoch: 1369, Train_loss: 0.0691 / Val_loss: 5.4127\n",
      "Epoch: 1370, Train_loss: 0.0656 / Val_loss: 5.3814\n",
      "Epoch: 1371, Train_loss: 0.0632 / Val_loss: 5.3488\n",
      "Epoch: 1372, Train_loss: 0.0616 / Val_loss: 5.3133\n",
      "Epoch: 1373, Train_loss: 0.0594 / Val_loss: 5.2943\n",
      "Epoch: 1374, Train_loss: 0.0330 / Val_loss: 5.2932\n",
      "Epoch: 1375, Train_loss: 0.0630 / Val_loss: 5.3013\n",
      "Epoch: 1376, Train_loss: 0.0798 / Val_loss: 5.3041\n",
      "Epoch: 1377, Train_loss: 0.0558 / Val_loss: 5.3071\n",
      "Epoch: 1378, Train_loss: 0.0361 / Val_loss: 5.3306\n",
      "Epoch: 1379, Train_loss: 0.0612 / Val_loss: 5.3354\n",
      "Epoch: 1380, Train_loss: 0.0273 / Val_loss: 5.3486\n",
      "Epoch: 1381, Train_loss: 0.0441 / Val_loss: 5.3838\n",
      "Epoch: 1382, Train_loss: 0.0516 / Val_loss: 5.4170\n",
      "Epoch: 1383, Train_loss: 0.0816 / Val_loss: 5.4576\n",
      "Epoch: 1384, Train_loss: 0.0855 / Val_loss: 5.4938\n",
      "Epoch: 1385, Train_loss: 0.0670 / Val_loss: 5.5242\n",
      "Epoch: 1386, Train_loss: 0.0370 / Val_loss: 5.5506\n",
      "Epoch: 1387, Train_loss: 0.0217 / Val_loss: 5.5832\n",
      "Epoch: 1388, Train_loss: 0.0460 / Val_loss: 5.6138\n",
      "Epoch: 1389, Train_loss: 0.0459 / Val_loss: 5.6246\n",
      "Epoch: 1390, Train_loss: 0.0428 / Val_loss: 5.6427\n",
      "Epoch: 1391, Train_loss: 0.0554 / Val_loss: 5.6574\n",
      "Epoch: 1392, Train_loss: 0.0564 / Val_loss: 5.6545\n",
      "Epoch: 1393, Train_loss: 0.0566 / Val_loss: 5.6635\n",
      "Epoch: 1394, Train_loss: 0.0961 / Val_loss: 5.6500\n",
      "Epoch: 1395, Train_loss: 0.1329 / Val_loss: 5.5818\n",
      "Epoch: 1396, Train_loss: 0.0506 / Val_loss: 5.5211\n",
      "Epoch: 1397, Train_loss: 0.0323 / Val_loss: 5.4756\n",
      "Epoch: 1398, Train_loss: 0.0628 / Val_loss: 5.4261\n",
      "Epoch: 1399, Train_loss: 0.0595 / Val_loss: 5.3743\n",
      "Epoch: 1400, Train_loss: 0.0526 / Val_loss: 5.3302\n",
      "Epoch: 1401, Train_loss: 0.0576 / Val_loss: 5.2735\n",
      "Epoch: 1402, Train_loss: 0.0541 / Val_loss: 5.2445\n",
      "Epoch: 1403, Train_loss: 0.0671 / Val_loss: 5.2442\n",
      "Epoch: 1404, Train_loss: 0.0569 / Val_loss: 5.2455\n",
      "Epoch: 1405, Train_loss: 0.0611 / Val_loss: 5.2370\n",
      "Epoch: 1406, Train_loss: 0.0533 / Val_loss: 5.2468\n",
      "Epoch: 1407, Train_loss: 0.0448 / Val_loss: 5.2704\n",
      "Epoch: 1408, Train_loss: 0.0440 / Val_loss: 5.3047\n",
      "Epoch: 1409, Train_loss: 0.0666 / Val_loss: 5.3584\n",
      "Epoch: 1410, Train_loss: 0.0573 / Val_loss: 5.4059\n",
      "Epoch: 1411, Train_loss: 0.0632 / Val_loss: 5.4405\n",
      "Epoch: 1412, Train_loss: 0.0329 / Val_loss: 5.4814\n",
      "Epoch: 1413, Train_loss: 0.0749 / Val_loss: 5.4916\n",
      "Epoch: 1414, Train_loss: 0.0513 / Val_loss: 5.5153\n",
      "Epoch: 1415, Train_loss: 0.0545 / Val_loss: 5.5443\n",
      "Epoch: 1416, Train_loss: 0.0843 / Val_loss: 5.5274\n",
      "Epoch: 1417, Train_loss: 0.0535 / Val_loss: 5.5403\n",
      "Epoch: 1418, Train_loss: 0.0527 / Val_loss: 5.5723\n",
      "Epoch: 1419, Train_loss: 0.0465 / Val_loss: 5.5929\n",
      "Epoch: 1420, Train_loss: 0.0758 / Val_loss: 5.6213\n",
      "Epoch: 1421, Train_loss: 0.0770 / Val_loss: 5.6293\n",
      "Epoch: 1422, Train_loss: 0.0895 / Val_loss: 5.6152\n",
      "Epoch: 1423, Train_loss: 0.0609 / Val_loss: 5.6121\n",
      "Epoch: 1424, Train_loss: 0.0438 / Val_loss: 5.6043\n",
      "Epoch: 1425, Train_loss: 0.0620 / Val_loss: 5.5935\n",
      "Epoch: 1426, Train_loss: 0.0365 / Val_loss: 5.5901\n",
      "Epoch: 1427, Train_loss: 0.0534 / Val_loss: 5.5989\n",
      "Epoch: 1428, Train_loss: 0.0392 / Val_loss: 5.6167\n",
      "Epoch: 1429, Train_loss: 0.0503 / Val_loss: 5.6489\n",
      "Epoch: 1430, Train_loss: 0.0693 / Val_loss: 5.6874\n",
      "Epoch: 1431, Train_loss: 0.0662 / Val_loss: 5.7240\n",
      "Epoch: 1432, Train_loss: 0.0684 / Val_loss: 5.7357\n",
      "Epoch: 1433, Train_loss: 0.0373 / Val_loss: 5.7465\n",
      "Epoch: 1434, Train_loss: 0.0657 / Val_loss: 5.7493\n",
      "Epoch: 1435, Train_loss: 0.0350 / Val_loss: 5.7508\n",
      "Epoch: 1436, Train_loss: 0.0413 / Val_loss: 5.7472\n",
      "Epoch: 1437, Train_loss: 0.0439 / Val_loss: 5.7546\n",
      "Epoch: 1438, Train_loss: 0.0810 / Val_loss: 5.7565\n",
      "Epoch: 1439, Train_loss: 0.0645 / Val_loss: 5.7465\n",
      "Epoch: 1440, Train_loss: 0.0470 / Val_loss: 5.7516\n",
      "Epoch: 1441, Train_loss: 0.0450 / Val_loss: 5.7741\n",
      "Epoch: 1442, Train_loss: 0.0868 / Val_loss: 5.8127\n",
      "Epoch: 1443, Train_loss: 0.0872 / Val_loss: 5.8455\n",
      "Epoch: 1444, Train_loss: 0.0718 / Val_loss: 5.8903\n",
      "Epoch: 1445, Train_loss: 0.0475 / Val_loss: 5.9396\n",
      "Epoch: 1446, Train_loss: 0.0407 / Val_loss: 5.9779\n",
      "Epoch: 1447, Train_loss: 0.0349 / Val_loss: 6.0031\n",
      "Epoch: 1448, Train_loss: 0.0353 / Val_loss: 6.0267\n",
      "Epoch: 1449, Train_loss: 0.0658 / Val_loss: 6.0117\n",
      "Epoch: 1450, Train_loss: 0.0712 / Val_loss: 5.9938\n",
      "Epoch: 1451, Train_loss: 0.0600 / Val_loss: 5.9650\n",
      "Epoch: 1452, Train_loss: 0.0486 / Val_loss: 5.9591\n",
      "Epoch: 1453, Train_loss: 0.0656 / Val_loss: 5.9547\n",
      "Epoch: 1454, Train_loss: 0.0624 / Val_loss: 5.9348\n",
      "Epoch: 1455, Train_loss: 0.0284 / Val_loss: 5.9369\n",
      "Epoch: 1456, Train_loss: 0.0463 / Val_loss: 5.9443\n",
      "Epoch: 1457, Train_loss: 0.0454 / Val_loss: 5.9415\n",
      "Epoch: 1458, Train_loss: 0.0524 / Val_loss: 5.9492\n",
      "Epoch: 1459, Train_loss: 0.0391 / Val_loss: 5.9698\n",
      "Epoch: 1460, Train_loss: 0.0712 / Val_loss: 5.9601\n",
      "Epoch: 1461, Train_loss: 0.0610 / Val_loss: 5.9310\n",
      "Epoch: 1462, Train_loss: 0.0213 / Val_loss: 5.9133\n",
      "Epoch: 1463, Train_loss: 0.0534 / Val_loss: 5.9080\n",
      "Epoch: 1464, Train_loss: 0.0410 / Val_loss: 5.9142\n",
      "Epoch: 1465, Train_loss: 0.0502 / Val_loss: 5.9346\n",
      "Epoch: 1466, Train_loss: 0.0326 / Val_loss: 5.9662\n",
      "Epoch: 1467, Train_loss: 0.0401 / Val_loss: 5.9981\n",
      "Epoch: 1468, Train_loss: 0.0264 / Val_loss: 6.0435\n",
      "Epoch: 1469, Train_loss: 0.0335 / Val_loss: 6.0922\n",
      "Epoch: 1470, Train_loss: 0.0426 / Val_loss: 6.1487\n",
      "Epoch: 1471, Train_loss: 0.0363 / Val_loss: 6.2223\n",
      "Epoch: 1472, Train_loss: 0.0507 / Val_loss: 6.2990\n",
      "Epoch: 1473, Train_loss: 0.0677 / Val_loss: 6.3759\n",
      "Epoch: 1474, Train_loss: 0.0397 / Val_loss: 6.4301\n",
      "Epoch: 1475, Train_loss: 0.0559 / Val_loss: 6.5043\n",
      "Epoch: 1476, Train_loss: 0.0704 / Val_loss: 6.5855\n",
      "Epoch: 1477, Train_loss: 0.0411 / Val_loss: 6.6707\n",
      "Epoch: 1478, Train_loss: 0.0733 / Val_loss: 6.7051\n",
      "Epoch: 1479, Train_loss: 0.0380 / Val_loss: 6.7375\n",
      "Epoch: 1480, Train_loss: 0.0431 / Val_loss: 6.7509\n",
      "Epoch: 1481, Train_loss: 0.0427 / Val_loss: 6.7425\n",
      "Epoch: 1482, Train_loss: 0.0794 / Val_loss: 6.7544\n",
      "Epoch: 1483, Train_loss: 0.0408 / Val_loss: 6.7591\n",
      "Epoch: 1484, Train_loss: 0.0626 / Val_loss: 6.7391\n",
      "Epoch: 1485, Train_loss: 0.0502 / Val_loss: 6.7054\n",
      "Epoch: 1486, Train_loss: 0.0231 / Val_loss: 6.6973\n",
      "Epoch: 1487, Train_loss: 0.0410 / Val_loss: 6.7007\n",
      "Epoch: 1488, Train_loss: 0.0250 / Val_loss: 6.7188\n",
      "Epoch: 1489, Train_loss: 0.0300 / Val_loss: 6.7531\n",
      "Epoch: 1490, Train_loss: 0.0718 / Val_loss: 6.7906\n",
      "Epoch: 1491, Train_loss: 0.0413 / Val_loss: 6.8448\n",
      "Epoch: 1492, Train_loss: 0.0805 / Val_loss: 6.8725\n",
      "Epoch: 1493, Train_loss: 0.0635 / Val_loss: 6.9160\n",
      "Epoch: 1494, Train_loss: 0.0483 / Val_loss: 6.9487\n",
      "Epoch: 1495, Train_loss: 0.0902 / Val_loss: 6.9152\n",
      "Epoch: 1496, Train_loss: 0.0321 / Val_loss: 6.8772\n",
      "Epoch: 1497, Train_loss: 0.0590 / Val_loss: 6.8475\n",
      "Epoch: 1498, Train_loss: 0.0549 / Val_loss: 6.7677\n",
      "Epoch: 1499, Train_loss: 0.0579 / Val_loss: 6.6782\n",
      "Epoch: 1500, Train_loss: 0.0304 / Val_loss: 6.6045\n",
      "Epoch: 1501, Train_loss: 0.0348 / Val_loss: 6.5444\n",
      "Epoch: 1502, Train_loss: 0.0407 / Val_loss: 6.4826\n",
      "Epoch: 1503, Train_loss: 0.0369 / Val_loss: 6.4343\n",
      "Epoch: 1504, Train_loss: 0.0507 / Val_loss: 6.4005\n",
      "Epoch: 1505, Train_loss: 0.0500 / Val_loss: 6.3614\n",
      "Epoch: 1506, Train_loss: 0.0326 / Val_loss: 6.3408\n",
      "Epoch: 1507, Train_loss: 0.0315 / Val_loss: 6.3314\n",
      "Epoch: 1508, Train_loss: 0.0304 / Val_loss: 6.3292\n",
      "Epoch: 1509, Train_loss: 0.0242 / Val_loss: 6.3408\n",
      "Epoch: 1510, Train_loss: 0.0569 / Val_loss: 6.3340\n",
      "Epoch: 1511, Train_loss: 0.0450 / Val_loss: 6.3370\n",
      "Epoch: 1512, Train_loss: 0.0092 / Val_loss: 6.3535\n",
      "Epoch: 1513, Train_loss: 0.0793 / Val_loss: 6.3781\n",
      "Epoch: 1514, Train_loss: 0.0599 / Val_loss: 6.4152\n",
      "Epoch: 1515, Train_loss: 0.0252 / Val_loss: 6.4551\n",
      "Epoch: 1516, Train_loss: 0.0631 / Val_loss: 6.4894\n",
      "Epoch: 1517, Train_loss: 0.0499 / Val_loss: 6.5223\n",
      "Epoch: 1518, Train_loss: 0.0526 / Val_loss: 6.5468\n",
      "Epoch: 1519, Train_loss: 0.0510 / Val_loss: 6.5828\n",
      "Epoch: 1520, Train_loss: 0.0291 / Val_loss: 6.6196\n",
      "Epoch: 1521, Train_loss: 0.0496 / Val_loss: 6.6359\n",
      "Epoch: 1522, Train_loss: 0.0380 / Val_loss: 6.6666\n",
      "Epoch: 1523, Train_loss: 0.0279 / Val_loss: 6.7038\n",
      "Epoch: 1524, Train_loss: 0.0442 / Val_loss: 6.7576\n",
      "Epoch: 1525, Train_loss: 0.0875 / Val_loss: 6.8148\n",
      "Epoch: 1526, Train_loss: 0.0367 / Val_loss: 6.8862\n",
      "Epoch: 1527, Train_loss: 0.0515 / Val_loss: 6.9617\n",
      "Epoch: 1528, Train_loss: 0.0352 / Val_loss: 7.0322\n",
      "Epoch: 1529, Train_loss: 0.0502 / Val_loss: 7.1071\n",
      "Epoch: 1530, Train_loss: 0.0428 / Val_loss: 7.1427\n",
      "Epoch: 1531, Train_loss: 0.0343 / Val_loss: 7.1674\n",
      "Epoch: 1532, Train_loss: 0.0489 / Val_loss: 7.1741\n",
      "Epoch: 1533, Train_loss: 0.0560 / Val_loss: 7.1800\n",
      "Epoch: 1534, Train_loss: 0.0789 / Val_loss: 7.1133\n",
      "Epoch: 1535, Train_loss: 0.0333 / Val_loss: 7.0537\n",
      "Epoch: 1536, Train_loss: 0.0579 / Val_loss: 7.0228\n",
      "Epoch: 1537, Train_loss: 0.0361 / Val_loss: 7.0284\n",
      "Epoch: 1538, Train_loss: 0.0288 / Val_loss: 7.0374\n",
      "Epoch: 1539, Train_loss: 0.0472 / Val_loss: 7.0376\n",
      "Epoch: 1540, Train_loss: 0.0217 / Val_loss: 7.0444\n",
      "Epoch: 1541, Train_loss: 0.0576 / Val_loss: 7.0598\n",
      "Epoch: 1542, Train_loss: 0.0423 / Val_loss: 7.0816\n",
      "Epoch: 1543, Train_loss: 0.0603 / Val_loss: 7.0779\n",
      "Epoch: 1544, Train_loss: 0.0382 / Val_loss: 7.0887\n",
      "Epoch: 1545, Train_loss: 0.0633 / Val_loss: 7.0735\n",
      "Epoch: 1546, Train_loss: 0.0198 / Val_loss: 7.0640\n",
      "Epoch: 1547, Train_loss: 0.0851 / Val_loss: 7.0220\n",
      "Epoch: 1548, Train_loss: 0.0561 / Val_loss: 6.9717\n",
      "Epoch: 1549, Train_loss: 0.0344 / Val_loss: 6.9256\n",
      "Epoch: 1550, Train_loss: 0.0554 / Val_loss: 6.8669\n",
      "Epoch: 1551, Train_loss: 0.0436 / Val_loss: 6.8294\n",
      "Epoch: 1552, Train_loss: 0.0292 / Val_loss: 6.8228\n",
      "Epoch: 1553, Train_loss: 0.0404 / Val_loss: 6.8114\n",
      "Epoch: 1554, Train_loss: 0.0374 / Val_loss: 6.8046\n",
      "Epoch: 1555, Train_loss: 0.0495 / Val_loss: 6.8011\n",
      "Epoch: 1556, Train_loss: 0.0395 / Val_loss: 6.8037\n",
      "Epoch: 1557, Train_loss: 0.0441 / Val_loss: 6.8308\n",
      "Epoch: 1558, Train_loss: 0.0914 / Val_loss: 6.8534\n",
      "Epoch: 1559, Train_loss: 0.0435 / Val_loss: 6.8970\n",
      "Epoch: 1560, Train_loss: 0.0532 / Val_loss: 6.9256\n",
      "Epoch: 1561, Train_loss: 0.0499 / Val_loss: 6.9751\n",
      "Epoch: 1562, Train_loss: 0.0332 / Val_loss: 7.0209\n",
      "Epoch: 1563, Train_loss: 0.0638 / Val_loss: 7.0579\n",
      "Epoch: 1564, Train_loss: 0.0375 / Val_loss: 7.0895\n",
      "Epoch: 1565, Train_loss: 0.0576 / Val_loss: 7.1178\n",
      "Epoch: 1566, Train_loss: 0.0327 / Val_loss: 7.1345\n",
      "Epoch: 1567, Train_loss: 0.0474 / Val_loss: 7.1559\n",
      "Epoch: 1568, Train_loss: 0.0426 / Val_loss: 7.1293\n",
      "Epoch: 1569, Train_loss: 0.0531 / Val_loss: 7.0732\n",
      "Epoch: 1570, Train_loss: 0.0632 / Val_loss: 6.9963\n",
      "Epoch: 1571, Train_loss: 0.0513 / Val_loss: 6.9230\n",
      "Epoch: 1572, Train_loss: 0.0242 / Val_loss: 6.8758\n",
      "Epoch: 1573, Train_loss: 0.0327 / Val_loss: 6.8493\n",
      "Epoch: 1574, Train_loss: 0.0178 / Val_loss: 6.8369\n",
      "Epoch: 1575, Train_loss: 0.0521 / Val_loss: 6.8226\n",
      "Epoch: 1576, Train_loss: 0.0469 / Val_loss: 6.8298\n",
      "Epoch: 1577, Train_loss: 0.0270 / Val_loss: 6.8481\n",
      "Epoch: 1578, Train_loss: 0.0464 / Val_loss: 6.8870\n",
      "Epoch: 1579, Train_loss: 0.0196 / Val_loss: 6.9366\n",
      "Epoch: 1580, Train_loss: 0.0402 / Val_loss: 7.0140\n",
      "Epoch: 1581, Train_loss: 0.0630 / Val_loss: 7.0560\n",
      "Epoch: 1582, Train_loss: 0.0269 / Val_loss: 7.1097\n",
      "Epoch: 1583, Train_loss: 0.0617 / Val_loss: 7.1493\n",
      "Epoch: 1584, Train_loss: 0.0555 / Val_loss: 7.1596\n",
      "Epoch: 1585, Train_loss: 0.0185 / Val_loss: 7.1864\n",
      "Epoch: 1586, Train_loss: 0.0241 / Val_loss: 7.2220\n",
      "Epoch: 1587, Train_loss: 0.0384 / Val_loss: 7.2622\n",
      "Epoch: 1588, Train_loss: 0.0287 / Val_loss: 7.3192\n",
      "Epoch: 1589, Train_loss: 0.0361 / Val_loss: 7.3554\n",
      "Epoch: 1590, Train_loss: 0.0417 / Val_loss: 7.4106\n",
      "Epoch: 1591, Train_loss: 0.0420 / Val_loss: 7.4490\n",
      "Epoch: 1592, Train_loss: 0.0790 / Val_loss: 7.4555\n",
      "Epoch: 1593, Train_loss: 0.0303 / Val_loss: 7.4648\n",
      "Epoch: 1594, Train_loss: 0.0394 / Val_loss: 7.4611\n",
      "Epoch: 1595, Train_loss: 0.0648 / Val_loss: 7.4496\n",
      "Epoch: 1596, Train_loss: 0.0401 / Val_loss: 7.4351\n",
      "Epoch: 1597, Train_loss: 0.0368 / Val_loss: 7.4083\n",
      "Epoch: 1598, Train_loss: 0.0442 / Val_loss: 7.3856\n",
      "Epoch: 1599, Train_loss: 0.0408 / Val_loss: 7.3652\n",
      "Epoch: 1600, Train_loss: 0.0432 / Val_loss: 7.3510\n",
      "Epoch: 1601, Train_loss: 0.0283 / Val_loss: 7.3587\n",
      "Epoch: 1602, Train_loss: 0.0517 / Val_loss: 7.3239\n",
      "Epoch: 1603, Train_loss: 0.0367 / Val_loss: 7.2942\n",
      "Epoch: 1604, Train_loss: 0.0601 / Val_loss: 7.2559\n",
      "Epoch: 1605, Train_loss: 0.0272 / Val_loss: 7.2305\n",
      "Epoch: 1606, Train_loss: 0.0790 / Val_loss: 7.1800\n",
      "Epoch: 1607, Train_loss: 0.0496 / Val_loss: 7.1437\n",
      "Epoch: 1608, Train_loss: 0.0272 / Val_loss: 7.1187\n",
      "Epoch: 1609, Train_loss: 0.0334 / Val_loss: 7.0962\n",
      "Epoch: 1610, Train_loss: 0.0433 / Val_loss: 7.0727\n",
      "Epoch: 1611, Train_loss: 0.0306 / Val_loss: 7.0708\n",
      "Epoch: 1612, Train_loss: 0.0404 / Val_loss: 7.0493\n",
      "Epoch: 1613, Train_loss: 0.0340 / Val_loss: 7.0422\n",
      "Epoch: 1614, Train_loss: 0.0796 / Val_loss: 7.0322\n",
      "Epoch: 1615, Train_loss: 0.0314 / Val_loss: 7.0160\n",
      "Epoch: 1616, Train_loss: 0.0359 / Val_loss: 6.9903\n",
      "Epoch: 1617, Train_loss: 0.0236 / Val_loss: 6.9775\n",
      "Epoch: 1618, Train_loss: 0.0302 / Val_loss: 6.9641\n",
      "Epoch: 1619, Train_loss: 0.0456 / Val_loss: 6.9727\n",
      "Epoch: 1620, Train_loss: 0.0602 / Val_loss: 6.9859\n",
      "Epoch: 1621, Train_loss: 0.0366 / Val_loss: 6.9991\n",
      "Epoch: 1622, Train_loss: 0.0251 / Val_loss: 7.0359\n",
      "Epoch: 1623, Train_loss: 0.0394 / Val_loss: 7.0468\n",
      "Epoch: 1624, Train_loss: 0.0489 / Val_loss: 7.0493\n",
      "Epoch: 1625, Train_loss: 0.0302 / Val_loss: 7.0670\n",
      "Epoch: 1626, Train_loss: 0.0362 / Val_loss: 7.0734\n",
      "Epoch: 1627, Train_loss: 0.0245 / Val_loss: 7.0810\n",
      "Epoch: 1628, Train_loss: 0.0343 / Val_loss: 7.0950\n",
      "Epoch: 1629, Train_loss: 0.0273 / Val_loss: 7.1324\n",
      "Epoch: 1630, Train_loss: 0.0280 / Val_loss: 7.1822\n",
      "Epoch: 1631, Train_loss: 0.0669 / Val_loss: 7.2213\n",
      "Epoch: 1632, Train_loss: 0.0247 / Val_loss: 7.2550\n",
      "Epoch: 1633, Train_loss: 0.0326 / Val_loss: 7.2578\n",
      "Epoch: 1634, Train_loss: 0.0433 / Val_loss: 7.2542\n",
      "Epoch: 1635, Train_loss: 0.0483 / Val_loss: 7.2145\n",
      "Epoch: 1636, Train_loss: 0.0370 / Val_loss: 7.1828\n",
      "Epoch: 1637, Train_loss: 0.0290 / Val_loss: 7.1548\n",
      "Epoch: 1638, Train_loss: 0.0969 / Val_loss: 7.0758\n",
      "Epoch: 1639, Train_loss: 0.0380 / Val_loss: 7.0316\n",
      "Epoch: 1640, Train_loss: 0.0399 / Val_loss: 6.9846\n",
      "Epoch: 1641, Train_loss: 0.0255 / Val_loss: 6.9742\n",
      "Epoch: 1642, Train_loss: 0.0408 / Val_loss: 6.9706\n",
      "Epoch: 1643, Train_loss: 0.0654 / Val_loss: 6.9843\n",
      "Epoch: 1644, Train_loss: 0.0419 / Val_loss: 6.9997\n",
      "Epoch: 1645, Train_loss: 0.0319 / Val_loss: 7.0193\n",
      "Epoch: 1646, Train_loss: 0.0320 / Val_loss: 7.0536\n",
      "Epoch: 1647, Train_loss: 0.0553 / Val_loss: 7.0945\n",
      "Epoch: 1648, Train_loss: 0.0804 / Val_loss: 7.1307\n",
      "Epoch: 1649, Train_loss: 0.0777 / Val_loss: 7.1217\n",
      "Epoch: 1650, Train_loss: 0.0202 / Val_loss: 7.1060\n",
      "Epoch: 1651, Train_loss: 0.0561 / Val_loss: 7.0624\n",
      "Epoch: 1652, Train_loss: 0.0471 / Val_loss: 7.0394\n",
      "Epoch: 1653, Train_loss: 0.0393 / Val_loss: 7.0272\n",
      "Epoch: 1654, Train_loss: 0.0410 / Val_loss: 6.9955\n",
      "Epoch: 1655, Train_loss: 0.0328 / Val_loss: 6.9644\n",
      "Epoch: 1656, Train_loss: 0.0488 / Val_loss: 6.9465\n",
      "Epoch: 1657, Train_loss: 0.0499 / Val_loss: 6.9364\n",
      "Epoch: 1658, Train_loss: 0.0552 / Val_loss: 6.9157\n",
      "Epoch: 1659, Train_loss: 0.0510 / Val_loss: 6.9283\n",
      "Epoch: 1660, Train_loss: 0.0286 / Val_loss: 6.9571\n",
      "Epoch: 1661, Train_loss: 0.0330 / Val_loss: 7.0022\n",
      "Epoch: 1662, Train_loss: 0.0396 / Val_loss: 7.0594\n",
      "Epoch: 1663, Train_loss: 0.0331 / Val_loss: 7.1197\n",
      "Epoch: 1664, Train_loss: 0.0392 / Val_loss: 7.1537\n",
      "Epoch: 1665, Train_loss: 0.0395 / Val_loss: 7.1950\n",
      "Epoch: 1666, Train_loss: 0.0440 / Val_loss: 7.2324\n",
      "Epoch: 1667, Train_loss: 0.0468 / Val_loss: 7.2499\n",
      "Epoch: 1668, Train_loss: 0.0402 / Val_loss: 7.2562\n",
      "Epoch: 1669, Train_loss: 0.0397 / Val_loss: 7.2599\n",
      "Epoch: 1670, Train_loss: 0.0545 / Val_loss: 7.2690\n",
      "Epoch: 1671, Train_loss: 0.0132 / Val_loss: 7.2858\n",
      "Epoch: 1672, Train_loss: 0.0206 / Val_loss: 7.3115\n",
      "Epoch: 1673, Train_loss: 0.0316 / Val_loss: 7.3452\n",
      "Epoch: 1674, Train_loss: 0.0360 / Val_loss: 7.3799\n",
      "Epoch: 1675, Train_loss: 0.0681 / Val_loss: 7.3842\n",
      "Epoch: 1676, Train_loss: 0.0360 / Val_loss: 7.3968\n",
      "Epoch: 1677, Train_loss: 0.0570 / Val_loss: 7.4221\n",
      "Epoch: 1678, Train_loss: 0.0277 / Val_loss: 7.4621\n",
      "Epoch: 1679, Train_loss: 0.0595 / Val_loss: 7.5007\n",
      "Epoch: 1680, Train_loss: 0.0343 / Val_loss: 7.5566\n",
      "Epoch: 1681, Train_loss: 0.0717 / Val_loss: 7.6382\n",
      "Epoch: 1682, Train_loss: 0.0367 / Val_loss: 7.7285\n",
      "Epoch: 1683, Train_loss: 0.0349 / Val_loss: 7.8235\n",
      "Epoch: 1684, Train_loss: 0.0149 / Val_loss: 7.9275\n",
      "Epoch: 1685, Train_loss: 0.0408 / Val_loss: 7.9739\n",
      "Epoch: 1686, Train_loss: 0.0455 / Val_loss: 8.0013\n",
      "Epoch: 1687, Train_loss: 0.0483 / Val_loss: 8.0148\n",
      "Epoch: 1688, Train_loss: 0.0192 / Val_loss: 8.0419\n",
      "Epoch: 1689, Train_loss: 0.0421 / Val_loss: 8.0607\n",
      "Epoch: 1690, Train_loss: 0.0426 / Val_loss: 8.0562\n",
      "Epoch: 1691, Train_loss: 0.0695 / Val_loss: 7.9867\n",
      "Epoch: 1692, Train_loss: 0.0375 / Val_loss: 7.9480\n",
      "Epoch: 1693, Train_loss: 0.0478 / Val_loss: 7.9139\n",
      "Epoch: 1694, Train_loss: 0.0514 / Val_loss: 7.8887\n",
      "Epoch: 1695, Train_loss: 0.0250 / Val_loss: 7.8693\n",
      "Epoch: 1696, Train_loss: 0.0405 / Val_loss: 7.8257\n",
      "Epoch: 1697, Train_loss: 0.0169 / Val_loss: 7.7844\n",
      "Epoch: 1698, Train_loss: 0.0238 / Val_loss: 7.7561\n",
      "Epoch: 1699, Train_loss: 0.0746 / Val_loss: 7.7235\n",
      "Epoch: 1700, Train_loss: 0.0263 / Val_loss: 7.7119\n",
      "Epoch: 1701, Train_loss: 0.0293 / Val_loss: 7.7342\n",
      "Epoch: 1702, Train_loss: 0.0494 / Val_loss: 7.7746\n",
      "Epoch: 1703, Train_loss: 0.0390 / Val_loss: 7.8274\n",
      "Epoch: 1704, Train_loss: 0.0425 / Val_loss: 7.8563\n",
      "Epoch: 1705, Train_loss: 0.0359 / Val_loss: 7.8909\n",
      "Epoch: 1706, Train_loss: 0.0586 / Val_loss: 7.8939\n",
      "Epoch: 1707, Train_loss: 0.0805 / Val_loss: 7.8793\n",
      "Epoch: 1708, Train_loss: 0.0499 / Val_loss: 7.8963\n",
      "Epoch: 1709, Train_loss: 0.0278 / Val_loss: 7.9178\n",
      "Epoch: 1710, Train_loss: 0.0281 / Val_loss: 7.9496\n",
      "Epoch: 1711, Train_loss: 0.0324 / Val_loss: 7.9670\n",
      "Epoch: 1712, Train_loss: 0.0207 / Val_loss: 7.9814\n",
      "Epoch: 1713, Train_loss: 0.0565 / Val_loss: 7.9589\n",
      "Epoch: 1714, Train_loss: 0.0348 / Val_loss: 7.9106\n",
      "Epoch: 1715, Train_loss: 0.0399 / Val_loss: 7.8794\n",
      "Epoch: 1716, Train_loss: 0.0379 / Val_loss: 7.8592\n",
      "Epoch: 1717, Train_loss: 0.0405 / Val_loss: 7.8082\n",
      "Epoch: 1718, Train_loss: 0.0349 / Val_loss: 7.7694\n",
      "Epoch: 1719, Train_loss: 0.0208 / Val_loss: 7.7498\n",
      "Epoch: 1720, Train_loss: 0.0406 / Val_loss: 7.7393\n",
      "Epoch: 1721, Train_loss: 0.0294 / Val_loss: 7.7089\n",
      "Epoch: 1722, Train_loss: 0.0539 / Val_loss: 7.6826\n",
      "Epoch: 1723, Train_loss: 0.0590 / Val_loss: 7.6684\n",
      "Epoch: 1724, Train_loss: 0.0244 / Val_loss: 7.6734\n",
      "Epoch: 1725, Train_loss: 0.0429 / Val_loss: 7.6731\n",
      "Epoch: 1726, Train_loss: 0.0346 / Val_loss: 7.6809\n",
      "Epoch: 1727, Train_loss: 0.0503 / Val_loss: 7.6847\n",
      "Epoch: 1728, Train_loss: 0.0175 / Val_loss: 7.6911\n",
      "Epoch: 1729, Train_loss: 0.0568 / Val_loss: 7.7197\n",
      "Epoch: 1730, Train_loss: 0.0263 / Val_loss: 7.7685\n",
      "Epoch: 1731, Train_loss: 0.0717 / Val_loss: 7.7809\n",
      "Epoch: 1732, Train_loss: 0.0287 / Val_loss: 7.8057\n",
      "Epoch: 1733, Train_loss: 0.0312 / Val_loss: 7.8535\n",
      "Epoch: 1734, Train_loss: 0.0434 / Val_loss: 7.9158\n",
      "Epoch: 1735, Train_loss: 0.0307 / Val_loss: 7.9928\n",
      "Epoch: 1736, Train_loss: 0.0215 / Val_loss: 8.0689\n",
      "Epoch: 1737, Train_loss: 0.0484 / Val_loss: 8.1414\n",
      "Epoch: 1738, Train_loss: 0.0226 / Val_loss: 8.1993\n",
      "Epoch: 1739, Train_loss: 0.0150 / Val_loss: 8.2585\n",
      "Epoch: 1740, Train_loss: 0.0197 / Val_loss: 8.3133\n",
      "Epoch: 1741, Train_loss: 0.0245 / Val_loss: 8.3819\n",
      "Epoch: 1742, Train_loss: 0.0582 / Val_loss: 8.4056\n",
      "Epoch: 1743, Train_loss: 0.0265 / Val_loss: 8.4241\n",
      "Epoch: 1744, Train_loss: 0.0211 / Val_loss: 8.4387\n",
      "Epoch: 1745, Train_loss: 0.0543 / Val_loss: 8.4309\n",
      "Epoch: 1746, Train_loss: 0.0171 / Val_loss: 8.4253\n",
      "Epoch: 1747, Train_loss: 0.0255 / Val_loss: 8.4275\n",
      "Epoch: 1748, Train_loss: 0.0294 / Val_loss: 8.4068\n",
      "Epoch: 1749, Train_loss: 0.0245 / Val_loss: 8.4004\n",
      "Epoch: 1750, Train_loss: 0.0312 / Val_loss: 8.4016\n",
      "Epoch: 1751, Train_loss: 0.0133 / Val_loss: 8.4221\n",
      "Epoch: 1752, Train_loss: 0.0884 / Val_loss: 8.4243\n",
      "Epoch: 1753, Train_loss: 0.0350 / Val_loss: 8.4452\n",
      "Epoch: 1754, Train_loss: 0.0487 / Val_loss: 8.4435\n",
      "Epoch: 1755, Train_loss: 0.0380 / Val_loss: 8.4582\n",
      "Epoch: 1756, Train_loss: 0.0327 / Val_loss: 8.4818\n",
      "Epoch: 1757, Train_loss: 0.0294 / Val_loss: 8.5152\n",
      "Epoch: 1758, Train_loss: 0.0530 / Val_loss: 8.5290\n",
      "Epoch: 1759, Train_loss: 0.0334 / Val_loss: 8.5467\n",
      "Epoch: 1760, Train_loss: 0.0453 / Val_loss: 8.5874\n",
      "Epoch: 1761, Train_loss: 0.0573 / Val_loss: 8.6282\n",
      "Epoch: 1762, Train_loss: 0.0343 / Val_loss: 8.6615\n",
      "Epoch: 1763, Train_loss: 0.0575 / Val_loss: 8.6697\n",
      "Epoch: 1764, Train_loss: 0.0274 / Val_loss: 8.6512\n",
      "Epoch: 1765, Train_loss: 0.0312 / Val_loss: 8.6225\n",
      "Epoch: 1766, Train_loss: 0.0474 / Val_loss: 8.6248\n",
      "Epoch: 1767, Train_loss: 0.0283 / Val_loss: 8.5909\n",
      "Epoch: 1768, Train_loss: 0.0349 / Val_loss: 8.5513\n",
      "Epoch: 1769, Train_loss: 0.0298 / Val_loss: 8.5163\n",
      "Epoch: 1770, Train_loss: 0.0252 / Val_loss: 8.4921\n",
      "Epoch: 1771, Train_loss: 0.0658 / Val_loss: 8.4858\n",
      "Epoch: 1772, Train_loss: 0.0576 / Val_loss: 8.4545\n",
      "Epoch: 1773, Train_loss: 0.0342 / Val_loss: 8.4343\n",
      "Epoch: 1774, Train_loss: 0.0584 / Val_loss: 8.4181\n",
      "Epoch: 1775, Train_loss: 0.0283 / Val_loss: 8.4295\n",
      "Epoch: 1776, Train_loss: 0.0466 / Val_loss: 8.4545\n",
      "Epoch: 1777, Train_loss: 0.0243 / Val_loss: 8.4837\n",
      "Epoch: 1778, Train_loss: 0.0398 / Val_loss: 8.4715\n",
      "Epoch: 1779, Train_loss: 0.0169 / Val_loss: 8.4660\n",
      "Epoch: 1780, Train_loss: 0.0206 / Val_loss: 8.4627\n",
      "Epoch: 1781, Train_loss: 0.0397 / Val_loss: 8.4816\n",
      "Epoch: 1782, Train_loss: 0.0249 / Val_loss: 8.5232\n",
      "Epoch: 1783, Train_loss: 0.0448 / Val_loss: 8.5278\n",
      "Epoch: 1784, Train_loss: 0.0173 / Val_loss: 8.5512\n",
      "Epoch: 1785, Train_loss: 0.0413 / Val_loss: 8.5511\n",
      "Epoch: 1786, Train_loss: 0.0546 / Val_loss: 8.5490\n",
      "Epoch: 1787, Train_loss: 0.0223 / Val_loss: 8.5622\n",
      "Epoch: 1788, Train_loss: 0.0289 / Val_loss: 8.5539\n",
      "Epoch: 1789, Train_loss: 0.0261 / Val_loss: 8.5526\n",
      "Epoch: 1790, Train_loss: 0.0414 / Val_loss: 8.5874\n",
      "Epoch: 1791, Train_loss: 0.0457 / Val_loss: 8.6112\n",
      "Epoch: 1792, Train_loss: 0.0335 / Val_loss: 8.6499\n",
      "Epoch: 1793, Train_loss: 0.0475 / Val_loss: 8.6738\n",
      "Epoch: 1794, Train_loss: 0.0274 / Val_loss: 8.6910\n",
      "Epoch: 1795, Train_loss: 0.0373 / Val_loss: 8.6921\n",
      "Epoch: 1796, Train_loss: 0.0276 / Val_loss: 8.7096\n",
      "Epoch: 1797, Train_loss: 0.0438 / Val_loss: 8.7471\n",
      "Epoch: 1798, Train_loss: 0.0297 / Val_loss: 8.7773\n",
      "Epoch: 1799, Train_loss: 0.0377 / Val_loss: 8.8033\n",
      "Epoch: 1800, Train_loss: 0.0668 / Val_loss: 8.7381\n",
      "Epoch: 1801, Train_loss: 0.0201 / Val_loss: 8.7081\n",
      "Epoch: 1802, Train_loss: 0.0248 / Val_loss: 8.7056\n",
      "Epoch: 1803, Train_loss: 0.0356 / Val_loss: 8.7300\n",
      "Epoch: 1804, Train_loss: 0.0227 / Val_loss: 8.7443\n",
      "Epoch: 1805, Train_loss: 0.0497 / Val_loss: 8.7720\n",
      "Epoch: 1806, Train_loss: 0.0515 / Val_loss: 8.7929\n",
      "Epoch: 1807, Train_loss: 0.0185 / Val_loss: 8.8150\n",
      "Epoch: 1808, Train_loss: 0.0209 / Val_loss: 8.8412\n",
      "Epoch: 1809, Train_loss: 0.0155 / Val_loss: 8.8813\n",
      "Epoch: 1810, Train_loss: 0.0744 / Val_loss: 8.8793\n",
      "Epoch: 1811, Train_loss: 0.0551 / Val_loss: 8.8843\n",
      "Epoch: 1812, Train_loss: 0.0518 / Val_loss: 8.8526\n",
      "Epoch: 1813, Train_loss: 0.0401 / Val_loss: 8.8268\n",
      "Epoch: 1814, Train_loss: 0.0313 / Val_loss: 8.7917\n",
      "Epoch: 1815, Train_loss: 0.0553 / Val_loss: 8.7297\n",
      "Epoch: 1816, Train_loss: 0.0199 / Val_loss: 8.6863\n",
      "Epoch: 1817, Train_loss: 0.0508 / Val_loss: 8.6211\n",
      "Epoch: 1818, Train_loss: 0.0291 / Val_loss: 8.5684\n",
      "Epoch: 1819, Train_loss: 0.0201 / Val_loss: 8.5215\n",
      "Epoch: 1820, Train_loss: 0.0419 / Val_loss: 8.4911\n",
      "Epoch: 1821, Train_loss: 0.0159 / Val_loss: 8.4723\n",
      "Epoch: 1822, Train_loss: 0.0377 / Val_loss: 8.4623\n",
      "Epoch: 1823, Train_loss: 0.0408 / Val_loss: 8.4465\n",
      "Epoch: 1824, Train_loss: 0.0311 / Val_loss: 8.4062\n",
      "Epoch: 1825, Train_loss: 0.0265 / Val_loss: 8.3804\n",
      "Epoch: 1826, Train_loss: 0.0465 / Val_loss: 8.3480\n",
      "Epoch: 1827, Train_loss: 0.0177 / Val_loss: 8.3296\n",
      "Epoch: 1828, Train_loss: 0.0466 / Val_loss: 8.3322\n",
      "Epoch: 1829, Train_loss: 0.0242 / Val_loss: 8.3574\n",
      "Epoch: 1830, Train_loss: 0.0305 / Val_loss: 8.3953\n",
      "Epoch: 1831, Train_loss: 0.0278 / Val_loss: 8.4521\n",
      "Epoch: 1832, Train_loss: 0.0507 / Val_loss: 8.4972\n",
      "Epoch: 1833, Train_loss: 0.0277 / Val_loss: 8.5390\n",
      "Epoch: 1834, Train_loss: 0.0802 / Val_loss: 8.5165\n",
      "Epoch: 1835, Train_loss: 0.0251 / Val_loss: 8.5053\n",
      "Epoch: 1836, Train_loss: 0.0194 / Val_loss: 8.5037\n",
      "Epoch: 1837, Train_loss: 0.0227 / Val_loss: 8.5235\n",
      "Epoch: 1838, Train_loss: 0.0501 / Val_loss: 8.5208\n",
      "Epoch: 1839, Train_loss: 0.0530 / Val_loss: 8.4958\n",
      "Epoch: 1840, Train_loss: 0.0168 / Val_loss: 8.4666\n",
      "Epoch: 1841, Train_loss: 0.0324 / Val_loss: 8.4338\n",
      "Epoch: 1842, Train_loss: 0.0541 / Val_loss: 8.4048\n",
      "Epoch: 1843, Train_loss: 0.0161 / Val_loss: 8.3986\n",
      "Epoch: 1844, Train_loss: 0.0302 / Val_loss: 8.4014\n",
      "Epoch: 1845, Train_loss: 0.0062 / Val_loss: 8.4176\n",
      "Epoch: 1846, Train_loss: 0.0193 / Val_loss: 8.4567\n",
      "Epoch: 1847, Train_loss: 0.0360 / Val_loss: 8.5068\n",
      "Epoch: 1848, Train_loss: 0.0595 / Val_loss: 8.5189\n",
      "Epoch: 1849, Train_loss: 0.0435 / Val_loss: 8.5132\n",
      "Epoch: 1850, Train_loss: 0.0419 / Val_loss: 8.5296\n",
      "Epoch: 1851, Train_loss: 0.0326 / Val_loss: 8.5531\n",
      "Epoch: 1852, Train_loss: 0.0473 / Val_loss: 8.5539\n",
      "Epoch: 1853, Train_loss: 0.0404 / Val_loss: 8.5674\n",
      "Epoch: 1854, Train_loss: 0.0556 / Val_loss: 8.5745\n",
      "Epoch: 1855, Train_loss: 0.0401 / Val_loss: 8.5791\n",
      "Epoch: 1856, Train_loss: 0.0363 / Val_loss: 8.5912\n",
      "Epoch: 1857, Train_loss: 0.0392 / Val_loss: 8.6104\n",
      "Epoch: 1858, Train_loss: 0.0572 / Val_loss: 8.6397\n",
      "Epoch: 1859, Train_loss: 0.0651 / Val_loss: 8.5993\n",
      "Epoch: 1860, Train_loss: 0.0229 / Val_loss: 8.5810\n",
      "Epoch: 1861, Train_loss: 0.0405 / Val_loss: 8.5792\n",
      "Epoch: 1862, Train_loss: 0.0158 / Val_loss: 8.5896\n",
      "Epoch: 1863, Train_loss: 0.0244 / Val_loss: 8.5969\n",
      "Epoch: 1864, Train_loss: 0.0330 / Val_loss: 8.5957\n",
      "Epoch: 1865, Train_loss: 0.0241 / Val_loss: 8.6089\n",
      "Epoch: 1866, Train_loss: 0.0304 / Val_loss: 8.6122\n",
      "Epoch: 1867, Train_loss: 0.0379 / Val_loss: 8.6118\n",
      "Epoch: 1868, Train_loss: 0.0309 / Val_loss: 8.6180\n",
      "Epoch: 1869, Train_loss: 0.0254 / Val_loss: 8.6457\n",
      "Epoch: 1870, Train_loss: 0.0430 / Val_loss: 8.7158\n",
      "Epoch: 1871, Train_loss: 0.0301 / Val_loss: 8.7870\n",
      "Epoch: 1872, Train_loss: 0.0585 / Val_loss: 8.8273\n",
      "Epoch: 1873, Train_loss: 0.0187 / Val_loss: 8.8792\n",
      "Epoch: 1874, Train_loss: 0.0539 / Val_loss: 8.9348\n",
      "Epoch: 1875, Train_loss: 0.0255 / Val_loss: 9.0036\n",
      "Epoch: 1876, Train_loss: 0.0366 / Val_loss: 9.0479\n",
      "Epoch: 1877, Train_loss: 0.0398 / Val_loss: 9.0530\n",
      "Epoch: 1878, Train_loss: 0.0326 / Val_loss: 9.0916\n",
      "Epoch: 1879, Train_loss: 0.0495 / Val_loss: 9.1260\n",
      "Epoch: 1880, Train_loss: 0.0523 / Val_loss: 9.1277\n",
      "Epoch: 1881, Train_loss: 0.0411 / Val_loss: 9.1443\n",
      "Epoch: 1882, Train_loss: 0.0324 / Val_loss: 9.1070\n",
      "Epoch: 1883, Train_loss: 0.0463 / Val_loss: 9.0366\n",
      "Epoch: 1884, Train_loss: 0.0206 / Val_loss: 8.9884\n",
      "Epoch: 1885, Train_loss: 0.0244 / Val_loss: 8.9600\n",
      "Epoch: 1886, Train_loss: 0.0191 / Val_loss: 8.9431\n",
      "Epoch: 1887, Train_loss: 0.0368 / Val_loss: 8.9113\n",
      "Epoch: 1888, Train_loss: 0.0419 / Val_loss: 8.8918\n",
      "Epoch: 1889, Train_loss: 0.0328 / Val_loss: 8.8873\n",
      "Epoch: 1890, Train_loss: 0.0509 / Val_loss: 8.8451\n",
      "Epoch: 1891, Train_loss: 0.0346 / Val_loss: 8.8070\n",
      "Epoch: 1892, Train_loss: 0.0180 / Val_loss: 8.7847\n",
      "Epoch: 1893, Train_loss: 0.0258 / Val_loss: 8.7914\n",
      "Epoch: 1894, Train_loss: 0.0247 / Val_loss: 8.8242\n",
      "Epoch: 1895, Train_loss: 0.0438 / Val_loss: 8.8327\n",
      "Epoch: 1896, Train_loss: 0.0246 / Val_loss: 8.8486\n",
      "Epoch: 1897, Train_loss: 0.0239 / Val_loss: 8.8750\n",
      "Epoch: 1898, Train_loss: 0.0537 / Val_loss: 8.9118\n",
      "Epoch: 1899, Train_loss: 0.0366 / Val_loss: 8.9532\n",
      "Epoch: 1900, Train_loss: 0.0827 / Val_loss: 8.9675\n",
      "Epoch: 1901, Train_loss: 0.0366 / Val_loss: 8.9517\n",
      "Epoch: 1902, Train_loss: 0.0427 / Val_loss: 8.9289\n",
      "Epoch: 1903, Train_loss: 0.0185 / Val_loss: 8.9023\n",
      "Epoch: 1904, Train_loss: 0.0669 / Val_loss: 8.8383\n",
      "Epoch: 1905, Train_loss: 0.0225 / Val_loss: 8.7889\n",
      "Epoch: 1906, Train_loss: 0.0313 / Val_loss: 8.7199\n",
      "Epoch: 1907, Train_loss: 0.0360 / Val_loss: 8.6422\n",
      "Epoch: 1908, Train_loss: 0.0368 / Val_loss: 8.5802\n",
      "Epoch: 1909, Train_loss: 0.0296 / Val_loss: 8.5397\n",
      "Epoch: 1910, Train_loss: 0.0467 / Val_loss: 8.5160\n",
      "Epoch: 1911, Train_loss: 0.0152 / Val_loss: 8.5172\n",
      "Epoch: 1912, Train_loss: 0.0393 / Val_loss: 8.4628\n",
      "Epoch: 1913, Train_loss: 0.0419 / Val_loss: 8.4115\n",
      "Epoch: 1914, Train_loss: 0.0440 / Val_loss: 8.3641\n",
      "Epoch: 1915, Train_loss: 0.0154 / Val_loss: 8.3400\n",
      "Epoch: 1916, Train_loss: 0.0635 / Val_loss: 8.3240\n",
      "Epoch: 1917, Train_loss: 0.0402 / Val_loss: 8.3263\n",
      "Epoch: 1918, Train_loss: 0.0249 / Val_loss: 8.3399\n",
      "Epoch: 1919, Train_loss: 0.0168 / Val_loss: 8.3825\n",
      "Epoch: 1920, Train_loss: 0.0238 / Val_loss: 8.4317\n",
      "Epoch: 1921, Train_loss: 0.0228 / Val_loss: 8.4977\n",
      "Epoch: 1922, Train_loss: 0.0303 / Val_loss: 8.5760\n",
      "Epoch: 1923, Train_loss: 0.0255 / Val_loss: 8.6720\n",
      "Epoch: 1924, Train_loss: 0.0544 / Val_loss: 8.7198\n",
      "Epoch: 1925, Train_loss: 0.0236 / Val_loss: 8.7783\n",
      "Epoch: 1926, Train_loss: 0.0133 / Val_loss: 8.8383\n",
      "Epoch: 1927, Train_loss: 0.0173 / Val_loss: 8.9001\n",
      "Epoch: 1928, Train_loss: 0.0376 / Val_loss: 8.9822\n",
      "Epoch: 1929, Train_loss: 0.0396 / Val_loss: 9.0269\n",
      "Epoch: 1930, Train_loss: 0.0550 / Val_loss: 9.0273\n",
      "Epoch: 1931, Train_loss: 0.0218 / Val_loss: 9.0366\n",
      "Epoch: 1932, Train_loss: 0.0339 / Val_loss: 8.9953\n",
      "Epoch: 1933, Train_loss: 0.0178 / Val_loss: 8.9773\n",
      "Epoch: 1934, Train_loss: 0.0486 / Val_loss: 8.9507\n",
      "Epoch: 1935, Train_loss: 0.0302 / Val_loss: 8.9239\n",
      "Epoch: 1936, Train_loss: 0.0241 / Val_loss: 8.9040\n",
      "Epoch: 1937, Train_loss: 0.0314 / Val_loss: 8.8611\n",
      "Epoch: 1938, Train_loss: 0.0610 / Val_loss: 8.7889\n",
      "Epoch: 1939, Train_loss: 0.0088 / Val_loss: 8.7307\n",
      "Epoch: 1940, Train_loss: 0.0506 / Val_loss: 8.6797\n",
      "Epoch: 1941, Train_loss: 0.0234 / Val_loss: 8.6415\n",
      "Epoch: 1942, Train_loss: 0.0266 / Val_loss: 8.6120\n",
      "Epoch: 1943, Train_loss: 0.0150 / Val_loss: 8.6102\n",
      "Epoch: 1944, Train_loss: 0.0710 / Val_loss: 8.6373\n",
      "Epoch: 1945, Train_loss: 0.0227 / Val_loss: 8.6940\n",
      "Epoch: 1946, Train_loss: 0.0574 / Val_loss: 8.7491\n",
      "Epoch: 1947, Train_loss: 0.0503 / Val_loss: 8.7644\n",
      "Epoch: 1948, Train_loss: 0.0445 / Val_loss: 8.7688\n",
      "Epoch: 1949, Train_loss: 0.0357 / Val_loss: 8.7827\n",
      "Epoch: 1950, Train_loss: 0.0322 / Val_loss: 8.7667\n",
      "Epoch: 1951, Train_loss: 0.0307 / Val_loss: 8.7522\n",
      "Epoch: 1952, Train_loss: 0.0186 / Val_loss: 8.7678\n",
      "Epoch: 1953, Train_loss: 0.0473 / Val_loss: 8.7491\n",
      "Epoch: 1954, Train_loss: 0.0158 / Val_loss: 8.7372\n",
      "Epoch: 1955, Train_loss: 0.0195 / Val_loss: 8.7319\n",
      "Epoch: 1956, Train_loss: 0.0244 / Val_loss: 8.7467\n",
      "Epoch: 1957, Train_loss: 0.0458 / Val_loss: 8.7214\n",
      "Epoch: 1958, Train_loss: 0.0407 / Val_loss: 8.6985\n",
      "Epoch: 1959, Train_loss: 0.0466 / Val_loss: 8.6949\n",
      "Epoch: 1960, Train_loss: 0.0067 / Val_loss: 8.6972\n",
      "Epoch: 1961, Train_loss: 0.0215 / Val_loss: 8.7223\n",
      "Epoch: 1962, Train_loss: 0.0525 / Val_loss: 8.7218\n",
      "Epoch: 1963, Train_loss: 0.0317 / Val_loss: 8.7317\n",
      "Epoch: 1964, Train_loss: 0.0287 / Val_loss: 8.7183\n",
      "Epoch: 1965, Train_loss: 0.0209 / Val_loss: 8.7026\n",
      "Epoch: 1966, Train_loss: 0.0320 / Val_loss: 8.6693\n",
      "Epoch: 1967, Train_loss: 0.0378 / Val_loss: 8.6419\n",
      "Epoch: 1968, Train_loss: 0.0333 / Val_loss: 8.6408\n",
      "Epoch: 1969, Train_loss: 0.0172 / Val_loss: 8.6619\n",
      "Epoch: 1970, Train_loss: 0.0159 / Val_loss: 8.6956\n",
      "Epoch: 1971, Train_loss: 0.0338 / Val_loss: 8.7568\n",
      "Epoch: 1972, Train_loss: 0.0193 / Val_loss: 8.8113\n",
      "Epoch: 1973, Train_loss: 0.0343 / Val_loss: 8.8882\n",
      "Epoch: 1974, Train_loss: 0.0290 / Val_loss: 8.9574\n",
      "Epoch: 1975, Train_loss: 0.0138 / Val_loss: 9.0119\n",
      "Epoch: 1976, Train_loss: 0.0280 / Val_loss: 9.0900\n",
      "Epoch: 1977, Train_loss: 0.0255 / Val_loss: 9.1515\n",
      "Epoch: 1978, Train_loss: 0.0343 / Val_loss: 9.1661\n",
      "Epoch: 1979, Train_loss: 0.0269 / Val_loss: 9.1862\n",
      "Epoch: 1980, Train_loss: 0.0236 / Val_loss: 9.2156\n",
      "Epoch: 1981, Train_loss: 0.0501 / Val_loss: 9.2686\n",
      "Epoch: 1982, Train_loss: 0.0404 / Val_loss: 9.2988\n",
      "Epoch: 1983, Train_loss: 0.0187 / Val_loss: 9.3309\n",
      "Epoch: 1984, Train_loss: 0.0386 / Val_loss: 9.3891\n",
      "Epoch: 1985, Train_loss: 0.0166 / Val_loss: 9.4386\n",
      "Epoch: 1986, Train_loss: 0.0448 / Val_loss: 9.4777\n",
      "Epoch: 1987, Train_loss: 0.0348 / Val_loss: 9.5132\n",
      "Epoch: 1988, Train_loss: 0.0289 / Val_loss: 9.5493\n",
      "Epoch: 1989, Train_loss: 0.0469 / Val_loss: 9.5518\n",
      "Epoch: 1990, Train_loss: 0.0431 / Val_loss: 9.5699\n",
      "Epoch: 1991, Train_loss: 0.0238 / Val_loss: 9.6077\n",
      "Epoch: 1992, Train_loss: 0.0567 / Val_loss: 9.6285\n",
      "Epoch: 1993, Train_loss: 0.0265 / Val_loss: 9.6574\n",
      "Epoch: 1994, Train_loss: 0.0377 / Val_loss: 9.6985\n",
      "Epoch: 1995, Train_loss: 0.0448 / Val_loss: 9.6918\n",
      "Epoch: 1996, Train_loss: 0.0343 / Val_loss: 9.6313\n",
      "Epoch: 1997, Train_loss: 0.0454 / Val_loss: 9.5536\n",
      "Epoch: 1998, Train_loss: 0.0415 / Val_loss: 9.4376\n",
      "Epoch: 1999, Train_loss: 0.0220 / Val_loss: 9.3658\n",
      "Epoch: 2000, Train_loss: 0.0301 / Val_loss: 9.2940\n"
     ]
    }
   ],
   "source": [
    "weight = torch.Tensor([1.0, 2.5])\n",
    "log_softmax = torch.nn.LogSoftmax(dim=1)\n",
    "criterion = torch.nn.NLLLoss(weight=weight)  # Define loss criterion.\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-4)  # Define optimizer.\n",
    "\n",
    "losses = []\n",
    "v_losses = []\n",
    "best_v_loss = 100000\n",
    "COUNT = 2000\n",
    "val_early_stop_count = COUNT\n",
    "val_early_stop_continuous_flag = False\n",
    "\n",
    "for epoch in range(1, 2001):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    X_tmp = data.x[data.train_mask]\n",
    "    y_tmp = data.y[data.train_mask].to(dtype=torch.long)\n",
    "    preds = model(X_tmp)  # Perform a single forward pass.\n",
    "    loss = criterion(log_softmax(preds), y_tmp)  # Compute the loss solely based on the training nodes.\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        v_X_tmp = data.x[data.val_mask]\n",
    "        v_y_tmp = data.y[data.val_mask].to(dtype=torch.long)\n",
    "        v_preds = model(v_X_tmp)\n",
    "        v_loss = criterion(log_softmax(v_preds), v_y_tmp)\n",
    "        v_losses.append(v_loss.item())\n",
    "    print(f'Epoch: {epoch:03d}, Train_loss: {loss:.4f} / Val_loss: {v_loss:.4f}')\n",
    "    \n",
    "    if v_loss.item() < best_v_loss:\n",
    "        best_v_loss = v_loss.item()\n",
    "        val_early_stop_continuous_flag = False\n",
    "        val_early_stop_count = COUNT\n",
    "    else:\n",
    "        val_early_stop_continuous_flag = True\n",
    "        val_early_stop_count -= 1\n",
    "        if val_early_stop_count == 0:\n",
    "            print(f\"============== Early stopped at Epoch: {epoch}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGwCAYAAACzXI8XAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAXhhJREFUeJzt3Qd4VFXaB/B/eiMJSUglQELvvYOCggIqithFwYogts9VV9aKrmJbllVZu9iwL6CCgICg9CodQocAaQRI75nvee+Zm5lJI4TJ1P/veea5dSbn5k5m3pzznnM8DAaDAUREREROyNPeBSAiIiKqLwYyRERE5LQYyBAREZHTYiBDRERETouBDBERETktBjJERETktBjIEBERkdPyhosrLy/HqVOnEBwcDA8PD3sXh4iIiOpAhrnLyclBXFwcPD093TeQkSCmWbNm9i4GERER1UNycjLi4+PdN5CRmhj9FxESEmLv4hAREVEdZGdnaxUR+ve42wYyenOSBDEMZIiIiJzL+dJC7Jrs++eff2L06NFa+5cUdP78+VXax55//nnExsYiICAAw4cPx4EDB+xWXiIiInIsdg1k8vLy0K1bN8yaNava42+88QbefvttvP/++9iwYQOCgoIwYsQIFBYW2rysRERE5Hjs2rQ0atQo7VEdqY2ZOXMmnn32WVx33XXavi+++ALR0dFazc2tt95a7fOKioq0h3kbGxEREbkmh82ROXLkCFJTU7XmJF1oaCj69euHdevW1RjITJ8+HdOmTbvgn1dWVoaSkpKLKrM78/X1rbV7HBERkVsFMhLECKmBMSfb+rHqTJ06FY8//niVrOeaSM2PvN65c+esUm53JUFMYmKiFtAQERHB3QOZ+vLz89MedaUHMVFRUQgMDOSgeRcx6GBKSgqaN2/O3yEREdmMwwYyMTEx2jItLU3rtaST7e7du1vlZ0hzkh7EREREWOU13VVkZKQWzJSWlsLHx8fexSEiIjfhsEkN0kwhwczy5cstmomk99KAAQOs8jP0nBipiaGLozcpSXBIRETkFjUyubm5OHjwoEWC77Zt2xAeHq41UTz22GP45z//iTZt2miBzXPPPaeNOTNmzBirloNNIRePv0MiInK7QGbz5s247LLLKrb1JN0JEybgs88+w1NPPaWNNTNx4kStCWjw4MFYvHgx/P397VhqIiIichQeBum248KkOUq6bWdlZVWZokAG1pNaIKntYXB0cfi7JCIiW31/O0WODNlWQkKCNgAhERGRM2Eg44S5KLU9XnzxxXq97qZNm7QmPCIiojopKwVKi2FvDtv9mqonY7XovvvuO21SzaSkpIp9jRo1qliXVkPpReTt7V2n7tNERER1DmLeGwCUFACTVgMBjWEvrJExI1/8+cWldnnUNVVJuqTrD2k7lFoYfXvfvn0IDg7GokWL0KtXL21gwNWrV+PQoUPafFUyKrIEOn369MGyZctqbVqS1/34449x/fXXa93TpefYzz//bPXfOREROaHMg8Dp/UBWMnBsjV2LwhoZMwUlZej4/BK7/Ow9L41AoK91bsfTTz+Nt956Cy1btkRYWBiSk5Nx1VVX4ZVXXtGCG5l8c/To0VpNjnRzr4nMWSUzkL/55pt45513MG7cOBw7dkzrHk9ERG4sdadpPTfdniVhjYwreumll3DFFVegVatWWtDRrVs3PPDAA+jcubNWs/Lyyy9rx85Xw3LXXXfhtttuQ+vWrfHqq69q4/5s3LjRZtdBREQOKmWbaT03zZ4lYY2MuQAfL61mxF4/21p69+5tsS0BiCQBL1y4UMuxkWkECgoKcPz48Vpfp2vXrhXrQUFBWve39HT7Rt5EROQAks3+qWUg4zgkL8RazTv2JEGHuSeeeAJLly7VmpukdiUgIAA33ngjiotrzzavPGeS/H5kgkgiInLzZqUTZoFMDgMZamBr1qzRmokkcVevoTl69Ki9i0VERM4oabHldsEZ2BNzZNyA5MXMnTtXm8dq+/btuP3221mzQkRE9ZO2Sy1bD1fLgrOwJwYybmDGjBla76WBAwdqvZVGjBiBnj172rtYRETkjNL3qmXCYIcIZDjXEucHsgr+LomI3EB5OfBKDFBWBExYAHx+DeDlBzybJomUVv1RnGuJiIiIrCsnRQUxnt5ATGe1T7ZlhF87YSBDREREdXPW2FEktBng31gFNHZuXmIgQ0RERBcWyIQlqKakgDC1nZ8Je2EgQ0RERHVz5rApkBFBxgmH8zJgLwxkiIiIqG5Sd6hldCe1bBSllgxkiIiIyOFl7LMMZIKiAE8foDjXbkXiyL5ERER0fsX5wLlktd6krVpe+w4w9kOrd72+EAxkiIiIqI61MQaV4BsYofb52H/cMDYtuaGhQ4fiscces3cxiIjImRxdpZbxfe1aA1MZAxknI1MMjBw5stpjq1at0mao3rHDmIxFRETu58BS4P3BwLG11n3dk1sspyZwEAxknMy9996LpUuX4sSJE1WOzZ49G71790bXrl3tUjYiIrIzgwGYcyOQuhP45VHrvnbWSbUMT4QjYSDjZK655hpERkbis88+s9ifm5uLH374AWPGjMFtt92Gpk2bIjAwEF26dME333xjt/ISEZENnTtumZxrTdmn1DIkDo6EgUzlSLY4zz6POs7d6e3tjfHjx2uBjPl8nxLElJWV4Y477kCvXr2wcOFC7Nq1CxMnTsSdd96JjRs3NuAvjoiIHELyBtN6WXHdniPTC5SX1X5OWSmQm6rWQ5rCkbDXkrmSfOBVO0Wa/zgF+AbV6dR77rkHb775Jv744w8tcVdvVrrhhhvQokULPPHEExXnPvzww1iyZAm+//579O3bt8GKT0REDuDAb6b1vHSgtBjw9q35/J0/Av+7F+gwGrjlq5rPkyDGUK7mVpKxYxwIa2ScUPv27TFw4EB8+umn2vbBgwe1RF/Jn5FamZdffllrUgoPD0ejRo20QOb4cbPqRiIicu0pBMxnq67N0ufVcu8vtbcM6M1KwXGAp2OFDqyRMecTqGpG7PWzL4AELVLbMmvWLK02plWrVhgyZAhef/11/Oc//8HMmTO1YCYoKEjral1cXMcqRiIicl5ZJ6oGNkFNgF+fAloMBHqMszyuz14tMpKAqPbVv272SYfMjxEMZMxJv/g6Nu/Y280334xHH30UX3/9Nb744gtMnjxZ63q9Zs0aXHfddVqujCgvL8f+/fvRsWNHexeZiIgaUkkhkJum1lsNAw4tV12wpQfTtq/Uo/NYwCfA9Jz8M6b1g0trDmT0HkuhjpUfIxyrfojqTJqMbrnlFkydOhUpKSm46667tP1t2rTRumevXbsWe/fuxQMPPIC0NOMbm4iIXFe2MdjwDgA6XmcaxC7zgOmcw3+Y1otygOKc6hOFnaTHkmAg48Skeens2bMYMWIE4uLUm+vZZ59Fz549tX2SCBwTE6N1ySYiIiex52fg312AjR/Vr1mpcTOg5RC1fnydyn/RndhkWs8x9kLSJW+qOU+momnJ8Wpk2LTkxAYMGGDRBVtIgu/8+fNrfd7KlSsbuGRERFRv8yYBJXnAr08Afe+/8EAmNB4ISwBiuwEp21X36soBiXktS2gztS49k+S4PN+JAhnWyBARETkC+cdU8lwkiNHlZdYvkBFtq5nORg9ezHs0yUi94S2r7/VU+XkMZIiIiKgKGZDukyuAV6It95/aWvfXyDYGMiHGQCaynelYTJeqgUxF4NMMCIk1Hk9RcyqZjxAsg+HpzVDMkSEiIqIqpGeRef6K+f66yq6UkBvfx3Ss/4Omc/SUBPMaHL2mZevnwEeXAzO7APuNg+tJTyhDmeqq3cixBsMTzJEhIiKyt5RtltsRbVRvI/OclvPJNjYV6bUrjZsDo/8DlBYBHccA8yerZquibMA/1DKQKS9V68fWmF7v65uAZv2B6E5qOzgW8PSCo2EgozVL1m2eI6oZf4dERBdBxnsx13M8sPS5qgPc1Sa7moTcXmpoDo1/Y6DwnAp4zAMZOV+Cneokr1cPB21Wgrs3Lfn4+GjL/HwrzxDqhvSRg728HC9aJyJyCAeWqV5EleWkATu+M21Lkm5UB7Ve10CmOF8FKXrNSXX0AEcCHvnnMyvZLEemUhLvVW9V83zHDGTcukZGvnQbN26M9PR0bTswMFAbHZcujIwenJGRof3+ZHZuIiKq5MifwJwbgIAw4PF9gI+/6djen03rt8wBmg9QEz4KPdioSV4mcOov1d1a+ASp2pbqSJNT+m6VJ6MNhpdr3B8HlJnVyARGAH3uAwqzgN9fNu2PNAZXDsbtv3VkwDihBzNUP56enmjevDkDQSKi6hxdrZYypsua/wBD/24Z5IhhzwMdrlHrXqrFQAsmJOjwC67+db8cA6TuAGK6mvJdavoc1mtUpNt1gXFqAm9/wK8R0MSsh5PU1shrXPoE0OFaYJYxabjFADgitw9k5Is3NjYWUVFRKCkpsXdxnJavr68WzBARUTXS95jWpXtzdYm+5r2M/ENUzYoEMjLPUXVzIEleS+oOta4vm/evuQzmTUsF50x5M8LbFwiKBPIygJZDTc+JbAuMegMoKQASLoEjcvtAxryZifkdRETUIMxzY/TARWo+fnnUNGaLjMRrTnJXtEAmufpAZtmLlttSK3P5szWXQc+dkWRfPZ8mwBjIiJs+B3Z8C1zyN8vn9XsAjoyBDBERUUM6e8xygDkZl0UGmDuwVI3bIoLjqua2SN5L2i4g8xAQ3Rn4+mbVpfqaf6sk4PX/Vef5BqsmqdFvq5qV89XISO1Q3mm1HtjEdDxhkHo4GQYyREREtsiPkaYjyXfJ2Aec2gZsMpsUcvTMqs+TkXn3LQAy9gKb0lXzkTykhkav4Wk7ErjdrMdTbSJaqaU8//AKtd4oEs6OgQwREZEtAhnJMZH8FAlkvrnFdPyhLUCT1lWfp/cSkpyaFoOqb6YaYpY0fD56zyaxxzgjdpDjjdR7oZidSUREZG1lJcD2b4GM/cD2r9W+xEuATtdbniddnfWakspaDgG8fNU0BbvmVj0e3QVo2rPuZZKeSP0mq/WiLLVkjQwRERFVIV2szcdgETLcf+Uh/q+eUXN3aZnXSKYW2Pm9aVwZyWnJN+a3xFVKDq6LsBaW26yRISIioiqkNsbcwEcA30DA2w/ocpPad+UrQKcxtb9O5bFbupo1ScVdQG2MTpKFLbabwdmxRoaIiMiaZMoBmfBReAcArS4DrnjJdPyamUDPCUDC4PO/Vmx307qnDzDoEWD/YhUUdb7hwsvWuFKNTHgNzVpOhIEMERGRNenTCoTEA4/vrnpcRtKVfJm6iOliWpdmqeAY4OEtNTdHnU94ouW2jATs5Ni0REREZE0Vs1DXMHnjhZCpCtobpy3ofa9aXsxUML5BQOsrTMnClXN2nBBrZIiIiKxJRs615mzRo/8DdLsVaD3cOq836nXgr86mwMjJMZAhIiKyppxTptF6rSGoCdBhNKwmohUwvNL0Bk6MTUtERETWlH3Kek1LdF4MZIiIiBqiaclaNTJUKwYyRERE1iSTQgrpYUQNjoEMERGRNeUaR+FtFG3vkrgFBjJERETWUlLoUvMYOQOHDmTKysrw3HPPITExEQEBAWjVqhVefvllGAwGexeNiIjcbbTe4+uB833/6HMiyWSP/o1tUjR359Ddr19//XW89957+Pzzz9GpUyds3rwZd999N0JDQ/HII4/Yu3hEROQuvrkVOLUVuPVroP3VdWtWupiB68g1Apm1a9fiuuuuw9VXqzdNQkICvvnmG2zcuNHeRSMiIneRdVIFMWLvgroFMkFsVrIVh25aGjhwIJYvX479+/dr29u3b8fq1asxatSoGp9TVFSE7OxsiwcREVG97fqfab04x7R+5giw8jWgOK9qjyUm+tqMQ9fIPP3001og0r59e3h5eWk5M6+88grGjRtX43OmT5+OadOm2bScRETkwk5uMa2fM04IKT4dCeSmAiUFwBXG7528DLVkoq/NOHSNzPfff485c+bg66+/xtatW7Vcmbfeektb1mTq1KnIysqqeCQnm73piIiILlT6HtP62SMq4Tf/jApixP4lpuOskbE5h66RefLJJ7VamVtvvVXb7tKlC44dO6bVukyYMKHa5/j5+WkPIiKiiyZBizQh6QqzgMxDwG/PmvYV5VQNZIKibFhI9+bQNTL5+fnw9LQsojQxlZeX261MRETkRkrygfIStR7dWS3XzwL2LzKdk31CBTh6YrAIbWrrkrothw5kRo8ereXELFy4EEePHsW8efMwY8YMXH/99fYuGhERuQM9QPH0Btpfo9Y3f2p2grGL9dE1apl1Qi1D421ZSrfm0E1L77zzjjYg3oMPPoj09HTExcXhgQcewPPPP2/vohERkTsFMn4hQFwPy2P9p6gB8Hb+AGTsA1pdbhoQL7SZ7cvqphw6kAkODsbMmTO1BxERkc0VnFXLgDAgqoPlsaj2QFawWj9zCDhzWK37BKnzySYcOpAhIiKyK+mdJCQwkVoW30ZAca7aF9ke8PZX6xn7gT0/qfXm/Tiqrw0xkCEiIjpfjUxgOCCdT4JjgcwDal9kO1M365ObTcFL25F2Kqx7cuhkXyIiIrsq0Gtkwk3Bi84/FAhrAcR2AwzlQPIGtT+8lR0K6r5YI0NERHS+piWpkRGjXgfKioFut5nO6TAaSNmu1j08qyYFU4NijQwREVFdkn31btXjfgA6jzWd02ks4OGl1oe9AARF2KGg7os1MkREROdtWqqlF1JEK+D+3wGfQCCyrc2KRgoDGSIioprkmyX71iauu02KQ1WxaYmIiKiuTUvkcBjIEBER1STnlFpyEkiHxUCGiIioph5Leo1MeEt7l4ZqwECGiIhch0wT8MujwPH1F/9amYfUMjgO8A28+NejBsFAhoiIXMcPdwFbPgO+uwMozru415L5k/ReSeSwGMgQEZFrkMBFH5guLwNIWnRxr3faOBUBm5UcGgMZIiJyDWePWm4f+r3+r1VWCuz9Ra3LFATksBjIEBGR6+THmNs2B0jZUb/XOrISOJ2kphzocK1VikcNg4EMERG5ViBjHnjsnlu/1zq1zfhao4FGkVYoHDUUBjJEROQaMg+qZVQHYNBjaj11V/1e6+QWtWzWz0qFo4bCQIaIiFxDprFGJrwV0P4atZ6yDTAYLM/LSQM2fwqcPVb96+SmA0dXq/X4Pg1ZYrICBjJERORaNTIRrYHoTiq/RXov5aRYnrfoSWDB/wH/u6/615k7ESjKVr2VmvZq+HLTRWEgQ0REzq8oB8hNVesRLdUAdpHtLfNddPt+VcsTG4HycstjhVnA4RVq/ZY5gKdXgxedLg4DGSIicjylRcDCvwGLp9btfH38mJCmpgkeY7ubmpfMX7e8xLSdfcLydTKSTKP5Rne8iAsgW2EgQ0REjkdyWDZ9DKz/r8ppqW76gHd6ARs+UNt6TkvTnqZz9PFf9CDHvPnJfLu8DCgzBjcZ+9Qysp01r4YaEAMZIiJyPHpgIirnuIiFj6sgZNFTavvAb2rZ8jLTOXHdqzYt6YGKLn0v8G5v4IMhQFGuaTTfJm2tdSXUwBjIEBGR4zn1l2n9ry+Bz64Bzh037Tth7B6tj8KrjyFj3l06pgsAD5U7k5Nq2XSkk9F75bnpu4Hd84CzR9R+TkvgNBjIEBGRY5GmHvNaGGliOroKmPuA2s7LBIpzTMczDwAFZ9V6eKJpv28QEGXMc1nzNpB9Ctj4oVmQA+D4OtP5kvx75kjV1yGHxkCGiIgcS/4ZwFCpN5E4vtY4MeRflfavV8tG0Sp4Mdf2SrXc9SPw4z0q4JFmo8uerfr6J7ea5msKYyDjLLztXQAiIiILeek1H5NAQxJ9qxuFNzS+6vmXPgXsnq+ajHKNScPXzAQaN696bprZKMDVHSeHxBoZIiJyLDKyrt6Vuvs44MbZQJyxN5Lks1TueSQ1Kdr5cVVfS8aTGWycrkAERgAtBqrXNtcoxnLdx99KF0MNjYEMERHZ3s4fgfkPAiWFVY/lnTYl3I75L9B5rCn5Vmpj9BoZTx+1lERdUTk40ZlPIimBkYcH4OkJtByq9iVeCvS803QOa2OcCgMZIiKyvf/dC2ybA2z+pOampUZRpn16IHPmkKlGRgIQc8Gx1f+swHDgullAz/HA0KdN+2/4BBj5GjD2IyBxiGl/aA0BETkkBjJERGRbhdmmdb3btDmZH0kERVYNZGRMmHPGyR5bmY0ZY35OdXrcAVz7jmUycFAToP9kIDgGSBhs6uHU6foLviSyHyb7EhGRbZkPSqf3EqouR8YikDH2IkrdoZZhCUB0Z8vnRbSqf5mkuenWr1WzVZvh9X8dsjkGMkREZL9AJtWsp5BOxnupnLwrgYu5pr2rBjIX22VagiWOH+N02LRERES2ZT66rnSJlpF5zxfIyBgx0uNIF98baBRpmpJAghrpoURuh4EMERHZjkwzkLrTbIcByDf2UtLpo/rKDNTmTT8jXzdttxikltfMAHrfC9z0eUOWmhwYm5aIiKjhGQzA6y2Awqzqc2Ik4VYU5QBFxmTgkEq9kLreZGxiMgCxXU0JvhLMkNtiIENERLaZBLJyEBPaDMhKthzJN9tYG+MXAvgFV32dZn0auKDkbNi0REREDS9lm+W29EjSexnpA+CJ7BO1jwlDVAkDGSIianh6Aq8ICFMD0QVFWXa3FmnGUXoj29q4gOSs2LREREQNT5+w8bJngCFPmZqbhHnTUsp2tYzpZusSkpNijQwRETW83GqmHdAHvMs1juRbXg4cWKrWm/ezdQnJSTGQISIi29XIyHgwOj2o0Wtkzh0FCs8BXn5A8wF2KCQ5IwYyRERkpxqZKMsaGX18magOgJdxZmui82AgQ0REDUuajCoCmWjLSRvNJ4lMMc6jFNPF1iUkJ8ZAhoiIGpY0F5WXVJ0IsqJpKUMFO3qNTCwTfanuGMgQEZFt8mOk27W3n2m/BDUenoChTOXJ6IEMa2ToAjCQISIi2yf6CsmD0We1PrYWyDGONRPdycYFJGfGQIaIiGyf6Ktr0k4td/5omjupuqkJiGrAQIaIiOxTI2M+gm/SQrWMMU4GSVRHDGSIiMiOgUx7y+14TgpJF4aBDBER2a9pKfFSy+32V9umTOQyGMgQETmrzENAXiacukYmNB649l21PvJ1IDzRtmUjp8dJI4mInNHZo8B/+6tAYPI6wMcfDl8jYz6GjLmed6oHUT2wRoaIyBkdWgGUFQNnDgO758Fpa2SILhIDGSIiZ5RtHHNFnNwMh1VWAuQbm78YyFADYCBDROSM9MHjxKm/4LD0eZQ8vIDAcHuXhlwQAxkiImevkZGh/UuL4dDNSpIf4+ll79KQC2IgQ0TkjLJTTOuSK5O+Gw4p66RahsTauyTkohjIEBE5c41MSFPHbl7KSlbLxs3tXRJyUQ4fyJw8eRJ33HEHIiIiEBAQgC5dumDzZgdObCMiamiFWUBRllpvdZlanjMGDI7m3HG1ZCBD7jiOzNmzZzFo0CBcdtllWLRoESIjI3HgwAGEhYXZu2hERPaTdUItA8KBxsbZo/NPw+4kT+enKUBsN2DgQ6bxbkQoAxlyw0Dm9ddfR7NmzTB79uyKfYmJtY/6WFRUpD102dnZDVpGIiK7BTIyGF5QE7We5wCBzOGVwM7v1aPLjUBwDJC+Rx2LNM5yTeROTUs///wzevfujZtuuglRUVHo0aMHPvroo1qfM336dISGhlY8JBAiInIpet5JaDOzQMbYzdmeTieZ1ufcCHw41FQjE93JbsUi1+bQgczhw4fx3nvvoU2bNliyZAkmT56MRx55BJ9//nmNz5k6dSqysrIqHsnJDtpuTERUX3o+TGhT07D/jlAjk7bbsku4noDcKMYUcBG5U9NSeXm5ViPz6quvattSI7Nr1y68//77mDBhQrXP8fPz0x5ERC5Lr+UISwAC69m0JN23ZVC9pr2sV660XdXvj+livZ9B5Ew1MrGxsejYsaPFvg4dOuD4cWMWPBGRO5L5lUR4S1NNR3EOUFJY99f4/k7go8uB3fOtNxVBhrFp6c55wJX/BHyC1Hbnsdb5GUTOViMjPZaSkszaXAHs378fLVq0sFuZiIjsymAw1chIIOMfCnj6AOUyp9FplQB8PqVFwIlNav2HCUDCoYtv+sk8qAbm8w0GEocCrS4HOt+ogq4WAy/utYmctUbm//7v/7B+/XqtaengwYP4+uuv8eGHH2LKlCn2LhoRkX3IBIxF0hvTA2jcAvDwuPCE39MHLLcPLr/4cqXuMiX1enqaRvNNGKTKSOSOgUyfPn0wb948fPPNN+jcuTNefvllzJw5E+PGjbN30YiI7OPMEdOIvj7+ar0ikDHOMn0++xdZbh9fZ738GPZOIhtz6KYlcc0112gPIiIyz48xG1OroudSRt0GrVv9H7Ue0Vo1CZ07dnFlSt4IrJmp1hnIkI05dI0MERHVMOR/mFmuYEXPpToEMhl7VWKwly8w6g217+xFBDJr3wE+ucK0Hd+7/q9FVA8MZIiInEn2ScvJIs1rZOoyTcGpbWrZvL+qkdEH2Csvq195NnxoWu92OxDTtX6vQ+SqTUtERFTdrNdxpn0yFUBda1ZOblHLuB4qGJJeRlJDk7pD7TNXXq6anpq0qT5hNycVyJIaIg9gajLgF1z/6yKqJ9bIEBE5ZSBjViMT09k0mm7FeSnAvoWqu7aQpTxXD2Sa9ga8vIHES9X27nlVc2neSARm9QE2fVy1HBLknNis1qM6Moghu2EgQ0TklE1LZjUyenPOmUNAcZ4KWr69XT12fG8KVGZ0MPUu0nNZOhg7Uxyr1HNp3y9A4Tm1vm1O1eYpCXK+M/YgZV4M2REDGSIiZyEj9xacqRrIBEaYRtGV5h6pKTm1VW3v+UktN5rlsviFmJ6vz0qtz6it2/KZab0ox/LYulmmIEc063uRF0ZUfwxkiIichcyNJHwCAf/Gpv2SvxIcbTwnFTi6ynTMYEziTdtj2uflY1qXGbS156WoaQb0ZiM9KVhknTQ1UQl9VGDhFwq0u8oKF0dUPwxkiIicMdG3cvKtzDAtclOBpF9N+yVAKcwCirJM+0ZMt+y67SUT7RpMtTJnjxhHDzYqLQAKzqr1355Tx8Udc4EH1wKB4Va9TKILwUCGiMjZApng2KrH9J5Lu+Za1phoPYuMeTVSi/PUEaDrzabjMp2A9EoS6XvVMmW7WsrM2PoYNXqQs/Zt03NbD6vb3E5EDYiBDBGRM48ho2tsbCLat6BSDU26aeReaUaS2pPKtTmx3SwDGH0p+0ObmoIofbJKcZ8V5mcisgIGMkREzjyGTOVgRHfdLMBThgozACeNib811Z7ovZ4qApltZoFMM9OIwodXqvX4vuypRA6DA+IREblCIBPfRw1MJ4HL4P8D2gxXtTLZJ0xNTXrtSk1BkAyKJ0m9FTUy3U0zZUtejIfxf18GMeRAGMgQETnzGDK6xs2BsR+pgGPQY6a8GQlk9EHwaqyR6aKCIHl9OVcSez19gKgOQHhLs8kqjU1SEa2sf21E9cRAhojI2SaMlKClOl1vqj4BWO+BFFJDIOPXSAUt6XuATZ+ofbLt7VcpkDEKZyBDjoM5MkREzqAoF8jPrD2Qqaxy76banqc3F23/2rK5SQ9kMg+ph/k+IgfAQIaIyBnIDNV6F2r/0Lo9R6+R0endrKsjCbzmOt9gao6SZiYZWE8eXr7sck0OhYEMEZEz0GtDwhLq/pzKNSe1DVxnPs1A4hCg1WVq3dPL8mdGtFb7iBwEc2SIiJyBPlid5K7UVfurTevNB9R+rsy5NPxFIO80MOSpqgFRprH3EnsskYNhIENE5AwOr1DLyPZ1f44k605cCWz7Guj7wPnPl27b1YnrDhxYotYTLq37zyeyAQYyRESOTqYHOLZGrbcdeWHPjeuhHhdDunPL+DI+/kDnsRf3WkRWxkCGiMjR7Z6vls0HAlEXUCNjLb6BwOXP2P7nEjVUsm9ycjJOnDBOIAZg48aNeOyxx/Dhhx/W5+WIiKg2x9epZdsR9i4JkWsEMrfffjtWrFDttampqbjiiiu0YOaZZ57BSy+9ZO0yEhG5r9Ji4JAxP6bFQHuXhsg1Apldu3ahb1/VVe/7779H586dsXbtWsyZMwefffaZtctIROS+9v4MlOSp8WMqTwxJRPULZEpKSuDn56etL1u2DNdee6223r59e6SkpFi3hERE7mzXXLXscYfqhUREFx/IdOrUCe+//z5WrVqFpUuXYuRIlUV/6tQpRERE1OcliYioMhnTJelXtc7eQkTWC2Ref/11fPDBBxg6dChuu+02dOumqjt//vnniiYnIiK6SId+B2AAojsDTXvZuzRErtP9WgKY06dPIzs7G2FhYRX7J06ciMDAQGuWj4jIfe35SS1bD7N3SYhcq0amoKAARUVFFUHMsWPHMHPmTCQlJSEqKsraZSQicl6bZwN/vKEGlLvQ3koHl6v1zjc2SNGI3LZG5rrrrsPYsWMxadIknDt3Dv369YOPj49WSzNjxgxMnjzZ+iUlInI2WSeBBY+p9ZiuQLuRFzZ2TGkBEBQJxHRpsCISuWWNzNatW3HJJZdo6z/++COio6O1WpkvvvgCb7/9trXLSETknNb/17S+6q0Le+6+BWrZ5krAw8O65SJy90AmPz8fwcHB2vpvv/2m1c54enqif//+WkBDROQyNn4ELJsGlJdd2POkKUnGgNGd2GRM3q2DY2uBjR/Wb24lIjdTr0CmdevWmD9/vjZVwZIlS3DllVdq+9PT0xESEmLtMhIR2UdJIfDrE8DqGcCu/13Yc3NSgXPHAQ8voO0otU/PeTmfvb+Y1ttffWE/l8jN1CuQef755/HEE08gISFB6249YMCAitqZHj0ucpZVIiJHkZVsWj+5tX7PDYkD2gxX66cP1O25abvU8rpZgKfXhf1cIjdTr2TfG2+8EYMHD9ZG8dXHkBHDhg3D9ddfb83yERHZz1mzpvL9i4ErXwa8fOr23CzjxLohTYGINmo98zyBzNYvgOA4INUYyER3qlexidxJvQIZERMToz30WbDj4+M5GB4RuZZzR03rZ48AB5YC7a+q23OzT6plaFOgSRtTYCTdqr19q56fvAn4+WHTtjRJRXa4qOITuYN6NS2Vl5drs1yHhoaiRYsW2qNx48Z4+eWXtWNERC5XIyNOXUDzknmNTHAs4NsIMJSpgKg6x9ZYbjfrC/j4X2iJidxOvWpknnnmGXzyySd47bXXMGjQIG3f6tWr8eKLL6KwsBCvvPKKtctJRGR7kqwrGsUAualVA5vanDEGLOGJqvt0RCsgZTuQkQREtqt6fuoOy+1ut15MyYncRr0Cmc8//xwff/xxxazXomvXrmjatCkefPBBBjJE5BrOGQOXxEuAnT+YtqtzZBVwfD0w8CHAJwA4c1jtD2+pljJXkgQyh1cAHU2fnRXkmOh0PdBhNNCJk0QSNVjT0pkzZ9C+ffsq+2WfHCMicqkamcRL1bKmGhlpUv/ffcCKfwK/PQeUFgFnjfk1YYlq2c6YW3NgWdXnF5wFMg+p9aveAjrfwEHwiBoykJGeSu+++26V/bJPamaIiJxeUS6Qn2kZyEjzUklB1XNPblHHxOZPgT0/A+UlqkmqcXO1v3l/wMMTyDqupi6obpZrSe4NatKgl0XkaurVtPTGG2/g6quvxrJlyyrGkFm3bp02QN6vv/5q7TISEdmvNsa/MdC4BeAbDBTnqP2Vc1ySFprWJaF37n1qXcaP0WtW/IKB2O4qYXjuROD690xBjvSG0s6/ouGvi8jF1KtGZsiQIdi/f782ZoxMGikPmaZg9+7d+PLLL61fSiIiewUyEmxIMBLWQm0v+nvV6Qr2Gf+B63ab5f6ulRJ2+96vlsdWA9/dCRTnAWUlZoGMGiWdiGwwjkxcXFyVpN7t27drvZk+/NA4RwgRkSsEMiIgTC0lWXft28Dg/1PbJ7YAp5MAT29g5GtA+l4gZRsQ2R5IGGz5mhLoSHPVb8+qc16NMx3zC1HNT0TU8DUyREQuT++hFJaglo2iTMckD0a37h1Tb6OAxsB9y4CbvwAmLKiasCvbAx8GWg2r+vNaD6v7qMFEdPE1MkREblUjM3Sq6okkib3nktUIvRJ4yEzVovc9ain7Ol5X+2sPfVrNhi35N9IVW+Zguvy5hrwaIpfFQIaIqLZAJrSZWso0A/cuA16JBsqKgZwUoLwUyE0DvHyBuJ51f20ZtfcJmXfJoMacISLbBDKS0FsbSfolInLJGhnh6alms5aaGZlLKcfY5Tqm64VPJ8DpB4hsH8jI3ErnOz5+/PiLLRMRkX1Jb6IC4+CejY01MrqQeBXIyFgw+tgxeh4NETl2IDN79uyGKwkRkaPQJ3z0CwX8K/0DJ7NZi+wTQE6a5T4isjnmyBARVSbJvCI0vuoxmc1aaDUyaZb7iMjmGMgQEVUm0whU16xkUSNjHsiYjQdDRDbFQIaIqLLTBy0nfKycI6M3P+VlGPexRobIXhjIEBFVlrpDLWO61Fwjc+YwUJJfcxMUEdkEAxkiInMGA5C6s+ZARq99Kc5Vy8AmQFCkDQtIROY4RQERkTlpMio8B3j6qPmSKpM5l4LMpiuI7Vp1KgIishkGMkTkfkoKgJWvA4v/UXUma702RoIYb9+qz5WgJb6PabvtqAYuLBHVhk1LROR+g919NAzI2Ku2214JtBxqOl5bs5Ku+23A/sVAs35ATw4CSmRPTlUj89prr8HDwwOPPfaYvYtCRM5q7bumIEYcXF73RF9dh9HAkweBu3/lVANEduY0gcymTZvwwQcfoGvXrvYuChE5sz3z1bLlZWq55TNVS6Mn+sqs1HruS20Cw5kbQ+QAnCKQyc3Nxbhx4/DRRx8hLCys1nOLioqQnZ1t8SAiqsiNyUhS69e9qyaELMoG/nwLWPo8MK2xGuTOJ8gyD4aIHJZTBDJTpkzB1VdfjeHDh5/33OnTp2uTV+qPZs2qGZmTiNxT2h7AUKa6S0s36vbXqP2rZwBr/mM6r+O1gLef3YpJRC4UyHz77bfYunWrFqDUxdSpU5GVlVXxSE42zplCRK4l85AKPspK6v6clL/UMrabaha65G+WxyUvpvs4YMSr1i0rEblnryUJQh599FEsXboU/v51S6jz8/PTHkTk4t7pqZZevkD/yec//8BSYKExcIkx5r8ENQEeXA+sfQdoPQzofEMDFpiI3C6Q2bJlC9LT09Gzp/EDC0BZWRn+/PNPvPvuu1o+jJeXl13LSEQ2Jgm5esKuSNtVt+ft+M603u4q03pUB2DMf61YQCKyJYcOZIYNG4adO41jOhjdfffdaN++Pf7+978ziCFyR1tmAwv+z7RdXl63550zNjN3vQVoxkReIlfh0IFMcHAwOnfubLEvKCgIERERVfYTkZs4vsFyO/tE3Z53er9aDphi/TIRkd04fLIvEZEFmXVa9L7HNDfS+eRlAgVn1HpE6wYsHBHZmkPXyFRn5cqV9i4CEdnTmUNq2epyYPOnQNZJlTdT2+B0mQfUMiQe8A2yTTmJyCZYI0NEzqPgLJCfqdZbDJIZHIGyIiDvdO3PO20MZJq0afgyEpFNMZAhIueRaWxWahSjpggIjlHbWcl1y49p0raBC0hEtsZAhoicR+ZByzyX0Hi1zD5Z9dzCLKC0SK2n7VbLSAYyRK6GgQwROV9+TERLtZRpBsSpv4Ad3wPZKWo7fS/wr/bAB0PUhJAnNqv9TXvbo9RE1ICcLtmXiNyYPuGjXiMT0UotV/1LLaM6AZPXAH++CZTkAxl7gSX/AIqyAJ9AIJrDNhC5GtbIEJHzkJoXfa4kkTjE8nj6btWTadf/TPu2fKaWTXsBXvzfjcjVMJAhIudw6Hfg3DHLQKb5ACCiDeBh9lG28HG1bDPC1PQk2o60ZWmJyEb47wkROT6Z4XreJLXe5SYgIEyte/sC9/+uumXL40NjDY00I139L+DkFuB/9wKx3YEe4+xXfiJqMAxkiMjxHV8P5KapAObady2P+YeoR1gLYPD/AVu/BG74GGjcTD06jAY8OS8bkatiIENEjm//YlPzkI9/zecNfxEY9oLlKL8MYohcGnNkiMh5knwrJ/dWp7apCojI5TCQISLHp4/MG9Xe3iUhIgfDQIaIHFv+GSAvQ61LDyUiIjMMZIjIsZ02m7nar5G9S0NEDoaBDBE5ttPG0Xw5czURVYOBDBE5R35MZDt7l4SIHBADGSKyvj0/A+vfA8rL63a+nCdNSAZD1WMZxkCmCWeuJqKqGMgQkfWTc3+8B1j8NLDl07o9Z/W/gHd7A6v/XXONDAMZIqoGAxkisq6kRUB5iVo/tOL85+9fAvz+T7W+fJrlsZJC0/xKbFoiomowkCGihhm8TqTurP3cI6uAr2+23Jd10rSeeRAwlAP+oUBQpJULSkSugIEMEVlX2m7TutSmFGYBpw8Cq2YAxfmW5+6eW/X5x9aY1jP2qWWTdhyxl4iqxUCGiKxHknXNAxmRvhf4frxqNlr6nOUxmZ1a3PQ5MPBhtX50leVzRVSHBi02ETkvBjJEZD1ZJ4CiLMDT2zQvUtKvQLoxuNn0salnkuS/6EFPXA8g4RK1fnR11RqZqI62uwYicioMZIjIetL3mKYSiOuu1tf8x/KcDOMAdxLElJcCgRFA4+ZA8/6Ahydw5rApT0YPdFgjQ0Q1YCBDRNajBx7RnYDoztWfs/ULtTy11VQbI/kvktAb203t278YWPwP4OwRVbuj7yciqoSBDBFZv0YmuqNlIOPhBYz9WK0f+l0tT20zBTK6dlep5cLHgfWz1HqbK4GAxjYoPBE5IwYyRGQ9acZAJqqTag7SB7FLvEQ99LyXohyzGpmepud3vM7y9aK7ANdUM0geEZGRt75CRHRRSotMo/BKjYw0F437EdjxHdB9HBAco2awzj4BHFtnSuQ1r5GRQe+ungFsmQ10uBYY8pR9roWInAYDGSKyXrOSjOgbEAaENlP7wlpYBiNNe6hAZuvnaqC7RhLcxFq+Tp971YOIqA7YtERE9VNWAvzvfmDB42rSR31E39juNQ9e17S3Wu5bYNzuZaPCEpGrYo0MEdXP3l+And+rdeldJLUrlZuKKus8Vo3wK2PNiDZX2KCgROTKWCNDRPVz5A/TuvRE2v61WteTeqsj48Xc+hXgEwgEx1VN7iUiukCskSGiC1deBiQtVuuhzYGs42o9vg+QOLT25yZeCjy+R40P4xfc8GUlIpfGQIaILtyCx4DcVJXY+/AW4MQmIHUH0ONOwLMOFb3yPCIiK2AgQ0QX5uAy0+i8Q54GvH2BhEHqQURkY8yRIaK6O/InMOdm03xKfe+3d4mIyM0xkCGiuik4B/x4D2AoA8ISgLt/BTy97F0qInJzbFoiovMzGIAl/wDyMoCwRGDSKibqEpFDYI0MkTvLSAK+uR04uLz285I3ANvmyOyPwOiZDGKIyGEwkCFyZz9NAZIWAj89VPt5h41jxnQYDbQ8T/dqIiIbYiBD5K6Or1fdpkXOKeDssZrPPbZaLVsOsU3ZiIjqiIEMkTtKWgR8OsJy3y+Pqq7Vkg9jrrQYSDYGPC0G266MRER1wECGyN1IoPLbc2rdwxPobZxp+vAK4KsbgD/ftDw/ZRtQWgAERgCR7WxfXiKiWjCQIXLHOZIyDwC+wcDTx4Fhz6kgRbd6JlCcZ9o+vFItWwyseVZrIiI7YSBD5G42fayW3W5VvY9kuoBJa4DH9wIh8UBJnuqlZN4MJVoPt095iYhqwUCGyJ1knQT2/arW+xiblERILBASZ5q5Wu+ltO0b4NRWwNMHaHeVHQpMRFQ7BjJErqqkAPjiOuCtdsCGD9S+LbPVyLyStBvVofqZqcWamcCLocD8SWq79z1AoygbFp6IqG44si+Rq9q30JTfsugpwCcAWP9+1doYc+2vAcJeB84etQxuRk63QYGJiC4cAxkiV7X3Z8vtnx9Wy4jWQIdrq3+Ofwjw0BYgZTuwfBoQ2gwY/gLnVCIih8VAhsgVFecDB5aq9TvmAktfANJ2qu0+9wFetfzpy7H4XsCESoEQEZEDYiBD5IoOLQdK8oHQ5kCry4GmvYClz6txYPpOtHfpiIishoEMkSva87NpbiQZ+yWgMXDt2/YuFRGR1bHXEpEzKjgLnDlc/bHyclUjI9pfbdNiERHZGgMZImcjo+5+dDnwdg9Tt2pzkguTnwn4NgKa9bVHCYmIbIaBDJGzkbmQ9NqYldNVYq85vct1wmDAy8f25SMisiEGMkTORJqNtn5p2cS05yfLcw6tUMuWQ21bNiIiO2AgQ+RMMg8C+acB7wDgkr+pfXt/MR0vKQSOr1PrLS+zTxmJiGyIgQyRMzm5WS3jugOdxqr1A0uAc8fV+uEVQGkhEByruloTEbk4hw5kpk+fjj59+iA4OBhRUVEYM2YMkpKS7F0sIvs5YQxkZFyY6E5A8wFAeSmw4zs1q/U3t6rjMsGjdLsmInJxDh3I/PHHH5gyZQrWr1+PpUuXoqSkBFdeeSXy8vLsXTQi+9bIxPdWgUqPO9T27/8EFhqbmiI7AJc/a78yEhHZkEMPiLd48WKL7c8++0yrmdmyZQsuvdQ4Sy+RO81mnbZbrTftrZZdbgJWvgZkJavtjmOAGz/l3EhE5DYcOpCpLCsrS1uGh4fXeE5RUZH20GVnZ9ukbEQNTiZylGakRtFAaLza5+0HjP4P8OuTqpfSVW8yiCEit+I0gUx5eTkee+wxDBo0CJ07d641r2batGk2LRuRTRxdrZbxfSzzX1oPAx7ZardiERHZk0PnyJiTXJldu3bh22+/rfW8qVOnajU3+iM52VjlTuTI8jKBOTcDy1+u+ZyDxmkHZBJIIiJynhqZhx56CAsWLMCff/6J+HhjlXoN/Pz8tAeR0ygvA74aC6RsU12pe44Hwlqowe5+eQxo3BwY+AiQvMFUA0NERI4fyBgMBjz88MOYN28eVq5cicTERHsXicj6dv6gghjd1i+AYc8B698H9sxX+05uBQxlQGx3ICzBbkUlInI0no7enPTVV1/h66+/1saSSU1N1R4FBQX2LhqR9eyep5ZRndRy7TvA6QPA7rmmc44Z82N63mmHAhIROS6HDmTee+89Lc9l6NChiI2NrXh899139i4akXWUFgFH/lTrY/4LxPUEyoqAH+4GTu+3PFcCne7GcWOIiMg5mpaIXNrx9UBJvupSHdsNuPot4KPLgbSd6niHa4EWg4CTW4DLpgI+/vYuMRGRQ3HoQIbIpWpefn8Z8PIDhj4NePmo/QeXqWWrYapLtUw9kHipqZZGRu5tO8J+5SYicnAMZIgaSlkp8OebQGkBkLJDTegoinOBUa9LlaNp5uo2w03PGzEdWPi4qo1pc6V9yk5E5CQYyBA1lL++AP54rer+rV+quZDW/Rc4ewTwDrAMWGI6A/f+ZtOiEhE5K4dO9iVyahKw6OJ6ADd8AkS0BkrygE9HAStfVceumAb4BdutmEREzow1MkQNIScNOGWcNuBvSUBwjFrPTQeWTDUl8/adqB5ERFQvrJEhaggHl6qlDGCnBzGi3wNA/ymApzfQ8TpgxKuW8yYREdEFYY0MUUPYv1gt24603C8zU498FRj+IuDta5eiERG5EtbIEFlbcT5wyNhDqaau0wxiiIisgjUyRNYYI+bYWjWtQPpuICRedbGWyR6laYmIiBoMAxmii1FwDphzI3BiU9VjksTryUpPIqKGxE9Zoovx+z+rD2KkJqbvA/YoERGRW2GNDNGFyssE1vwbyNgPHFii9o3/CWg5FCgpBDL2AZHtmQdDRGQDDGSILsTZY8DHw4G8dNO+VperIEbIpI5xzIshIrIVBjJE51NeBvz2HLD1C6A4R+0LSwS63gIUZQODH7d3CYmI3BYDGaLzWfg3YMts03ZQJHD7d0BkO3uWioiIGMgQncf+JSqI8fAERr2h5kyS/Be/RvYuGRERMZAhqkVRDrDA2GzU/0Gg7/32LhEREVXC7tfkvgqzVf5LTZa+AGSfAMISgMuesWXJiIiojhjIkOuRGaZ3zwNO/QUYDNWfs3cB8EYi8NHlKqAxV14O/PQQsPkTtX3NTMA3sOHLTUREF4xNS+RaDq8EfrgbKDijtq99B+g53vKcc8dVAm95KZCyDdjwATDkSTUGzIb3gB3fA+l7AA8v4IqXgFaX2eVSiIjo/FgjQ65D5jv6cqwpiBF/fWV5zsmtwAdDgNxU0z4JXopygW9uBZa9qIIYeABjPwQGPmS78hMR0QVjIEOuQXJdfn0KMJQB7a8BHtmmgpHkDaoGRq+tmX2VCnRkCgE5p3ELID8TmNkZOGycsbr3vcA9S4AuN9r1koiI6PwYyJBr2PkjkLYT8AsFRr8NhCcCCYPVsV1zgdMHge8nAKUFQMIlwF0L1DmDHlHnFJxVy6tnANfMAJr3s9+1EBFRnTFHhlyDnpg78GEgKEKtdx4LHF0F/P4ysOJVoKwIaNoLGPejmkpA9BgPpGwHUnYAfe4Det5pv2sgIqILxkCGXCM3RpqQvHwtA5EuNwObZwOpOwCUAnE9gZu/NAUxQiZ2lIRgIiJySgxkyPlzY1ZOV+vdxwHBMaZjMvru/b8Dx9YAAWFATFfAw8NuRSUiIutjIEPO6+xRleB75E/A0wcY/H9Vz/HyMc1MTURELoeBDDmHshJg3wIg8yBQnK96J8n4L6WFKoiRrtJhLexdSiIisjEGMuR4ZDRe6RLtH6pqVKT79Fc3AqeTqp4rPZBGvgbEdLZHSYmIyM4YyJD9pe4ETmwCYroBh5YD2+aoZiMJZDrfoGagzj6pzm07CgiJM/VA6jkB8PSy9xUQEZGdMJAh25EmIQlYGkUBUR3UvqRFwHd3qOkCKivMAjZ/qtZl4sa7fgVCm9q2zERE5NAYyJBtJG8E5twEFJ5T2x3HAG1HAgseU0GM9CqSwCWmC9B/CtBuFLDnJ1VDExwHXPI4ENTE3ldBREQOxsNgqGl6YNeQnZ2N0NBQZGVlISQkxN7FcU85acAHl6r5jfxCgOJcwFBuOi7NRbd8pbpGs5mIiIhQ9+9vTlFADd/b6Me7VRAT2R54fC8w8Q+gxWAV1HQaC9z4CeDlzSCGiIguGJuWqOFIZd8vj6oB6XyDVa2LDFIX2xW4e6G9S0dERC6AgQxZ144fgP2L1Qi7MoeRzHXk4QXc8DHQpI29S0dERC6GgQxZr0fS8mnAhvct98v8RzIbdbuR9ioZERG5MAYy9bR5wYfw3jMPpa2uQLtLb0RwZHO4dBORjKp7eKUaqE7yXiRACYwAOl4L5J8BFj8N5KSo8ztdb+oyLeO8hCfatfhEROS6GMjUk9fen9E9fy2wUx7TsLM8AUvLemOjRxdcO3IkIsPD0DU+FNEhZjMtO6O0PcCvT6g8l+ps+si03rg5cNVbQNsRNiseERG5N3a/rqdDOzcgbfM8hBxfjo7lB+DpYfo1lhi8sMXQFj+UDsGi8r7Ihz/GD2iBPgnhWmAjAY6/j5fjziadvgc4sRk4uRnY/q0a58U7AOg5HohoBXh6q1qZ1B3AgaXqed1vB4Y+DfgE2PsKiIjIjb6/GchcpLJyA9Zs34tj6+aifc5aJOTvQqRHVsXxfIMflpT3xvyywdhc3hZ5UF/0V3aMRklZOfq1jMD9l7TEgfQc5BWVoleL8AsvRG4GcOQPoM0Valj/2pQWA/sXAaVFQGi82rdvIZC2CygpVEsZ58Vc+2uAkdNVjQsREZENMJCx04B4xSVlyE45gNwt3wF/zUGCZ5rF8cPlMdhhaIn5ZYPwR3k3GCoN5fP+HT0xvEM0vDw94CEDxFVHclJWvAoUnFF5KJtnq3UJYoY8DUS2VedFtFHBSuYhNdjcyS3AqhnVT75oTrpKx/cGwlsCnccCCYMv7pdCRER0gRjIOMLIvvKrPbkFZdu+gUfSQnjqybBG5wxB8IABmYYQzCsbjHCPHMR4nMEvGIplhp64tE0UJg9thbTsQuSfScGNZb+qhFqZn0iSbutCmoRKCyz3+TcGojsB2adUzUzTniqvxTdIDVonDw5OR0REdsRAxhGnKMjLBFL+guHgchRv/hJ+pTk1nrqvvJkW4OTBH8XwwaWeOxDikW86IbyVakrKOgEkDgF6TQDWvg2seQcIDAe8/YHMA6b8FkMZENEa6HAt0H+SmtuIiIjIQTGQccRAxlxJgTZgnME/FMnbV6Js13xszPRHIXxwm9fv8PUoqza42VmeiOSAdnj0qVfh5eN7/sDp7FE1EaOXj2peIiIicgIMZBw9kKnB95uT8a8fV6KT51GEIB+NPAog9TKHDHFYWt4b5WY5Nc3DA9G/ZTgW7UzFlMtbY9KQVli8KxVHM/O09X2p2Zjx2348fmVbtI9x/GsnIiLSMZBx0kBGN2vFQby55DxJubXo0jQUO0+q3lNNGvli87NX4OS5Avh7e2Lu1pMY2i4SbaKDqzxP3g65RaUI9ve5qPITERFdDAYyTh7I6KSL9t6UbBQUl+GWD9db9bVbRgahSSM//Oumbli6Jw2hAT44cjoP7644iG8n9kf/lhEV58rb5FRWIZo2DrDoev6/LSdw4lwBHr/C2FOKiIjIChjIuEggY+5QRi4ycooQGeyHYf/6o8F/3kfje2N4hyj8vi8dX284juX70jF9bBfc1rc5/rlgDz5efaTi3AUPD0bnpucZw4aIiKiOGMi4YCBjbkVSOhbtTMH3m0/Y/GdLTc7hjDyLfQ8ObaXV0IztGY83l+xDSZkBH0/oDR8vy3FyxPHMfCzYeQp39m+hNWFlF5ZoPdWlRoiIiEgwkHHxQEa351Q27v9iM1KyCvDlvf20WpGk1Bz0bN4Yry3aZ1FrYg+DWzfB7Lv7wNPDQyujDPI36LXftWN3DUzAs1d3QPeXliK/uBR/PXclQgNNwYwEOPd9thmjusTg7kGJWjObvI4MFkhERK6NgYybBDK6otIy+Hl7VVv74evtibAgH+w+lY1OcSEoLC7HxqNnMGfDMS33ZsORM7AXybmRJGTd9uevRF5xKe74eAMOnzbV+vw4aQAe/XYbYkP9MfWqDlqwdkufZhZBTWlZObzNaoDSswu1HCBPTw8tx0fe6bKuyyoowXebjuPy9lFoHVU18dkeTYfn8ovrN00FEZGLYSDjZoGMtRSWlOGfC/fgsnZRGNYhGr/tTsXK/Rlajow5ydORfB1HIM1aksezLzUHEy9tiQcubYlVB07jse+24Y7+zfHIsDbo+8py7dwDr4yCt6cHjmbm47K3Vla8xg+TBuBAWi5u69us5qkhGljC0wu15eq/X4b4sEC7lIGIyFEwkDFiINNw1h/O1Gp75C10w3vrKuaKmvTVVjizhy9vjSs7xuD9Pw7hqZHt0CIi6LzPkZqUEH8fFJeVV5nZXJrEJFdow+FMPPzNX3jl+i64omO0xTnyO0yc+qu2/vk9fTGkbaSVr4qIyLkwkDFiIGO7mhxppgoL8tUCnDs/2aAl/FZn2rWdEODrhad+3AFn1KN5Y/x1/BzG9WuuBSifrT1a5ZwXR3fEW7/t18bkEQ8MaYkP/jhccVxqhiS3aWVSBn5+aBBaRjZC5xeWaMfeua0Hks/mo7C4TMt5euTbv/DosLa4qXe81lRGROQOshnIKAxk7EveXq8s3IuYUH8tAOgW37gijyWvqFTrfRXg44VGft6457NN6NE8DOsOZ2o9oB4d1kar4Rg/oAXeXJyEuX+dhDtrG90In0zoozXr/bDlhDYp6du/H0TXpqFa7tMtfZsjNasAd36yEW2jg/HlvX2x+sBpNA0L0AIlySuKDwtAdIg/ikvLtdo0yU/674qD6N6sMUZ1idUCUgmWZCmJ1XJOZeXlhopcIwle/zp+FiHGHmfmXfBPnM3Xyiq5W/I+kHudmVuMa7rGaYFsZXJ+VLB/tT+zprywP5IyMKBVBAdwJHJBDGSMGMg4H3lLZheWWnTHlkTeA+m52J+Wgz0p2YgI8kVuYSmu7R6Hq95erX0xm0tsEoQ3buyKXSez8Mv2U9h6/Jy2f6Ixf0YGGaS6uf+SRFzVJVb7XaZkFeK/Kw9V1Ky98PNui3Nfvb6LFrBK9/wpX2/FqM4xuLprrFb7ll9smj/su4n90TshHBuOZKJ1ZCMkny3ADe+t1abckJ5uHWJDMH/bKfh4eWgDNlbOWzp1rgBvLz+AbzclY3iHaK2rv9R+nc0rRrPwQO099Lfvt6O03ICZt3SvSPhedyhTyz969qddWkAmz9ObAn/fl6ZN5RFnNuhjdSQAl/eb1D66g4U7UhAd4qfdLyJbYiBjxEDGPUj+ybHMfNzcp1mdzv/gj0NaLyEvT0+0bBKEewYnorS8vKL555PVR7ReTW2iGqGRv7dWY7T56FkUlJRV1I7sT8tt0GuiqpqFB2DqqA54cI5lHpYMyHjNO6sr8rSkuW/9YdUbL9jfGwsfvgRrD53G03N3WjxPmvwa+XrjX0v3V+x7+bpOuHNAQsX2l+uO4uuNyRjQMgJ9E8Mx6ast2n4JlLMLSvD6YjVu0i8PyaCQIdUmi8/dekKraZIAWj5xnxrZXtv/684UtIgIRKe4mgeTlNoxSVA375FXHQnEpKnyjv4t0CqyEaQUn645ogVqsq8+JHjVf69HX7sa1iZfP/VJrq/cQ7G+DqbnarWUlfPayDEwkDFiIEPWJF9ES3anauPaBPl64WBGLny9PLHp6Bntv/QRnWIQFeKv/ecvX14PX94GN76/VusFdueAFsjILdJqk+S/fh9PT3R76TftdTvGhmDGLd0wcuYqi5/3zFUd0DU+FCuSMrTkY3MyMaj5Pj9vTxRVqpmiiw+cks+Yhge4UMv/NgR3zd5Y5TUSIgK1nnPnc03XWCzYkaKtX90lVmuqk5G107IL8eGfh7H64GktEJf7bj6MQU2u7BiNd27vgXP5JVpTrnyRy3MlmBrVOVZLQpcaGAm6th4/q70v9RywFU8MReMAH21i2+mL9mn7LmnTRAssJafrpV/2aGWYPLSVNr2J1MxtPXZWa/qTvxH5m1iwM0ULQsYPSKgIkObc1w+DWjfRrkn+gbh7UAK+33RC+zuTqU9k2IiHLm+Nr9Yf04aNuHtggtZ8Kr0Vp1zWGiXl5RXNl/JtJnPMzd92UmuaLiwp18ovTaebj57BEyPaaUGL1KrJtCzSs7F3izCth6Y0Vcrfq/mQDlLDJ//QyPVJTeHelBxtrKs/92dof8cbj5zBkyPbVQx9IbV8fxzI0JrQw401dgt2nNLG9Jp1e090a9ZY25eZW4SwQF+L4SD0oFVqFuVvWSYANm+Glet7e/lBxDX2x029Lf9hy8ovsRiDqzK5tqf/t1N7r0wa2krL7ZPm+8pjcmm1locz0S46GBEOkI/nUoHMrFmz8OabbyI1NRXdunXDO++8g759+9bpuQxkyJmkZhXCAANiQ6s2b0izmnzsSBAkXzTyYSS9pSQH6fZ+zbX8old/3at9mcgHkfynKR+mMn/WhAEJeHruDvyxPwP/uKqDNiZPv8RwbZTmBdtTECQ5SoMTtNyau2Zvssu1k/uS9+mZvGKb/KzGgT5aIFNTZwQJNi5t00RrtqzrEBPSJKrXANY2AnplV3WJwcYjZ7XxsSTYqK6WV2qDb+wVX6VTQYi/t9YEr7tvcCL8fDwxa4X650aC3rE9m2odEyTgqs5NveKxNzUbRSWq6b5ybaVc044T5/Da2C5aUCVB4M/bT+KX7Sk4fiZfC4Tl9/nvm7vjsvZRsDaXCWS+++47jB8/Hu+//z769euHmTNn4ocffkBSUhKios7/i2MgQ3Rh5Atl4c4U7D6ZhedHd9QSdOWLRoIdnST5yn++Eiy98ute7YO2U2yIluvyr9+SkFdchjdu6Kr9py//UZcbDFpSt3y4PzNvF+aZJW7/b/JAnM4twnsrD2kjPXeMC0Ggr7c22vOX645p//3Lh6XUIpiT4M18fKPKH+zd4kOx/YSaAb46UqMm5dRJbYR8UEtO1flIDg/zrIhMpLfl6G5xsCaXCWQkeOnTpw/effddbbu8vBzNmjXDww8/jKeffrrK+UVFRdrD/Bch5zOQIXIs8tEj1faNA+ueNCvV7jL44RUdorUq95zCEpzOLdaq26V6X6rL31t5UAuGLm8fXfFzpGknOlT1oDqQlqMlkksTYHVk3J/JX23Bsr3piAnx14Kod2/vCX8fT22kbEl6lRoxCeakV528ljQpHD6di9AAX+0/1ZVJ6fh41REtp2rRo5dor/nTtlNa00mryCAcMv6n/voNXTC0XRSW7U3Tml4ubRupNfUkpWajRXiQ1rwi/+lKs8iDl7XGQ19vRVp21VqCN2/sqjVvShOkXosgg0FKXpeMni3/bUu5pGnptz1pFc1bEvgF+XmhvBxaM4M0baTXUAsxtF2kdh1rDmZq22O6x2kJ2eYkd0zuaXVlJNf21k3dtH9orMklApni4mIEBgbixx9/xJgxYyr2T5gwAefOncNPP/1U5Tkvvvgipk2bVmU/Axkiqiv5WCw3qC93R1eXhFk5R5LhpYZMPvHl9JqeI0GZNE9KEJZTWIpeLcIuuEzyGmfyi7WmUmkyke7x0mwppFlHhlKQHm3S1V+2vb088I+5u/DngQx8MqG3NrikDNkgNWQSMEqeiQSP0lzSISbEosfYD5uTtUBQhhiQ29UvMQJ9jMGm9G7LzCvWel1JgJddUKrVDsq6NOe0imqkrUswKsng13ZrqgXHkh8iNXM7TmRpTa7SxCI5K7K+bE+61vwr+TvyO91y7Kx2bZJHIzk18nuTZt81B08jNbtQa166tU8zLZfI01M1EZeVQ/s5EuzK71p63smo4jIti+Qm7UjOQruYYC1H6dVFezGoVRMtv25011hsPnZWC4qFjEHVNb4xZq04iFUHMrTcvQ2Hz2i5S9IE/cW6o0iICML2E+e03KrvNiWjdVQj7Z8Buf1SSyq5fTLUQnpOYUXe1tu39cB/lqlxsOSYvAckKJbrkSlddp/K0oIWeW2pnZR58Qa2agJrc4lA5tSpU2jatCnWrl2LAQMGVOx/6qmn8Mcff2DDhg1VnsMaGSIiIudX10DG1OjtIvz8/LQHERERub6L74jfgJo0aQIvLy+kpak2XZ1sx8TE2K1cRERE5BgcOpDx9fVFr169sHy5mrlYT/aVbfOmJiIiInJPDt+09Pjjj2vJvb1799bGjpHu13l5ebj77rvtXTQiIiKyM4cPZG655RZkZGTg+eef1wbE6969OxYvXozoaNW1koiIiNyXQ/dasgYOiEdEROS6398OnSNDREREVBsGMkREROS0GMgQERGR02IgQ0RERE6LgQwRERE5LQYyRERE5LQYyBAREZHTYiBDRERETsvhR/a9WPp4fzKwDhERETkH/Xv7fOP2unwgk5OToy2bNWtm76IQERFRPb7HZYRft52iQGbLPnXqFIKDg+Hh4WHVSFGCo+TkZJed+sDVr9HVr88drpHX5/xc/Rpd/foa8holPJEgJi4uDp6enu5bIyMXHx8f32CvLzfNVd+c7nKNrn597nCNvD7n5+rX6OrX11DXWFtNjI7JvkREROS0GMgQERGR02IgU09+fn544YUXtKWrcvVrdPXrc4dr5PU5P1e/Rle/Pke4RpdP9iUiIiLXxRoZIiIicloMZIiIiMhpMZAhIiIip8VAhoiIiJwWA5l6mjVrFhISEuDv749+/fph48aNcAbTp09Hnz59tJGOo6KiMGbMGCQlJVmcM3ToUG0UZPPHpEmTLM45fvw4rr76agQGBmqv8+STT6K0tBT29uKLL1Ype/v27SuOFxYWYsqUKYiIiECjRo1www03IC0tzSmuTSfvu8rXKA+5Lme8f3/++SdGjx6tjd4pZZ0/f77FcemP8PzzzyM2NhYBAQEYPnw4Dhw4YHHOmTNnMG7cOG0wrsaNG+Pee+9Fbm6uxTk7duzAJZdcov3Nyiikb7zxht2vr6SkBH//+9/RpUsXBAUFaeeMHz9eG438fPf8tddec4jrO981irvuuqtK+UeOHOkS91BU9/cojzfffNMp7uH0OnwvWOuzc+XKlejZs6fWw6l169b47LPPLv4CpNcSXZhvv/3W4Ovra/j0008Nu3fvNtx///2Gxo0bG9LS0gyObsSIEYbZs2cbdu3aZdi2bZvhqquuMjRv3tyQm5tbcc6QIUO0a0pJSal4ZGVlVRwvLS01dO7c2TB8+HDDX3/9Zfj1118NTZo0MUydOtVgby+88IKhU6dOFmXPyMioOD5p0iRDs2bNDMuXLzds3rzZ0L9/f8PAgQOd4tp06enpFte3dOlS6XloWLFihVPeP/n5zzzzjGHu3LnadcybN8/i+GuvvWYIDQ01zJ8/37B9+3bDtddea0hMTDQUFBRUnDNy5EhDt27dDOvXrzesWrXK0Lp1a8Ntt91WcVyuPzo62jBu3Djtvf/NN98YAgICDB988IFdr+/cuXPaffjuu+8M+/btM6xbt87Qt29fQ69evSxeo0WLFoaXXnrJ4p6a/83a8/rOd41iwoQJ2j0yL/+ZM2csznHWeyjMr0se8t3g4eFhOHTokFPcwxF1+F6wxmfn4cOHDYGBgYbHH3/csGfPHsM777xj8PLyMixevPiiys9Aph7kg2bKlCkV22VlZYa4uDjD9OnTDc5GvhTlD/OPP/6o2CdfhI8++miNz5E3qKenpyE1NbVi33vvvWcICQkxFBUVGewdyMiHYXXkS8PHx8fwww8/VOzbu3evdv3yBeLo11YTuVetWrUylJeXO/39q/wlIdcUExNjePPNNy3uo5+fn/ZBL+QDUZ63adOminMWLVqkfZGcPHlS2/7vf/9rCAsLs7i+v//974Z27doZbKm6L8HKNm7cqJ137Ngxiy/Bf//73zU+x1GuT9QUyFx33XU1PsfV7qFc6+WXX26xz5nuYXql7wVrfXY+9dRT2j+a5m655RYtkLoYbFq6QMXFxdiyZYtWvW0+n5Nsr1u3Ds4mKytLW4aHh1vsnzNnDpo0aYLOnTtj6tSpyM/Przgm1ylV4dHR0RX7RowYoU0ctnv3bhuWvnrS7CBVwC1bttSqqqW6U8h9k6p883snzU7NmzevuHeOfm3VvR+/+uor3HPPPRaTojrz/TN35MgRpKamWtwzmXtFmnPN75k0RfTu3bviHDlf/i43bNhQcc6ll14KX19fi2uW6vOzZ8/C0f4m5V7KNZmTZgip1u/Ro4fWZGFeZe8M1ydNCtLc0K5dO0yePBmZmZkVx1zpHkpzy8KFC7Wmscqc5R5mVfpesNZnp5xj/hr6ORf73enyk0Za2+nTp1FWVmZxs4Rs79u3D842M/hjjz2GQYMGaV94uttvvx0tWrTQggFps5U2fPljmjt3rnZcvliqu379mD3JF5y0ucqHZUpKCqZNm6a1Oe/atUsrm3xIVP6CkLLr5Xbka6uOtNWfO3dOy0FwhftXmV6e6sprfs/kC9Kct7e39iFsfk5iYmKV19CPhYWFwRFIHoLcr9tuu81i8r1HHnlEyyuQa1q7dq0WnMr7e8aMGU5xfZIPM3bsWK2Mhw4dwj/+8Q+MGjVK+wLz8vJyqXv4+eefa7kmcr3mnOUellfzvWCtz86azpFgp6CgQMuBqw8GMm5MErfkC3716tUW+ydOnFixLhG2JFkOGzZM+wBq1aoVHJl8OOq6du2qBTbypf7999/X+4/EkX3yySfaNUvQ4gr3z53Jf7w333yzltz83nvvWRx7/PHHLd7X8qXywAMPaEmazjD0/a233mrxnpRrkPei1NLIe9OVfPrpp1pNsCTsOuM9nFLD94IjY9PSBZLqevkPonK2tmzHxMTAWTz00ENYsGABVqxYgfj4+FrPlWBAHDx4UFvKdVZ3/foxRyL/QbRt21Yru5RNmmKkBqOme+dM13bs2DEsW7YM9913n8veP708tf29yTI9Pd3iuFTZSy8YZ7mvehAj93Tp0qUWtTE13VO5xqNHjzrF9VUmzb7yWWr+nnT2eyhWrVql1X6e72/SUe/hQzV8L1jrs7Omc+T9fjH/aDKQuUASRffq1QvLly+3qIqT7QEDBsDRyX978madN28efv/99ypVmdXZtm2btpT/7IVc586dOy0+ePQP344dO8KRSPdNqYmQsst98/Hxsbh38qEjOTT6vXOma5s9e7ZWHS/dHV31/sn7Uz78zO+ZVENL3oT5PZMPWGnH18l7W/4u9SBOzpEutBIwmF+zNEHau0lCD2Ikt0sCU8mhOB+5p5I/ojfHOPL1VefEiRNajoz5e9KZ76F5Dal8znTr1s2p7qHhPN8L1vrslHPMX0M/56K/Oy8qVdiNu19Lr4nPPvtMy7afOHGi1v3aPFvbUU2ePFnryrpy5UqLboD5+fna8YMHD2pdBKV73ZEjRww//fSToWXLloZLL720Sje7K6+8UuuqJ13nIiMjHaKL8t/+9jft2qTsa9as0boCShdAycLXuxBKt8Lff/9du8YBAwZoD2e4NnPSU06uQ3o1mHPG+5eTk6N115SHfCTNmDFDW9d77Uj3a/n7kmvZsWOH1iOkuu7XPXr0MGzYsMGwevVqQ5s2bSy67kqvC+naeuedd2pdTOVvWLqB2qJra23XV1xcrHUnj4+P1+6F+d+k3tNj7dq1Wm8XOS7deb/66ivtfo0fP94hru981yjHnnjiCa13i7wnly1bZujZs6d2jwoLC53+Hpp3n5bySE+dyhz9Hk4+z/eCtT479e7XTz75pNbradasWex+bU/S/11uqownI92xZewDZyB/hNU9ZAwBcfz4ce1LLzw8XAvWZCwHedOZj0Mijh49ahg1apQ2zoEEChJAlJSUGOxNuvLFxsZq96Vp06batny56+TL78EHH9S6Ocof1PXXX6/9wTrDtZlbsmSJdt+SkpIs9jvj/ZPxb6p7T0qXXb0L9nPPPad9yMs1DRs2rMp1Z2Zmal96jRo10rp73n333dqXjzkZg2bw4MHaa8h7QwIke1+ffLHX9Depjwu0ZcsWQ79+/bQvGn9/f0OHDh0Mr776qkUQYM/rO981ypehfLnJl5p04ZVuyDLOUeV//Jz1Huok4JC/JwlIKnP0e4jzfC9Y87NTfpfdu3fXPqPlnyzzn1FfHsaLICIiInI6zJEhIiIip8VAhoiIiJwWAxkiIiJyWgxkiIiIyGkxkCEiIiKnxUCGiIiInBYDGSIiInJaDGSIiIjIaTGQISK34+Hhgfnz59u7GERkBQxkiMim7rrrLi2QqPwYOXKkvYtGRE7I294FICL3I0GLzN5tzs/Pz27lISLnxRoZIrI5CVpiYmIsHmFhYdoxqZ157733MGrUKAQEBKBly5b48ccfLZ6/c+dOXH755drxiIgITJw4Ebm5uRbnfPrpp+jUqZP2s2JjY/HQQw9ZHD99+jSuv/56BAYGok2bNvj5559tcOVEZG0MZIjI4Tz33HO44YYbsH37dowbNw633nor9u7dqx3Ly8vDiBEjtMBn06ZN+OGHH7Bs2TKLQEUCoSlTpmgBjgQ9EqS0bt3a4mdMmzYNN998M3bs2IGrrrpK+zlnzpyx+bUS0UW66PmziYguwIQJEwxeXl6GoKAgi8crr7yiHZePpUmTJlk8p1+/fobJkydr6x9++KEhLCzMkJubW3F84cKFBk9PT0Nqaqq2HRcXZ3jmmWdqLIP8jGeffbZiW15L9i1atMjq10tEDYs5MkRkc5dddplWa2IuPDy8Yn3AgAEWx2R727Zt2rrUzHTr1g1BQUEVxwcNGoTy8nIkJSVpTVOnTp3CsGHDai1D165dK9bltUJCQpCenn7R10ZEtsVAhohsTgKHyk091iJ5M3Xh4+NjsS0BkARDRORcmCNDRA5n/fr1VbY7dOigrctScmckV0a3Zs0aeHp6ol27dggODkZCQgKWL19u83ITke2xRoaIbK6oqAipqakW+7y9vdGkSRNtXRJ4e/fujcGDB2POnDnYuHEjPvnkE+2YJOW+8MILmDBhAl588UVkZGTg4Ycfxp133ono6GjtHNk/adIkREVFab2fcnJytGBHziMi18JAhohsbvHixVqXaHNSm7Jv376KHkXffvstHnzwQe28b775Bh07dtSOSXfpJUuW4NFHH0WfPn20benhNGPGjIrXkiCnsLAQ//73v/HEE09oAdKNN95o46skIlvwkIxfm/wkIqI6kFyVefPmYcyYMfYuChE5AebIEBERkdNiIENEREROizkyRORQ2NpNRBeCNTJERETktBjIEBERkdNiIENEREROi4EMEREROS0GMkREROS0GMgQERGR02IgQ0RERE6LgQwRERHBWf0/XNBzx2ColyUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.plot(v_losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Train\", \"Val\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7534\n",
      "Precision: 0.4000\n",
      "Recall: 0.4000\n",
      "f1 score: 0.4000\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "X_tmp_test = data.x[data.test_mask]\n",
    "y_tmp_test = data.y[data.test_mask]\n",
    "out = model(X_tmp_test)\n",
    "pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "\n",
    "cm = confusion_matrix(y_tmp_test, pred, normalize=None)\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    ")\n",
    "\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_tmp_test.numpy(), pred.numpy()):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_tmp_test.numpy(), pred.numpy()):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_tmp_test.numpy(), pred.numpy()):.4f}\")\n",
    "print(f\"f1 score: {f1_score(y_tmp_test.numpy(), pred.numpy()):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341,826\n",
      "GCN model number of params: 341,826\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234567)\n",
    "        self.conv1 = GCNConv(data.num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels * 2)\n",
    "        self.conv3 = GCNConv(hidden_channels * 2, hidden_channels * 4)\n",
    "        self.conv4 = GCNConv(hidden_channels * 4, hidden_channels * 8)\n",
    "        self.conv5 = GCNConv(hidden_channels * 8, hidden_channels * 4)\n",
    "        self.conv6 = GCNConv(hidden_channels * 4, hidden_channels * 2)\n",
    "        self.conv7 = GCNConv(hidden_channels * 2, 2)\n",
    "        self.norm1 = LayerNorm(hidden_channels)\n",
    "        self.norm2 = LayerNorm(hidden_channels * 2)\n",
    "        self.norm3 = LayerNorm(hidden_channels * 4)\n",
    "        self.norm4 = LayerNorm(hidden_channels * 8)\n",
    "        self.norm5 = LayerNorm(hidden_channels * 4)\n",
    "        self.norm6 = LayerNorm(hidden_channels * 2)\n",
    "        \n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.norm1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.norm2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.norm3(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = self.norm4(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = self.norm5(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv6(x, edge_index)\n",
    "        x = self.norm6(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv7(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=64)\n",
    "print(f\"GCN model number of params: {count_parameters(model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train_loss: 0.7452 / Val_loss: 0.7680\n",
      "Epoch: 002, Train_loss: 0.7418 / Val_loss: 0.6620\n",
      "Epoch: 003, Train_loss: 0.6977 / Val_loss: 0.6223\n",
      "Epoch: 004, Train_loss: 0.7107 / Val_loss: 0.6979\n",
      "Epoch: 005, Train_loss: 0.6887 / Val_loss: 0.7121\n",
      "Epoch: 006, Train_loss: 0.6633 / Val_loss: 0.6997\n",
      "Epoch: 007, Train_loss: 0.6466 / Val_loss: 0.6671\n",
      "Epoch: 008, Train_loss: 0.6691 / Val_loss: 0.7069\n",
      "Epoch: 009, Train_loss: 0.6298 / Val_loss: 0.6525\n",
      "Epoch: 010, Train_loss: 0.7389 / Val_loss: 0.6048\n",
      "Epoch: 011, Train_loss: 0.7366 / Val_loss: 0.6546\n",
      "Epoch: 012, Train_loss: 0.6777 / Val_loss: 0.6472\n",
      "Epoch: 013, Train_loss: 0.6470 / Val_loss: 0.6687\n",
      "Epoch: 014, Train_loss: 0.6735 / Val_loss: 0.5949\n",
      "Epoch: 015, Train_loss: 0.6605 / Val_loss: 0.6245\n",
      "Epoch: 016, Train_loss: 0.6499 / Val_loss: 0.6223\n",
      "Epoch: 017, Train_loss: 0.6770 / Val_loss: 0.5713\n",
      "Epoch: 018, Train_loss: 0.6372 / Val_loss: 0.6056\n",
      "Epoch: 019, Train_loss: 0.6385 / Val_loss: 0.5703\n",
      "Epoch: 020, Train_loss: 0.6298 / Val_loss: 0.6150\n",
      "Epoch: 021, Train_loss: 0.6593 / Val_loss: 0.6145\n",
      "Epoch: 022, Train_loss: 0.6445 / Val_loss: 0.6387\n",
      "Epoch: 023, Train_loss: 0.6575 / Val_loss: 0.6585\n",
      "Epoch: 024, Train_loss: 0.6434 / Val_loss: 0.6291\n",
      "Epoch: 025, Train_loss: 0.6440 / Val_loss: 0.5774\n",
      "Epoch: 026, Train_loss: 0.6947 / Val_loss: 0.6019\n",
      "Epoch: 027, Train_loss: 0.6708 / Val_loss: 0.6242\n",
      "Epoch: 028, Train_loss: 0.6234 / Val_loss: 0.6043\n",
      "Epoch: 029, Train_loss: 0.6142 / Val_loss: 0.6013\n",
      "Epoch: 030, Train_loss: 0.6280 / Val_loss: 0.5605\n",
      "Epoch: 031, Train_loss: 0.6571 / Val_loss: 0.6094\n",
      "Epoch: 032, Train_loss: 0.6146 / Val_loss: 0.6233\n",
      "Epoch: 033, Train_loss: 0.6468 / Val_loss: 0.7512\n",
      "Epoch: 034, Train_loss: 0.6389 / Val_loss: 0.6509\n",
      "Epoch: 035, Train_loss: 0.6246 / Val_loss: 0.6063\n",
      "Epoch: 036, Train_loss: 0.6266 / Val_loss: 0.5761\n",
      "Epoch: 037, Train_loss: 0.6225 / Val_loss: 0.7628\n",
      "Epoch: 038, Train_loss: 0.6442 / Val_loss: 0.5755\n",
      "Epoch: 039, Train_loss: 0.6424 / Val_loss: 0.6559\n",
      "Epoch: 040, Train_loss: 0.6293 / Val_loss: 0.5915\n",
      "Epoch: 041, Train_loss: 0.6279 / Val_loss: 0.5909\n",
      "Epoch: 042, Train_loss: 0.6244 / Val_loss: 0.6330\n",
      "Epoch: 043, Train_loss: 0.6114 / Val_loss: 0.5714\n",
      "Epoch: 044, Train_loss: 0.6322 / Val_loss: 0.6192\n",
      "Epoch: 045, Train_loss: 0.6634 / Val_loss: 0.5973\n",
      "Epoch: 046, Train_loss: 0.6180 / Val_loss: 0.6009\n",
      "Epoch: 047, Train_loss: 0.6048 / Val_loss: 0.6141\n",
      "Epoch: 048, Train_loss: 0.6148 / Val_loss: 0.5738\n",
      "Epoch: 049, Train_loss: 0.6581 / Val_loss: 0.6571\n",
      "Epoch: 050, Train_loss: 0.6132 / Val_loss: 0.6232\n",
      "Epoch: 051, Train_loss: 0.6095 / Val_loss: 0.5528\n",
      "Epoch: 052, Train_loss: 0.6196 / Val_loss: 0.5590\n",
      "Epoch: 053, Train_loss: 0.6159 / Val_loss: 0.7037\n",
      "Epoch: 054, Train_loss: 0.6280 / Val_loss: 0.5958\n",
      "Epoch: 055, Train_loss: 0.6117 / Val_loss: 0.6475\n",
      "Epoch: 056, Train_loss: 0.6064 / Val_loss: 0.5735\n",
      "Epoch: 057, Train_loss: 0.6102 / Val_loss: 0.5471\n",
      "Epoch: 058, Train_loss: 0.6099 / Val_loss: 0.5808\n",
      "Epoch: 059, Train_loss: 0.6291 / Val_loss: 0.5879\n",
      "Epoch: 060, Train_loss: 0.6181 / Val_loss: 0.5661\n",
      "Epoch: 061, Train_loss: 0.6277 / Val_loss: 0.5918\n",
      "Epoch: 062, Train_loss: 0.6009 / Val_loss: 0.5729\n",
      "Epoch: 063, Train_loss: 0.6405 / Val_loss: 0.5948\n",
      "Epoch: 064, Train_loss: 0.6140 / Val_loss: 0.7050\n",
      "Epoch: 065, Train_loss: 0.6181 / Val_loss: 0.5934\n",
      "Epoch: 066, Train_loss: 0.6110 / Val_loss: 0.7029\n",
      "Epoch: 067, Train_loss: 0.5919 / Val_loss: 0.6165\n",
      "Epoch: 068, Train_loss: 0.6119 / Val_loss: 0.5910\n",
      "Epoch: 069, Train_loss: 0.6134 / Val_loss: 0.6242\n",
      "Epoch: 070, Train_loss: 0.6078 / Val_loss: 0.5709\n",
      "Epoch: 071, Train_loss: 0.6255 / Val_loss: 0.6048\n",
      "Epoch: 072, Train_loss: 0.6349 / Val_loss: 0.6947\n",
      "Epoch: 073, Train_loss: 0.6144 / Val_loss: 0.5823\n",
      "Epoch: 074, Train_loss: 0.6219 / Val_loss: 0.5647\n",
      "Epoch: 075, Train_loss: 0.6113 / Val_loss: 0.5953\n",
      "Epoch: 076, Train_loss: 0.6179 / Val_loss: 0.5924\n",
      "Epoch: 077, Train_loss: 0.6138 / Val_loss: 0.5935\n",
      "Epoch: 078, Train_loss: 0.5976 / Val_loss: 0.5966\n",
      "Epoch: 079, Train_loss: 0.6177 / Val_loss: 0.6108\n",
      "Epoch: 080, Train_loss: 0.6133 / Val_loss: 0.5641\n",
      "Epoch: 081, Train_loss: 0.6154 / Val_loss: 0.5893\n",
      "Epoch: 082, Train_loss: 0.6099 / Val_loss: 0.5923\n",
      "Epoch: 083, Train_loss: 0.6060 / Val_loss: 0.6114\n",
      "Epoch: 084, Train_loss: 0.6103 / Val_loss: 0.5924\n",
      "Epoch: 085, Train_loss: 0.5967 / Val_loss: 0.5520\n",
      "Epoch: 086, Train_loss: 0.6061 / Val_loss: 0.5959\n",
      "Epoch: 087, Train_loss: 0.6179 / Val_loss: 0.5863\n",
      "Epoch: 088, Train_loss: 0.6192 / Val_loss: 0.5764\n",
      "Epoch: 089, Train_loss: 0.6185 / Val_loss: 0.6459\n",
      "Epoch: 090, Train_loss: 0.5965 / Val_loss: 0.5876\n",
      "Epoch: 091, Train_loss: 0.6056 / Val_loss: 0.5590\n",
      "Epoch: 092, Train_loss: 0.5952 / Val_loss: 0.5652\n",
      "Epoch: 093, Train_loss: 0.6239 / Val_loss: 0.5394\n",
      "Epoch: 094, Train_loss: 0.6014 / Val_loss: 0.5641\n",
      "Epoch: 095, Train_loss: 0.5966 / Val_loss: 0.6488\n",
      "Epoch: 096, Train_loss: 0.6141 / Val_loss: 0.6262\n",
      "Epoch: 097, Train_loss: 0.6020 / Val_loss: 0.6263\n",
      "Epoch: 098, Train_loss: 0.5982 / Val_loss: 0.6138\n",
      "Epoch: 099, Train_loss: 0.5944 / Val_loss: 0.6517\n",
      "Epoch: 100, Train_loss: 0.5901 / Val_loss: 0.6051\n",
      "Epoch: 101, Train_loss: 0.6085 / Val_loss: 0.5878\n",
      "Epoch: 102, Train_loss: 0.6059 / Val_loss: 0.5581\n",
      "Epoch: 103, Train_loss: 0.6143 / Val_loss: 0.5498\n",
      "Epoch: 104, Train_loss: 0.6088 / Val_loss: 0.5789\n",
      "Epoch: 105, Train_loss: 0.5980 / Val_loss: 0.5585\n",
      "Epoch: 106, Train_loss: 0.6102 / Val_loss: 0.6226\n",
      "Epoch: 107, Train_loss: 0.5952 / Val_loss: 0.6245\n",
      "Epoch: 108, Train_loss: 0.6131 / Val_loss: 0.6183\n",
      "Epoch: 109, Train_loss: 0.5981 / Val_loss: 0.6582\n",
      "Epoch: 110, Train_loss: 0.6134 / Val_loss: 0.6199\n",
      "Epoch: 111, Train_loss: 0.6167 / Val_loss: 0.6132\n",
      "Epoch: 112, Train_loss: 0.5809 / Val_loss: 0.5762\n",
      "Epoch: 113, Train_loss: 0.5969 / Val_loss: 0.5835\n",
      "Epoch: 114, Train_loss: 0.5865 / Val_loss: 0.6094\n",
      "Epoch: 115, Train_loss: 0.6096 / Val_loss: 0.6023\n",
      "Epoch: 116, Train_loss: 0.6000 / Val_loss: 0.7444\n",
      "Epoch: 117, Train_loss: 0.5708 / Val_loss: 0.5701\n",
      "Epoch: 118, Train_loss: 0.6066 / Val_loss: 0.6566\n",
      "Epoch: 119, Train_loss: 0.5815 / Val_loss: 0.5719\n",
      "Epoch: 120, Train_loss: 0.5963 / Val_loss: 0.6296\n",
      "Epoch: 121, Train_loss: 0.5964 / Val_loss: 0.5575\n",
      "Epoch: 122, Train_loss: 0.5916 / Val_loss: 0.5776\n",
      "Epoch: 123, Train_loss: 0.5813 / Val_loss: 0.6045\n",
      "Epoch: 124, Train_loss: 0.6275 / Val_loss: 0.6568\n",
      "Epoch: 125, Train_loss: 0.5882 / Val_loss: 0.6124\n",
      "Epoch: 126, Train_loss: 0.5872 / Val_loss: 0.6009\n",
      "Epoch: 127, Train_loss: 0.5852 / Val_loss: 0.6117\n",
      "Epoch: 128, Train_loss: 0.5985 / Val_loss: 0.6012\n",
      "Epoch: 129, Train_loss: 0.6220 / Val_loss: 0.5817\n",
      "Epoch: 130, Train_loss: 0.5881 / Val_loss: 0.5966\n",
      "Epoch: 131, Train_loss: 0.5650 / Val_loss: 0.5628\n",
      "Epoch: 132, Train_loss: 0.5884 / Val_loss: 0.6168\n",
      "Epoch: 133, Train_loss: 0.5919 / Val_loss: 0.6367\n",
      "Epoch: 134, Train_loss: 0.5768 / Val_loss: 0.7873\n",
      "Epoch: 135, Train_loss: 0.6036 / Val_loss: 0.6040\n",
      "Epoch: 136, Train_loss: 0.5914 / Val_loss: 0.5891\n",
      "Epoch: 137, Train_loss: 0.5982 / Val_loss: 0.5699\n",
      "Epoch: 138, Train_loss: 0.5728 / Val_loss: 0.6227\n",
      "Epoch: 139, Train_loss: 0.5915 / Val_loss: 0.5631\n",
      "Epoch: 140, Train_loss: 0.5882 / Val_loss: 0.6926\n",
      "Epoch: 141, Train_loss: 0.5960 / Val_loss: 0.6507\n",
      "Epoch: 142, Train_loss: 0.5851 / Val_loss: 0.6121\n",
      "Epoch: 143, Train_loss: 0.5646 / Val_loss: 0.5674\n",
      "Epoch: 144, Train_loss: 0.5923 / Val_loss: 0.6061\n",
      "Epoch: 145, Train_loss: 0.5714 / Val_loss: 0.6381\n",
      "Epoch: 146, Train_loss: 0.5952 / Val_loss: 0.6564\n",
      "Epoch: 147, Train_loss: 0.5756 / Val_loss: 0.5714\n",
      "Epoch: 148, Train_loss: 0.5817 / Val_loss: 0.6082\n",
      "Epoch: 149, Train_loss: 0.5791 / Val_loss: 0.6263\n",
      "Epoch: 150, Train_loss: 0.5803 / Val_loss: 0.6602\n",
      "Epoch: 151, Train_loss: 0.5817 / Val_loss: 0.5790\n",
      "Epoch: 152, Train_loss: 0.5861 / Val_loss: 0.5691\n",
      "Epoch: 153, Train_loss: 0.5717 / Val_loss: 0.5854\n",
      "Epoch: 154, Train_loss: 0.5833 / Val_loss: 0.6319\n",
      "Epoch: 155, Train_loss: 0.5693 / Val_loss: 0.7136\n",
      "Epoch: 156, Train_loss: 0.5990 / Val_loss: 0.5907\n",
      "Epoch: 157, Train_loss: 0.5634 / Val_loss: 0.6004\n",
      "Epoch: 158, Train_loss: 0.5861 / Val_loss: 0.6594\n",
      "Epoch: 159, Train_loss: 0.5738 / Val_loss: 0.6063\n",
      "Epoch: 160, Train_loss: 0.5638 / Val_loss: 0.7022\n",
      "Epoch: 161, Train_loss: 0.5659 / Val_loss: 0.6097\n",
      "Epoch: 162, Train_loss: 0.5672 / Val_loss: 0.6211\n",
      "Epoch: 163, Train_loss: 0.5818 / Val_loss: 0.8498\n",
      "Epoch: 164, Train_loss: 0.5951 / Val_loss: 0.6040\n",
      "Epoch: 165, Train_loss: 0.5565 / Val_loss: 0.6803\n",
      "Epoch: 166, Train_loss: 0.5950 / Val_loss: 0.6940\n",
      "Epoch: 167, Train_loss: 0.5810 / Val_loss: 0.6631\n",
      "Epoch: 168, Train_loss: 0.5759 / Val_loss: 0.6048\n",
      "Epoch: 169, Train_loss: 0.5886 / Val_loss: 0.6569\n",
      "Epoch: 170, Train_loss: 0.5827 / Val_loss: 0.6304\n",
      "Epoch: 171, Train_loss: 0.5753 / Val_loss: 0.7049\n",
      "Epoch: 172, Train_loss: 0.5679 / Val_loss: 0.6125\n",
      "Epoch: 173, Train_loss: 0.5741 / Val_loss: 0.5787\n",
      "Epoch: 174, Train_loss: 0.5874 / Val_loss: 0.6313\n",
      "Epoch: 175, Train_loss: 0.5780 / Val_loss: 0.6390\n",
      "Epoch: 176, Train_loss: 0.5755 / Val_loss: 0.5549\n",
      "Epoch: 177, Train_loss: 0.5863 / Val_loss: 0.6237\n",
      "Epoch: 178, Train_loss: 0.5675 / Val_loss: 0.6141\n",
      "Epoch: 179, Train_loss: 0.5937 / Val_loss: 0.6569\n",
      "Epoch: 180, Train_loss: 0.5764 / Val_loss: 0.6130\n",
      "Epoch: 181, Train_loss: 0.5933 / Val_loss: 0.6150\n",
      "Epoch: 182, Train_loss: 0.5672 / Val_loss: 0.7382\n",
      "Epoch: 183, Train_loss: 0.5599 / Val_loss: 0.6728\n",
      "Epoch: 184, Train_loss: 0.5704 / Val_loss: 0.6090\n",
      "Epoch: 185, Train_loss: 0.5724 / Val_loss: 0.6087\n",
      "Epoch: 186, Train_loss: 0.5814 / Val_loss: 0.6657\n",
      "Epoch: 187, Train_loss: 0.5889 / Val_loss: 0.7243\n",
      "Epoch: 188, Train_loss: 0.5754 / Val_loss: 0.6203\n",
      "Epoch: 189, Train_loss: 0.5988 / Val_loss: 0.5807\n",
      "Epoch: 190, Train_loss: 0.5862 / Val_loss: 0.5997\n",
      "Epoch: 191, Train_loss: 0.5600 / Val_loss: 0.6420\n",
      "Epoch: 192, Train_loss: 0.5733 / Val_loss: 0.5740\n",
      "Epoch: 193, Train_loss: 0.5970 / Val_loss: 0.6139\n",
      "Epoch: 194, Train_loss: 0.5460 / Val_loss: 0.6103\n",
      "Epoch: 195, Train_loss: 0.5651 / Val_loss: 0.6803\n",
      "Epoch: 196, Train_loss: 0.5627 / Val_loss: 0.6387\n",
      "Epoch: 197, Train_loss: 0.5804 / Val_loss: 0.6397\n",
      "Epoch: 198, Train_loss: 0.5700 / Val_loss: 0.6359\n",
      "Epoch: 199, Train_loss: 0.5626 / Val_loss: 0.6323\n",
      "Epoch: 200, Train_loss: 0.5943 / Val_loss: 0.6279\n",
      "Epoch: 201, Train_loss: 0.5544 / Val_loss: 0.6933\n",
      "Epoch: 202, Train_loss: 0.5710 / Val_loss: 0.6385\n",
      "Epoch: 203, Train_loss: 0.5737 / Val_loss: 0.6567\n",
      "Epoch: 204, Train_loss: 0.5747 / Val_loss: 0.7000\n",
      "Epoch: 205, Train_loss: 0.5542 / Val_loss: 0.6280\n",
      "Epoch: 206, Train_loss: 0.5825 / Val_loss: 0.6334\n",
      "Epoch: 207, Train_loss: 0.5759 / Val_loss: 0.5932\n",
      "Epoch: 208, Train_loss: 0.5597 / Val_loss: 0.6488\n",
      "Epoch: 209, Train_loss: 0.5719 / Val_loss: 0.6485\n",
      "Epoch: 210, Train_loss: 0.5745 / Val_loss: 0.6202\n",
      "Epoch: 211, Train_loss: 0.5514 / Val_loss: 0.6862\n",
      "Epoch: 212, Train_loss: 0.5659 / Val_loss: 0.7187\n",
      "Epoch: 213, Train_loss: 0.5503 / Val_loss: 0.6444\n",
      "Epoch: 214, Train_loss: 0.5648 / Val_loss: 0.5811\n",
      "Epoch: 215, Train_loss: 0.5604 / Val_loss: 0.6160\n",
      "Epoch: 216, Train_loss: 0.5861 / Val_loss: 0.6869\n",
      "Epoch: 217, Train_loss: 0.5666 / Val_loss: 0.7131\n",
      "Epoch: 218, Train_loss: 0.5640 / Val_loss: 0.6815\n",
      "Epoch: 219, Train_loss: 0.5484 / Val_loss: 0.6030\n",
      "Epoch: 220, Train_loss: 0.5545 / Val_loss: 0.6335\n",
      "Epoch: 221, Train_loss: 0.5566 / Val_loss: 0.7143\n",
      "Epoch: 222, Train_loss: 0.5709 / Val_loss: 0.6358\n",
      "Epoch: 223, Train_loss: 0.5725 / Val_loss: 0.6735\n",
      "Epoch: 224, Train_loss: 0.5541 / Val_loss: 0.5805\n",
      "Epoch: 225, Train_loss: 0.5611 / Val_loss: 0.6380\n",
      "Epoch: 226, Train_loss: 0.5950 / Val_loss: 0.6447\n",
      "Epoch: 227, Train_loss: 0.5454 / Val_loss: 0.7234\n",
      "Epoch: 228, Train_loss: 0.5699 / Val_loss: 0.6221\n",
      "Epoch: 229, Train_loss: 0.5733 / Val_loss: 0.6503\n",
      "Epoch: 230, Train_loss: 0.5483 / Val_loss: 0.6443\n",
      "Epoch: 231, Train_loss: 0.5520 / Val_loss: 0.6593\n",
      "Epoch: 232, Train_loss: 0.5567 / Val_loss: 0.6695\n",
      "Epoch: 233, Train_loss: 0.5740 / Val_loss: 0.6685\n",
      "Epoch: 234, Train_loss: 0.5857 / Val_loss: 0.6655\n",
      "Epoch: 235, Train_loss: 0.5756 / Val_loss: 0.5934\n",
      "Epoch: 236, Train_loss: 0.5553 / Val_loss: 0.6556\n",
      "Epoch: 237, Train_loss: 0.5723 / Val_loss: 0.6673\n",
      "Epoch: 238, Train_loss: 0.5668 / Val_loss: 0.6738\n",
      "Epoch: 239, Train_loss: 0.5719 / Val_loss: 0.7077\n",
      "Epoch: 240, Train_loss: 0.5643 / Val_loss: 0.6587\n",
      "Epoch: 241, Train_loss: 0.5725 / Val_loss: 0.6481\n",
      "Epoch: 242, Train_loss: 0.5635 / Val_loss: 0.6053\n",
      "Epoch: 243, Train_loss: 0.5691 / Val_loss: 0.6178\n",
      "Epoch: 244, Train_loss: 0.5537 / Val_loss: 0.6331\n",
      "Epoch: 245, Train_loss: 0.5635 / Val_loss: 0.5984\n",
      "Epoch: 246, Train_loss: 0.5597 / Val_loss: 0.5777\n",
      "Epoch: 247, Train_loss: 0.5573 / Val_loss: 0.6203\n",
      "Epoch: 248, Train_loss: 0.5745 / Val_loss: 0.7029\n",
      "Epoch: 249, Train_loss: 0.5688 / Val_loss: 0.7801\n",
      "Epoch: 250, Train_loss: 0.5666 / Val_loss: 0.6962\n",
      "Epoch: 251, Train_loss: 0.5648 / Val_loss: 0.6180\n",
      "Epoch: 252, Train_loss: 0.5740 / Val_loss: 0.6891\n",
      "Epoch: 253, Train_loss: 0.5439 / Val_loss: 0.6210\n",
      "Epoch: 254, Train_loss: 0.5609 / Val_loss: 0.6775\n",
      "Epoch: 255, Train_loss: 0.5537 / Val_loss: 0.7027\n",
      "Epoch: 256, Train_loss: 0.5537 / Val_loss: 0.6557\n",
      "Epoch: 257, Train_loss: 0.5608 / Val_loss: 0.6883\n",
      "Epoch: 258, Train_loss: 0.5429 / Val_loss: 0.6114\n",
      "Epoch: 259, Train_loss: 0.5787 / Val_loss: 0.6468\n",
      "Epoch: 260, Train_loss: 0.5587 / Val_loss: 0.7001\n",
      "Epoch: 261, Train_loss: 0.5600 / Val_loss: 0.6901\n",
      "Epoch: 262, Train_loss: 0.5516 / Val_loss: 0.6959\n",
      "Epoch: 263, Train_loss: 0.5941 / Val_loss: 0.6269\n",
      "Epoch: 264, Train_loss: 0.5759 / Val_loss: 0.6477\n",
      "Epoch: 265, Train_loss: 0.5673 / Val_loss: 0.5339\n",
      "Epoch: 266, Train_loss: 0.5511 / Val_loss: 0.6376\n",
      "Epoch: 267, Train_loss: 0.5670 / Val_loss: 0.5878\n",
      "Epoch: 268, Train_loss: 0.5612 / Val_loss: 0.6034\n",
      "Epoch: 269, Train_loss: 0.5518 / Val_loss: 0.6338\n",
      "Epoch: 270, Train_loss: 0.5654 / Val_loss: 0.6764\n",
      "Epoch: 271, Train_loss: 0.5586 / Val_loss: 0.6775\n",
      "Epoch: 272, Train_loss: 0.5418 / Val_loss: 0.5985\n",
      "Epoch: 273, Train_loss: 0.5668 / Val_loss: 0.6448\n",
      "Epoch: 274, Train_loss: 0.5660 / Val_loss: 0.6674\n",
      "Epoch: 275, Train_loss: 0.5779 / Val_loss: 0.6427\n",
      "Epoch: 276, Train_loss: 0.5661 / Val_loss: 0.6582\n",
      "Epoch: 277, Train_loss: 0.5602 / Val_loss: 0.6239\n",
      "Epoch: 278, Train_loss: 0.5720 / Val_loss: 0.6288\n",
      "Epoch: 279, Train_loss: 0.5602 / Val_loss: 0.5946\n",
      "Epoch: 280, Train_loss: 0.5589 / Val_loss: 0.6318\n",
      "Epoch: 281, Train_loss: 0.5719 / Val_loss: 0.6192\n",
      "Epoch: 282, Train_loss: 0.5534 / Val_loss: 0.7079\n",
      "Epoch: 283, Train_loss: 0.5663 / Val_loss: 0.6447\n",
      "Epoch: 284, Train_loss: 0.5565 / Val_loss: 0.6310\n",
      "Epoch: 285, Train_loss: 0.5396 / Val_loss: 0.6656\n",
      "Epoch: 286, Train_loss: 0.5460 / Val_loss: 0.6819\n",
      "Epoch: 287, Train_loss: 0.5483 / Val_loss: 0.6510\n",
      "Epoch: 288, Train_loss: 0.5609 / Val_loss: 0.6455\n",
      "Epoch: 289, Train_loss: 0.5641 / Val_loss: 0.6526\n",
      "Epoch: 290, Train_loss: 0.5418 / Val_loss: 0.6229\n",
      "Epoch: 291, Train_loss: 0.5461 / Val_loss: 0.6850\n",
      "Epoch: 292, Train_loss: 0.5342 / Val_loss: 0.6619\n",
      "Epoch: 293, Train_loss: 0.5484 / Val_loss: 0.6742\n",
      "Epoch: 294, Train_loss: 0.5436 / Val_loss: 0.6652\n",
      "Epoch: 295, Train_loss: 0.5517 / Val_loss: 0.6603\n",
      "Epoch: 296, Train_loss: 0.5403 / Val_loss: 0.6055\n",
      "Epoch: 297, Train_loss: 0.5626 / Val_loss: 0.6707\n",
      "Epoch: 298, Train_loss: 0.5404 / Val_loss: 0.6985\n",
      "Epoch: 299, Train_loss: 0.5584 / Val_loss: 0.6209\n",
      "Epoch: 300, Train_loss: 0.5610 / Val_loss: 0.6642\n",
      "Epoch: 301, Train_loss: 0.5534 / Val_loss: 0.6148\n",
      "Epoch: 302, Train_loss: 0.5424 / Val_loss: 0.5811\n",
      "Epoch: 303, Train_loss: 0.5445 / Val_loss: 0.7012\n",
      "Epoch: 304, Train_loss: 0.5455 / Val_loss: 0.6396\n",
      "Epoch: 305, Train_loss: 0.5308 / Val_loss: 0.5865\n",
      "Epoch: 306, Train_loss: 0.5587 / Val_loss: 0.6537\n",
      "Epoch: 307, Train_loss: 0.5503 / Val_loss: 0.7225\n",
      "Epoch: 308, Train_loss: 0.5397 / Val_loss: 0.6286\n",
      "Epoch: 309, Train_loss: 0.5560 / Val_loss: 0.6884\n",
      "Epoch: 310, Train_loss: 0.5377 / Val_loss: 0.5963\n",
      "Epoch: 311, Train_loss: 0.5475 / Val_loss: 0.6917\n",
      "Epoch: 312, Train_loss: 0.5583 / Val_loss: 0.6312\n",
      "Epoch: 313, Train_loss: 0.5574 / Val_loss: 0.6465\n",
      "Epoch: 314, Train_loss: 0.5375 / Val_loss: 0.7183\n",
      "Epoch: 315, Train_loss: 0.5567 / Val_loss: 0.6489\n",
      "Epoch: 316, Train_loss: 0.5498 / Val_loss: 0.7095\n",
      "Epoch: 317, Train_loss: 0.5572 / Val_loss: 0.6855\n",
      "Epoch: 318, Train_loss: 0.5587 / Val_loss: 0.7508\n",
      "Epoch: 319, Train_loss: 0.5319 / Val_loss: 0.6203\n",
      "Epoch: 320, Train_loss: 0.5405 / Val_loss: 0.8187\n",
      "Epoch: 321, Train_loss: 0.5348 / Val_loss: 0.6520\n",
      "Epoch: 322, Train_loss: 0.5519 / Val_loss: 0.6878\n",
      "Epoch: 323, Train_loss: 0.5478 / Val_loss: 0.7397\n",
      "Epoch: 324, Train_loss: 0.5375 / Val_loss: 0.6312\n",
      "Epoch: 325, Train_loss: 0.5470 / Val_loss: 0.6429\n",
      "Epoch: 326, Train_loss: 0.5479 / Val_loss: 0.6554\n",
      "Epoch: 327, Train_loss: 0.5720 / Val_loss: 0.6678\n",
      "Epoch: 328, Train_loss: 0.5327 / Val_loss: 0.7228\n",
      "Epoch: 329, Train_loss: 0.5508 / Val_loss: 0.6013\n",
      "Epoch: 330, Train_loss: 0.5437 / Val_loss: 0.6557\n",
      "Epoch: 331, Train_loss: 0.5378 / Val_loss: 0.6416\n",
      "Epoch: 332, Train_loss: 0.5418 / Val_loss: 0.7181\n",
      "Epoch: 333, Train_loss: 0.5542 / Val_loss: 0.7020\n",
      "Epoch: 334, Train_loss: 0.5392 / Val_loss: 0.7435\n",
      "Epoch: 335, Train_loss: 0.5781 / Val_loss: 0.6669\n",
      "Epoch: 336, Train_loss: 0.5556 / Val_loss: 0.5851\n",
      "Epoch: 337, Train_loss: 0.5464 / Val_loss: 0.6622\n",
      "Epoch: 338, Train_loss: 0.5412 / Val_loss: 0.5979\n",
      "Epoch: 339, Train_loss: 0.5530 / Val_loss: 0.6381\n",
      "Epoch: 340, Train_loss: 0.5448 / Val_loss: 0.6864\n",
      "Epoch: 341, Train_loss: 0.5441 / Val_loss: 0.6785\n",
      "Epoch: 342, Train_loss: 0.5440 / Val_loss: 0.6182\n",
      "Epoch: 343, Train_loss: 0.5504 / Val_loss: 0.6421\n",
      "Epoch: 344, Train_loss: 0.5422 / Val_loss: 0.6557\n",
      "Epoch: 345, Train_loss: 0.5502 / Val_loss: 0.6103\n",
      "Epoch: 346, Train_loss: 0.5613 / Val_loss: 0.7854\n",
      "Epoch: 347, Train_loss: 0.5440 / Val_loss: 0.6303\n",
      "Epoch: 348, Train_loss: 0.5539 / Val_loss: 0.7040\n",
      "Epoch: 349, Train_loss: 0.5485 / Val_loss: 0.6374\n",
      "Epoch: 350, Train_loss: 0.5428 / Val_loss: 0.6811\n",
      "Epoch: 351, Train_loss: 0.5385 / Val_loss: 0.6729\n",
      "Epoch: 352, Train_loss: 0.5639 / Val_loss: 0.6811\n",
      "Epoch: 353, Train_loss: 0.5440 / Val_loss: 0.5805\n",
      "Epoch: 354, Train_loss: 0.5545 / Val_loss: 0.7555\n",
      "Epoch: 355, Train_loss: 0.5509 / Val_loss: 0.6517\n",
      "Epoch: 356, Train_loss: 0.5388 / Val_loss: 0.6692\n",
      "Epoch: 357, Train_loss: 0.5607 / Val_loss: 0.5956\n",
      "Epoch: 358, Train_loss: 0.5315 / Val_loss: 0.6026\n",
      "Epoch: 359, Train_loss: 0.5407 / Val_loss: 0.6760\n",
      "Epoch: 360, Train_loss: 0.5343 / Val_loss: 0.6707\n",
      "Epoch: 361, Train_loss: 0.5792 / Val_loss: 0.7656\n",
      "Epoch: 362, Train_loss: 0.5423 / Val_loss: 0.7241\n",
      "Epoch: 363, Train_loss: 0.5564 / Val_loss: 0.8050\n",
      "Epoch: 364, Train_loss: 0.5513 / Val_loss: 0.6990\n",
      "Epoch: 365, Train_loss: 0.5713 / Val_loss: 0.6781\n",
      "Epoch: 366, Train_loss: 0.5454 / Val_loss: 0.6860\n",
      "Epoch: 367, Train_loss: 0.5453 / Val_loss: 0.6311\n",
      "Epoch: 368, Train_loss: 0.5306 / Val_loss: 0.6567\n",
      "Epoch: 369, Train_loss: 0.5477 / Val_loss: 0.6673\n",
      "Epoch: 370, Train_loss: 0.5555 / Val_loss: 0.6653\n",
      "Epoch: 371, Train_loss: 0.5384 / Val_loss: 0.6310\n",
      "Epoch: 372, Train_loss: 0.5379 / Val_loss: 0.7876\n",
      "Epoch: 373, Train_loss: 0.5348 / Val_loss: 0.6510\n",
      "Epoch: 374, Train_loss: 0.5285 / Val_loss: 0.6933\n",
      "Epoch: 375, Train_loss: 0.5427 / Val_loss: 0.6462\n",
      "Epoch: 376, Train_loss: 0.5558 / Val_loss: 0.7318\n",
      "Epoch: 377, Train_loss: 0.5464 / Val_loss: 0.7581\n",
      "Epoch: 378, Train_loss: 0.5453 / Val_loss: 0.6029\n",
      "Epoch: 379, Train_loss: 0.5561 / Val_loss: 0.5925\n",
      "Epoch: 380, Train_loss: 0.5312 / Val_loss: 0.7581\n",
      "Epoch: 381, Train_loss: 0.5446 / Val_loss: 0.7383\n",
      "Epoch: 382, Train_loss: 0.5467 / Val_loss: 0.6729\n",
      "Epoch: 383, Train_loss: 0.5375 / Val_loss: 0.6145\n",
      "Epoch: 384, Train_loss: 0.5265 / Val_loss: 0.6644\n",
      "Epoch: 385, Train_loss: 0.5469 / Val_loss: 0.7500\n",
      "Epoch: 386, Train_loss: 0.5459 / Val_loss: 0.7110\n",
      "Epoch: 387, Train_loss: 0.5414 / Val_loss: 0.7194\n",
      "Epoch: 388, Train_loss: 0.5293 / Val_loss: 0.7345\n",
      "Epoch: 389, Train_loss: 0.5455 / Val_loss: 0.6044\n",
      "Epoch: 390, Train_loss: 0.5299 / Val_loss: 0.6557\n",
      "Epoch: 391, Train_loss: 0.5333 / Val_loss: 0.7959\n",
      "Epoch: 392, Train_loss: 0.5377 / Val_loss: 0.6908\n",
      "Epoch: 393, Train_loss: 0.5481 / Val_loss: 0.7524\n",
      "Epoch: 394, Train_loss: 0.5521 / Val_loss: 0.7240\n",
      "Epoch: 395, Train_loss: 0.5472 / Val_loss: 0.5961\n",
      "Epoch: 396, Train_loss: 0.5345 / Val_loss: 0.7505\n",
      "Epoch: 397, Train_loss: 0.5355 / Val_loss: 0.6587\n",
      "Epoch: 398, Train_loss: 0.5332 / Val_loss: 0.7118\n",
      "Epoch: 399, Train_loss: 0.5272 / Val_loss: 0.6126\n",
      "Epoch: 400, Train_loss: 0.5216 / Val_loss: 0.7600\n",
      "Epoch: 401, Train_loss: 0.5353 / Val_loss: 0.6319\n",
      "Epoch: 402, Train_loss: 0.5440 / Val_loss: 0.6681\n",
      "Epoch: 403, Train_loss: 0.5587 / Val_loss: 0.6903\n",
      "Epoch: 404, Train_loss: 0.5355 / Val_loss: 0.6690\n",
      "Epoch: 405, Train_loss: 0.5173 / Val_loss: 0.6189\n",
      "Epoch: 406, Train_loss: 0.5287 / Val_loss: 0.7819\n",
      "Epoch: 407, Train_loss: 0.5545 / Val_loss: 0.8499\n",
      "Epoch: 408, Train_loss: 0.5559 / Val_loss: 0.5943\n",
      "Epoch: 409, Train_loss: 0.5305 / Val_loss: 0.7051\n",
      "Epoch: 410, Train_loss: 0.5340 / Val_loss: 0.6497\n",
      "Epoch: 411, Train_loss: 0.5341 / Val_loss: 0.7285\n",
      "Epoch: 412, Train_loss: 0.5399 / Val_loss: 0.6460\n",
      "Epoch: 413, Train_loss: 0.5367 / Val_loss: 0.6909\n",
      "Epoch: 414, Train_loss: 0.5428 / Val_loss: 0.5606\n",
      "Epoch: 415, Train_loss: 0.5583 / Val_loss: 0.6803\n",
      "Epoch: 416, Train_loss: 0.5368 / Val_loss: 0.6581\n",
      "Epoch: 417, Train_loss: 0.5437 / Val_loss: 0.6461\n",
      "Epoch: 418, Train_loss: 0.5482 / Val_loss: 0.6561\n",
      "Epoch: 419, Train_loss: 0.5317 / Val_loss: 0.7017\n",
      "Epoch: 420, Train_loss: 0.5240 / Val_loss: 0.6934\n",
      "Epoch: 421, Train_loss: 0.5239 / Val_loss: 0.6257\n",
      "Epoch: 422, Train_loss: 0.5378 / Val_loss: 0.6274\n",
      "Epoch: 423, Train_loss: 0.5261 / Val_loss: 0.6046\n",
      "Epoch: 424, Train_loss: 0.5596 / Val_loss: 0.6185\n",
      "Epoch: 425, Train_loss: 0.5394 / Val_loss: 0.6219\n",
      "Epoch: 426, Train_loss: 0.5429 / Val_loss: 0.6915\n",
      "Epoch: 427, Train_loss: 0.5248 / Val_loss: 0.6893\n",
      "Epoch: 428, Train_loss: 0.5319 / Val_loss: 0.6205\n",
      "Epoch: 429, Train_loss: 0.5276 / Val_loss: 0.6420\n",
      "Epoch: 430, Train_loss: 0.5398 / Val_loss: 0.7074\n",
      "Epoch: 431, Train_loss: 0.5325 / Val_loss: 0.6680\n",
      "Epoch: 432, Train_loss: 0.5434 / Val_loss: 0.6852\n",
      "Epoch: 433, Train_loss: 0.5398 / Val_loss: 0.7664\n",
      "Epoch: 434, Train_loss: 0.5325 / Val_loss: 0.6090\n",
      "Epoch: 435, Train_loss: 0.5284 / Val_loss: 0.6325\n",
      "Epoch: 436, Train_loss: 0.5295 / Val_loss: 0.7983\n",
      "Epoch: 437, Train_loss: 0.5242 / Val_loss: 0.7719\n",
      "Epoch: 438, Train_loss: 0.5171 / Val_loss: 0.7180\n",
      "Epoch: 439, Train_loss: 0.5527 / Val_loss: 0.6221\n",
      "Epoch: 440, Train_loss: 0.5570 / Val_loss: 0.6876\n",
      "Epoch: 441, Train_loss: 0.5094 / Val_loss: 0.7502\n",
      "Epoch: 442, Train_loss: 0.5291 / Val_loss: 0.6366\n",
      "Epoch: 443, Train_loss: 0.5386 / Val_loss: 0.7068\n",
      "Epoch: 444, Train_loss: 0.5282 / Val_loss: 0.6527\n",
      "Epoch: 445, Train_loss: 0.5392 / Val_loss: 0.6780\n",
      "Epoch: 446, Train_loss: 0.5276 / Val_loss: 0.7122\n",
      "Epoch: 447, Train_loss: 0.5427 / Val_loss: 0.6991\n",
      "Epoch: 448, Train_loss: 0.5303 / Val_loss: 0.7111\n",
      "Epoch: 449, Train_loss: 0.5517 / Val_loss: 0.6821\n",
      "Epoch: 450, Train_loss: 0.5205 / Val_loss: 0.5947\n",
      "Epoch: 451, Train_loss: 0.5387 / Val_loss: 0.7089\n",
      "Epoch: 452, Train_loss: 0.5294 / Val_loss: 0.7302\n",
      "Epoch: 453, Train_loss: 0.5473 / Val_loss: 0.6946\n",
      "Epoch: 454, Train_loss: 0.5321 / Val_loss: 0.6816\n",
      "Epoch: 455, Train_loss: 0.5477 / Val_loss: 0.6725\n",
      "Epoch: 456, Train_loss: 0.5108 / Val_loss: 0.7116\n",
      "Epoch: 457, Train_loss: 0.5161 / Val_loss: 0.5953\n",
      "Epoch: 458, Train_loss: 0.5564 / Val_loss: 0.6189\n",
      "Epoch: 459, Train_loss: 0.5329 / Val_loss: 0.6203\n",
      "Epoch: 460, Train_loss: 0.5535 / Val_loss: 0.5979\n",
      "Epoch: 461, Train_loss: 0.5224 / Val_loss: 0.7220\n",
      "Epoch: 462, Train_loss: 0.5377 / Val_loss: 0.6769\n",
      "Epoch: 463, Train_loss: 0.5285 / Val_loss: 0.7779\n",
      "Epoch: 464, Train_loss: 0.5423 / Val_loss: 0.6231\n",
      "Epoch: 465, Train_loss: 0.5335 / Val_loss: 0.6999\n",
      "Epoch: 466, Train_loss: 0.5422 / Val_loss: 0.7330\n",
      "Epoch: 467, Train_loss: 0.5502 / Val_loss: 0.6786\n",
      "Epoch: 468, Train_loss: 0.5426 / Val_loss: 0.7291\n",
      "Epoch: 469, Train_loss: 0.5429 / Val_loss: 0.7228\n",
      "Epoch: 470, Train_loss: 0.5582 / Val_loss: 0.8357\n",
      "Epoch: 471, Train_loss: 0.5227 / Val_loss: 0.7908\n",
      "Epoch: 472, Train_loss: 0.5399 / Val_loss: 0.6661\n",
      "Epoch: 473, Train_loss: 0.5129 / Val_loss: 0.6932\n",
      "Epoch: 474, Train_loss: 0.5312 / Val_loss: 0.7703\n",
      "Epoch: 475, Train_loss: 0.5203 / Val_loss: 0.6787\n",
      "Epoch: 476, Train_loss: 0.5276 / Val_loss: 0.6171\n",
      "Epoch: 477, Train_loss: 0.5439 / Val_loss: 0.5951\n",
      "Epoch: 478, Train_loss: 0.5402 / Val_loss: 0.6867\n",
      "Epoch: 479, Train_loss: 0.5140 / Val_loss: 0.5718\n",
      "Epoch: 480, Train_loss: 0.5205 / Val_loss: 0.6306\n",
      "Epoch: 481, Train_loss: 0.5253 / Val_loss: 0.7479\n",
      "Epoch: 482, Train_loss: 0.5660 / Val_loss: 0.6249\n",
      "Epoch: 483, Train_loss: 0.5305 / Val_loss: 0.6099\n",
      "Epoch: 484, Train_loss: 0.5311 / Val_loss: 0.5953\n",
      "Epoch: 485, Train_loss: 0.5375 / Val_loss: 0.7030\n",
      "Epoch: 486, Train_loss: 0.5392 / Val_loss: 0.6417\n",
      "Epoch: 487, Train_loss: 0.5279 / Val_loss: 0.5570\n",
      "Epoch: 488, Train_loss: 0.5285 / Val_loss: 0.6905\n",
      "Epoch: 489, Train_loss: 0.5518 / Val_loss: 0.6442\n",
      "Epoch: 490, Train_loss: 0.5352 / Val_loss: 0.6482\n",
      "Epoch: 491, Train_loss: 0.5278 / Val_loss: 0.7317\n",
      "Epoch: 492, Train_loss: 0.5552 / Val_loss: 0.7742\n",
      "Epoch: 493, Train_loss: 0.5364 / Val_loss: 0.7728\n",
      "Epoch: 494, Train_loss: 0.5257 / Val_loss: 0.7841\n",
      "Epoch: 495, Train_loss: 0.5620 / Val_loss: 0.7224\n",
      "Epoch: 496, Train_loss: 0.5225 / Val_loss: 0.6014\n",
      "Epoch: 497, Train_loss: 0.5345 / Val_loss: 0.6599\n",
      "Epoch: 498, Train_loss: 0.5335 / Val_loss: 0.6976\n",
      "Epoch: 499, Train_loss: 0.5228 / Val_loss: 0.7011\n",
      "Epoch: 500, Train_loss: 0.5141 / Val_loss: 0.6122\n",
      "Epoch: 501, Train_loss: 0.5288 / Val_loss: 0.6465\n",
      "Epoch: 502, Train_loss: 0.5386 / Val_loss: 0.6775\n",
      "Epoch: 503, Train_loss: 0.5297 / Val_loss: 0.6735\n",
      "Epoch: 504, Train_loss: 0.5409 / Val_loss: 0.6639\n",
      "Epoch: 505, Train_loss: 0.5172 / Val_loss: 0.7173\n",
      "Epoch: 506, Train_loss: 0.5135 / Val_loss: 0.6388\n",
      "Epoch: 507, Train_loss: 0.5209 / Val_loss: 0.6502\n",
      "Epoch: 508, Train_loss: 0.5163 / Val_loss: 0.6574\n",
      "Epoch: 509, Train_loss: 0.5137 / Val_loss: 0.6590\n",
      "Epoch: 510, Train_loss: 0.5295 / Val_loss: 0.7485\n",
      "Epoch: 511, Train_loss: 0.5248 / Val_loss: 0.6221\n",
      "Epoch: 512, Train_loss: 0.5239 / Val_loss: 0.7745\n",
      "Epoch: 513, Train_loss: 0.5299 / Val_loss: 0.7681\n",
      "Epoch: 514, Train_loss: 0.5274 / Val_loss: 0.7586\n",
      "Epoch: 515, Train_loss: 0.5341 / Val_loss: 0.7017\n",
      "Epoch: 516, Train_loss: 0.5354 / Val_loss: 0.6849\n",
      "Epoch: 517, Train_loss: 0.5246 / Val_loss: 0.6280\n",
      "Epoch: 518, Train_loss: 0.5310 / Val_loss: 0.6337\n",
      "Epoch: 519, Train_loss: 0.5374 / Val_loss: 0.6882\n",
      "Epoch: 520, Train_loss: 0.5373 / Val_loss: 0.8149\n",
      "Epoch: 521, Train_loss: 0.5434 / Val_loss: 0.6708\n",
      "Epoch: 522, Train_loss: 0.5066 / Val_loss: 0.6780\n",
      "Epoch: 523, Train_loss: 0.5257 / Val_loss: 0.5908\n",
      "Epoch: 524, Train_loss: 0.5222 / Val_loss: 0.6193\n",
      "Epoch: 525, Train_loss: 0.5267 / Val_loss: 0.7475\n",
      "Epoch: 526, Train_loss: 0.5130 / Val_loss: 0.5820\n",
      "Epoch: 527, Train_loss: 0.5327 / Val_loss: 0.6367\n",
      "Epoch: 528, Train_loss: 0.5274 / Val_loss: 0.6756\n",
      "Epoch: 529, Train_loss: 0.5280 / Val_loss: 0.6808\n",
      "Epoch: 530, Train_loss: 0.5342 / Val_loss: 0.6496\n",
      "Epoch: 531, Train_loss: 0.5199 / Val_loss: 0.6900\n",
      "Epoch: 532, Train_loss: 0.5153 / Val_loss: 0.6530\n",
      "Epoch: 533, Train_loss: 0.5303 / Val_loss: 0.6452\n",
      "Epoch: 534, Train_loss: 0.5244 / Val_loss: 0.7761\n",
      "Epoch: 535, Train_loss: 0.5095 / Val_loss: 0.5823\n",
      "Epoch: 536, Train_loss: 0.5304 / Val_loss: 0.6278\n",
      "Epoch: 537, Train_loss: 0.5161 / Val_loss: 0.5443\n",
      "Epoch: 538, Train_loss: 0.5297 / Val_loss: 0.5958\n",
      "Epoch: 539, Train_loss: 0.5259 / Val_loss: 0.6082\n",
      "Epoch: 540, Train_loss: 0.5378 / Val_loss: 0.5721\n",
      "Epoch: 541, Train_loss: 0.5229 / Val_loss: 0.6593\n",
      "Epoch: 542, Train_loss: 0.5313 / Val_loss: 0.6809\n",
      "Epoch: 543, Train_loss: 0.5423 / Val_loss: 0.7209\n",
      "Epoch: 544, Train_loss: 0.5365 / Val_loss: 0.6794\n",
      "Epoch: 545, Train_loss: 0.5364 / Val_loss: 0.6935\n",
      "Epoch: 546, Train_loss: 0.5393 / Val_loss: 0.6482\n",
      "Epoch: 547, Train_loss: 0.5378 / Val_loss: 0.7375\n",
      "Epoch: 548, Train_loss: 0.5438 / Val_loss: 0.6929\n",
      "Epoch: 549, Train_loss: 0.5323 / Val_loss: 0.6785\n",
      "Epoch: 550, Train_loss: 0.5223 / Val_loss: 0.6851\n",
      "Epoch: 551, Train_loss: 0.5247 / Val_loss: 0.7101\n",
      "Epoch: 552, Train_loss: 0.5358 / Val_loss: 0.7666\n",
      "Epoch: 553, Train_loss: 0.5217 / Val_loss: 0.6079\n",
      "Epoch: 554, Train_loss: 0.5195 / Val_loss: 0.6254\n",
      "Epoch: 555, Train_loss: 0.5396 / Val_loss: 0.6718\n",
      "Epoch: 556, Train_loss: 0.5457 / Val_loss: 0.6148\n",
      "Epoch: 557, Train_loss: 0.5334 / Val_loss: 0.8273\n",
      "Epoch: 558, Train_loss: 0.5210 / Val_loss: 0.6828\n",
      "Epoch: 559, Train_loss: 0.5203 / Val_loss: 0.6462\n",
      "Epoch: 560, Train_loss: 0.5161 / Val_loss: 0.6638\n",
      "Epoch: 561, Train_loss: 0.5345 / Val_loss: 0.6269\n",
      "Epoch: 562, Train_loss: 0.5331 / Val_loss: 0.5734\n",
      "Epoch: 563, Train_loss: 0.5331 / Val_loss: 0.8204\n",
      "Epoch: 564, Train_loss: 0.5155 / Val_loss: 0.6705\n",
      "Epoch: 565, Train_loss: 0.5011 / Val_loss: 0.6593\n",
      "Epoch: 566, Train_loss: 0.5209 / Val_loss: 0.5859\n",
      "Epoch: 567, Train_loss: 0.5156 / Val_loss: 0.5953\n",
      "Epoch: 568, Train_loss: 0.5228 / Val_loss: 0.6399\n",
      "Epoch: 569, Train_loss: 0.5238 / Val_loss: 0.6547\n",
      "Epoch: 570, Train_loss: 0.5379 / Val_loss: 0.6618\n",
      "Epoch: 571, Train_loss: 0.5292 / Val_loss: 0.7345\n",
      "Epoch: 572, Train_loss: 0.5191 / Val_loss: 0.7166\n",
      "Epoch: 573, Train_loss: 0.5424 / Val_loss: 0.8714\n",
      "Epoch: 574, Train_loss: 0.5200 / Val_loss: 0.6731\n",
      "Epoch: 575, Train_loss: 0.5235 / Val_loss: 0.7545\n",
      "Epoch: 576, Train_loss: 0.5220 / Val_loss: 0.7103\n",
      "Epoch: 577, Train_loss: 0.5339 / Val_loss: 0.6274\n",
      "Epoch: 578, Train_loss: 0.5250 / Val_loss: 0.6190\n",
      "Epoch: 579, Train_loss: 0.5156 / Val_loss: 0.6544\n",
      "Epoch: 580, Train_loss: 0.5106 / Val_loss: 0.6101\n",
      "Epoch: 581, Train_loss: 0.5148 / Val_loss: 0.6305\n",
      "Epoch: 582, Train_loss: 0.5202 / Val_loss: 0.7646\n",
      "Epoch: 583, Train_loss: 0.5176 / Val_loss: 0.7717\n",
      "Epoch: 584, Train_loss: 0.5290 / Val_loss: 0.6771\n",
      "Epoch: 585, Train_loss: 0.5062 / Val_loss: 0.6628\n",
      "Epoch: 586, Train_loss: 0.5332 / Val_loss: 0.7773\n",
      "Epoch: 587, Train_loss: 0.5124 / Val_loss: 0.5852\n",
      "Epoch: 588, Train_loss: 0.5127 / Val_loss: 0.6403\n",
      "Epoch: 589, Train_loss: 0.5173 / Val_loss: 0.6758\n",
      "Epoch: 590, Train_loss: 0.5343 / Val_loss: 0.7453\n",
      "Epoch: 591, Train_loss: 0.5083 / Val_loss: 0.8595\n",
      "Epoch: 592, Train_loss: 0.5297 / Val_loss: 0.6442\n",
      "Epoch: 593, Train_loss: 0.5206 / Val_loss: 0.6778\n",
      "Epoch: 594, Train_loss: 0.5553 / Val_loss: 0.6773\n",
      "Epoch: 595, Train_loss: 0.5149 / Val_loss: 0.6247\n",
      "Epoch: 596, Train_loss: 0.5435 / Val_loss: 0.6925\n",
      "Epoch: 597, Train_loss: 0.5234 / Val_loss: 0.7638\n",
      "Epoch: 598, Train_loss: 0.5118 / Val_loss: 0.6920\n",
      "Epoch: 599, Train_loss: 0.5180 / Val_loss: 0.6961\n",
      "Epoch: 600, Train_loss: 0.5155 / Val_loss: 0.6557\n",
      "Epoch: 601, Train_loss: 0.5231 / Val_loss: 0.6302\n",
      "Epoch: 602, Train_loss: 0.5141 / Val_loss: 0.7094\n",
      "Epoch: 603, Train_loss: 0.5284 / Val_loss: 0.6256\n",
      "Epoch: 604, Train_loss: 0.5322 / Val_loss: 0.6722\n",
      "Epoch: 605, Train_loss: 0.5090 / Val_loss: 0.8200\n",
      "Epoch: 606, Train_loss: 0.5132 / Val_loss: 0.8959\n",
      "Epoch: 607, Train_loss: 0.5198 / Val_loss: 0.6271\n",
      "Epoch: 608, Train_loss: 0.5225 / Val_loss: 0.5765\n",
      "Epoch: 609, Train_loss: 0.5104 / Val_loss: 0.7648\n",
      "Epoch: 610, Train_loss: 0.5133 / Val_loss: 0.6085\n",
      "Epoch: 611, Train_loss: 0.5568 / Val_loss: 0.6799\n",
      "Epoch: 612, Train_loss: 0.5173 / Val_loss: 0.6523\n",
      "Epoch: 613, Train_loss: 0.5179 / Val_loss: 0.6800\n",
      "Epoch: 614, Train_loss: 0.5155 / Val_loss: 0.6444\n",
      "Epoch: 615, Train_loss: 0.5339 / Val_loss: 0.6146\n",
      "Epoch: 616, Train_loss: 0.5275 / Val_loss: 0.6149\n",
      "Epoch: 617, Train_loss: 0.5259 / Val_loss: 0.6892\n",
      "Epoch: 618, Train_loss: 0.5070 / Val_loss: 0.7258\n",
      "Epoch: 619, Train_loss: 0.5078 / Val_loss: 0.6305\n",
      "Epoch: 620, Train_loss: 0.5056 / Val_loss: 0.7618\n",
      "Epoch: 621, Train_loss: 0.5157 / Val_loss: 0.7275\n",
      "Epoch: 622, Train_loss: 0.5343 / Val_loss: 0.7382\n",
      "Epoch: 623, Train_loss: 0.5129 / Val_loss: 0.6626\n",
      "Epoch: 624, Train_loss: 0.5084 / Val_loss: 0.6313\n",
      "Epoch: 625, Train_loss: 0.5043 / Val_loss: 0.7032\n",
      "Epoch: 626, Train_loss: 0.5114 / Val_loss: 0.6423\n",
      "Epoch: 627, Train_loss: 0.5327 / Val_loss: 0.6607\n",
      "Epoch: 628, Train_loss: 0.5042 / Val_loss: 0.7549\n",
      "Epoch: 629, Train_loss: 0.5251 / Val_loss: 0.6954\n",
      "Epoch: 630, Train_loss: 0.5327 / Val_loss: 0.7250\n",
      "Epoch: 631, Train_loss: 0.5130 / Val_loss: 0.6530\n",
      "Epoch: 632, Train_loss: 0.5242 / Val_loss: 0.7264\n",
      "Epoch: 633, Train_loss: 0.5083 / Val_loss: 0.6654\n",
      "Epoch: 634, Train_loss: 0.5055 / Val_loss: 0.6222\n",
      "Epoch: 635, Train_loss: 0.5101 / Val_loss: 0.5690\n",
      "Epoch: 636, Train_loss: 0.5169 / Val_loss: 0.6649\n",
      "Epoch: 637, Train_loss: 0.5251 / Val_loss: 0.6091\n",
      "Epoch: 638, Train_loss: 0.5308 / Val_loss: 0.6822\n",
      "Epoch: 639, Train_loss: 0.5031 / Val_loss: 0.7726\n",
      "Epoch: 640, Train_loss: 0.5174 / Val_loss: 0.8053\n",
      "Epoch: 641, Train_loss: 0.5113 / Val_loss: 0.7345\n",
      "Epoch: 642, Train_loss: 0.5284 / Val_loss: 0.6135\n",
      "Epoch: 643, Train_loss: 0.5071 / Val_loss: 0.7611\n",
      "Epoch: 644, Train_loss: 0.5131 / Val_loss: 0.7006\n",
      "Epoch: 645, Train_loss: 0.5247 / Val_loss: 0.7815\n",
      "Epoch: 646, Train_loss: 0.5048 / Val_loss: 0.7724\n",
      "Epoch: 647, Train_loss: 0.5258 / Val_loss: 0.6667\n",
      "Epoch: 648, Train_loss: 0.5145 / Val_loss: 0.6708\n",
      "Epoch: 649, Train_loss: 0.5272 / Val_loss: 0.8030\n",
      "Epoch: 650, Train_loss: 0.5260 / Val_loss: 0.6459\n",
      "Epoch: 651, Train_loss: 0.5133 / Val_loss: 0.6762\n",
      "Epoch: 652, Train_loss: 0.5148 / Val_loss: 0.7183\n",
      "Epoch: 653, Train_loss: 0.5170 / Val_loss: 0.7233\n",
      "Epoch: 654, Train_loss: 0.5224 / Val_loss: 0.7229\n",
      "Epoch: 655, Train_loss: 0.5146 / Val_loss: 0.8248\n",
      "Epoch: 656, Train_loss: 0.5074 / Val_loss: 0.8664\n",
      "Epoch: 657, Train_loss: 0.5341 / Val_loss: 0.7946\n",
      "Epoch: 658, Train_loss: 0.5533 / Val_loss: 0.7802\n",
      "Epoch: 659, Train_loss: 0.5179 / Val_loss: 0.7855\n",
      "Epoch: 660, Train_loss: 0.5249 / Val_loss: 0.6257\n",
      "Epoch: 661, Train_loss: 0.5242 / Val_loss: 0.7868\n",
      "Epoch: 662, Train_loss: 0.5187 / Val_loss: 0.6640\n",
      "Epoch: 663, Train_loss: 0.5192 / Val_loss: 0.7117\n",
      "Epoch: 664, Train_loss: 0.5213 / Val_loss: 0.6366\n",
      "Epoch: 665, Train_loss: 0.5146 / Val_loss: 0.6302\n",
      "Epoch: 666, Train_loss: 0.5170 / Val_loss: 0.7583\n",
      "Epoch: 667, Train_loss: 0.5123 / Val_loss: 0.5837\n",
      "Epoch: 668, Train_loss: 0.5219 / Val_loss: 0.8113\n",
      "Epoch: 669, Train_loss: 0.5167 / Val_loss: 0.6288\n",
      "Epoch: 670, Train_loss: 0.5158 / Val_loss: 0.7237\n",
      "Epoch: 671, Train_loss: 0.5151 / Val_loss: 0.6383\n",
      "Epoch: 672, Train_loss: 0.5275 / Val_loss: 0.7448\n",
      "Epoch: 673, Train_loss: 0.5279 / Val_loss: 0.6609\n",
      "Epoch: 674, Train_loss: 0.5063 / Val_loss: 0.6339\n",
      "Epoch: 675, Train_loss: 0.5445 / Val_loss: 0.7341\n",
      "Epoch: 676, Train_loss: 0.5188 / Val_loss: 0.7046\n",
      "Epoch: 677, Train_loss: 0.5302 / Val_loss: 0.6630\n",
      "Epoch: 678, Train_loss: 0.5152 / Val_loss: 0.7025\n",
      "Epoch: 679, Train_loss: 0.5090 / Val_loss: 0.7011\n",
      "Epoch: 680, Train_loss: 0.5276 / Val_loss: 0.6195\n",
      "Epoch: 681, Train_loss: 0.5198 / Val_loss: 0.6407\n",
      "Epoch: 682, Train_loss: 0.5320 / Val_loss: 0.6809\n",
      "Epoch: 683, Train_loss: 0.5201 / Val_loss: 0.6813\n",
      "Epoch: 684, Train_loss: 0.5089 / Val_loss: 0.7879\n",
      "Epoch: 685, Train_loss: 0.5227 / Val_loss: 0.6219\n",
      "Epoch: 686, Train_loss: 0.5307 / Val_loss: 0.7345\n",
      "Epoch: 687, Train_loss: 0.5071 / Val_loss: 0.7009\n",
      "Epoch: 688, Train_loss: 0.5216 / Val_loss: 0.6699\n",
      "Epoch: 689, Train_loss: 0.5072 / Val_loss: 0.7347\n",
      "Epoch: 690, Train_loss: 0.5158 / Val_loss: 0.7259\n",
      "Epoch: 691, Train_loss: 0.5201 / Val_loss: 0.6411\n",
      "Epoch: 692, Train_loss: 0.5141 / Val_loss: 0.6432\n",
      "Epoch: 693, Train_loss: 0.5248 / Val_loss: 0.6543\n",
      "Epoch: 694, Train_loss: 0.5087 / Val_loss: 0.6413\n",
      "Epoch: 695, Train_loss: 0.5030 / Val_loss: 0.7093\n",
      "Epoch: 696, Train_loss: 0.5130 / Val_loss: 0.8210\n",
      "Epoch: 697, Train_loss: 0.5110 / Val_loss: 0.6243\n",
      "Epoch: 698, Train_loss: 0.5356 / Val_loss: 0.8045\n",
      "Epoch: 699, Train_loss: 0.5279 / Val_loss: 0.6431\n",
      "Epoch: 700, Train_loss: 0.5085 / Val_loss: 0.6696\n",
      "Epoch: 701, Train_loss: 0.5136 / Val_loss: 0.5898\n",
      "Epoch: 702, Train_loss: 0.4999 / Val_loss: 0.7314\n",
      "Epoch: 703, Train_loss: 0.5053 / Val_loss: 0.5907\n",
      "Epoch: 704, Train_loss: 0.5033 / Val_loss: 0.5408\n",
      "Epoch: 705, Train_loss: 0.5141 / Val_loss: 0.7730\n",
      "Epoch: 706, Train_loss: 0.5171 / Val_loss: 0.6405\n",
      "Epoch: 707, Train_loss: 0.5114 / Val_loss: 0.7986\n",
      "Epoch: 708, Train_loss: 0.5042 / Val_loss: 0.6889\n",
      "Epoch: 709, Train_loss: 0.5090 / Val_loss: 0.6628\n",
      "Epoch: 710, Train_loss: 0.5151 / Val_loss: 0.7805\n",
      "Epoch: 711, Train_loss: 0.5235 / Val_loss: 0.7063\n",
      "Epoch: 712, Train_loss: 0.5137 / Val_loss: 0.6567\n",
      "Epoch: 713, Train_loss: 0.5264 / Val_loss: 0.7292\n",
      "Epoch: 714, Train_loss: 0.5128 / Val_loss: 0.6866\n",
      "Epoch: 715, Train_loss: 0.5068 / Val_loss: 0.6535\n",
      "Epoch: 716, Train_loss: 0.5158 / Val_loss: 0.6409\n",
      "Epoch: 717, Train_loss: 0.5050 / Val_loss: 0.7412\n",
      "Epoch: 718, Train_loss: 0.4973 / Val_loss: 0.7712\n",
      "Epoch: 719, Train_loss: 0.5310 / Val_loss: 0.6535\n",
      "Epoch: 720, Train_loss: 0.5030 / Val_loss: 0.7065\n",
      "Epoch: 721, Train_loss: 0.5107 / Val_loss: 0.5782\n",
      "Epoch: 722, Train_loss: 0.5006 / Val_loss: 0.7848\n",
      "Epoch: 723, Train_loss: 0.5035 / Val_loss: 0.6900\n",
      "Epoch: 724, Train_loss: 0.5196 / Val_loss: 0.6826\n",
      "Epoch: 725, Train_loss: 0.5370 / Val_loss: 0.6081\n",
      "Epoch: 726, Train_loss: 0.5162 / Val_loss: 0.7111\n",
      "Epoch: 727, Train_loss: 0.5009 / Val_loss: 0.7079\n",
      "Epoch: 728, Train_loss: 0.5102 / Val_loss: 0.8427\n",
      "Epoch: 729, Train_loss: 0.5061 / Val_loss: 0.7318\n",
      "Epoch: 730, Train_loss: 0.5050 / Val_loss: 0.8497\n",
      "Epoch: 731, Train_loss: 0.5075 / Val_loss: 0.6192\n",
      "Epoch: 732, Train_loss: 0.5281 / Val_loss: 0.6932\n",
      "Epoch: 733, Train_loss: 0.5219 / Val_loss: 0.6782\n",
      "Epoch: 734, Train_loss: 0.5230 / Val_loss: 0.8316\n",
      "Epoch: 735, Train_loss: 0.5105 / Val_loss: 0.7209\n",
      "Epoch: 736, Train_loss: 0.5127 / Val_loss: 0.7132\n",
      "Epoch: 737, Train_loss: 0.5037 / Val_loss: 0.7182\n",
      "Epoch: 738, Train_loss: 0.5200 / Val_loss: 0.7384\n",
      "Epoch: 739, Train_loss: 0.4912 / Val_loss: 0.7532\n",
      "Epoch: 740, Train_loss: 0.5109 / Val_loss: 0.6935\n",
      "Epoch: 741, Train_loss: 0.5087 / Val_loss: 0.6270\n",
      "Epoch: 742, Train_loss: 0.5142 / Val_loss: 0.6675\n",
      "Epoch: 743, Train_loss: 0.5330 / Val_loss: 0.6553\n",
      "Epoch: 744, Train_loss: 0.5309 / Val_loss: 0.7246\n",
      "Epoch: 745, Train_loss: 0.5141 / Val_loss: 0.6717\n",
      "Epoch: 746, Train_loss: 0.5180 / Val_loss: 0.6585\n",
      "Epoch: 747, Train_loss: 0.5101 / Val_loss: 0.6797\n",
      "Epoch: 748, Train_loss: 0.5160 / Val_loss: 0.6940\n",
      "Epoch: 749, Train_loss: 0.5296 / Val_loss: 0.6886\n",
      "Epoch: 750, Train_loss: 0.5010 / Val_loss: 0.6706\n",
      "Epoch: 751, Train_loss: 0.5141 / Val_loss: 0.7506\n",
      "Epoch: 752, Train_loss: 0.5086 / Val_loss: 0.6863\n",
      "Epoch: 753, Train_loss: 0.5036 / Val_loss: 0.7058\n",
      "Epoch: 754, Train_loss: 0.5204 / Val_loss: 0.5951\n",
      "Epoch: 755, Train_loss: 0.5145 / Val_loss: 0.6866\n",
      "Epoch: 756, Train_loss: 0.5044 / Val_loss: 0.7652\n",
      "Epoch: 757, Train_loss: 0.5101 / Val_loss: 0.7022\n",
      "Epoch: 758, Train_loss: 0.5091 / Val_loss: 0.6847\n",
      "Epoch: 759, Train_loss: 0.5329 / Val_loss: 0.6632\n",
      "Epoch: 760, Train_loss: 0.5122 / Val_loss: 0.8331\n",
      "Epoch: 761, Train_loss: 0.5076 / Val_loss: 0.6532\n",
      "Epoch: 762, Train_loss: 0.5217 / Val_loss: 0.7004\n",
      "Epoch: 763, Train_loss: 0.5113 / Val_loss: 0.6616\n",
      "Epoch: 764, Train_loss: 0.5200 / Val_loss: 0.7715\n",
      "Epoch: 765, Train_loss: 0.4971 / Val_loss: 0.6375\n",
      "Epoch: 766, Train_loss: 0.4956 / Val_loss: 0.7694\n",
      "Epoch: 767, Train_loss: 0.5281 / Val_loss: 0.7352\n",
      "Epoch: 768, Train_loss: 0.5087 / Val_loss: 0.6851\n",
      "Epoch: 769, Train_loss: 0.5018 / Val_loss: 0.7785\n",
      "Epoch: 770, Train_loss: 0.5031 / Val_loss: 0.6644\n",
      "Epoch: 771, Train_loss: 0.5039 / Val_loss: 0.6681\n",
      "Epoch: 772, Train_loss: 0.5226 / Val_loss: 0.7781\n",
      "Epoch: 773, Train_loss: 0.5113 / Val_loss: 0.7528\n",
      "Epoch: 774, Train_loss: 0.5213 / Val_loss: 0.7905\n",
      "Epoch: 775, Train_loss: 0.4973 / Val_loss: 0.5708\n",
      "Epoch: 776, Train_loss: 0.5087 / Val_loss: 0.7736\n",
      "Epoch: 777, Train_loss: 0.4932 / Val_loss: 0.6352\n",
      "Epoch: 778, Train_loss: 0.5064 / Val_loss: 0.6572\n",
      "Epoch: 779, Train_loss: 0.5285 / Val_loss: 0.7193\n",
      "Epoch: 780, Train_loss: 0.5031 / Val_loss: 0.7448\n",
      "Epoch: 781, Train_loss: 0.5121 / Val_loss: 0.6508\n",
      "Epoch: 782, Train_loss: 0.5149 / Val_loss: 0.7276\n",
      "Epoch: 783, Train_loss: 0.4940 / Val_loss: 0.6352\n",
      "Epoch: 784, Train_loss: 0.4949 / Val_loss: 0.6947\n",
      "Epoch: 785, Train_loss: 0.5106 / Val_loss: 0.7265\n",
      "Epoch: 786, Train_loss: 0.5193 / Val_loss: 0.7726\n",
      "Epoch: 787, Train_loss: 0.5201 / Val_loss: 0.6270\n",
      "Epoch: 788, Train_loss: 0.4916 / Val_loss: 0.6783\n",
      "Epoch: 789, Train_loss: 0.5141 / Val_loss: 0.6259\n",
      "Epoch: 790, Train_loss: 0.5129 / Val_loss: 0.8175\n",
      "Epoch: 791, Train_loss: 0.5063 / Val_loss: 0.6533\n",
      "Epoch: 792, Train_loss: 0.5299 / Val_loss: 0.6854\n",
      "Epoch: 793, Train_loss: 0.5178 / Val_loss: 0.8236\n",
      "Epoch: 794, Train_loss: 0.5080 / Val_loss: 0.7444\n",
      "Epoch: 795, Train_loss: 0.5296 / Val_loss: 0.7401\n",
      "Epoch: 796, Train_loss: 0.5163 / Val_loss: 0.7038\n",
      "Epoch: 797, Train_loss: 0.5164 / Val_loss: 0.7135\n",
      "Epoch: 798, Train_loss: 0.5183 / Val_loss: 0.8950\n",
      "Epoch: 799, Train_loss: 0.5097 / Val_loss: 0.6806\n",
      "Epoch: 800, Train_loss: 0.5263 / Val_loss: 0.7483\n",
      "Epoch: 801, Train_loss: 0.5055 / Val_loss: 0.6797\n",
      "Epoch: 802, Train_loss: 0.5008 / Val_loss: 0.6161\n",
      "Epoch: 803, Train_loss: 0.5334 / Val_loss: 0.6256\n",
      "Epoch: 804, Train_loss: 0.5184 / Val_loss: 0.5862\n",
      "Epoch: 805, Train_loss: 0.4947 / Val_loss: 0.6162\n",
      "Epoch: 806, Train_loss: 0.5268 / Val_loss: 0.6850\n",
      "Epoch: 807, Train_loss: 0.4975 / Val_loss: 0.6679\n",
      "Epoch: 808, Train_loss: 0.5314 / Val_loss: 0.7519\n",
      "Epoch: 809, Train_loss: 0.5083 / Val_loss: 0.7647\n",
      "Epoch: 810, Train_loss: 0.5086 / Val_loss: 0.6889\n",
      "Epoch: 811, Train_loss: 0.4953 / Val_loss: 0.6257\n",
      "Epoch: 812, Train_loss: 0.5008 / Val_loss: 0.6686\n",
      "Epoch: 813, Train_loss: 0.4989 / Val_loss: 0.6128\n",
      "Epoch: 814, Train_loss: 0.5293 / Val_loss: 0.6921\n",
      "Epoch: 815, Train_loss: 0.5045 / Val_loss: 0.6510\n",
      "Epoch: 816, Train_loss: 0.5101 / Val_loss: 0.7809\n",
      "Epoch: 817, Train_loss: 0.4915 / Val_loss: 0.7866\n",
      "Epoch: 818, Train_loss: 0.5119 / Val_loss: 0.7172\n",
      "Epoch: 819, Train_loss: 0.5107 / Val_loss: 0.6729\n",
      "Epoch: 820, Train_loss: 0.5037 / Val_loss: 0.5987\n",
      "Epoch: 821, Train_loss: 0.5063 / Val_loss: 0.6667\n",
      "Epoch: 822, Train_loss: 0.5013 / Val_loss: 0.6432\n",
      "Epoch: 823, Train_loss: 0.4990 / Val_loss: 0.6118\n",
      "Epoch: 824, Train_loss: 0.5034 / Val_loss: 0.6831\n",
      "Epoch: 825, Train_loss: 0.5032 / Val_loss: 0.6980\n",
      "Epoch: 826, Train_loss: 0.5277 / Val_loss: 0.7204\n",
      "Epoch: 827, Train_loss: 0.5051 / Val_loss: 0.6485\n",
      "Epoch: 828, Train_loss: 0.5036 / Val_loss: 0.7732\n",
      "Epoch: 829, Train_loss: 0.5008 / Val_loss: 0.6436\n",
      "Epoch: 830, Train_loss: 0.5065 / Val_loss: 0.7363\n",
      "Epoch: 831, Train_loss: 0.4862 / Val_loss: 0.7092\n",
      "Epoch: 832, Train_loss: 0.5082 / Val_loss: 0.6727\n",
      "Epoch: 833, Train_loss: 0.4963 / Val_loss: 0.7975\n",
      "Epoch: 834, Train_loss: 0.4927 / Val_loss: 0.7236\n",
      "Epoch: 835, Train_loss: 0.5023 / Val_loss: 0.6666\n",
      "Epoch: 836, Train_loss: 0.5246 / Val_loss: 0.6515\n",
      "Epoch: 837, Train_loss: 0.5331 / Val_loss: 0.6551\n",
      "Epoch: 838, Train_loss: 0.5052 / Val_loss: 0.7339\n",
      "Epoch: 839, Train_loss: 0.5061 / Val_loss: 0.6473\n",
      "Epoch: 840, Train_loss: 0.5126 / Val_loss: 0.7261\n",
      "Epoch: 841, Train_loss: 0.5149 / Val_loss: 0.7445\n",
      "Epoch: 842, Train_loss: 0.5143 / Val_loss: 0.6511\n",
      "Epoch: 843, Train_loss: 0.5071 / Val_loss: 0.6120\n",
      "Epoch: 844, Train_loss: 0.4968 / Val_loss: 0.8475\n",
      "Epoch: 845, Train_loss: 0.5320 / Val_loss: 0.7503\n",
      "Epoch: 846, Train_loss: 0.4938 / Val_loss: 0.7090\n",
      "Epoch: 847, Train_loss: 0.5111 / Val_loss: 0.7101\n",
      "Epoch: 848, Train_loss: 0.4999 / Val_loss: 0.6536\n",
      "Epoch: 849, Train_loss: 0.5074 / Val_loss: 0.6630\n",
      "Epoch: 850, Train_loss: 0.5146 / Val_loss: 0.7315\n",
      "Epoch: 851, Train_loss: 0.4984 / Val_loss: 0.7059\n",
      "Epoch: 852, Train_loss: 0.5069 / Val_loss: 0.7482\n",
      "Epoch: 853, Train_loss: 0.5018 / Val_loss: 0.6639\n",
      "Epoch: 854, Train_loss: 0.5008 / Val_loss: 0.6925\n",
      "Epoch: 855, Train_loss: 0.4907 / Val_loss: 0.6669\n",
      "Epoch: 856, Train_loss: 0.5181 / Val_loss: 0.6437\n",
      "Epoch: 857, Train_loss: 0.5087 / Val_loss: 0.7223\n",
      "Epoch: 858, Train_loss: 0.4938 / Val_loss: 0.6608\n",
      "Epoch: 859, Train_loss: 0.5044 / Val_loss: 0.5997\n",
      "Epoch: 860, Train_loss: 0.4941 / Val_loss: 0.5965\n",
      "Epoch: 861, Train_loss: 0.4958 / Val_loss: 0.7184\n",
      "Epoch: 862, Train_loss: 0.5193 / Val_loss: 0.6530\n",
      "Epoch: 863, Train_loss: 0.5405 / Val_loss: 0.8549\n",
      "Epoch: 864, Train_loss: 0.5123 / Val_loss: 0.6935\n",
      "Epoch: 865, Train_loss: 0.5242 / Val_loss: 0.7381\n",
      "Epoch: 866, Train_loss: 0.4997 / Val_loss: 0.7212\n",
      "Epoch: 867, Train_loss: 0.5060 / Val_loss: 0.7910\n",
      "Epoch: 868, Train_loss: 0.4968 / Val_loss: 0.7500\n",
      "Epoch: 869, Train_loss: 0.5046 / Val_loss: 0.6904\n",
      "Epoch: 870, Train_loss: 0.5126 / Val_loss: 0.7743\n",
      "Epoch: 871, Train_loss: 0.5088 / Val_loss: 0.7590\n",
      "Epoch: 872, Train_loss: 0.5218 / Val_loss: 0.8560\n",
      "Epoch: 873, Train_loss: 0.4952 / Val_loss: 0.7530\n",
      "Epoch: 874, Train_loss: 0.5143 / Val_loss: 0.7933\n",
      "Epoch: 875, Train_loss: 0.5032 / Val_loss: 0.6442\n",
      "Epoch: 876, Train_loss: 0.5024 / Val_loss: 0.6397\n",
      "Epoch: 877, Train_loss: 0.4988 / Val_loss: 0.7594\n",
      "Epoch: 878, Train_loss: 0.5027 / Val_loss: 0.6546\n",
      "Epoch: 879, Train_loss: 0.5003 / Val_loss: 0.7291\n",
      "Epoch: 880, Train_loss: 0.4988 / Val_loss: 0.7900\n",
      "Epoch: 881, Train_loss: 0.5002 / Val_loss: 0.6898\n",
      "Epoch: 882, Train_loss: 0.5076 / Val_loss: 0.6352\n",
      "Epoch: 883, Train_loss: 0.4966 / Val_loss: 0.7553\n",
      "Epoch: 884, Train_loss: 0.4990 / Val_loss: 0.8474\n",
      "Epoch: 885, Train_loss: 0.5029 / Val_loss: 0.7218\n",
      "Epoch: 886, Train_loss: 0.4949 / Val_loss: 0.6183\n",
      "Epoch: 887, Train_loss: 0.4942 / Val_loss: 0.6766\n",
      "Epoch: 888, Train_loss: 0.5110 / Val_loss: 0.7588\n",
      "Epoch: 889, Train_loss: 0.5083 / Val_loss: 0.7418\n",
      "Epoch: 890, Train_loss: 0.5105 / Val_loss: 0.8284\n",
      "Epoch: 891, Train_loss: 0.5133 / Val_loss: 0.6861\n",
      "Epoch: 892, Train_loss: 0.4897 / Val_loss: 0.7084\n",
      "Epoch: 893, Train_loss: 0.5139 / Val_loss: 0.6759\n",
      "Epoch: 894, Train_loss: 0.4894 / Val_loss: 0.6480\n",
      "Epoch: 895, Train_loss: 0.5028 / Val_loss: 0.6322\n",
      "Epoch: 896, Train_loss: 0.4923 / Val_loss: 0.7060\n",
      "Epoch: 897, Train_loss: 0.5036 / Val_loss: 0.7667\n",
      "Epoch: 898, Train_loss: 0.4843 / Val_loss: 0.7582\n",
      "Epoch: 899, Train_loss: 0.5004 / Val_loss: 0.6210\n",
      "Epoch: 900, Train_loss: 0.4975 / Val_loss: 0.7620\n",
      "Epoch: 901, Train_loss: 0.5135 / Val_loss: 0.8334\n",
      "Epoch: 902, Train_loss: 0.5088 / Val_loss: 0.8153\n",
      "Epoch: 903, Train_loss: 0.4860 / Val_loss: 0.6210\n",
      "Epoch: 904, Train_loss: 0.4941 / Val_loss: 0.7452\n",
      "Epoch: 905, Train_loss: 0.4957 / Val_loss: 0.7343\n",
      "Epoch: 906, Train_loss: 0.4949 / Val_loss: 0.7998\n",
      "Epoch: 907, Train_loss: 0.4972 / Val_loss: 0.6299\n",
      "Epoch: 908, Train_loss: 0.5124 / Val_loss: 0.6576\n",
      "Epoch: 909, Train_loss: 0.4825 / Val_loss: 0.7564\n",
      "Epoch: 910, Train_loss: 0.5087 / Val_loss: 0.7310\n",
      "Epoch: 911, Train_loss: 0.4864 / Val_loss: 1.0379\n",
      "Epoch: 912, Train_loss: 0.4974 / Val_loss: 0.5871\n",
      "Epoch: 913, Train_loss: 0.4919 / Val_loss: 0.6830\n",
      "Epoch: 914, Train_loss: 0.5196 / Val_loss: 0.7926\n",
      "Epoch: 915, Train_loss: 0.4955 / Val_loss: 0.8227\n",
      "Epoch: 916, Train_loss: 0.5107 / Val_loss: 0.7063\n",
      "Epoch: 917, Train_loss: 0.5222 / Val_loss: 0.6960\n",
      "Epoch: 918, Train_loss: 0.5065 / Val_loss: 0.7186\n",
      "Epoch: 919, Train_loss: 0.5205 / Val_loss: 0.5898\n",
      "Epoch: 920, Train_loss: 0.4838 / Val_loss: 0.7130\n",
      "Epoch: 921, Train_loss: 0.5108 / Val_loss: 0.6700\n",
      "Epoch: 922, Train_loss: 0.5040 / Val_loss: 0.5957\n",
      "Epoch: 923, Train_loss: 0.5128 / Val_loss: 0.6715\n",
      "Epoch: 924, Train_loss: 0.5323 / Val_loss: 0.6512\n",
      "Epoch: 925, Train_loss: 0.4970 / Val_loss: 0.8614\n",
      "Epoch: 926, Train_loss: 0.5139 / Val_loss: 0.6515\n",
      "Epoch: 927, Train_loss: 0.4921 / Val_loss: 0.7142\n",
      "Epoch: 928, Train_loss: 0.5081 / Val_loss: 0.6942\n",
      "Epoch: 929, Train_loss: 0.4809 / Val_loss: 0.6877\n",
      "Epoch: 930, Train_loss: 0.4893 / Val_loss: 0.6846\n",
      "Epoch: 931, Train_loss: 0.5128 / Val_loss: 0.7202\n",
      "Epoch: 932, Train_loss: 0.5092 / Val_loss: 0.6003\n",
      "Epoch: 933, Train_loss: 0.5200 / Val_loss: 0.6657\n",
      "Epoch: 934, Train_loss: 0.5055 / Val_loss: 0.6759\n",
      "Epoch: 935, Train_loss: 0.4832 / Val_loss: 0.7577\n",
      "Epoch: 936, Train_loss: 0.5233 / Val_loss: 0.8173\n",
      "Epoch: 937, Train_loss: 0.4857 / Val_loss: 0.6811\n",
      "Epoch: 938, Train_loss: 0.4982 / Val_loss: 0.5992\n",
      "Epoch: 939, Train_loss: 0.5036 / Val_loss: 0.6633\n",
      "Epoch: 940, Train_loss: 0.4963 / Val_loss: 0.6617\n",
      "Epoch: 941, Train_loss: 0.5008 / Val_loss: 0.6122\n",
      "Epoch: 942, Train_loss: 0.4944 / Val_loss: 0.6431\n",
      "Epoch: 943, Train_loss: 0.5080 / Val_loss: 0.6617\n",
      "Epoch: 944, Train_loss: 0.5021 / Val_loss: 0.6374\n",
      "Epoch: 945, Train_loss: 0.5094 / Val_loss: 0.6198\n",
      "Epoch: 946, Train_loss: 0.4981 / Val_loss: 0.7800\n",
      "Epoch: 947, Train_loss: 0.5093 / Val_loss: 0.6208\n",
      "Epoch: 948, Train_loss: 0.5027 / Val_loss: 0.8750\n",
      "Epoch: 949, Train_loss: 0.4922 / Val_loss: 0.6398\n",
      "Epoch: 950, Train_loss: 0.5200 / Val_loss: 0.7402\n",
      "Epoch: 951, Train_loss: 0.5147 / Val_loss: 0.7607\n",
      "Epoch: 952, Train_loss: 0.5023 / Val_loss: 0.7994\n",
      "Epoch: 953, Train_loss: 0.5005 / Val_loss: 0.6443\n",
      "Epoch: 954, Train_loss: 0.5014 / Val_loss: 0.7126\n",
      "Epoch: 955, Train_loss: 0.4865 / Val_loss: 0.6724\n",
      "Epoch: 956, Train_loss: 0.4885 / Val_loss: 0.7850\n",
      "Epoch: 957, Train_loss: 0.5054 / Val_loss: 0.6459\n",
      "Epoch: 958, Train_loss: 0.5035 / Val_loss: 0.7043\n",
      "Epoch: 959, Train_loss: 0.5309 / Val_loss: 0.7180\n",
      "Epoch: 960, Train_loss: 0.5191 / Val_loss: 0.6240\n",
      "Epoch: 961, Train_loss: 0.5171 / Val_loss: 0.8774\n",
      "Epoch: 962, Train_loss: 0.5101 / Val_loss: 0.7595\n",
      "Epoch: 963, Train_loss: 0.4923 / Val_loss: 0.6218\n",
      "Epoch: 964, Train_loss: 0.4844 / Val_loss: 0.7902\n",
      "Epoch: 965, Train_loss: 0.5161 / Val_loss: 0.6807\n",
      "Epoch: 966, Train_loss: 0.5006 / Val_loss: 0.6950\n",
      "Epoch: 967, Train_loss: 0.5091 / Val_loss: 0.8933\n",
      "Epoch: 968, Train_loss: 0.5121 / Val_loss: 0.7514\n",
      "Epoch: 969, Train_loss: 0.5194 / Val_loss: 0.8200\n",
      "Epoch: 970, Train_loss: 0.4988 / Val_loss: 0.8107\n",
      "Epoch: 971, Train_loss: 0.5101 / Val_loss: 0.7944\n",
      "Epoch: 972, Train_loss: 0.4948 / Val_loss: 0.6704\n",
      "Epoch: 973, Train_loss: 0.4884 / Val_loss: 0.8455\n",
      "Epoch: 974, Train_loss: 0.4937 / Val_loss: 0.6314\n",
      "Epoch: 975, Train_loss: 0.4950 / Val_loss: 0.6763\n",
      "Epoch: 976, Train_loss: 0.5009 / Val_loss: 0.6944\n",
      "Epoch: 977, Train_loss: 0.4986 / Val_loss: 0.7663\n",
      "Epoch: 978, Train_loss: 0.4924 / Val_loss: 0.6667\n",
      "Epoch: 979, Train_loss: 0.5151 / Val_loss: 0.7250\n",
      "Epoch: 980, Train_loss: 0.4878 / Val_loss: 0.7142\n",
      "Epoch: 981, Train_loss: 0.4926 / Val_loss: 0.7889\n",
      "Epoch: 982, Train_loss: 0.4809 / Val_loss: 0.9284\n",
      "Epoch: 983, Train_loss: 0.4848 / Val_loss: 0.6938\n",
      "Epoch: 984, Train_loss: 0.5113 / Val_loss: 0.8019\n",
      "Epoch: 985, Train_loss: 0.4987 / Val_loss: 0.7431\n",
      "Epoch: 986, Train_loss: 0.4993 / Val_loss: 0.8391\n",
      "Epoch: 987, Train_loss: 0.4875 / Val_loss: 0.8582\n",
      "Epoch: 988, Train_loss: 0.4959 / Val_loss: 0.7213\n",
      "Epoch: 989, Train_loss: 0.5157 / Val_loss: 0.6669\n",
      "Epoch: 990, Train_loss: 0.4963 / Val_loss: 0.6587\n",
      "Epoch: 991, Train_loss: 0.4867 / Val_loss: 0.7752\n",
      "Epoch: 992, Train_loss: 0.5100 / Val_loss: 0.5647\n",
      "Epoch: 993, Train_loss: 0.5163 / Val_loss: 0.7400\n",
      "Epoch: 994, Train_loss: 0.4804 / Val_loss: 0.7901\n",
      "Epoch: 995, Train_loss: 0.4856 / Val_loss: 0.7238\n",
      "Epoch: 996, Train_loss: 0.5046 / Val_loss: 0.6619\n",
      "Epoch: 997, Train_loss: 0.5064 / Val_loss: 0.7292\n",
      "Epoch: 998, Train_loss: 0.4971 / Val_loss: 0.6465\n",
      "Epoch: 999, Train_loss: 0.4926 / Val_loss: 0.8201\n",
      "Epoch: 1000, Train_loss: 0.4982 / Val_loss: 0.7610\n",
      "Epoch: 1001, Train_loss: 0.5190 / Val_loss: 0.7132\n",
      "Epoch: 1002, Train_loss: 0.4943 / Val_loss: 0.6788\n",
      "Epoch: 1003, Train_loss: 0.4744 / Val_loss: 0.7679\n",
      "Epoch: 1004, Train_loss: 0.4860 / Val_loss: 0.6444\n",
      "Epoch: 1005, Train_loss: 0.4735 / Val_loss: 0.6971\n",
      "Epoch: 1006, Train_loss: 0.4996 / Val_loss: 0.7401\n",
      "Epoch: 1007, Train_loss: 0.5094 / Val_loss: 0.7151\n",
      "Epoch: 1008, Train_loss: 0.4980 / Val_loss: 0.7841\n",
      "Epoch: 1009, Train_loss: 0.4823 / Val_loss: 0.7717\n",
      "Epoch: 1010, Train_loss: 0.4891 / Val_loss: 0.6600\n",
      "Epoch: 1011, Train_loss: 0.5222 / Val_loss: 0.6597\n",
      "Epoch: 1012, Train_loss: 0.5093 / Val_loss: 0.6368\n",
      "Epoch: 1013, Train_loss: 0.4880 / Val_loss: 0.7387\n",
      "Epoch: 1014, Train_loss: 0.4849 / Val_loss: 0.6989\n",
      "Epoch: 1015, Train_loss: 0.4864 / Val_loss: 0.6220\n",
      "Epoch: 1016, Train_loss: 0.5125 / Val_loss: 0.9136\n",
      "Epoch: 1017, Train_loss: 0.4939 / Val_loss: 0.6743\n",
      "Epoch: 1018, Train_loss: 0.5115 / Val_loss: 0.7849\n",
      "Epoch: 1019, Train_loss: 0.5007 / Val_loss: 0.7581\n",
      "Epoch: 1020, Train_loss: 0.4981 / Val_loss: 0.7012\n",
      "Epoch: 1021, Train_loss: 0.5144 / Val_loss: 0.9336\n",
      "Epoch: 1022, Train_loss: 0.5044 / Val_loss: 0.6714\n",
      "Epoch: 1023, Train_loss: 0.4872 / Val_loss: 0.7295\n",
      "Epoch: 1024, Train_loss: 0.4876 / Val_loss: 0.6467\n",
      "Epoch: 1025, Train_loss: 0.4992 / Val_loss: 0.7364\n",
      "Epoch: 1026, Train_loss: 0.4981 / Val_loss: 0.7286\n",
      "Epoch: 1027, Train_loss: 0.5099 / Val_loss: 0.6517\n",
      "Epoch: 1028, Train_loss: 0.4806 / Val_loss: 0.7424\n",
      "Epoch: 1029, Train_loss: 0.4939 / Val_loss: 0.6603\n",
      "Epoch: 1030, Train_loss: 0.4871 / Val_loss: 0.7709\n",
      "Epoch: 1031, Train_loss: 0.4817 / Val_loss: 0.6553\n",
      "Epoch: 1032, Train_loss: 0.5083 / Val_loss: 0.7486\n",
      "Epoch: 1033, Train_loss: 0.5047 / Val_loss: 0.8273\n",
      "Epoch: 1034, Train_loss: 0.4887 / Val_loss: 0.7551\n",
      "Epoch: 1035, Train_loss: 0.5023 / Val_loss: 0.6749\n",
      "Epoch: 1036, Train_loss: 0.5091 / Val_loss: 0.9018\n",
      "Epoch: 1037, Train_loss: 0.4960 / Val_loss: 0.7633\n",
      "Epoch: 1038, Train_loss: 0.4970 / Val_loss: 0.7560\n",
      "Epoch: 1039, Train_loss: 0.4891 / Val_loss: 0.7109\n",
      "Epoch: 1040, Train_loss: 0.5076 / Val_loss: 0.6911\n",
      "Epoch: 1041, Train_loss: 0.4848 / Val_loss: 0.7456\n",
      "Epoch: 1042, Train_loss: 0.4917 / Val_loss: 0.7528\n",
      "Epoch: 1043, Train_loss: 0.4730 / Val_loss: 0.7206\n",
      "Epoch: 1044, Train_loss: 0.4941 / Val_loss: 0.7637\n",
      "Epoch: 1045, Train_loss: 0.4997 / Val_loss: 0.7740\n",
      "Epoch: 1046, Train_loss: 0.4897 / Val_loss: 0.6927\n",
      "Epoch: 1047, Train_loss: 0.4871 / Val_loss: 0.7054\n",
      "Epoch: 1048, Train_loss: 0.5023 / Val_loss: 0.6192\n",
      "Epoch: 1049, Train_loss: 0.4954 / Val_loss: 0.6365\n",
      "Epoch: 1050, Train_loss: 0.4865 / Val_loss: 0.6803\n",
      "Epoch: 1051, Train_loss: 0.5042 / Val_loss: 0.8303\n",
      "Epoch: 1052, Train_loss: 0.5004 / Val_loss: 0.6953\n",
      "Epoch: 1053, Train_loss: 0.4725 / Val_loss: 0.6610\n",
      "Epoch: 1054, Train_loss: 0.5119 / Val_loss: 0.6181\n",
      "Epoch: 1055, Train_loss: 0.4975 / Val_loss: 0.6542\n",
      "Epoch: 1056, Train_loss: 0.4877 / Val_loss: 0.7270\n",
      "Epoch: 1057, Train_loss: 0.5090 / Val_loss: 0.6671\n",
      "Epoch: 1058, Train_loss: 0.4873 / Val_loss: 0.6506\n",
      "Epoch: 1059, Train_loss: 0.4953 / Val_loss: 0.6802\n",
      "Epoch: 1060, Train_loss: 0.5021 / Val_loss: 0.6467\n",
      "Epoch: 1061, Train_loss: 0.4713 / Val_loss: 0.8113\n",
      "Epoch: 1062, Train_loss: 0.4833 / Val_loss: 0.6223\n",
      "Epoch: 1063, Train_loss: 0.4916 / Val_loss: 0.7814\n",
      "Epoch: 1064, Train_loss: 0.4811 / Val_loss: 0.7245\n",
      "Epoch: 1065, Train_loss: 0.4766 / Val_loss: 0.7778\n",
      "Epoch: 1066, Train_loss: 0.4914 / Val_loss: 0.7757\n",
      "Epoch: 1067, Train_loss: 0.4925 / Val_loss: 0.7277\n",
      "Epoch: 1068, Train_loss: 0.5060 / Val_loss: 0.7870\n",
      "Epoch: 1069, Train_loss: 0.4934 / Val_loss: 0.8350\n",
      "Epoch: 1070, Train_loss: 0.4966 / Val_loss: 0.6587\n",
      "Epoch: 1071, Train_loss: 0.4718 / Val_loss: 0.7955\n",
      "Epoch: 1072, Train_loss: 0.4814 / Val_loss: 0.7863\n",
      "Epoch: 1073, Train_loss: 0.4957 / Val_loss: 0.8507\n",
      "Epoch: 1074, Train_loss: 0.4795 / Val_loss: 0.7266\n",
      "Epoch: 1075, Train_loss: 0.5187 / Val_loss: 0.7173\n",
      "Epoch: 1076, Train_loss: 0.4833 / Val_loss: 0.6725\n",
      "Epoch: 1077, Train_loss: 0.5070 / Val_loss: 0.7292\n",
      "Epoch: 1078, Train_loss: 0.4828 / Val_loss: 0.6731\n",
      "Epoch: 1079, Train_loss: 0.4813 / Val_loss: 0.6538\n",
      "Epoch: 1080, Train_loss: 0.5249 / Val_loss: 0.6921\n",
      "Epoch: 1081, Train_loss: 0.4955 / Val_loss: 0.6560\n",
      "Epoch: 1082, Train_loss: 0.4826 / Val_loss: 0.7462\n",
      "Epoch: 1083, Train_loss: 0.4880 / Val_loss: 0.7267\n",
      "Epoch: 1084, Train_loss: 0.4982 / Val_loss: 0.6668\n",
      "Epoch: 1085, Train_loss: 0.4856 / Val_loss: 0.6170\n",
      "Epoch: 1086, Train_loss: 0.4950 / Val_loss: 0.7575\n",
      "Epoch: 1087, Train_loss: 0.4713 / Val_loss: 0.7529\n",
      "Epoch: 1088, Train_loss: 0.5077 / Val_loss: 0.5982\n",
      "Epoch: 1089, Train_loss: 0.4886 / Val_loss: 0.6675\n",
      "Epoch: 1090, Train_loss: 0.5043 / Val_loss: 0.8096\n",
      "Epoch: 1091, Train_loss: 0.4986 / Val_loss: 0.8649\n",
      "Epoch: 1092, Train_loss: 0.4767 / Val_loss: 0.8319\n",
      "Epoch: 1093, Train_loss: 0.4968 / Val_loss: 0.7822\n",
      "Epoch: 1094, Train_loss: 0.4874 / Val_loss: 0.6896\n",
      "Epoch: 1095, Train_loss: 0.4896 / Val_loss: 0.7223\n",
      "Epoch: 1096, Train_loss: 0.4730 / Val_loss: 0.6852\n",
      "Epoch: 1097, Train_loss: 0.4915 / Val_loss: 0.8880\n",
      "Epoch: 1098, Train_loss: 0.4901 / Val_loss: 0.6264\n",
      "Epoch: 1099, Train_loss: 0.4994 / Val_loss: 0.7629\n",
      "Epoch: 1100, Train_loss: 0.5098 / Val_loss: 0.6836\n",
      "Epoch: 1101, Train_loss: 0.4934 / Val_loss: 0.8816\n",
      "Epoch: 1102, Train_loss: 0.4978 / Val_loss: 0.6477\n",
      "Epoch: 1103, Train_loss: 0.4836 / Val_loss: 0.7544\n",
      "Epoch: 1104, Train_loss: 0.4864 / Val_loss: 0.7970\n",
      "Epoch: 1105, Train_loss: 0.4797 / Val_loss: 0.7637\n",
      "Epoch: 1106, Train_loss: 0.5148 / Val_loss: 0.7463\n",
      "Epoch: 1107, Train_loss: 0.4893 / Val_loss: 0.7074\n",
      "Epoch: 1108, Train_loss: 0.4915 / Val_loss: 0.6322\n",
      "Epoch: 1109, Train_loss: 0.5100 / Val_loss: 0.9138\n",
      "Epoch: 1110, Train_loss: 0.4809 / Val_loss: 0.6934\n",
      "Epoch: 1111, Train_loss: 0.5103 / Val_loss: 0.8124\n",
      "Epoch: 1112, Train_loss: 0.4804 / Val_loss: 0.7704\n",
      "Epoch: 1113, Train_loss: 0.4996 / Val_loss: 0.6501\n",
      "Epoch: 1114, Train_loss: 0.5084 / Val_loss: 0.6423\n",
      "Epoch: 1115, Train_loss: 0.4904 / Val_loss: 0.6202\n",
      "Epoch: 1116, Train_loss: 0.5006 / Val_loss: 0.7364\n",
      "Epoch: 1117, Train_loss: 0.4798 / Val_loss: 0.8246\n",
      "Epoch: 1118, Train_loss: 0.5057 / Val_loss: 0.7948\n",
      "Epoch: 1119, Train_loss: 0.4825 / Val_loss: 0.6375\n",
      "Epoch: 1120, Train_loss: 0.5067 / Val_loss: 0.7176\n",
      "Epoch: 1121, Train_loss: 0.5137 / Val_loss: 0.6231\n",
      "Epoch: 1122, Train_loss: 0.5073 / Val_loss: 0.7186\n",
      "Epoch: 1123, Train_loss: 0.5053 / Val_loss: 0.8227\n",
      "Epoch: 1124, Train_loss: 0.4995 / Val_loss: 0.6910\n",
      "Epoch: 1125, Train_loss: 0.5114 / Val_loss: 0.7536\n",
      "Epoch: 1126, Train_loss: 0.5018 / Val_loss: 0.6108\n",
      "Epoch: 1127, Train_loss: 0.5186 / Val_loss: 0.8466\n",
      "Epoch: 1128, Train_loss: 0.5020 / Val_loss: 0.6735\n",
      "Epoch: 1129, Train_loss: 0.4969 / Val_loss: 0.8150\n",
      "Epoch: 1130, Train_loss: 0.4917 / Val_loss: 0.7604\n",
      "Epoch: 1131, Train_loss: 0.4915 / Val_loss: 0.6223\n",
      "Epoch: 1132, Train_loss: 0.4750 / Val_loss: 0.8259\n",
      "Epoch: 1133, Train_loss: 0.4687 / Val_loss: 0.6921\n",
      "Epoch: 1134, Train_loss: 0.5076 / Val_loss: 0.7548\n",
      "Epoch: 1135, Train_loss: 0.4957 / Val_loss: 0.7476\n",
      "Epoch: 1136, Train_loss: 0.5035 / Val_loss: 0.7506\n",
      "Epoch: 1137, Train_loss: 0.4984 / Val_loss: 0.8510\n",
      "Epoch: 1138, Train_loss: 0.4648 / Val_loss: 0.8328\n",
      "Epoch: 1139, Train_loss: 0.4788 / Val_loss: 0.6962\n",
      "Epoch: 1140, Train_loss: 0.4797 / Val_loss: 0.8169\n",
      "Epoch: 1141, Train_loss: 0.4873 / Val_loss: 0.7625\n",
      "Epoch: 1142, Train_loss: 0.4754 / Val_loss: 0.6702\n",
      "Epoch: 1143, Train_loss: 0.4972 / Val_loss: 0.6029\n",
      "Epoch: 1144, Train_loss: 0.4847 / Val_loss: 0.6878\n",
      "Epoch: 1145, Train_loss: 0.4823 / Val_loss: 0.6661\n",
      "Epoch: 1146, Train_loss: 0.4919 / Val_loss: 0.6996\n",
      "Epoch: 1147, Train_loss: 0.4778 / Val_loss: 0.6927\n",
      "Epoch: 1148, Train_loss: 0.5067 / Val_loss: 0.7120\n",
      "Epoch: 1149, Train_loss: 0.4940 / Val_loss: 0.7087\n",
      "Epoch: 1150, Train_loss: 0.4803 / Val_loss: 0.8531\n",
      "Epoch: 1151, Train_loss: 0.4731 / Val_loss: 0.8188\n",
      "Epoch: 1152, Train_loss: 0.4892 / Val_loss: 0.8457\n",
      "Epoch: 1153, Train_loss: 0.4898 / Val_loss: 0.6701\n",
      "Epoch: 1154, Train_loss: 0.5066 / Val_loss: 0.8325\n",
      "Epoch: 1155, Train_loss: 0.4964 / Val_loss: 0.7663\n",
      "Epoch: 1156, Train_loss: 0.4932 / Val_loss: 0.8191\n",
      "Epoch: 1157, Train_loss: 0.4867 / Val_loss: 0.6931\n",
      "Epoch: 1158, Train_loss: 0.4784 / Val_loss: 0.8553\n",
      "Epoch: 1159, Train_loss: 0.5136 / Val_loss: 0.5884\n",
      "Epoch: 1160, Train_loss: 0.4948 / Val_loss: 0.7357\n",
      "Epoch: 1161, Train_loss: 0.5215 / Val_loss: 0.7745\n",
      "Epoch: 1162, Train_loss: 0.5119 / Val_loss: 0.6475\n",
      "Epoch: 1163, Train_loss: 0.4860 / Val_loss: 0.6930\n",
      "Epoch: 1164, Train_loss: 0.4709 / Val_loss: 0.6294\n",
      "Epoch: 1165, Train_loss: 0.4866 / Val_loss: 0.6408\n",
      "Epoch: 1166, Train_loss: 0.4831 / Val_loss: 0.7452\n",
      "Epoch: 1167, Train_loss: 0.4703 / Val_loss: 0.7378\n",
      "Epoch: 1168, Train_loss: 0.4728 / Val_loss: 0.6805\n",
      "Epoch: 1169, Train_loss: 0.4774 / Val_loss: 0.6607\n",
      "Epoch: 1170, Train_loss: 0.5182 / Val_loss: 0.7992\n",
      "Epoch: 1171, Train_loss: 0.5137 / Val_loss: 0.7783\n",
      "Epoch: 1172, Train_loss: 0.4691 / Val_loss: 0.7552\n",
      "Epoch: 1173, Train_loss: 0.4860 / Val_loss: 0.7898\n",
      "Epoch: 1174, Train_loss: 0.4755 / Val_loss: 0.7908\n",
      "Epoch: 1175, Train_loss: 0.5017 / Val_loss: 0.8401\n",
      "Epoch: 1176, Train_loss: 0.4990 / Val_loss: 0.7791\n",
      "Epoch: 1177, Train_loss: 0.4732 / Val_loss: 0.7823\n",
      "Epoch: 1178, Train_loss: 0.4827 / Val_loss: 0.8128\n",
      "Epoch: 1179, Train_loss: 0.4929 / Val_loss: 0.5702\n",
      "Epoch: 1180, Train_loss: 0.4770 / Val_loss: 0.7310\n",
      "Epoch: 1181, Train_loss: 0.4831 / Val_loss: 0.7265\n",
      "Epoch: 1182, Train_loss: 0.4775 / Val_loss: 0.6061\n",
      "Epoch: 1183, Train_loss: 0.4951 / Val_loss: 0.8203\n",
      "Epoch: 1184, Train_loss: 0.4867 / Val_loss: 0.8669\n",
      "Epoch: 1185, Train_loss: 0.4897 / Val_loss: 0.7463\n",
      "Epoch: 1186, Train_loss: 0.5022 / Val_loss: 0.7762\n",
      "Epoch: 1187, Train_loss: 0.4941 / Val_loss: 0.7510\n",
      "Epoch: 1188, Train_loss: 0.5032 / Val_loss: 0.7149\n",
      "Epoch: 1189, Train_loss: 0.5127 / Val_loss: 0.7321\n",
      "Epoch: 1190, Train_loss: 0.4880 / Val_loss: 0.9009\n",
      "Epoch: 1191, Train_loss: 0.4873 / Val_loss: 0.6859\n",
      "Epoch: 1192, Train_loss: 0.4775 / Val_loss: 0.8604\n",
      "Epoch: 1193, Train_loss: 0.4935 / Val_loss: 0.6889\n",
      "Epoch: 1194, Train_loss: 0.4999 / Val_loss: 0.6809\n",
      "Epoch: 1195, Train_loss: 0.4882 / Val_loss: 0.5914\n",
      "Epoch: 1196, Train_loss: 0.4840 / Val_loss: 0.8668\n",
      "Epoch: 1197, Train_loss: 0.4838 / Val_loss: 0.6044\n",
      "Epoch: 1198, Train_loss: 0.4741 / Val_loss: 0.6306\n",
      "Epoch: 1199, Train_loss: 0.4792 / Val_loss: 0.7174\n",
      "Epoch: 1200, Train_loss: 0.5024 / Val_loss: 0.8798\n",
      "Epoch: 1201, Train_loss: 0.4766 / Val_loss: 0.7851\n",
      "Epoch: 1202, Train_loss: 0.4572 / Val_loss: 0.8099\n",
      "Epoch: 1203, Train_loss: 0.4860 / Val_loss: 0.7293\n",
      "Epoch: 1204, Train_loss: 0.4914 / Val_loss: 0.8262\n",
      "Epoch: 1205, Train_loss: 0.4812 / Val_loss: 0.8783\n",
      "Epoch: 1206, Train_loss: 0.4827 / Val_loss: 0.6769\n",
      "Epoch: 1207, Train_loss: 0.4745 / Val_loss: 0.8211\n",
      "Epoch: 1208, Train_loss: 0.4882 / Val_loss: 0.6765\n",
      "Epoch: 1209, Train_loss: 0.4694 / Val_loss: 0.7603\n",
      "Epoch: 1210, Train_loss: 0.4891 / Val_loss: 0.6072\n",
      "Epoch: 1211, Train_loss: 0.4822 / Val_loss: 0.7176\n",
      "Epoch: 1212, Train_loss: 0.5086 / Val_loss: 0.6258\n",
      "Epoch: 1213, Train_loss: 0.5141 / Val_loss: 0.7123\n",
      "Epoch: 1214, Train_loss: 0.5018 / Val_loss: 0.6584\n",
      "Epoch: 1215, Train_loss: 0.4707 / Val_loss: 0.8809\n",
      "Epoch: 1216, Train_loss: 0.4926 / Val_loss: 0.6500\n",
      "Epoch: 1217, Train_loss: 0.5169 / Val_loss: 0.7504\n",
      "Epoch: 1218, Train_loss: 0.4857 / Val_loss: 0.7822\n",
      "Epoch: 1219, Train_loss: 0.4747 / Val_loss: 0.5995\n",
      "Epoch: 1220, Train_loss: 0.4941 / Val_loss: 0.7889\n",
      "Epoch: 1221, Train_loss: 0.5042 / Val_loss: 0.6461\n",
      "Epoch: 1222, Train_loss: 0.4742 / Val_loss: 0.8493\n",
      "Epoch: 1223, Train_loss: 0.4709 / Val_loss: 0.7635\n",
      "Epoch: 1224, Train_loss: 0.5021 / Val_loss: 0.7041\n",
      "Epoch: 1225, Train_loss: 0.5001 / Val_loss: 0.8326\n",
      "Epoch: 1226, Train_loss: 0.4738 / Val_loss: 0.7020\n",
      "Epoch: 1227, Train_loss: 0.5005 / Val_loss: 0.7432\n",
      "Epoch: 1228, Train_loss: 0.4680 / Val_loss: 0.6590\n",
      "Epoch: 1229, Train_loss: 0.4942 / Val_loss: 0.7274\n",
      "Epoch: 1230, Train_loss: 0.4777 / Val_loss: 0.6906\n",
      "Epoch: 1231, Train_loss: 0.5014 / Val_loss: 0.6797\n",
      "Epoch: 1232, Train_loss: 0.4925 / Val_loss: 0.7660\n",
      "Epoch: 1233, Train_loss: 0.4718 / Val_loss: 0.6316\n",
      "Epoch: 1234, Train_loss: 0.4734 / Val_loss: 0.8188\n",
      "Epoch: 1235, Train_loss: 0.4618 / Val_loss: 0.7893\n",
      "Epoch: 1236, Train_loss: 0.4813 / Val_loss: 0.7792\n",
      "Epoch: 1237, Train_loss: 0.4701 / Val_loss: 0.7088\n",
      "Epoch: 1238, Train_loss: 0.4748 / Val_loss: 0.7108\n",
      "Epoch: 1239, Train_loss: 0.4911 / Val_loss: 0.8817\n",
      "Epoch: 1240, Train_loss: 0.4807 / Val_loss: 0.7151\n",
      "Epoch: 1241, Train_loss: 0.4833 / Val_loss: 0.7045\n",
      "Epoch: 1242, Train_loss: 0.4927 / Val_loss: 0.8066\n",
      "Epoch: 1243, Train_loss: 0.4646 / Val_loss: 0.7801\n",
      "Epoch: 1244, Train_loss: 0.5138 / Val_loss: 0.8206\n",
      "Epoch: 1245, Train_loss: 0.4887 / Val_loss: 0.7580\n",
      "Epoch: 1246, Train_loss: 0.4890 / Val_loss: 0.6156\n",
      "Epoch: 1247, Train_loss: 0.4828 / Val_loss: 0.7184\n",
      "Epoch: 1248, Train_loss: 0.4590 / Val_loss: 0.7997\n",
      "Epoch: 1249, Train_loss: 0.4651 / Val_loss: 0.7146\n",
      "Epoch: 1250, Train_loss: 0.4769 / Val_loss: 0.7063\n",
      "Epoch: 1251, Train_loss: 0.4822 / Val_loss: 0.6708\n",
      "Epoch: 1252, Train_loss: 0.4789 / Val_loss: 0.6548\n",
      "Epoch: 1253, Train_loss: 0.4625 / Val_loss: 0.7549\n",
      "Epoch: 1254, Train_loss: 0.4886 / Val_loss: 0.6807\n",
      "Epoch: 1255, Train_loss: 0.4996 / Val_loss: 0.7626\n",
      "Epoch: 1256, Train_loss: 0.4826 / Val_loss: 0.7491\n",
      "Epoch: 1257, Train_loss: 0.4775 / Val_loss: 0.6994\n",
      "Epoch: 1258, Train_loss: 0.4834 / Val_loss: 0.9627\n",
      "Epoch: 1259, Train_loss: 0.5051 / Val_loss: 0.8055\n",
      "Epoch: 1260, Train_loss: 0.4896 / Val_loss: 0.6791\n",
      "Epoch: 1261, Train_loss: 0.4638 / Val_loss: 0.8694\n",
      "Epoch: 1262, Train_loss: 0.4938 / Val_loss: 0.8481\n",
      "Epoch: 1263, Train_loss: 0.4902 / Val_loss: 0.8042\n",
      "Epoch: 1264, Train_loss: 0.4956 / Val_loss: 0.7463\n",
      "Epoch: 1265, Train_loss: 0.4782 / Val_loss: 0.7196\n",
      "Epoch: 1266, Train_loss: 0.4778 / Val_loss: 0.7840\n",
      "Epoch: 1267, Train_loss: 0.4693 / Val_loss: 0.6312\n",
      "Epoch: 1268, Train_loss: 0.4902 / Val_loss: 0.7091\n",
      "Epoch: 1269, Train_loss: 0.4808 / Val_loss: 0.6965\n",
      "Epoch: 1270, Train_loss: 0.4765 / Val_loss: 0.8682\n",
      "Epoch: 1271, Train_loss: 0.4782 / Val_loss: 0.9235\n",
      "Epoch: 1272, Train_loss: 0.4903 / Val_loss: 0.8825\n",
      "Epoch: 1273, Train_loss: 0.5028 / Val_loss: 0.8551\n",
      "Epoch: 1274, Train_loss: 0.4678 / Val_loss: 0.8173\n",
      "Epoch: 1275, Train_loss: 0.4704 / Val_loss: 0.6053\n",
      "Epoch: 1276, Train_loss: 0.4502 / Val_loss: 0.7864\n",
      "Epoch: 1277, Train_loss: 0.4858 / Val_loss: 0.7680\n",
      "Epoch: 1278, Train_loss: 0.4880 / Val_loss: 0.7158\n",
      "Epoch: 1279, Train_loss: 0.4990 / Val_loss: 0.6373\n",
      "Epoch: 1280, Train_loss: 0.4758 / Val_loss: 0.7009\n",
      "Epoch: 1281, Train_loss: 0.4708 / Val_loss: 0.6679\n",
      "Epoch: 1282, Train_loss: 0.4810 / Val_loss: 0.6573\n",
      "Epoch: 1283, Train_loss: 0.4784 / Val_loss: 0.6845\n",
      "Epoch: 1284, Train_loss: 0.4877 / Val_loss: 0.5798\n",
      "Epoch: 1285, Train_loss: 0.4964 / Val_loss: 0.7943\n",
      "Epoch: 1286, Train_loss: 0.4885 / Val_loss: 0.6944\n",
      "Epoch: 1287, Train_loss: 0.4793 / Val_loss: 0.7689\n",
      "Epoch: 1288, Train_loss: 0.4731 / Val_loss: 0.8027\n",
      "Epoch: 1289, Train_loss: 0.4714 / Val_loss: 0.7665\n",
      "Epoch: 1290, Train_loss: 0.4801 / Val_loss: 0.6678\n",
      "Epoch: 1291, Train_loss: 0.4697 / Val_loss: 0.7599\n",
      "Epoch: 1292, Train_loss: 0.4853 / Val_loss: 0.6972\n",
      "Epoch: 1293, Train_loss: 0.4697 / Val_loss: 0.7676\n",
      "Epoch: 1294, Train_loss: 0.4861 / Val_loss: 0.8265\n",
      "Epoch: 1295, Train_loss: 0.4890 / Val_loss: 0.7055\n",
      "Epoch: 1296, Train_loss: 0.5036 / Val_loss: 0.5937\n",
      "Epoch: 1297, Train_loss: 0.4840 / Val_loss: 0.6576\n",
      "Epoch: 1298, Train_loss: 0.4719 / Val_loss: 0.6649\n",
      "Epoch: 1299, Train_loss: 0.4630 / Val_loss: 0.7585\n",
      "Epoch: 1300, Train_loss: 0.4737 / Val_loss: 0.7263\n",
      "Epoch: 1301, Train_loss: 0.4652 / Val_loss: 0.7954\n",
      "Epoch: 1302, Train_loss: 0.4915 / Val_loss: 0.9109\n",
      "Epoch: 1303, Train_loss: 0.4716 / Val_loss: 0.7555\n",
      "Epoch: 1304, Train_loss: 0.4978 / Val_loss: 0.9302\n",
      "Epoch: 1305, Train_loss: 0.4771 / Val_loss: 0.7249\n",
      "Epoch: 1306, Train_loss: 0.4788 / Val_loss: 0.8470\n",
      "Epoch: 1307, Train_loss: 0.4853 / Val_loss: 0.8702\n",
      "Epoch: 1308, Train_loss: 0.4716 / Val_loss: 0.6688\n",
      "Epoch: 1309, Train_loss: 0.4668 / Val_loss: 0.8259\n",
      "Epoch: 1310, Train_loss: 0.4807 / Val_loss: 0.9570\n",
      "Epoch: 1311, Train_loss: 0.4796 / Val_loss: 0.7090\n",
      "Epoch: 1312, Train_loss: 0.4834 / Val_loss: 0.7263\n",
      "Epoch: 1313, Train_loss: 0.4605 / Val_loss: 0.6592\n",
      "Epoch: 1314, Train_loss: 0.4907 / Val_loss: 0.7324\n",
      "Epoch: 1315, Train_loss: 0.4739 / Val_loss: 0.8036\n",
      "Epoch: 1316, Train_loss: 0.4726 / Val_loss: 0.7257\n",
      "Epoch: 1317, Train_loss: 0.4957 / Val_loss: 0.7210\n",
      "Epoch: 1318, Train_loss: 0.4900 / Val_loss: 0.7293\n",
      "Epoch: 1319, Train_loss: 0.4723 / Val_loss: 0.8316\n",
      "Epoch: 1320, Train_loss: 0.4831 / Val_loss: 0.7231\n",
      "Epoch: 1321, Train_loss: 0.4700 / Val_loss: 0.8169\n",
      "Epoch: 1322, Train_loss: 0.4837 / Val_loss: 0.6273\n",
      "Epoch: 1323, Train_loss: 0.4758 / Val_loss: 0.7309\n",
      "Epoch: 1324, Train_loss: 0.4828 / Val_loss: 0.7108\n",
      "Epoch: 1325, Train_loss: 0.4924 / Val_loss: 0.9134\n",
      "Epoch: 1326, Train_loss: 0.4552 / Val_loss: 0.8025\n",
      "Epoch: 1327, Train_loss: 0.4964 / Val_loss: 0.8265\n",
      "Epoch: 1328, Train_loss: 0.4654 / Val_loss: 0.7159\n",
      "Epoch: 1329, Train_loss: 0.4665 / Val_loss: 0.7643\n",
      "Epoch: 1330, Train_loss: 0.4717 / Val_loss: 0.8400\n",
      "Epoch: 1331, Train_loss: 0.4782 / Val_loss: 0.8471\n",
      "Epoch: 1332, Train_loss: 0.4816 / Val_loss: 0.6662\n",
      "Epoch: 1333, Train_loss: 0.4753 / Val_loss: 0.7107\n",
      "Epoch: 1334, Train_loss: 0.4658 / Val_loss: 0.8626\n",
      "Epoch: 1335, Train_loss: 0.4676 / Val_loss: 0.7375\n",
      "Epoch: 1336, Train_loss: 0.4849 / Val_loss: 0.9803\n",
      "Epoch: 1337, Train_loss: 0.4661 / Val_loss: 0.7467\n",
      "Epoch: 1338, Train_loss: 0.4928 / Val_loss: 0.9369\n",
      "Epoch: 1339, Train_loss: 0.4729 / Val_loss: 0.7565\n",
      "Epoch: 1340, Train_loss: 0.5089 / Val_loss: 1.1422\n",
      "Epoch: 1341, Train_loss: 0.4715 / Val_loss: 0.7975\n",
      "Epoch: 1342, Train_loss: 0.4635 / Val_loss: 0.6408\n",
      "Epoch: 1343, Train_loss: 0.4869 / Val_loss: 0.7111\n",
      "Epoch: 1344, Train_loss: 0.4873 / Val_loss: 0.7703\n",
      "Epoch: 1345, Train_loss: 0.4762 / Val_loss: 0.8377\n",
      "Epoch: 1346, Train_loss: 0.4650 / Val_loss: 0.7355\n",
      "Epoch: 1347, Train_loss: 0.4839 / Val_loss: 0.7034\n",
      "Epoch: 1348, Train_loss: 0.4817 / Val_loss: 0.7447\n",
      "Epoch: 1349, Train_loss: 0.4953 / Val_loss: 0.7167\n",
      "Epoch: 1350, Train_loss: 0.4754 / Val_loss: 0.6278\n",
      "Epoch: 1351, Train_loss: 0.4757 / Val_loss: 0.7950\n",
      "Epoch: 1352, Train_loss: 0.4681 / Val_loss: 0.6917\n",
      "Epoch: 1353, Train_loss: 0.4905 / Val_loss: 0.6991\n",
      "Epoch: 1354, Train_loss: 0.4662 / Val_loss: 0.7565\n",
      "Epoch: 1355, Train_loss: 0.4921 / Val_loss: 0.7126\n",
      "Epoch: 1356, Train_loss: 0.4895 / Val_loss: 0.8840\n",
      "Epoch: 1357, Train_loss: 0.4713 / Val_loss: 0.7680\n",
      "Epoch: 1358, Train_loss: 0.4777 / Val_loss: 0.8294\n",
      "Epoch: 1359, Train_loss: 0.4713 / Val_loss: 0.8106\n",
      "Epoch: 1360, Train_loss: 0.4571 / Val_loss: 0.7184\n",
      "Epoch: 1361, Train_loss: 0.4695 / Val_loss: 0.6794\n",
      "Epoch: 1362, Train_loss: 0.4657 / Val_loss: 0.8062\n",
      "Epoch: 1363, Train_loss: 0.5032 / Val_loss: 0.6900\n",
      "Epoch: 1364, Train_loss: 0.4779 / Val_loss: 0.7884\n",
      "Epoch: 1365, Train_loss: 0.4826 / Val_loss: 0.6958\n",
      "Epoch: 1366, Train_loss: 0.4749 / Val_loss: 0.8099\n",
      "Epoch: 1367, Train_loss: 0.4850 / Val_loss: 0.7880\n",
      "Epoch: 1368, Train_loss: 0.4826 / Val_loss: 0.9616\n",
      "Epoch: 1369, Train_loss: 0.4709 / Val_loss: 0.6167\n",
      "Epoch: 1370, Train_loss: 0.4728 / Val_loss: 0.8322\n",
      "Epoch: 1371, Train_loss: 0.4598 / Val_loss: 0.8207\n",
      "Epoch: 1372, Train_loss: 0.4654 / Val_loss: 0.7502\n",
      "Epoch: 1373, Train_loss: 0.4953 / Val_loss: 0.8456\n",
      "Epoch: 1374, Train_loss: 0.4654 / Val_loss: 0.7862\n",
      "Epoch: 1375, Train_loss: 0.4630 / Val_loss: 0.8085\n",
      "Epoch: 1376, Train_loss: 0.4772 / Val_loss: 0.6796\n",
      "Epoch: 1377, Train_loss: 0.4871 / Val_loss: 0.6694\n",
      "Epoch: 1378, Train_loss: 0.4633 / Val_loss: 0.6724\n",
      "Epoch: 1379, Train_loss: 0.4713 / Val_loss: 0.6821\n",
      "Epoch: 1380, Train_loss: 0.4599 / Val_loss: 0.6630\n",
      "Epoch: 1381, Train_loss: 0.4785 / Val_loss: 0.6594\n",
      "Epoch: 1382, Train_loss: 0.4794 / Val_loss: 0.7929\n",
      "Epoch: 1383, Train_loss: 0.4851 / Val_loss: 0.7650\n",
      "Epoch: 1384, Train_loss: 0.4628 / Val_loss: 0.7416\n",
      "Epoch: 1385, Train_loss: 0.4842 / Val_loss: 0.8094\n",
      "Epoch: 1386, Train_loss: 0.4828 / Val_loss: 0.8269\n",
      "Epoch: 1387, Train_loss: 0.4759 / Val_loss: 0.8222\n",
      "Epoch: 1388, Train_loss: 0.4639 / Val_loss: 0.7815\n",
      "Epoch: 1389, Train_loss: 0.4663 / Val_loss: 0.7868\n",
      "Epoch: 1390, Train_loss: 0.4989 / Val_loss: 0.7174\n",
      "Epoch: 1391, Train_loss: 0.4769 / Val_loss: 0.6832\n",
      "Epoch: 1392, Train_loss: 0.5066 / Val_loss: 0.6481\n",
      "Epoch: 1393, Train_loss: 0.4608 / Val_loss: 0.8607\n",
      "Epoch: 1394, Train_loss: 0.4752 / Val_loss: 0.7412\n",
      "Epoch: 1395, Train_loss: 0.4598 / Val_loss: 0.7565\n",
      "Epoch: 1396, Train_loss: 0.4581 / Val_loss: 0.8023\n",
      "Epoch: 1397, Train_loss: 0.4624 / Val_loss: 0.7317\n",
      "Epoch: 1398, Train_loss: 0.4818 / Val_loss: 0.7017\n",
      "Epoch: 1399, Train_loss: 0.4876 / Val_loss: 0.6929\n",
      "Epoch: 1400, Train_loss: 0.4666 / Val_loss: 0.7018\n",
      "Epoch: 1401, Train_loss: 0.4705 / Val_loss: 0.6879\n",
      "Epoch: 1402, Train_loss: 0.5004 / Val_loss: 0.7529\n",
      "Epoch: 1403, Train_loss: 0.4609 / Val_loss: 0.8142\n",
      "Epoch: 1404, Train_loss: 0.4750 / Val_loss: 0.8155\n",
      "Epoch: 1405, Train_loss: 0.4839 / Val_loss: 0.8755\n",
      "Epoch: 1406, Train_loss: 0.4788 / Val_loss: 0.8727\n",
      "Epoch: 1407, Train_loss: 0.4662 / Val_loss: 0.7858\n",
      "Epoch: 1408, Train_loss: 0.4640 / Val_loss: 0.8919\n",
      "Epoch: 1409, Train_loss: 0.4935 / Val_loss: 0.8089\n",
      "Epoch: 1410, Train_loss: 0.4624 / Val_loss: 0.8773\n",
      "Epoch: 1411, Train_loss: 0.4744 / Val_loss: 0.7693\n",
      "Epoch: 1412, Train_loss: 0.4727 / Val_loss: 0.8593\n",
      "Epoch: 1413, Train_loss: 0.4643 / Val_loss: 0.8257\n",
      "Epoch: 1414, Train_loss: 0.4948 / Val_loss: 0.8192\n",
      "Epoch: 1415, Train_loss: 0.4890 / Val_loss: 0.8626\n",
      "Epoch: 1416, Train_loss: 0.4776 / Val_loss: 0.7735\n",
      "Epoch: 1417, Train_loss: 0.4629 / Val_loss: 0.9152\n",
      "Epoch: 1418, Train_loss: 0.4490 / Val_loss: 0.6882\n",
      "Epoch: 1419, Train_loss: 0.4762 / Val_loss: 0.7089\n",
      "Epoch: 1420, Train_loss: 0.4949 / Val_loss: 0.8057\n",
      "Epoch: 1421, Train_loss: 0.4730 / Val_loss: 0.6851\n",
      "Epoch: 1422, Train_loss: 0.4635 / Val_loss: 0.6644\n",
      "Epoch: 1423, Train_loss: 0.4683 / Val_loss: 0.7148\n",
      "Epoch: 1424, Train_loss: 0.4555 / Val_loss: 0.7447\n",
      "Epoch: 1425, Train_loss: 0.4765 / Val_loss: 0.8655\n",
      "Epoch: 1426, Train_loss: 0.4855 / Val_loss: 0.9834\n",
      "Epoch: 1427, Train_loss: 0.4832 / Val_loss: 0.7911\n",
      "Epoch: 1428, Train_loss: 0.4912 / Val_loss: 0.7862\n",
      "Epoch: 1429, Train_loss: 0.4811 / Val_loss: 0.8407\n",
      "Epoch: 1430, Train_loss: 0.4782 / Val_loss: 0.7519\n",
      "Epoch: 1431, Train_loss: 0.4748 / Val_loss: 0.7712\n",
      "Epoch: 1432, Train_loss: 0.4836 / Val_loss: 0.8238\n",
      "Epoch: 1433, Train_loss: 0.4558 / Val_loss: 0.8579\n",
      "Epoch: 1434, Train_loss: 0.4861 / Val_loss: 0.6667\n",
      "Epoch: 1435, Train_loss: 0.4628 / Val_loss: 0.7490\n",
      "Epoch: 1436, Train_loss: 0.4757 / Val_loss: 0.7905\n",
      "Epoch: 1437, Train_loss: 0.4826 / Val_loss: 0.7487\n",
      "Epoch: 1438, Train_loss: 0.4794 / Val_loss: 0.7561\n",
      "Epoch: 1439, Train_loss: 0.4935 / Val_loss: 0.6655\n",
      "Epoch: 1440, Train_loss: 0.4614 / Val_loss: 0.9699\n",
      "Epoch: 1441, Train_loss: 0.4672 / Val_loss: 0.6606\n",
      "Epoch: 1442, Train_loss: 0.4618 / Val_loss: 0.6825\n",
      "Epoch: 1443, Train_loss: 0.4786 / Val_loss: 0.9948\n",
      "Epoch: 1444, Train_loss: 0.4562 / Val_loss: 0.7891\n",
      "Epoch: 1445, Train_loss: 0.4814 / Val_loss: 0.8186\n",
      "Epoch: 1446, Train_loss: 0.4579 / Val_loss: 0.8175\n",
      "Epoch: 1447, Train_loss: 0.4736 / Val_loss: 0.7115\n",
      "Epoch: 1448, Train_loss: 0.4659 / Val_loss: 0.7231\n",
      "Epoch: 1449, Train_loss: 0.4920 / Val_loss: 1.0172\n",
      "Epoch: 1450, Train_loss: 0.4714 / Val_loss: 0.8020\n",
      "Epoch: 1451, Train_loss: 0.4705 / Val_loss: 0.8645\n",
      "Epoch: 1452, Train_loss: 0.4762 / Val_loss: 0.9594\n",
      "Epoch: 1453, Train_loss: 0.4767 / Val_loss: 0.8035\n",
      "Epoch: 1454, Train_loss: 0.4691 / Val_loss: 0.8307\n",
      "Epoch: 1455, Train_loss: 0.4595 / Val_loss: 0.8318\n",
      "Epoch: 1456, Train_loss: 0.4519 / Val_loss: 0.7398\n",
      "Epoch: 1457, Train_loss: 0.4746 / Val_loss: 0.8515\n",
      "Epoch: 1458, Train_loss: 0.4734 / Val_loss: 0.7902\n",
      "Epoch: 1459, Train_loss: 0.5032 / Val_loss: 0.8482\n",
      "Epoch: 1460, Train_loss: 0.4914 / Val_loss: 0.7751\n",
      "Epoch: 1461, Train_loss: 0.4605 / Val_loss: 0.9764\n",
      "Epoch: 1462, Train_loss: 0.4831 / Val_loss: 0.7564\n",
      "Epoch: 1463, Train_loss: 0.4700 / Val_loss: 0.7044\n",
      "Epoch: 1464, Train_loss: 0.4744 / Val_loss: 0.6541\n",
      "Epoch: 1465, Train_loss: 0.4742 / Val_loss: 0.6413\n",
      "Epoch: 1466, Train_loss: 0.4646 / Val_loss: 0.6669\n",
      "Epoch: 1467, Train_loss: 0.4726 / Val_loss: 0.7970\n",
      "Epoch: 1468, Train_loss: 0.4919 / Val_loss: 0.7275\n",
      "Epoch: 1469, Train_loss: 0.4689 / Val_loss: 0.6685\n",
      "Epoch: 1470, Train_loss: 0.4663 / Val_loss: 0.9018\n",
      "Epoch: 1471, Train_loss: 0.4757 / Val_loss: 0.8046\n",
      "Epoch: 1472, Train_loss: 0.4666 / Val_loss: 0.6146\n",
      "Epoch: 1473, Train_loss: 0.4773 / Val_loss: 0.8513\n",
      "Epoch: 1474, Train_loss: 0.4744 / Val_loss: 0.9333\n",
      "Epoch: 1475, Train_loss: 0.4831 / Val_loss: 0.8600\n",
      "Epoch: 1476, Train_loss: 0.4615 / Val_loss: 0.7755\n",
      "Epoch: 1477, Train_loss: 0.4850 / Val_loss: 0.8455\n",
      "Epoch: 1478, Train_loss: 0.4656 / Val_loss: 0.7432\n",
      "Epoch: 1479, Train_loss: 0.4733 / Val_loss: 0.9287\n",
      "Epoch: 1480, Train_loss: 0.4639 / Val_loss: 0.9280\n",
      "Epoch: 1481, Train_loss: 0.4615 / Val_loss: 0.8333\n",
      "Epoch: 1482, Train_loss: 0.4826 / Val_loss: 0.7894\n",
      "Epoch: 1483, Train_loss: 0.4770 / Val_loss: 0.6380\n",
      "Epoch: 1484, Train_loss: 0.5225 / Val_loss: 0.6979\n",
      "Epoch: 1485, Train_loss: 0.4591 / Val_loss: 0.6803\n",
      "Epoch: 1486, Train_loss: 0.4786 / Val_loss: 0.6622\n",
      "Epoch: 1487, Train_loss: 0.4708 / Val_loss: 0.8152\n",
      "Epoch: 1488, Train_loss: 0.4628 / Val_loss: 0.7890\n",
      "Epoch: 1489, Train_loss: 0.4623 / Val_loss: 0.8462\n",
      "Epoch: 1490, Train_loss: 0.4890 / Val_loss: 0.7834\n",
      "Epoch: 1491, Train_loss: 0.4770 / Val_loss: 0.7765\n",
      "Epoch: 1492, Train_loss: 0.4682 / Val_loss: 0.7789\n",
      "Epoch: 1493, Train_loss: 0.4724 / Val_loss: 0.8612\n",
      "Epoch: 1494, Train_loss: 0.4718 / Val_loss: 0.9039\n",
      "Epoch: 1495, Train_loss: 0.4774 / Val_loss: 0.8083\n",
      "Epoch: 1496, Train_loss: 0.4613 / Val_loss: 0.7260\n",
      "Epoch: 1497, Train_loss: 0.4749 / Val_loss: 0.8076\n",
      "Epoch: 1498, Train_loss: 0.4755 / Val_loss: 0.7727\n",
      "Epoch: 1499, Train_loss: 0.4632 / Val_loss: 0.8934\n",
      "Epoch: 1500, Train_loss: 0.4667 / Val_loss: 0.8000\n",
      "Epoch: 1501, Train_loss: 0.4709 / Val_loss: 0.7876\n",
      "Epoch: 1502, Train_loss: 0.4558 / Val_loss: 0.6952\n",
      "Epoch: 1503, Train_loss: 0.4559 / Val_loss: 0.7489\n",
      "Epoch: 1504, Train_loss: 0.4748 / Val_loss: 0.7518\n",
      "Epoch: 1505, Train_loss: 0.4587 / Val_loss: 0.8317\n",
      "Epoch: 1506, Train_loss: 0.4596 / Val_loss: 0.8221\n",
      "Epoch: 1507, Train_loss: 0.4728 / Val_loss: 0.8333\n",
      "Epoch: 1508, Train_loss: 0.4956 / Val_loss: 0.7374\n",
      "Epoch: 1509, Train_loss: 0.4609 / Val_loss: 0.6686\n",
      "Epoch: 1510, Train_loss: 0.4639 / Val_loss: 0.7857\n",
      "Epoch: 1511, Train_loss: 0.4673 / Val_loss: 0.7204\n",
      "Epoch: 1512, Train_loss: 0.4613 / Val_loss: 0.8112\n",
      "Epoch: 1513, Train_loss: 0.4665 / Val_loss: 0.6020\n",
      "Epoch: 1514, Train_loss: 0.4624 / Val_loss: 0.7949\n",
      "Epoch: 1515, Train_loss: 0.4764 / Val_loss: 0.7339\n",
      "Epoch: 1516, Train_loss: 0.4698 / Val_loss: 0.7837\n",
      "Epoch: 1517, Train_loss: 0.4612 / Val_loss: 0.8841\n",
      "Epoch: 1518, Train_loss: 0.4734 / Val_loss: 0.6307\n",
      "Epoch: 1519, Train_loss: 0.4780 / Val_loss: 0.8303\n",
      "Epoch: 1520, Train_loss: 0.4646 / Val_loss: 0.8897\n",
      "Epoch: 1521, Train_loss: 0.4815 / Val_loss: 0.6117\n",
      "Epoch: 1522, Train_loss: 0.4784 / Val_loss: 0.8398\n",
      "Epoch: 1523, Train_loss: 0.4813 / Val_loss: 0.6351\n",
      "Epoch: 1524, Train_loss: 0.4683 / Val_loss: 0.8261\n",
      "Epoch: 1525, Train_loss: 0.4761 / Val_loss: 0.8571\n",
      "Epoch: 1526, Train_loss: 0.4559 / Val_loss: 0.8803\n",
      "Epoch: 1527, Train_loss: 0.4589 / Val_loss: 0.7654\n",
      "Epoch: 1528, Train_loss: 0.4443 / Val_loss: 0.8333\n",
      "Epoch: 1529, Train_loss: 0.4639 / Val_loss: 0.6728\n",
      "Epoch: 1530, Train_loss: 0.4951 / Val_loss: 0.9252\n",
      "Epoch: 1531, Train_loss: 0.4711 / Val_loss: 0.7798\n",
      "Epoch: 1532, Train_loss: 0.4808 / Val_loss: 0.8032\n",
      "Epoch: 1533, Train_loss: 0.4733 / Val_loss: 0.7326\n",
      "Epoch: 1534, Train_loss: 0.4601 / Val_loss: 0.7670\n",
      "Epoch: 1535, Train_loss: 0.4687 / Val_loss: 0.6935\n",
      "Epoch: 1536, Train_loss: 0.4683 / Val_loss: 0.7133\n",
      "Epoch: 1537, Train_loss: 0.5251 / Val_loss: 1.0609\n",
      "Epoch: 1538, Train_loss: 0.4670 / Val_loss: 0.9374\n",
      "Epoch: 1539, Train_loss: 0.4781 / Val_loss: 0.8124\n",
      "Epoch: 1540, Train_loss: 0.4489 / Val_loss: 0.6972\n",
      "Epoch: 1541, Train_loss: 0.4689 / Val_loss: 0.7540\n",
      "Epoch: 1542, Train_loss: 0.4742 / Val_loss: 0.8328\n",
      "Epoch: 1543, Train_loss: 0.4794 / Val_loss: 0.8937\n",
      "Epoch: 1544, Train_loss: 0.4468 / Val_loss: 0.8518\n",
      "Epoch: 1545, Train_loss: 0.4710 / Val_loss: 0.7140\n",
      "Epoch: 1546, Train_loss: 0.4524 / Val_loss: 0.6240\n",
      "Epoch: 1547, Train_loss: 0.4875 / Val_loss: 0.6560\n",
      "Epoch: 1548, Train_loss: 0.4803 / Val_loss: 0.7109\n",
      "Epoch: 1549, Train_loss: 0.4547 / Val_loss: 0.6325\n",
      "Epoch: 1550, Train_loss: 0.4502 / Val_loss: 0.8032\n",
      "Epoch: 1551, Train_loss: 0.4826 / Val_loss: 1.0212\n",
      "Epoch: 1552, Train_loss: 0.4647 / Val_loss: 0.8420\n",
      "Epoch: 1553, Train_loss: 0.4853 / Val_loss: 0.7824\n",
      "Epoch: 1554, Train_loss: 0.4563 / Val_loss: 0.7397\n",
      "Epoch: 1555, Train_loss: 0.4550 / Val_loss: 0.7730\n",
      "Epoch: 1556, Train_loss: 0.4835 / Val_loss: 0.7027\n",
      "Epoch: 1557, Train_loss: 0.4714 / Val_loss: 0.6988\n",
      "Epoch: 1558, Train_loss: 0.4696 / Val_loss: 0.9995\n",
      "Epoch: 1559, Train_loss: 0.4608 / Val_loss: 0.7618\n",
      "Epoch: 1560, Train_loss: 0.4554 / Val_loss: 0.8643\n",
      "Epoch: 1561, Train_loss: 0.4833 / Val_loss: 0.7812\n",
      "Epoch: 1562, Train_loss: 0.4754 / Val_loss: 0.8301\n",
      "Epoch: 1563, Train_loss: 0.4548 / Val_loss: 0.8894\n",
      "Epoch: 1564, Train_loss: 0.4650 / Val_loss: 0.7865\n",
      "Epoch: 1565, Train_loss: 0.4764 / Val_loss: 0.8679\n",
      "Epoch: 1566, Train_loss: 0.4665 / Val_loss: 0.7834\n",
      "Epoch: 1567, Train_loss: 0.4768 / Val_loss: 0.7781\n",
      "Epoch: 1568, Train_loss: 0.4569 / Val_loss: 0.9031\n",
      "Epoch: 1569, Train_loss: 0.4699 / Val_loss: 0.8594\n",
      "Epoch: 1570, Train_loss: 0.4701 / Val_loss: 0.9141\n",
      "Epoch: 1571, Train_loss: 0.4458 / Val_loss: 0.7063\n",
      "Epoch: 1572, Train_loss: 0.4522 / Val_loss: 0.7198\n",
      "Epoch: 1573, Train_loss: 0.4654 / Val_loss: 0.8131\n",
      "Epoch: 1574, Train_loss: 0.4659 / Val_loss: 0.6304\n",
      "Epoch: 1575, Train_loss: 0.4571 / Val_loss: 0.8083\n",
      "Epoch: 1576, Train_loss: 0.4610 / Val_loss: 0.7559\n",
      "Epoch: 1577, Train_loss: 0.4686 / Val_loss: 0.8336\n",
      "Epoch: 1578, Train_loss: 0.4741 / Val_loss: 0.7707\n",
      "Epoch: 1579, Train_loss: 0.4678 / Val_loss: 0.7943\n",
      "Epoch: 1580, Train_loss: 0.4645 / Val_loss: 0.8932\n",
      "Epoch: 1581, Train_loss: 0.4735 / Val_loss: 0.8060\n",
      "Epoch: 1582, Train_loss: 0.4569 / Val_loss: 1.0282\n",
      "Epoch: 1583, Train_loss: 0.4697 / Val_loss: 0.6389\n",
      "Epoch: 1584, Train_loss: 0.4601 / Val_loss: 0.6905\n",
      "Epoch: 1585, Train_loss: 0.4569 / Val_loss: 0.6592\n",
      "Epoch: 1586, Train_loss: 0.4719 / Val_loss: 0.6148\n",
      "Epoch: 1587, Train_loss: 0.4717 / Val_loss: 0.6610\n",
      "Epoch: 1588, Train_loss: 0.4520 / Val_loss: 0.7198\n",
      "Epoch: 1589, Train_loss: 0.4878 / Val_loss: 0.7608\n",
      "Epoch: 1590, Train_loss: 0.4890 / Val_loss: 0.7465\n",
      "Epoch: 1591, Train_loss: 0.4637 / Val_loss: 0.9896\n",
      "Epoch: 1592, Train_loss: 0.4731 / Val_loss: 0.8691\n",
      "Epoch: 1593, Train_loss: 0.4513 / Val_loss: 0.7416\n",
      "Epoch: 1594, Train_loss: 0.4320 / Val_loss: 0.7532\n",
      "Epoch: 1595, Train_loss: 0.4801 / Val_loss: 0.7181\n",
      "Epoch: 1596, Train_loss: 0.4721 / Val_loss: 0.7537\n",
      "Epoch: 1597, Train_loss: 0.4492 / Val_loss: 0.7748\n",
      "Epoch: 1598, Train_loss: 0.4778 / Val_loss: 0.7073\n",
      "Epoch: 1599, Train_loss: 0.4491 / Val_loss: 0.7672\n",
      "Epoch: 1600, Train_loss: 0.4640 / Val_loss: 0.7051\n",
      "Epoch: 1601, Train_loss: 0.4631 / Val_loss: 1.0753\n",
      "Epoch: 1602, Train_loss: 0.4546 / Val_loss: 0.8267\n",
      "Epoch: 1603, Train_loss: 0.4608 / Val_loss: 0.8570\n",
      "Epoch: 1604, Train_loss: 0.4683 / Val_loss: 0.7821\n",
      "Epoch: 1605, Train_loss: 0.4572 / Val_loss: 0.7767\n",
      "Epoch: 1606, Train_loss: 0.4604 / Val_loss: 0.8293\n",
      "Epoch: 1607, Train_loss: 0.4659 / Val_loss: 0.8964\n",
      "Epoch: 1608, Train_loss: 0.4734 / Val_loss: 0.8246\n",
      "Epoch: 1609, Train_loss: 0.4582 / Val_loss: 0.8632\n",
      "Epoch: 1610, Train_loss: 0.4630 / Val_loss: 0.8743\n",
      "Epoch: 1611, Train_loss: 0.4530 / Val_loss: 0.8604\n",
      "Epoch: 1612, Train_loss: 0.4763 / Val_loss: 0.6194\n",
      "Epoch: 1613, Train_loss: 0.4663 / Val_loss: 0.7671\n",
      "Epoch: 1614, Train_loss: 0.4427 / Val_loss: 0.8259\n",
      "Epoch: 1615, Train_loss: 0.4780 / Val_loss: 0.8116\n",
      "Epoch: 1616, Train_loss: 0.4512 / Val_loss: 0.7520\n",
      "Epoch: 1617, Train_loss: 0.4655 / Val_loss: 0.7808\n",
      "Epoch: 1618, Train_loss: 0.4786 / Val_loss: 0.7626\n",
      "Epoch: 1619, Train_loss: 0.4739 / Val_loss: 0.7503\n",
      "Epoch: 1620, Train_loss: 0.4503 / Val_loss: 0.6611\n",
      "Epoch: 1621, Train_loss: 0.4463 / Val_loss: 0.8458\n",
      "Epoch: 1622, Train_loss: 0.4344 / Val_loss: 0.7647\n",
      "Epoch: 1623, Train_loss: 0.4474 / Val_loss: 0.8081\n",
      "Epoch: 1624, Train_loss: 0.4606 / Val_loss: 0.7837\n",
      "Epoch: 1625, Train_loss: 0.4851 / Val_loss: 0.9108\n",
      "Epoch: 1626, Train_loss: 0.4582 / Val_loss: 0.9532\n",
      "Epoch: 1627, Train_loss: 0.4627 / Val_loss: 1.0330\n",
      "Epoch: 1628, Train_loss: 0.4551 / Val_loss: 0.7745\n",
      "Epoch: 1629, Train_loss: 0.4796 / Val_loss: 0.9880\n",
      "Epoch: 1630, Train_loss: 0.4618 / Val_loss: 0.9448\n",
      "Epoch: 1631, Train_loss: 0.4693 / Val_loss: 0.9280\n",
      "Epoch: 1632, Train_loss: 0.4536 / Val_loss: 0.7254\n",
      "Epoch: 1633, Train_loss: 0.4713 / Val_loss: 0.8190\n",
      "Epoch: 1634, Train_loss: 0.5047 / Val_loss: 0.9342\n",
      "Epoch: 1635, Train_loss: 0.4603 / Val_loss: 0.7272\n",
      "Epoch: 1636, Train_loss: 0.4646 / Val_loss: 0.7636\n",
      "Epoch: 1637, Train_loss: 0.4459 / Val_loss: 0.8649\n",
      "Epoch: 1638, Train_loss: 0.4710 / Val_loss: 0.7677\n",
      "Epoch: 1639, Train_loss: 0.4652 / Val_loss: 0.6667\n",
      "Epoch: 1640, Train_loss: 0.4447 / Val_loss: 0.6980\n",
      "Epoch: 1641, Train_loss: 0.4589 / Val_loss: 0.7498\n",
      "Epoch: 1642, Train_loss: 0.4660 / Val_loss: 0.8261\n",
      "Epoch: 1643, Train_loss: 0.4622 / Val_loss: 0.8822\n",
      "Epoch: 1644, Train_loss: 0.4567 / Val_loss: 0.6374\n",
      "Epoch: 1645, Train_loss: 0.4417 / Val_loss: 0.7455\n",
      "Epoch: 1646, Train_loss: 0.4808 / Val_loss: 0.7284\n",
      "Epoch: 1647, Train_loss: 0.4766 / Val_loss: 0.7705\n",
      "Epoch: 1648, Train_loss: 0.4518 / Val_loss: 0.7788\n",
      "Epoch: 1649, Train_loss: 0.4578 / Val_loss: 0.7796\n",
      "Epoch: 1650, Train_loss: 0.4641 / Val_loss: 0.7362\n",
      "Epoch: 1651, Train_loss: 0.4592 / Val_loss: 0.9689\n",
      "Epoch: 1652, Train_loss: 0.4837 / Val_loss: 0.8695\n",
      "Epoch: 1653, Train_loss: 0.4555 / Val_loss: 1.0509\n",
      "Epoch: 1654, Train_loss: 0.5092 / Val_loss: 0.9755\n",
      "Epoch: 1655, Train_loss: 0.4620 / Val_loss: 0.8494\n",
      "Epoch: 1656, Train_loss: 0.4589 / Val_loss: 0.7483\n",
      "Epoch: 1657, Train_loss: 0.4648 / Val_loss: 0.8099\n",
      "Epoch: 1658, Train_loss: 0.4562 / Val_loss: 0.8533\n",
      "Epoch: 1659, Train_loss: 0.4835 / Val_loss: 0.8030\n",
      "Epoch: 1660, Train_loss: 0.4616 / Val_loss: 0.8967\n",
      "Epoch: 1661, Train_loss: 0.4717 / Val_loss: 0.8209\n",
      "Epoch: 1662, Train_loss: 0.4596 / Val_loss: 0.7066\n",
      "Epoch: 1663, Train_loss: 0.4727 / Val_loss: 0.7828\n",
      "Epoch: 1664, Train_loss: 0.4740 / Val_loss: 0.8459\n",
      "Epoch: 1665, Train_loss: 0.4691 / Val_loss: 0.6934\n",
      "Epoch: 1666, Train_loss: 0.4792 / Val_loss: 0.8044\n",
      "Epoch: 1667, Train_loss: 0.4626 / Val_loss: 0.8576\n",
      "Epoch: 1668, Train_loss: 0.4684 / Val_loss: 0.8018\n",
      "Epoch: 1669, Train_loss: 0.4592 / Val_loss: 0.7202\n",
      "Epoch: 1670, Train_loss: 0.4647 / Val_loss: 1.0681\n",
      "Epoch: 1671, Train_loss: 0.4557 / Val_loss: 0.7944\n",
      "Epoch: 1672, Train_loss: 0.4677 / Val_loss: 0.7382\n",
      "Epoch: 1673, Train_loss: 0.4753 / Val_loss: 0.8954\n",
      "Epoch: 1674, Train_loss: 0.4569 / Val_loss: 0.7878\n",
      "Epoch: 1675, Train_loss: 0.4690 / Val_loss: 0.9523\n",
      "Epoch: 1676, Train_loss: 0.4563 / Val_loss: 0.7994\n",
      "Epoch: 1677, Train_loss: 0.4468 / Val_loss: 0.6711\n",
      "Epoch: 1678, Train_loss: 0.4549 / Val_loss: 0.6189\n",
      "Epoch: 1679, Train_loss: 0.4564 / Val_loss: 0.6666\n",
      "Epoch: 1680, Train_loss: 0.4704 / Val_loss: 0.9401\n",
      "Epoch: 1681, Train_loss: 0.4792 / Val_loss: 0.8383\n",
      "Epoch: 1682, Train_loss: 0.4688 / Val_loss: 0.6941\n",
      "Epoch: 1683, Train_loss: 0.4745 / Val_loss: 0.6625\n",
      "Epoch: 1684, Train_loss: 0.4619 / Val_loss: 0.7437\n",
      "Epoch: 1685, Train_loss: 0.4650 / Val_loss: 0.8051\n",
      "Epoch: 1686, Train_loss: 0.4639 / Val_loss: 0.6490\n",
      "Epoch: 1687, Train_loss: 0.4720 / Val_loss: 0.7313\n",
      "Epoch: 1688, Train_loss: 0.4737 / Val_loss: 0.7055\n",
      "Epoch: 1689, Train_loss: 0.4626 / Val_loss: 0.7300\n",
      "Epoch: 1690, Train_loss: 0.4630 / Val_loss: 0.8272\n",
      "Epoch: 1691, Train_loss: 0.4653 / Val_loss: 1.0841\n",
      "Epoch: 1692, Train_loss: 0.4486 / Val_loss: 0.9357\n",
      "Epoch: 1693, Train_loss: 0.4538 / Val_loss: 0.8466\n",
      "Epoch: 1694, Train_loss: 0.4665 / Val_loss: 0.9108\n",
      "Epoch: 1695, Train_loss: 0.4748 / Val_loss: 0.8499\n",
      "Epoch: 1696, Train_loss: 0.4619 / Val_loss: 0.7788\n",
      "Epoch: 1697, Train_loss: 0.4462 / Val_loss: 0.8141\n",
      "Epoch: 1698, Train_loss: 0.4509 / Val_loss: 0.9446\n",
      "Epoch: 1699, Train_loss: 0.4643 / Val_loss: 0.7626\n",
      "Epoch: 1700, Train_loss: 0.4746 / Val_loss: 0.7312\n",
      "Epoch: 1701, Train_loss: 0.4629 / Val_loss: 0.7896\n",
      "Epoch: 1702, Train_loss: 0.4524 / Val_loss: 0.7499\n",
      "Epoch: 1703, Train_loss: 0.4429 / Val_loss: 0.9183\n",
      "Epoch: 1704, Train_loss: 0.4614 / Val_loss: 0.6140\n",
      "Epoch: 1705, Train_loss: 0.4584 / Val_loss: 0.8994\n",
      "Epoch: 1706, Train_loss: 0.4429 / Val_loss: 0.7063\n",
      "Epoch: 1707, Train_loss: 0.4659 / Val_loss: 0.8583\n",
      "Epoch: 1708, Train_loss: 0.4588 / Val_loss: 0.9077\n",
      "Epoch: 1709, Train_loss: 0.4638 / Val_loss: 0.7616\n",
      "Epoch: 1710, Train_loss: 0.4610 / Val_loss: 0.8555\n",
      "Epoch: 1711, Train_loss: 0.4577 / Val_loss: 0.8196\n",
      "Epoch: 1712, Train_loss: 0.4614 / Val_loss: 0.7144\n",
      "Epoch: 1713, Train_loss: 0.4324 / Val_loss: 0.9201\n",
      "Epoch: 1714, Train_loss: 0.4524 / Val_loss: 0.7489\n",
      "Epoch: 1715, Train_loss: 0.4646 / Val_loss: 0.6912\n",
      "Epoch: 1716, Train_loss: 0.4669 / Val_loss: 0.9360\n",
      "Epoch: 1717, Train_loss: 0.4408 / Val_loss: 0.8788\n",
      "Epoch: 1718, Train_loss: 0.4543 / Val_loss: 0.9182\n",
      "Epoch: 1719, Train_loss: 0.4536 / Val_loss: 0.8422\n",
      "Epoch: 1720, Train_loss: 0.4632 / Val_loss: 0.7132\n",
      "Epoch: 1721, Train_loss: 0.4529 / Val_loss: 0.7789\n",
      "Epoch: 1722, Train_loss: 0.4636 / Val_loss: 0.8517\n",
      "Epoch: 1723, Train_loss: 0.4601 / Val_loss: 0.8978\n",
      "Epoch: 1724, Train_loss: 0.4735 / Val_loss: 0.7324\n",
      "Epoch: 1725, Train_loss: 0.4557 / Val_loss: 0.7418\n",
      "Epoch: 1726, Train_loss: 0.4517 / Val_loss: 0.7016\n",
      "Epoch: 1727, Train_loss: 0.4786 / Val_loss: 0.7648\n",
      "Epoch: 1728, Train_loss: 0.4577 / Val_loss: 0.7149\n",
      "Epoch: 1729, Train_loss: 0.4456 / Val_loss: 0.7518\n",
      "Epoch: 1730, Train_loss: 0.4507 / Val_loss: 0.7687\n",
      "Epoch: 1731, Train_loss: 0.4738 / Val_loss: 0.8106\n",
      "Epoch: 1732, Train_loss: 0.4780 / Val_loss: 0.7863\n",
      "Epoch: 1733, Train_loss: 0.4479 / Val_loss: 0.9625\n",
      "Epoch: 1734, Train_loss: 0.4625 / Val_loss: 0.7426\n",
      "Epoch: 1735, Train_loss: 0.4724 / Val_loss: 0.8628\n",
      "Epoch: 1736, Train_loss: 0.4741 / Val_loss: 0.8484\n",
      "Epoch: 1737, Train_loss: 0.4509 / Val_loss: 0.9201\n",
      "Epoch: 1738, Train_loss: 0.4756 / Val_loss: 0.7315\n",
      "Epoch: 1739, Train_loss: 0.4600 / Val_loss: 0.8919\n",
      "Epoch: 1740, Train_loss: 0.4571 / Val_loss: 0.9897\n",
      "Epoch: 1741, Train_loss: 0.4671 / Val_loss: 0.7457\n",
      "Epoch: 1742, Train_loss: 0.4555 / Val_loss: 0.7254\n",
      "Epoch: 1743, Train_loss: 0.4486 / Val_loss: 0.8076\n",
      "Epoch: 1744, Train_loss: 0.4731 / Val_loss: 0.8679\n",
      "Epoch: 1745, Train_loss: 0.4907 / Val_loss: 1.0997\n",
      "Epoch: 1746, Train_loss: 0.4556 / Val_loss: 0.8784\n",
      "Epoch: 1747, Train_loss: 0.4523 / Val_loss: 0.7684\n",
      "Epoch: 1748, Train_loss: 0.4518 / Val_loss: 0.6585\n",
      "Epoch: 1749, Train_loss: 0.4388 / Val_loss: 0.8491\n",
      "Epoch: 1750, Train_loss: 0.4826 / Val_loss: 0.8611\n",
      "Epoch: 1751, Train_loss: 0.4762 / Val_loss: 0.7742\n",
      "Epoch: 1752, Train_loss: 0.4671 / Val_loss: 0.8667\n",
      "Epoch: 1753, Train_loss: 0.4508 / Val_loss: 0.8975\n",
      "Epoch: 1754, Train_loss: 0.4629 / Val_loss: 0.7452\n",
      "Epoch: 1755, Train_loss: 0.4576 / Val_loss: 0.8102\n",
      "Epoch: 1756, Train_loss: 0.4659 / Val_loss: 0.8102\n",
      "Epoch: 1757, Train_loss: 0.4737 / Val_loss: 0.7297\n",
      "Epoch: 1758, Train_loss: 0.4609 / Val_loss: 0.8107\n",
      "Epoch: 1759, Train_loss: 0.4558 / Val_loss: 0.6902\n",
      "Epoch: 1760, Train_loss: 0.4432 / Val_loss: 0.6964\n",
      "Epoch: 1761, Train_loss: 0.4640 / Val_loss: 0.7207\n",
      "Epoch: 1762, Train_loss: 0.4377 / Val_loss: 0.8755\n",
      "Epoch: 1763, Train_loss: 0.4588 / Val_loss: 0.8140\n",
      "Epoch: 1764, Train_loss: 0.4609 / Val_loss: 0.8896\n",
      "Epoch: 1765, Train_loss: 0.4538 / Val_loss: 0.7333\n",
      "Epoch: 1766, Train_loss: 0.4352 / Val_loss: 0.7119\n",
      "Epoch: 1767, Train_loss: 0.4402 / Val_loss: 0.8020\n",
      "Epoch: 1768, Train_loss: 0.4517 / Val_loss: 0.7624\n",
      "Epoch: 1769, Train_loss: 0.4549 / Val_loss: 1.0351\n",
      "Epoch: 1770, Train_loss: 0.4667 / Val_loss: 0.7565\n",
      "Epoch: 1771, Train_loss: 0.4481 / Val_loss: 0.7149\n",
      "Epoch: 1772, Train_loss: 0.4773 / Val_loss: 0.6877\n",
      "Epoch: 1773, Train_loss: 0.4516 / Val_loss: 0.8991\n",
      "Epoch: 1774, Train_loss: 0.4538 / Val_loss: 0.7687\n",
      "Epoch: 1775, Train_loss: 0.4374 / Val_loss: 0.8519\n",
      "Epoch: 1776, Train_loss: 0.4283 / Val_loss: 0.8242\n",
      "Epoch: 1777, Train_loss: 0.4806 / Val_loss: 0.8619\n",
      "Epoch: 1778, Train_loss: 0.4878 / Val_loss: 0.9397\n",
      "Epoch: 1779, Train_loss: 0.4568 / Val_loss: 0.8834\n",
      "Epoch: 1780, Train_loss: 0.4540 / Val_loss: 0.7201\n",
      "Epoch: 1781, Train_loss: 0.4549 / Val_loss: 0.7895\n",
      "Epoch: 1782, Train_loss: 0.4345 / Val_loss: 0.7100\n",
      "Epoch: 1783, Train_loss: 0.4457 / Val_loss: 0.7650\n",
      "Epoch: 1784, Train_loss: 0.4488 / Val_loss: 0.7999\n",
      "Epoch: 1785, Train_loss: 0.4434 / Val_loss: 0.8326\n",
      "Epoch: 1786, Train_loss: 0.4414 / Val_loss: 0.7336\n",
      "Epoch: 1787, Train_loss: 0.4519 / Val_loss: 0.7302\n",
      "Epoch: 1788, Train_loss: 0.4477 / Val_loss: 0.7344\n",
      "Epoch: 1789, Train_loss: 0.4568 / Val_loss: 0.8550\n",
      "Epoch: 1790, Train_loss: 0.4503 / Val_loss: 0.9163\n",
      "Epoch: 1791, Train_loss: 0.4369 / Val_loss: 0.7765\n",
      "Epoch: 1792, Train_loss: 0.4493 / Val_loss: 0.8269\n",
      "Epoch: 1793, Train_loss: 0.4397 / Val_loss: 0.8298\n",
      "Epoch: 1794, Train_loss: 0.4447 / Val_loss: 0.8805\n",
      "Epoch: 1795, Train_loss: 0.4656 / Val_loss: 0.9544\n",
      "Epoch: 1796, Train_loss: 0.4408 / Val_loss: 0.7212\n",
      "Epoch: 1797, Train_loss: 0.4555 / Val_loss: 0.8950\n",
      "Epoch: 1798, Train_loss: 0.4616 / Val_loss: 0.8988\n",
      "Epoch: 1799, Train_loss: 0.4586 / Val_loss: 0.7090\n",
      "Epoch: 1800, Train_loss: 0.4346 / Val_loss: 0.9407\n",
      "Epoch: 1801, Train_loss: 0.4643 / Val_loss: 0.7791\n",
      "Epoch: 1802, Train_loss: 0.4696 / Val_loss: 0.8586\n",
      "Epoch: 1803, Train_loss: 0.4512 / Val_loss: 0.7086\n",
      "Epoch: 1804, Train_loss: 0.4606 / Val_loss: 0.8919\n",
      "Epoch: 1805, Train_loss: 0.4539 / Val_loss: 0.9445\n",
      "Epoch: 1806, Train_loss: 0.4365 / Val_loss: 0.7671\n",
      "Epoch: 1807, Train_loss: 0.4655 / Val_loss: 0.8954\n",
      "Epoch: 1808, Train_loss: 0.4329 / Val_loss: 0.7721\n",
      "Epoch: 1809, Train_loss: 0.4657 / Val_loss: 0.9033\n",
      "Epoch: 1810, Train_loss: 0.4404 / Val_loss: 0.7915\n",
      "Epoch: 1811, Train_loss: 0.4446 / Val_loss: 0.7742\n",
      "Epoch: 1812, Train_loss: 0.4601 / Val_loss: 1.0173\n",
      "Epoch: 1813, Train_loss: 0.4798 / Val_loss: 0.7421\n",
      "Epoch: 1814, Train_loss: 0.4585 / Val_loss: 0.9061\n",
      "Epoch: 1815, Train_loss: 0.4639 / Val_loss: 0.7984\n",
      "Epoch: 1816, Train_loss: 0.4612 / Val_loss: 0.7793\n",
      "Epoch: 1817, Train_loss: 0.4441 / Val_loss: 0.7687\n",
      "Epoch: 1818, Train_loss: 0.4656 / Val_loss: 0.5995\n",
      "Epoch: 1819, Train_loss: 0.4584 / Val_loss: 0.8256\n",
      "Epoch: 1820, Train_loss: 0.4777 / Val_loss: 0.8860\n",
      "Epoch: 1821, Train_loss: 0.4728 / Val_loss: 0.7503\n",
      "Epoch: 1822, Train_loss: 0.4507 / Val_loss: 1.0068\n",
      "Epoch: 1823, Train_loss: 0.4463 / Val_loss: 0.7239\n",
      "Epoch: 1824, Train_loss: 0.4605 / Val_loss: 1.0957\n",
      "Epoch: 1825, Train_loss: 0.4575 / Val_loss: 0.9732\n",
      "Epoch: 1826, Train_loss: 0.4677 / Val_loss: 0.9706\n",
      "Epoch: 1827, Train_loss: 0.4378 / Val_loss: 0.8949\n",
      "Epoch: 1828, Train_loss: 0.4716 / Val_loss: 1.0211\n",
      "Epoch: 1829, Train_loss: 0.4701 / Val_loss: 0.8205\n",
      "Epoch: 1830, Train_loss: 0.4511 / Val_loss: 0.7521\n",
      "Epoch: 1831, Train_loss: 0.4807 / Val_loss: 0.7954\n",
      "Epoch: 1832, Train_loss: 0.4532 / Val_loss: 0.8202\n",
      "Epoch: 1833, Train_loss: 0.4370 / Val_loss: 0.8992\n",
      "Epoch: 1834, Train_loss: 0.4352 / Val_loss: 0.8638\n",
      "Epoch: 1835, Train_loss: 0.4443 / Val_loss: 0.7528\n",
      "Epoch: 1836, Train_loss: 0.4751 / Val_loss: 0.8249\n",
      "Epoch: 1837, Train_loss: 0.4644 / Val_loss: 0.8028\n",
      "Epoch: 1838, Train_loss: 0.4279 / Val_loss: 0.7706\n",
      "Epoch: 1839, Train_loss: 0.4375 / Val_loss: 0.7881\n",
      "Epoch: 1840, Train_loss: 0.4735 / Val_loss: 0.7692\n",
      "Epoch: 1841, Train_loss: 0.4535 / Val_loss: 0.6862\n",
      "Epoch: 1842, Train_loss: 0.4628 / Val_loss: 0.7575\n",
      "Epoch: 1843, Train_loss: 0.4489 / Val_loss: 0.9023\n",
      "Epoch: 1844, Train_loss: 0.4594 / Val_loss: 0.8794\n",
      "Epoch: 1845, Train_loss: 0.4661 / Val_loss: 0.8778\n",
      "Epoch: 1846, Train_loss: 0.4589 / Val_loss: 0.9584\n",
      "Epoch: 1847, Train_loss: 0.4434 / Val_loss: 0.8742\n",
      "Epoch: 1848, Train_loss: 0.4796 / Val_loss: 0.7082\n",
      "Epoch: 1849, Train_loss: 0.4395 / Val_loss: 0.8336\n",
      "Epoch: 1850, Train_loss: 0.4397 / Val_loss: 0.7880\n",
      "Epoch: 1851, Train_loss: 0.4614 / Val_loss: 0.8682\n",
      "Epoch: 1852, Train_loss: 0.4496 / Val_loss: 0.7872\n",
      "Epoch: 1853, Train_loss: 0.4560 / Val_loss: 0.8448\n",
      "Epoch: 1854, Train_loss: 0.4749 / Val_loss: 0.8104\n",
      "Epoch: 1855, Train_loss: 0.4447 / Val_loss: 0.8851\n",
      "Epoch: 1856, Train_loss: 0.4691 / Val_loss: 0.7522\n",
      "Epoch: 1857, Train_loss: 0.4596 / Val_loss: 0.7147\n",
      "Epoch: 1858, Train_loss: 0.4519 / Val_loss: 0.8304\n",
      "Epoch: 1859, Train_loss: 0.4511 / Val_loss: 0.8526\n",
      "Epoch: 1860, Train_loss: 0.4613 / Val_loss: 0.7577\n",
      "Epoch: 1861, Train_loss: 0.4860 / Val_loss: 1.0154\n",
      "Epoch: 1862, Train_loss: 0.4484 / Val_loss: 0.8775\n",
      "Epoch: 1863, Train_loss: 0.4720 / Val_loss: 0.9005\n",
      "Epoch: 1864, Train_loss: 0.4468 / Val_loss: 0.7882\n",
      "Epoch: 1865, Train_loss: 0.4490 / Val_loss: 0.8792\n",
      "Epoch: 1866, Train_loss: 0.4518 / Val_loss: 0.8548\n",
      "Epoch: 1867, Train_loss: 0.4552 / Val_loss: 0.7757\n",
      "Epoch: 1868, Train_loss: 0.4560 / Val_loss: 0.8922\n",
      "Epoch: 1869, Train_loss: 0.4437 / Val_loss: 1.0213\n",
      "Epoch: 1870, Train_loss: 0.4479 / Val_loss: 0.6978\n",
      "Epoch: 1871, Train_loss: 0.4432 / Val_loss: 0.7691\n",
      "Epoch: 1872, Train_loss: 0.4271 / Val_loss: 0.8266\n",
      "Epoch: 1873, Train_loss: 0.4675 / Val_loss: 0.7893\n",
      "Epoch: 1874, Train_loss: 0.4429 / Val_loss: 0.7135\n",
      "Epoch: 1875, Train_loss: 0.4545 / Val_loss: 0.8613\n",
      "Epoch: 1876, Train_loss: 0.4484 / Val_loss: 0.8164\n",
      "Epoch: 1877, Train_loss: 0.4626 / Val_loss: 0.7973\n",
      "Epoch: 1878, Train_loss: 0.4520 / Val_loss: 0.7254\n",
      "Epoch: 1879, Train_loss: 0.4489 / Val_loss: 0.9702\n",
      "Epoch: 1880, Train_loss: 0.4467 / Val_loss: 0.8095\n",
      "Epoch: 1881, Train_loss: 0.4326 / Val_loss: 0.8059\n",
      "Epoch: 1882, Train_loss: 0.4463 / Val_loss: 0.8016\n",
      "Epoch: 1883, Train_loss: 0.4407 / Val_loss: 0.9755\n",
      "Epoch: 1884, Train_loss: 0.4585 / Val_loss: 0.8870\n",
      "Epoch: 1885, Train_loss: 0.4587 / Val_loss: 0.8626\n",
      "Epoch: 1886, Train_loss: 0.4797 / Val_loss: 0.6893\n",
      "Epoch: 1887, Train_loss: 0.4671 / Val_loss: 0.9642\n",
      "Epoch: 1888, Train_loss: 0.4416 / Val_loss: 0.9757\n",
      "Epoch: 1889, Train_loss: 0.4358 / Val_loss: 0.8619\n",
      "Epoch: 1890, Train_loss: 0.4428 / Val_loss: 0.8145\n",
      "Epoch: 1891, Train_loss: 0.4511 / Val_loss: 0.8793\n",
      "Epoch: 1892, Train_loss: 0.4437 / Val_loss: 0.8016\n",
      "Epoch: 1893, Train_loss: 0.4399 / Val_loss: 0.7852\n",
      "Epoch: 1894, Train_loss: 0.4570 / Val_loss: 0.9602\n",
      "Epoch: 1895, Train_loss: 0.4639 / Val_loss: 0.8121\n",
      "Epoch: 1896, Train_loss: 0.4617 / Val_loss: 0.7752\n",
      "Epoch: 1897, Train_loss: 0.4342 / Val_loss: 0.8608\n",
      "Epoch: 1898, Train_loss: 0.4563 / Val_loss: 0.7048\n",
      "Epoch: 1899, Train_loss: 0.4619 / Val_loss: 0.9859\n",
      "Epoch: 1900, Train_loss: 0.4422 / Val_loss: 0.8239\n",
      "Epoch: 1901, Train_loss: 0.4763 / Val_loss: 0.8197\n",
      "Epoch: 1902, Train_loss: 0.4469 / Val_loss: 0.8257\n",
      "Epoch: 1903, Train_loss: 0.4568 / Val_loss: 0.8581\n",
      "Epoch: 1904, Train_loss: 0.4498 / Val_loss: 0.8514\n",
      "Epoch: 1905, Train_loss: 0.4584 / Val_loss: 0.8076\n",
      "Epoch: 1906, Train_loss: 0.4843 / Val_loss: 0.9229\n",
      "Epoch: 1907, Train_loss: 0.4557 / Val_loss: 0.8608\n",
      "Epoch: 1908, Train_loss: 0.4513 / Val_loss: 0.7905\n",
      "Epoch: 1909, Train_loss: 0.4755 / Val_loss: 0.9046\n",
      "Epoch: 1910, Train_loss: 0.4471 / Val_loss: 0.8242\n",
      "Epoch: 1911, Train_loss: 0.4554 / Val_loss: 0.8306\n",
      "Epoch: 1912, Train_loss: 0.4596 / Val_loss: 0.8708\n",
      "Epoch: 1913, Train_loss: 0.4616 / Val_loss: 0.9294\n",
      "Epoch: 1914, Train_loss: 0.4540 / Val_loss: 0.8688\n",
      "Epoch: 1915, Train_loss: 0.4427 / Val_loss: 0.9800\n",
      "Epoch: 1916, Train_loss: 0.4427 / Val_loss: 0.7657\n",
      "Epoch: 1917, Train_loss: 0.4545 / Val_loss: 0.6438\n",
      "Epoch: 1918, Train_loss: 0.4521 / Val_loss: 1.0679\n",
      "Epoch: 1919, Train_loss: 0.4473 / Val_loss: 0.7965\n",
      "Epoch: 1920, Train_loss: 0.4663 / Val_loss: 0.8498\n",
      "Epoch: 1921, Train_loss: 0.4428 / Val_loss: 0.8478\n",
      "Epoch: 1922, Train_loss: 0.4677 / Val_loss: 0.8390\n",
      "Epoch: 1923, Train_loss: 0.4657 / Val_loss: 0.8095\n",
      "Epoch: 1924, Train_loss: 0.4373 / Val_loss: 1.0607\n",
      "Epoch: 1925, Train_loss: 0.4459 / Val_loss: 0.8888\n",
      "Epoch: 1926, Train_loss: 0.4402 / Val_loss: 0.8066\n",
      "Epoch: 1927, Train_loss: 0.4601 / Val_loss: 1.1160\n",
      "Epoch: 1928, Train_loss: 0.4567 / Val_loss: 0.8073\n",
      "Epoch: 1929, Train_loss: 0.4457 / Val_loss: 0.9224\n",
      "Epoch: 1930, Train_loss: 0.4419 / Val_loss: 0.7621\n",
      "Epoch: 1931, Train_loss: 0.4567 / Val_loss: 0.8796\n",
      "Epoch: 1932, Train_loss: 0.4505 / Val_loss: 0.7027\n",
      "Epoch: 1933, Train_loss: 0.4696 / Val_loss: 0.9921\n",
      "Epoch: 1934, Train_loss: 0.4521 / Val_loss: 0.8011\n",
      "Epoch: 1935, Train_loss: 0.4510 / Val_loss: 0.7127\n",
      "Epoch: 1936, Train_loss: 0.4748 / Val_loss: 0.8141\n",
      "Epoch: 1937, Train_loss: 0.4419 / Val_loss: 0.8571\n",
      "Epoch: 1938, Train_loss: 0.4449 / Val_loss: 0.7069\n",
      "Epoch: 1939, Train_loss: 0.4447 / Val_loss: 0.8401\n",
      "Epoch: 1940, Train_loss: 0.4431 / Val_loss: 0.8031\n",
      "Epoch: 1941, Train_loss: 0.4534 / Val_loss: 0.8136\n",
      "Epoch: 1942, Train_loss: 0.4553 / Val_loss: 0.8831\n",
      "Epoch: 1943, Train_loss: 0.4803 / Val_loss: 1.0163\n",
      "Epoch: 1944, Train_loss: 0.4628 / Val_loss: 0.7759\n",
      "Epoch: 1945, Train_loss: 0.4485 / Val_loss: 0.9044\n",
      "Epoch: 1946, Train_loss: 0.4483 / Val_loss: 0.9166\n",
      "Epoch: 1947, Train_loss: 0.4477 / Val_loss: 0.9337\n",
      "Epoch: 1948, Train_loss: 0.4429 / Val_loss: 0.9549\n",
      "Epoch: 1949, Train_loss: 0.4454 / Val_loss: 0.9002\n",
      "Epoch: 1950, Train_loss: 0.4644 / Val_loss: 0.9436\n",
      "Epoch: 1951, Train_loss: 0.4575 / Val_loss: 0.7244\n",
      "Epoch: 1952, Train_loss: 0.4591 / Val_loss: 0.8588\n",
      "Epoch: 1953, Train_loss: 0.4515 / Val_loss: 0.6967\n",
      "Epoch: 1954, Train_loss: 0.4669 / Val_loss: 0.7381\n",
      "Epoch: 1955, Train_loss: 0.4525 / Val_loss: 0.8226\n",
      "Epoch: 1956, Train_loss: 0.4457 / Val_loss: 0.8599\n",
      "Epoch: 1957, Train_loss: 0.4642 / Val_loss: 0.9145\n",
      "Epoch: 1958, Train_loss: 0.4422 / Val_loss: 1.0026\n",
      "Epoch: 1959, Train_loss: 0.4488 / Val_loss: 0.7932\n",
      "Epoch: 1960, Train_loss: 0.4581 / Val_loss: 0.9001\n",
      "Epoch: 1961, Train_loss: 0.4533 / Val_loss: 0.8381\n",
      "Epoch: 1962, Train_loss: 0.4765 / Val_loss: 0.8994\n",
      "Epoch: 1963, Train_loss: 0.4417 / Val_loss: 0.8159\n",
      "Epoch: 1964, Train_loss: 0.4498 / Val_loss: 0.6958\n",
      "Epoch: 1965, Train_loss: 0.4437 / Val_loss: 0.7766\n",
      "Epoch: 1966, Train_loss: 0.4895 / Val_loss: 0.7566\n",
      "Epoch: 1967, Train_loss: 0.4163 / Val_loss: 0.8294\n",
      "Epoch: 1968, Train_loss: 0.4692 / Val_loss: 0.7167\n",
      "Epoch: 1969, Train_loss: 0.4421 / Val_loss: 0.7550\n",
      "Epoch: 1970, Train_loss: 0.4468 / Val_loss: 0.7759\n",
      "Epoch: 1971, Train_loss: 0.4506 / Val_loss: 0.7989\n",
      "Epoch: 1972, Train_loss: 0.4677 / Val_loss: 0.7834\n",
      "Epoch: 1973, Train_loss: 0.4438 / Val_loss: 1.0873\n",
      "Epoch: 1974, Train_loss: 0.4670 / Val_loss: 0.8553\n",
      "Epoch: 1975, Train_loss: 0.4353 / Val_loss: 0.8498\n",
      "Epoch: 1976, Train_loss: 0.4604 / Val_loss: 0.8787\n",
      "Epoch: 1977, Train_loss: 0.4716 / Val_loss: 0.8216\n",
      "Epoch: 1978, Train_loss: 0.4630 / Val_loss: 0.7959\n",
      "Epoch: 1979, Train_loss: 0.4371 / Val_loss: 0.7713\n",
      "Epoch: 1980, Train_loss: 0.4426 / Val_loss: 0.6824\n",
      "Epoch: 1981, Train_loss: 0.4637 / Val_loss: 0.9031\n",
      "Epoch: 1982, Train_loss: 0.4410 / Val_loss: 0.7241\n",
      "Epoch: 1983, Train_loss: 0.4470 / Val_loss: 0.7607\n",
      "Epoch: 1984, Train_loss: 0.4642 / Val_loss: 0.7304\n",
      "Epoch: 1985, Train_loss: 0.4644 / Val_loss: 0.8863\n",
      "Epoch: 1986, Train_loss: 0.4488 / Val_loss: 0.7383\n",
      "Epoch: 1987, Train_loss: 0.4354 / Val_loss: 0.8660\n",
      "Epoch: 1988, Train_loss: 0.4605 / Val_loss: 1.0097\n",
      "Epoch: 1989, Train_loss: 0.4473 / Val_loss: 0.8408\n",
      "Epoch: 1990, Train_loss: 0.4458 / Val_loss: 0.7641\n",
      "Epoch: 1991, Train_loss: 0.4482 / Val_loss: 0.9106\n",
      "Epoch: 1992, Train_loss: 0.4426 / Val_loss: 0.7828\n",
      "Epoch: 1993, Train_loss: 0.4413 / Val_loss: 0.9962\n",
      "Epoch: 1994, Train_loss: 0.4418 / Val_loss: 0.7351\n",
      "Epoch: 1995, Train_loss: 0.4487 / Val_loss: 0.8289\n",
      "Epoch: 1996, Train_loss: 0.4756 / Val_loss: 0.8219\n",
      "Epoch: 1997, Train_loss: 0.4567 / Val_loss: 0.8069\n",
      "Epoch: 1998, Train_loss: 0.4351 / Val_loss: 0.7563\n",
      "Epoch: 1999, Train_loss: 0.4487 / Val_loss: 0.8144\n",
      "Epoch: 2000, Train_loss: 0.4543 / Val_loss: 0.9260\n"
     ]
    }
   ],
   "source": [
    "weight = torch.Tensor([1.0, 2.5])\n",
    "log_softmax = torch.nn.LogSoftmax(dim=1)\n",
    "criterion = torch.nn.NLLLoss(weight=weight)  # Define loss criterion.\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)  # Define optimizer.\n",
    "\n",
    "losses = []\n",
    "v_losses = []\n",
    "best_v_loss = 100000\n",
    "COUNT = 2000\n",
    "val_early_stop_count = COUNT\n",
    "val_early_stop_continuous_flag = False\n",
    "\n",
    "for epoch in range(1, 2001):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    outs = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "    preds = outs[data.train_mask].squeeze()\n",
    "    loss = criterion(log_softmax(preds), data.y[data.train_mask].to(dtype=torch.long))  # Compute the loss solely based on the training nodes.\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        v_preds = outs[data.val_mask].squeeze()\n",
    "        v_loss = criterion(log_softmax(v_preds), data.y[data.val_mask].to(dtype=torch.long))\n",
    "        v_losses.append(v_loss.item())\n",
    "    print(f'Epoch: {epoch:03d}, Train_loss: {loss:.4f} / Val_loss: {v_loss:.4f}')\n",
    "    \n",
    "    if v_loss.item() < best_v_loss:\n",
    "        best_v_loss = v_loss.item()\n",
    "        val_early_stop_continuous_flag = False\n",
    "        val_early_stop_count = COUNT\n",
    "    else:\n",
    "        val_early_stop_continuous_flag = True\n",
    "        val_early_stop_count -= 1\n",
    "        if val_early_stop_count == 0:\n",
    "            print(f\"============== Early stopped at Epoch: {epoch}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAkFdJREFUeJztnQec0+Qbx3+94zg49t577ynIUEBABAeg/sUJoqKguBAHDkAcqCjiQEEFwQ0i4GAJyN57yZC99z7gZv+fJ7320jZJkzRp0vT53qefXpv1ZjTvL8/7DJfb7XaDYRiGYRjGIcRZ3QCGYRiGYRgjYXHDMAzDMIyjYHHDMAzDMIyjYHHDMAzDMIyjYHHDMAzDMIyjYHHDMAzDMIyjYHHDMAzDMIyjyIEYIzMzE0ePHkW+fPngcrmsbg7DMAzDMCqgtHyXLl1C6dKlERenbJuJOXFDwqZcuXJWN4NhGIZhGB0cOnQIZcuWVZwn5sQNWWy8Byd//vxWN4dhGIZhGBVcvHhRME54+3ElYk7ceIeiSNiwuGEYhmGY6EKNSwk7FDMMwzAM4yhY3DAMwzAM4yhY3DAMwzAM4yhizudGLRkZGUhLS7O6GVFLQkIC4uPjrW4GwzAME4OwuJGIoz9+/DjOnz9vdVOinoIFC6JkyZKcT4hhGIaJKCxuAvAKm+LFiyMpKYk7Zp0C8cqVKzh58qTwuVSpUlY3iWEYhokhWNwEDEV5hU2RIkWsbk5Ukzt3buGdBA4dTx6iYhiGYSIFOxSL8PrYkMWGCR/vcWTfJYZhGCaSsLiRgIeijIGPI8MwDGMFLG4YhmEYhnEULG4YhmEYhnEULG4YWSpWrIhRo0ZZ3QyGYRiG0QSLG4f4tii9hg4dqmu9a9asweOPP254exmGsRHpqUAGO/0zzoJDwR3AsWPHfP9PmjQJgwcPxs6dO33f5c2b1y8HDYW858gR+tQXK1bMhNYyDGMbMtKBj2oAOXIBz28D4vh5l3EGfCWrSUiXmm7Ji7atBsoC7H0VKFBAsNZ4P+/YsQP58uXDrFmz0KRJEyQmJmLp0qXYs2cPunbtihIlSgji57rrrsO8efMUh6Vovd988w26d+8uhHlXq1YNf/zxh+HHnGGYCHHpKHD1rOc9/arVrWEYw2DLTQiupmWg9uA5lmz732GdkJTTmFP0yiuv4MMPP0TlypVRqFAhHDp0CF26dME777wjCJ7vvvsOt99+u2DxKV++vOx63nzzTXzwwQcYMWIEPvvsMzzwwAM4cOAAChcubEg7GYZhGCZc2HITIwwbNgwdO3ZElSpVBCHSoEEDPPHEE6hbt65ggXnrrbeEaaEsMQ8//DDuu+8+VK1aFe+++y4uX76M1atXR2w/GIYxCZWWYoaJBthyE4LcCfGCBcWqbRtF06ZN/T6TKCFH4xkzZgg+O+np6bh69SoOHjyouJ769ev7/s+TJw/y58/vqyHFMAzDMHaAxU0IyM/EqKEhKyEhImbgwIGYO3euMFRFVhiqBXX33XcjNTVVcT0JCQlBxyczM9OUNjMME0E4ozjjIKK/12Z0sWzZMmGIiZyDvZac/fv3W90shmGsgoelGAfBPjcxCvnZTJ06FRs3bsSmTZtw//33swWGYRiGcQQsbmKUkSNHClFTLVu2FKKkOnXqhMaNG1vdLIZhrIKHpRgH4XKrTabiEC5evCjkgrlw4YLgDCvm2rVr2LdvHypVqoRcuXJZ1kanwMeTYWzO+YPAqHqe/wcdARKzE34yTDT134Gw5YZhGIZhGEfB4oZhGIZhmGwcMKDD4oZhGCZmYT8bJoANPwAfVgOObkA0w+KGYRgmZon+J3TGYH5/Ckg+BUx5BNEMixuGYRiGYfxxR3dqEBY3DMMwMQsPSzHOhMUNwzBMzMLDUowzsVTcLF68WEggV7p0aaFG0fTp0xXnpwKPlEm3evXqiIuLw3PPPRextjIMwzAMEx1YKm6Sk5PRoEEDjB49WtX8KSkpKFasGF5//XVhOcY42rZty2KRYWIOHpZinImlhTM7d+4svNRSsWJFfPLJJ8L/48ePVy2I6CXOcOg0yPqVlpaG2bNnB01bsmQJbrzxRqF+VP369S1pH8MwdoWHpSLKxaPA/mVAnW5AfILVrXE0jve5GT58uJCu2fsqV64cnMajjz6KuXPn4vDhw0HTvv32WzRt2pSFDcMwIWChYzpftACmPgYs/8zqljgex4ubQYMGCXUovK9Dhw7Badx2223CcN2ECRP8vr98+TJ+/fVXdOvWDffddx/KlCmDpKQk1KtXDz///LNl7WUYxi7wsFREuXbe8757Xnjr2fOPRyA5IJOwI4elIkFiYqLw0g1dPGlXYAkJSaoq9ebIkQM9e/YUxM1rr70mOGcTJGwyMjLw4IMPCv+//PLLQrGxGTNm4KGHHkKVKlXQrFmzCOwIwzC2hzvK6OH77p734rWAqh2sbo0tcby4CRsSNu+Wtmbbrx4FcuZRNesjjzyCESNGYNGiRYJzsHdI6q677kKFChUwcOBA37xPP/005syZg8mTJ7O4YRiGiVbOO28kwigcPywVK9SsWRMtW7b0OVrv3r1bcCYmfxyy3rz11lvCcFThwoWRN29eQdwcPHjQ6mYzDMMwumFrmy0tN+QTQp2wl3379mHjxo1CB1y+fHnBX+bIkSP47rvvfPPQdO+yp06dEj7nzJkTtWvXNm9oiCwoVkDb1gAJGbLKUGg9WW1o2KlNmzZ4//33hSizUaNGCQInT548Qth3amqqaU1nGCba4I4yYjhhCDA9FZj7hmdYrFpH2A1Lxc3atWvRrl073+cBAwYI77169RL8RyhpX6B1oVGjRr7/161bh59++kkYdtm/f785jST/FZVDQ1Zzzz334NlnnxWOCQnCfv36Cf43y5YtQ9euXQXfGyIzMxO7du0yTxAyDMPEAukpwLWLQN5isSeS1o4HVo3xvIZegN2wVNyQb4hb4eQERv8QSvPHOjTc1KNHD8HiRfl8Hn74YeH7atWqYcqUKVi+fDkKFSqEkSNH4sSJEyxuGIZhwuHTxsDFw8BzW4GCGtKMqAgUUYeF/eEFe/v7sM+Nw6ChqXPnzqFTp05CWQuCMjo3btxY+I4EZcmSJYXwcIZhGB/84KgdEjZGhHYzhsPRUg6jRYsWQdYt8mEKVbdr4cKFJreMYRiGMRQWpLKw5YZhGIaJDVKTgcwME1bMIsNusLhhGIZhnN9BJ5/25Cz7pr3VLWEiAIsbhmEYxvnsyiosfHSD9cNDRg0n8bCULCxuGIZhGO4ooxI+Z3KwuJGAw82NgY8jwzCO4cAK4Md7gLN7JSY64F63fxnw22NwChwtJSIhIUF4v3LlCnLnzm11c6IeOo7i48owDBO1fHuL5/3yceCJxf7TrHqQM3K7E7rASbC4EREfH4+CBQvi5MmTwuekpCRfhW1Gm8WGhA0dRzqedFwZhmGsxaB7+YWs3Da2wAEWI5NgcRMAJbgjvAKH0Q8JG+/xZBiGMYTLJz3OwXXvsqY0Dg+3RwUsbgIgS02pUqVQvHhxpKWlWd2cqIWGothiwzCM4Uy4DTi9Ezi8FrjjU8Q0LLRkYXEjA3XM3DkzDBMzREtHScKG2P6nfcSNZccuSs6ZBXC0FMMwDBOFRHHHbpQvZ7QIUgtgccMwDMMwYWFREr9oFngmw+KGYRiGib6OUqtA0GotOf0f8O2twF4bFxW20nLjsnckMYsbhmGYWMXmHZQyJnfsk3sBB5YC33VV0ZQoE4YxAIsbhmGYWEXcKXMH7c/lE7A/fM7kYHHDMAzDRB9uO1m1HJCh2GGwuGEYhmGYIDSIGxYZtoPFDcMwTMwi7pSjrYM2ub3RYLmJunMWOVjcMAxjHau/Br7rBqQmW90SJtrQbC1xOU9QWGoxcsHOsLhhGMY6Zg4E9i4AVn9ldUsYxh9XXGRERmYmsPZb4MS/+tfBBMHihmEY62HLjTVEdbSUQe1NTwWWjgKObbbGMrHpJ+Cv54AvW+hYONrOWeRgccMwDMNEH0aJsVVjgHlDgLE3hNMY/Yse3RDGZlncyMHihmEYhnEeGWnAngWhrYLHNoU/LMXYDj57DMMwMYuDo6X+eQv4vhswuae+9WiJluKq4LaDxQ3DMAwTfYQSFGvGed53z1MWK1YP7YSzfdY2srC4YRjGBtg7rDQmsLqT10vqlfD2x50ZvXluMtOVp7vdQMolxCIsbhiGYWKVaBU0Am5g+5/Au6WAJR+Ftx4rBXc4xUsXveeJ9pLj9/7A8LLAoTWINVjcMAzDMOYKqDN7PPlcjOb3pzzv84dZK/AiIRIz0j3h6oHH8eQ2+WU2/uB5X/IhYg0WNwzDMIx5QysrvwQ+awz89ayx6zVMUMg5FNuse/zzGU+4+uIPAia4pIfqdsxQnkctM1/yvKIMm509hmFiknBM80wYRMDisOAdz/v674xdr5yvjOb1aIyWkpw/Asdx44+e98UjQs/7+5PAL/eH//u6chZYPdbzov+j6DfL4oZhGOuJat8Pxp4EXlP27ox1IyUytk0zLleQ0WIyQrC4YRiGYaJQYLpNttxEqLZURHCZv451EzwOzGb4Vukgh9UNYBiGsbuJ27HYvlO20OfGVEtPOLltMiP4+3Krn/XPLJ+q6p2AWrcjpi03ixcvxu23347SpUvD5XJh+vTpIZdZuHAhGjdujMTERFStWhUTJkyISFsZhmEYPbhiQCSFI1Y0LmvV8JBL5Xm8dgF2wFJxk5ycjAYNGmD06NGq5t+3bx9uvfVWtGvXDhs3bsRzzz2Hxx57DHPmzDG9rQzDMM7G7az2qhYNBpRfcJrgk+PScWDDD0DaVdgdS4elOnfuLLzUMmbMGFSqVAkffeRJ2FSrVi0sXboUH3/8MTp16mRiSxmGYRhbESheyNcjTsfzuqwIiobaUibjDtivr28CLh4BTm4H4uzt1RJVDsUrVqxAhw4d/L4jUUPfy5GSkoKLFy/6vRiGYRgndNAiAfJxHeCawv1d1hJjheXGSFS002XQvpCwIXYpjZbY47hFlbg5fvw4SpQo4fcdfSbBcvWqtJls+PDhKFCggO9Vrly5CLWWYRiGMQ+3vzC5dBTYNlXHaoxwKLa7MHTpXM4tLZCUxBLlxBGHkFtEVIkbPQwaNAgXLlzwvQ4dOmR1kxiGYWLDWrPqKyD1kkX7E0GfGyu1jd0sTMc2AWu+sboV0RUKXrJkSZw4ccLvO/qcP39+5M6dW3IZiqqiF8MwdsZmN+iYxIQeetaLsP11Ixt9FCHLTSTEiUvHNs7tBw6tkluh8rJHN8Bqospy06JFC8yfP9/vu7lz5wrfMwzDMLGGSlGx6Rcg+ZTMKrRabnQKGSp6aRkufYv9+rDM6uz/MGKp5eby5cvYvXu3X6g3hXgXLlwY5cuXF4aUjhw5gu++89Qk6du3Lz7//HO89NJLeOSRR/DPP/9g8uTJmDFDXCCMYRiGcYavSBiIRcu0J5RmzP43MwOIizcnWoqKXkptM2ysEBou2B1LLTdr165Fo0aNhBcxYMAA4f/BgwcLn48dO4aDBw/65qcwcBIyZK2h/DgUEv7NN99wGDjDMEysR0sZsd/imkwuBx13l8TOrBgNzH5VXzvZcqNM27Zt4VY4sVLZh2mZDRusH89jGIZhAji1C9jyK9CyP5CrAKIDUR90+aRDo6UkmJMlbBrcC5SqD6cRVQ7FDMMwjIGkXzN2faOv87xfOAx0/xJRgfgBW+xcHAXWCfXtdMlPSk3Ws1HYnahyKGYYhmEMZExrc6wPR9YiKvGLnHJQhmJXiH05/Z+x67MBLG4YhmGYyHDlLHBgub3EgFjQuDN0duCWJrrRNrtboq2zXta4nMv2AoeHpRiGsR6b3yhjAkMFh8z5/Pw64Mpp4J7vgdp3wFzc4Q1LmTr0Eunr3QXs+Qf4vrvnY7cvw6s0HgU/V7bcMAzDMJGBhA2xcybsgzgUPFOfZtIsDC2w9HyfJWyI6f10tMUdVeqHxQ3DMAxjvCUuPRVRQSw4FKddCbH/WsWW/Y8NixuGYRjGeGvCnEGIPGKhosciIfr/yDoN/bqNfIik2GmApSzK8tywuGEYhmGMxwbFEzV32pShOOT8prYmSnDZ3nrD4oZhGCYasVPEURD27vj8kXMo1rKKKIqW0g1bbhiGYRgz2TEDeL8i8N9c49YZ2EGf3g2sGQdkpMHR+PncqLDcaOXUTuCzprAvbuPFmQ3ED4eCMwxjA6y/GUYVv9zvef/xbmDoBXO28XmTbGfUlk/DuRhguVEaq6LIpDMak+Tp3TaJFLOEhTsgz43NYcsNwzCM0zl/CNg9T9+yh1bZ98ld73b8rDVGiBsF0q7CVLzt/+0x4LMmQJqekhruqLPMhIItNwzDME5nVF3P+4NTgartNS6spyOzQ+enI1pK7/CM0nLhDPlcPArkK6VOTFDBUuK/v2EKlATQVudXGbbcMAzDxAoHV1jdAnsQjuUm5UJkHIg3/wqMrAX80T/EjO7wrCpulT430/vq34YFsLhhGIaJGRQ6JSM77Cjo/CQFjZpQcGLuG4ErgeEseMfzvuGHKI6asw4WNwzDMIwzhIrqTj9Mn5vln8lbf4zCDP8fw7D/NcHihmEYhold5KqCa1uJUa3Rsc5wt+12pOBlccMwjPVEwc3S+USgKrjdc9tosZaI17HsE+DAcoMaJ7X+T2EvXLA7LG4YhmFiBV0i0v4dWVjDQ34+N+n6t/1tZ5i2L0E+PjLzhbsdvdeRDf1+WNwwDMMwDkSlz43YiVhLNuZT2w1oRwB7FgAXjmi0IlkhLFz+AseG4obz3DAMw8QMkYqWQvQgFhHpKeqX+7Kl8W35vpvnXcg6HUHB4LbAb8dk2HLDMAwTi6jt0Ezxh3LZ0+cmIzX8dZMlaP5bwO754a1HreXGEFHqNnhYynp1y+KGYRhns/1PYMsUq1thD2zjuO0Gzh3QXxLCSEuUeL6dM4Hk0+E1afNkYMmHwA93hrce1aLFCquLy+A2GA+LG4ZhnAv5UEx6EPjt0fA7LacR1HnKdVAmOSF/Uh/44S5g70LoR+0+KCwXmLhv/rAw2gPgwiE4Ps+Nix2KGYZhzINuqimX5aeLo19SLiLmoCKKX5jgGxI2os5x9ddWNiRYRFw9G+YKjbKOabA8hSsuDizTsZBdrIDSsLhhGMYG6LxR/nwfMLwMcGaP0Q1yzpDcyW0yE932ePre8ZcnT4wujKgKnmFsp23U0J/enDuat+M2YB8D1kEPEkoPHRGAxQ3DMNHLrlme9/UTrW6JPTGi43ZFYJl5b6rrhBcMD/xS23bUiIhwxYkroFs1o9K4/4wW+Ly4AprgDhasnzWBlbC4YRiGiWb+mwt81RY48a+2DtKGfhKK7JoDLHrPoJUp+NyES6C40X3s1Q5Lhemfs/hD/cv6NcJezussbhiGYaKZH+8Gjm7wOE6Hwq/D0euMqwYTOrZLRzVuR604yDS27VfPwRC0iM9whOqBpSY5FLO4YRiGCRN7OzdGBClHWEOeniNxbN0622HAkI+RUUnHNgPLRklvR+t50TIsFfHIKldwG4JmYXHDMAxjDtE29GL0vkZyWCozMzrPk5E+N2Nv8P/87+/61nP5JJB6ScOxEx+/CIgKttwwDMNEALkO6cxu47d1cKU9o7O0CIRLx42NlloxGni/ggVP7RLb2fQLcHBViOWULDcGtl1vpfCfemibny03QXBtKYZhrMeM++DFo8FP0uFy+j9gfCdR/R87oXJohzLoTu0DNO6pbrVqOqk5ryI8DLLcHFoDbP5F2zJGOxRrdS6W4uh6DTNbMSwVAFtuGIZhzEDiRnp8S+h5tHJiK2yLVAcjFSI/b2jWtO8QVagRWWotdUo+N0ZaHIR1RWDILdLDenHxgQ0Inod9bhiGYZjwkehgDq7w/yz0N3Kdjs2jpdSgx4JhqtXDZb4YcVtguXGpyOXD4gYYPXo0KlasiFy5cqF58+ZYvXq17LxpaWkYNmwYqlSpIszfoEEDzJ49O6LtZRiGsR2mdXB2iURT0w4jik0abbkxGwuS+LkCpQMPSwUxadIkDBgwAEOGDMH69esFsdKpUyecPHlScv7XX38dY8eOxWeffYZ///0Xffv2Rffu3bFhw4aIt51hGMY2qLIGuOQ7XCOtCXo69avnPeU0tk3Tv90rZ3Qs5DZxWCpCXWykh6Vccf7H6d8/JOaJcXEzcuRI9OnTB71790bt2rUxZswYJCUlYfz48ZLzf//993j11VfRpUsXVK5cGf369RP+/+ijjyLedoZhbILaG+mef4Bvu3gcg/VtCIZxdh+wX0/BQjlM6uB0dVIhlpEKkV70PrBzJvDrw9DN+YP2EgOR6OBpXzb9jIjiCtivP5+RmgkxK25SU1Oxbt06dOjQIbtBcXHC5xUrAsaKs0hJSRGGo8Tkzp0bS5culZ3/4sWLfi+GYWKU77t7KiCH04EaxacNgQldgONbYy+nT1qydG4XWxBllpvFHwREq0XgOqCCrKkS51BMLFtuTp8+jYyMDJQoUcLve/p8/DjlYQiGhqzI2vPff/8hMzMTc+fOxdSpU3Hs2DHJ+YcPH44CBQr4XuXKlTNlXxhGFaFuCDGLK7LLJ5+CbTi+OcI+N5FwKNaDO3Kd5ZF12ubf+pu+7Sz9GDi9K/j7Qys9uWwy0hE2ZI20QuSu/CLEDDEsbvTwySefoFq1aqhZsyZy5syJ/v37C0NaZPGRYtCgQbhw4YLvdejQoYi3mWF8BereLQ3smAHbk3oFmPECsHchHEk0WTlUo2KfSCBo7nMiVEk8knzfTT7Rn1TbpzxifBt2zfYMwxmOTa7tWLbcFC1aFPHx8Thx4oTf9/S5ZMmSkssUK1YM06dPR3JyMg4cOIAdO3Ygb968gv+NFImJicifP7/fi2Es4Z+3PO9/PgvbQ/Vx1nwDfNcVtiI9BZh4O7DwfRUz27yDdYJgS08FTu82vv3eXDyhzqdUPS217F1g/XWTkWq8GLE6oZ+PGBY3ZHlp0qQJ5s+f7/uOhproc4sWLRSXJb+bMmXKID09Hb/99hu6drXZTZhhornTJWdXO0KRNPsWAwvfDfMp0SZPt4ZeD2qLTxoYLfXDncDnTWA4NJwj5twBm50zA31yjPY1sotV0hUX2+UXKAy8V69eaNq0KZo1a4ZRo0YJVhkaaiJ69uwpiBjynSFWrVqFI0eOoGHDhsL70KFDBUH00ksvWbwnDOMQk72dSb9mzXZP7QLOmlVPym3vJ3al63X/ErmFjDsOa8cDfz0PxOeE436fO/7yvJxouXHFeG2pHj164NSpUxg8eLDgREyihZLyeZ2MDx486OdPc+3aNSHXzd69e4XhKAoDp/DwggULWrgXDOMwnC7AtD7djr7O8379U4hqBJ8bV3Sdk/lviYZwjMQGx0Gvo3I0WG4Q4+KGIKdgekmxcKG/Q2ObNm2E5H0ME73Y4KYaNTdImx07oyKbbHk9uIErZ4GVXwIN7oVtCMevJqrPh06mPgZbEMsOxQzDMMYQoRup7DCMgaRcIudD/++ObQY2/Gi+6CRnd8qbMqa1BdFSEvt2bBMiDvl0/dYn8tt1HC5Lt87ihmEijV2HBawklo/JyX+BWS8Dl095HLmHl/U46ooZewPw+5Oe8OGwUXAoPpQVHp12BbYg+XTkr7mLh4Etk83bbqzgsnbzthiWYhiGCUnyGWDN1/rFkd88Nhp2W/6p533VGKBkfeUw5RNbgRqdw9iYDp+bSAlPSauUmecphgV1RGDLDcPEGHxTVU3aVWDrVE9RxUkPAse3ONsaZIpPTyBKx0XDMaNzYsR6lISMmdrGLlFFTsXF4oZhYoto7HStYvYrwJTenlT1B5crzMjHNPxrT6OSWPYJoprAXEmMo/LcsLhhGCOZOxhY+F6ImbgjVs2mX7Jr8cRENFgUcfGIsQI+4sNSjLlwKDjDOIMLh7OfZlsPAHJEKOmYKXCn4kxC+NxoESU588B0WIRGLy4elmIYZ0B1j3y4w/vRZ2YA//4BXJSuds+Ei4WdJlWCnvUKbIcgJKSuTZdzz5MRVbkZGVjcMIwzMPIpc923wOSHgM+zMuM6HpsO1VHn97vBWYk3/gis+hLWoTVaSs/1btSwlMmkX438NmMFF4sbhnEgYUak7JrjeU+9hNjA7encFCNwLLiRbp4EbPghcr4qkSCaHNrNFjxpFtUqiwlclm6dxQ3DmJ2b5dIJ7cvFoq/B7EHA+xWyhZ1TU/+HE4LsNjlaKpTwoevyj2eABVTI2Ohr1AKHYrbcmAdbbhjGibg9KfRHVAY+qg6kJmdPUvWbjzVx48oeqpk3VPviC4cD1y6oF4yqxaPLgflVXPrnP7ENWD8RWBQiIlAxbF8GqXNitsj385NjjIXFDcM4D7opZ4qcFS8d1/ajt7wDNMDcf/o/T2i8mSn0xegRRWbn6ji9G7h41LgOO+z+QmEFapqVfi22rYtM1OS54VBwhjEMt3Hm2mjuOBaNABa8nf351E7g/knmb5esCoq4I2dav3wSOLMb+DarVMLQC84Rrj4cMCwVzb8zu+PiPDcM40Dopil341Tzo4/im65Y2BCH10Rmu3EJAV/ozMZLBSyTCgNx8dqePskZmix0xWsCH1azr8+NYqcjMc1v/gh3WCw+ohiXpVvnYSknc+Jf4NeHPU/OTty37+8EjqyDLX/MgTdlrU8xRtzUD68FpvXV59AcjU958YHiRscxPbYZ+LAqMOHWrHZpuEWOqgd80Rw4tinEjCrP7fLP/H21TEdFu1wmCg9LMhSzeDINttwwpvHtLR4nywMrgIEOEzjfdQWSTwJ75vub/C0l4EYpd/NXNSxlwNDFN+0971fOAA/8CtPYNAk4tx9o+7L8PNumA6d3ATe+aN5NLz5n+H3a+u887wdXqF/X2X1AQm4g5aLn839/h9i2yg7179c9Wa87v5/9nSGHLpyVmFhZPSPV2PUxMQ2LGyfjjR65LHZmdQgkbKJ2WCrCkO+HmUx73PNetQNQton0PL/28rxXbA1UaGnMdqdmbVet5UYVgRa3EJabK2eBTxv6f5eRZpxw3b8MhqNVXJLga/ksULSq//dGX957F0R+WIqygDPmwKHgDONQ/G7MGv0WDL2pRyhbLFmIQpF8CoYm2DNa3GgdTjy7V7sFQsuxDRRCbjOjpRTy3FC2bGFxV+Qco4Xj5I6sfxhjICxuGMZ5BN6YNT/FhHlTp+GMiBOOA3WEh6WMstxIoWS5odBwTVmn3fbInn1BIquy6eImkx2KoxkX+9wwjHPLCfhwRdbnRpxXJ1I3GdmOSM6CZTCaHIrdKvfBZZy4ObgKGH9zmJYk7c3xX15hBYqiSyrBXiQsN0z04rJ062y5YWKP84eA9FTzb8ayN2eH57lRxMT9csWbsM5Qt0iX+mGpbdPMP17hXDffdweunQ+xXhMdiu3st8ZEXRI/FjdMbHFwJTCqrvYnaCOHpVRZUiLgc0PlIQxFg5i7dhFIvWLs5kMe1xDHlAQvVWM3c1gqbMEcYv7MjBAzhMhz4434Cm5I5C03KZccLPIdQK6CytN5WIphIsjGnzzvRzdEeFhK6+IG3tTP/BfsLDr9SWDvIuCplUBiPmO2o7bNaVeB98oFWFqMuBG6wmvrv79LrFJHuzLlxI2Oc3paYwoHd4bybZ0KgZ7Yqr0d3uMVSYfiDyoBBcubuw3GxN87D0sxTOSI6NNEOMNS4XYcAdv4d7r/540/AhcP6xwqCZPzB0UdsYm4QtyMycLyx9PZxyBNypKkR9yIaooZwZk96psTatuLRDlzNGFBUUvxtcLYj5QQ+cU4FJxhongcmHIJ7fkneDiAbvyyoeBqMLjjkLJKGL59FctM7qnPcmAIAQ7FG7735HChLN5B06WWCZykUbzqFQNiH56wh6XCgNpPQ0WOq5HFmAOLG4aJXnHzbRePI+bKLzS0wQKH4kg8ZavdxpRHzNl+qOO6c2ZwcctQ7VfqwCUtPRbjtdwc3Qh8VNO49dKxWfBOdlkKz5fGrZ9xHi72uWGY6BU3XisElSCoJnZSDrDcaC4+GGbHEc59Jfk0sPU3HQuG0eYrp2E62/9Sni4lZJTEzbulgSLVNNzUIyEwM7MF5KVjRq4YWDwi4CsWN4wSbLlhmOj/waVe9r/Zh5tdVU3HQdFOW6d6QtuNhPxQIg0VibQareLG66wdSaiGlxrLjZERW3KwuGGUYJ8bJmY4vM7fOdJJuRfO7QOm9zWucKaaechnZEpvT2i7keiNJAtnf41ici/g6/YyvieB4lMFRvqw6BUDJ7Zl/7/xB2ULlK+9BgsPqePAPjeMjcUvD0sxkYGiHr65yfO/lVW8zexog0SBXGeqpg0q5tm7UHXTVHd21E7dwxlqs/6GWk0mMPtVoDQVpNRyvlzZUWHkc6Jm/sDtSrVFK4dWyUzQebP/7VH/z6vHhrbcGN2xSEZhseWGsW+VdxY3TGQ4vQu2QKvlZuPPnh9pk6yq1lqQ6xitMNeq7eyOrDd/G6E4tcPzInLk1tmWUKJEpfOwnn2SCl+OVCFUX3i90cLDbX7IO+MsMljcMIw9SbuWPdRU63YgqbD6ZYNCwSP9lKtTQKVfNbohkRNzftvRkZdFa7SUVSgdT+8+RGJI4JRNHlgYe5J+zdLNs88NE1tosdyIM81qDvtVcijW6HOzbTrw+XXA8a02Hxawuj2B2XM1lGOY8igwZ5DELAb53ETKcpO9QZiOXB0qhrGB5YbFDRNbRLKYW1D0lM4O7NdenmE9ch6WW79uXM6MngllcQls69Yp+tZjxfFRcw1HJK+RDa1ajH3IiEDEngIsbpgIEWbdH8OaEaFLPigUXJzzRqFwY8rlrHlc0jWZDMfIY22QQ7ERSG7TbWEHbuAxiHjh1SgQs4z9yGDLDUaPHo2KFSsiV65caN68OVavXq04/6hRo1CjRg3kzp0b5cqVw/PPP49r16wd32NCodahdR0wogqw4UdzmqHF/yOsm7eOwpmf1AeGl/FUzFb11CNaf4adnTvdNtlm4Ll3RelxsInPjdm1wZjoJjM9tsXNpEmTMGDAAAwZMgTr169HgwYN0KlTJ5w8GZAaPYuffvoJr7zyijD/9u3bMW7cOGEdr776asTbzpjAr72BK2eA35+0meVGT0eoMRTcG4L9XnngmJpQZhHbpqpviyJhdPhyHWqknvBDVqzWY7kxqO1GHoNQAn3pKCBZ+v7pJIdRhlFC153+0KFDOHz4sO8zWVqee+45fPXVV5rXNXLkSPTp0we9e/dG7dq1MWbMGCQlJWH8+PGS8y9fvhytWrXC/fffL1h7br75Ztx3332y1p6UlBRcvHjR78VYgcpO08zCf5EeltLdoakUCeLPVMBTl/UmqHQ2jMdtgY+TjlDwsOYLtZpMYP8yY9b1399KGwLmDTFmOwwTxcOWuu70JCwWLFgg/H/8+HF07NhREBevvfYahg0bpno9qampWLduHTp06JDdoLg44fOKFSskl2nZsqWwjFfM7N27FzNnzkSXLl0k5x8+fDgKFCjge9EwFuNw/noe+OFuT3mCICI5FCHnc2NCG2YOBN4rF1wMMuSNRucNiHyDVnwBnDsQel5LfG4M8pUxqu2rvwJO74TpsB8Mw+gXN1u3bkWzZs2E/ydPnoy6desKFpUff/wREyZMUL2e06dPIyMjAyVKlPD7nj6TaJITViSgWrdujYSEBFSpUgVt27aVHZYaNGgQLly44HuR1YmxMwpWiz+fBZZ8FHoVa8cDu+d6/HcC0SQsDPS50ZyhWAcUrr5uYtYm9G5D5XJkHaDQ6TE3mCegwkEyZ42e6DWD2r7RJB8yhrEt7ugTN2lpaUhMTBT+nzdvHu644w7h/5o1a+LYMSMr0QazcOFCvPvuu/jiiy8EH52pU6dixowZeOuttyTnp3bmz5/f78VEIUfXA+smAPPVWwaRkRLesFQ4T8HCsJTZGYqV2qd2Gzrb4i39kHIhdHtoyCwihBN6L7dKg9YTF6F8qfsXR2Y7jHNp9BCcgC5xU6dOHcE3ZsmSJZg7dy5uueUW4fujR4+iSJEiqtdTtGhRxMfH48SJE37f0+eSJUtKLvPGG2/goYcewmOPPYZ69eqhe/fugtih4adMyWEIxhHoCYOW8t+JmOVGCZfOTlTB5yYcKDrr4CqN69O7DyZnlNYyLBXJkOpIiZsZL0RmO4xzqdPdmPW4o1DcvP/++xg7dqwwHETOvBThRPzxxx++4So15MyZE02aNMH8+fN935FAoc8tWrSQXObKlSuCX44YEkiE2+qbKyNP2NYKueVd6jIMS80fSgxHMhRcy7wk2owM/f66HTD+ZmCLTCI7u9THCgVVzPYRKs+N2kKiMIb4BINWxDAm47Lhb1sHuh4nSNSQvwxFHhUqVMj3/eOPPy5EOmmBwsB79eqFpk2bCsKIctgkJycL0VNEz549UaZMGcEyQ9x+++1ChFWjRo2EnDi7d+8WrDn0vVfkxBTUKf7eH8hTFOj4JmyL2s5bPN/H9YC2LwONHtT3QwxpuXFHLomfeL+k2qzWAZYE2WdNPDkkStaT2nDAuwrO7M4OJ2/RX36+PQs8uU2qUgCA1HG30cOFmuMZyYehOBY3jE3pNBzYtwjYNTvrixgWN1evXhWsJF5hc+DAAUybNg21atUSctRooUePHjh16hQGDx4sOBE3bNgQs2fP9jkZHzx40M9S8/rrr8PlcgnvR44cQbFixQRh88477yAmObUz+4nVzuJGjitngXEdgXr3eISMmAsHgd+fUhY3ipabDPWd26XjnkijUvWlp+t5mtFkuclUX8/n3D7P/3n9HfF90H7MegWaUfJHouio77t5/n/1qIxAc9vnKfL8IYMypBo1LBWDD15MdNDiSc9Q1Mians+xbLnp2rUr7rzzTvTt2xfnz58XLCgUuUTWHLKq9OvXT9P6+vfvL7zkHIj9Gpwjh5DAj16MjNOsHZH7wSz7xGM5WPhulrjR2JkoWm5CDd2ItvVRDc/7U2uAYtWDp2tGofyCpL+KDn8xuX2f9gRwaKXKlYgFXJz8Okn8eRGyJ9vccjPrxdh0KGYYPbjEv2dniBtdPjcUpXTDDZ4Q0ClTpghWFrLefPfdd/j000+NbiNjF9P6v78Dh9YYu85AARJOgclQ6w5EalsUlSU1Xc9x1rK8HnEjtc5NPwNHNWY3VmNdoKzR2RuO3NOd5mrsKol0KDiLGyZacMXFbig4OfXmy5dP+P/vv/8WrDg0dHT99dcLIodxICf+BSb3BMZlJ1yMKHKdqRafm2ObgK1TlX98Cbllpru1d55XTktPC8fnJhRn92obMto8WdQuhdtB6uWAddkwWioUge1TI9DYcsPEBC7RvzFsualatSqmT58uJMSbM2eOUAKBoHpQnEfGQszsXLx+Hpbh0n4MAi03Y28ETmwNnlcceZQjt7zlZfd8YPGH6o7z1bPAhFvFDRP9b6K4kUWmzfuXZP/vildft0nyBmhzceNHpC037HPD2BiXCYImGssvkPPvwIEDhdpOFOHkDdsmKw5FMTGMqRe9UrZfJXETvCLPm9jCkpDL875iNPBtZ/95f7gT+OctYMeM0G2Uyo7sa3IY4kbVsdN5ozrzn7r5yOdGLBKjxXKDgGtjgYogBKP2yReJwjgO8QNR1OKC09BlK7377ruF8geUjdib44Zo3769kFSPsQi6EdvWpOhS2U63cR2OWp8bynwcGLI751X5bV5QUcLjwHL55aUbE3qdQeuQWUZuOCwURzcA398ZetuzXkJUclVPpmSDxI0hkVtMSJKKhr7+y7cADkrXLtSF44YcXcFfFaoInNuvcT1RaLkhKIMwWWkoK7G3QjhZcagEA2MVZudtCWsFBjUkYF1BIkmD5WbzL573/GWklw+HLb8qTLSxv0q6XCZoUfu2/xF6HjtCqQUYZ6Nm+C9nHps64EaQ8i215f9q3BPRhq6zQlmEqXglVdmuUKGC8CpYsKBQ3ylmSyBcPgV8WB34iMVdaMIdllK4xrSIBKoeTsTnVLFuiaEwTSUhjIqWcls0FBiBbdgRJ+6Tk1EjNKjciKHbtKu1XEubAyzrwQsg2tBlT3vttdcwbtw4vPfee2jVqpXw3dKlSzF06FBcu3YtNhPqUed0+YQFF4EJxQJNIdSPJwvhGIZAafmZA9XNJycs5ESG1Lq+DHj6UdyGaHmpHDS6HIp1XmtHROHuaqAcN0aa8aMKO/+mbMLtnwIzX7RJzi0Vv4nDqw3eZBRabrQKNFeMiJuJEyfim2++8VUDJ+rXry+USXjyySdjU9z4Tr7CzfDQauDqeaC6J7osdm/EOtqptmzCum91OOmqEDdSQ2EUdq2WLwNqpZ3d5xnH9q5LVVsD61W59deS0oI3waFjrj8N2PqBwSbU6eZJ37/1N6tbYo3QcIK4CYnJGdpNQNdZOXv2rKRvDX1H02ITFSefygz89D/gwuHIbtdppFxSuf8mW27CYdMvwIiq2cUq9QxL2a3jtVt7DMGJ+2RC526Xc6/XwlCkWhjbdJq4ccMJ6DorFCH1+eefB31P35EFJybxywMS4uIQp7IPGxt3dnJobed/8/w7/xFVVG7HSMuNwSx6zxPV8duj2rar+xxH4tqIkutPC9Hym7ISoXO3yXHqOlrfcuKacrFY8d1lxrCUO/qGpT744APceuutmDdvni/HzYoVK4SkfjNnzkRsojbU2UxMvJgM3R+ZdqbLjNn/eBdQua2OzegQN3IO8Uq5dYxAl0OxTToUp3J6N7BslNWtsD92slyUvz7yItYRoeAuxwl6XVdlmzZtsGvXLiGnDRXOpBeVYNi2bRu+//57xCRqfUJiFTWWrbeLyy+/d2Ho9QZipEOxmUy4zeODowa/rMka2hqqQroROOSm6GPJR1a3IDqw07CUFcP0drbcJOQx5jjpOb8VNARcmIBuyVm6dOkgx+FNmzYJUVRfffUVYo7A9PQIyLdg1o8/3OKOerep1ZIj1zYzLVxmORQbDZVAOLNH5cw6xc3uuZ7EgqbecOzSwRlErgJWtyA6sNOwlN77STj3IXEqCbuRtxhwLjn0fGbch2+19uHARvbEaCeEZYJS9zsliZ8eEbVrjnhl4a1LLQvelR9m0moNEc9jxo1ATQh8YDu0HrpfewNLP4Zp2Obp3SByF7S6BdGBrSw3FmDnYSm33HkJ/N6EkYfchWAlLG4iNSy1558IbDdS6Lj4V30pWjxCN0LKu7FNXAVcgkUjgMw0f3Fz7YJygUkzcKsYNqLj5ie+3NpvwvOGwjRo3WtFofhRTwxGIka95caCLs3KoqgdhwG3vCc/3a3jvEguY5PzqwEbS87oIjk1A77RzUg+xVgyLCUx7KZtBZHrgM6HSLm/4G2gRD3/fVv2SfB8MwbAclIos2oY59ts34DUy8Bfz8ExLHzX6hZEB7ZK8OaKLYfqVs8Ch9bIT3dnqjtOtjqHFogbchpWghyLY5Wzyek+cUMlKEy73NNTga9vAko1ALoFhj1G0OcmXHbP8yQ0NPtHpWb94mrYdDNIuQxbknbFkwhSr/OznR0fmejE27E7eViKqn7L1lwjLBYGivc4t9qVKE+OwvOrSdxQLalQ03v2jL4CW0ZQqmB22fsTF6+gVLEkcza0Zz5wYovnFSRuIkS4EUX0Q/nhLs//tbuZLF5c9o+W0sLSMEKTvRXPGcaJYeCEGQ9LRap67reR3KYWFCNGM3WsI/qETNji5ttvnTSebiw54rOHaeZuO4FGVRNQr6wJ0RZBF6vGYQoq9pgjV3g/yHAFAEXteLlyBpbjJ27cNv9xh5HnJp5HoRmHixvdhGP9sHpIx4B0GA70uXHKlWk9IrHw/uztuP3zpUhOSY9wI0JcgOf2A++UBCaHa10L80KnEhR2eerRa7lZHpyhOyKEY2Viyw1jx2Gp+ETDmqP/fuK2v8DLUwy47jFt23ervUfY4D5sMCxuDCP74nBl/VB2HCcHUIMJuolouCjXjve8b/8jzDYYOXRjA5+bQMGg5kb992uwBLE/0Old2pZlnxvGaHwdq4rfTMungWZPwHFE8gEtMZ/G7bvVrdcOD5kGw+LGKEQXh/e/a2mR8N/QMixl0AVspHNZ2D8qA3xutAo3K28EF0JEf0VrPg7G+ZabhCSgYDlEFY0eitx9VS+Klhu32pWIFwq3RUDN22A1LG5MuMC8lpvMiHuYRzIU3CBMN+m6PZFZySp9e+zuUBwObLlhrLTcCJnN46PLakB5ZELt29VzkWmLbH+iw6HYZdIxb9wT+N9EoPtYWA0/ypk4LJVpitZQWGkoMWXYBe22j7hJveQRLnmKSE9f/x1wZjdQsLy69Qk3g+hznlMF+9wwRqPpnuKW/r3bIcxYqQ2h2ndqu8cfJvkULMEInxuXQaHgZZoCdcKMgDUIttyYMiyVJW7MUTdhYMNhKSPa9PuT8tNI2KhJ5qfpZmDjJ00l2HLDWO1QbGU2Xz3kUOns/JQo/5QcJetr23bVDuruPXp8btwKvpvh3N4bPQi7wOLGVMuNzYalxD+Czb8qz3vxKHDlrMxmbGS5CQwtDxcnD0vt+MvqFjCI9WEpmz4YyBW/zJlH3b5Reo1Q5Cvp/7loDWP8VozwuXGF8rmJPvHK4sZEh+IMUyw34eQ0EC07VSKk0AuJmpG1gA8qhS8A/ngamP2qQpNsdrNTEy1ltzYzjFVoejiR8bkR0+MHWELtrkDFG8x9mKMq2TnzaljAgOzCbrcx97CKNyLaYHFj5rCUKZabcPIxuEKXdpALMdZTsPHcAY/Py0qFTMp2GG/X2p6/no9ESxjGWcNSZB2REkPi+1LldtYM+9KQ7cNylk0V+6ZGLJDfX59/1AvDUELo3p9Cr8ctum8nKiWVDdH+8s0RkvxlYCdY3BhIZtYFkm25icBGNWkDhQt4+5/A28WAdROlb1R6ksdliKpth1MNO5JQhfAdM6xuBcM4b1hKyIwep0IkuKPLoVgTLvX30TrdAxviL6Jq3pq1SrXRUm6FZrnC39/itWAnWNwYilfcZFrjcxPOcMqkLEewP58BMtND5NNRq9pUjsPbrXbT5eNWt4JhogSXhjw3uaV9MvyWtWrIV61PiVyAscp2i+/BkvfZEAEAUsdZrUOxW2kfnTfUzuLGQNwBl0nkHYqzuHYB+OMZ/RfwxNtU1F8yCpuJm+STVreAYZwJiRtVlhsTMCqfltaIp+CGmGC1NsByo5c7v7btgyqLGwOJz7LYvJfwtXkOxYoXUNa0+W8B6ycGTw6rWKYey42a9RqxLuc9dTBMdOC9L6jMUBzKodis33KoHE9q7qvhiKR7vpOw3Oi490ndw6XaVPEG4KFp/vulFKattyp4/Xv0LRcBWNyYwE3xG02MllLAeyGf3Sszg0HiRu4i9jokSy6jZr16sdePimFiBu/DiZrfcZkmoR+wLLPcqPS5kWtfqHZ7w761DEupRWrbD/8FVLnJ/+FRyLasYh1678lsuYkNyuBUhM61hpwEem4cJ/4FPq4LbPhetHqJJ45/3vY4JB9Zr3EDBh6k5NPGrYthGA3iJoQV4pE5QOFK0j43kUitEFb+FSN8gtzqhqUooix3IaDDUM/nqh1DD4mpjZbKYWD1demNwU7YQtyMHj0aFStWRK5cudC8eXOsXi2f7bFt27ZwuVxBr1tvzfIctwk/5nwXGaHUTWpydkK9mS/pM1OqsagQfz4LpIoqSqtlel/gwiFg3yKZbWaxeITn/e831LVHaV16WfCucetiGCY03s4zlBWiRF2VFhSLLDdK96HyLdRsQN1xCmW5KVwZeHEv0Dor3cRdX3sqqde9W6Fek2idBcoDD00XbxgRgy03/kyaNAkDBgzAkCFDsH79ejRo0ACdOnXCyZPSjp1Tp07FsWPHfK+tW7ciPj4e//vf/2AnKsadUB6WOrQaeLc08NcAT0K91WOBeUN0bEnCG17qIls3AVj2ifbVp14J/u7v14OHoJTaY7bPTcol4OIxjyM1wzCRw9tBq0n7QISqLWWEFUcqPwxtt33W/bVyW4mFFO5VtwxXbl/TR0K3ybePIcRNZgYQJzpGZMXp8gFw9zggXwmZ8gui+fvMB6pQrqBwHKMDjsUTi0OvT2q5WBc3I0eORJ8+fdC7d2/Url0bY8aMQVJSEsaPHy85f+HChVGyZEnfa+7cucL8dhM3IaOlFrzjeV87Lvu75Z9GXi3T8jtmahMflMZ/QhcFgZPFtMfVbT9s3MDImsDxLQasi2FsSt6A9P12wPtAQfmhlPCKgkg4FDfuJbHaOI815PFFwP2Tta0vVwHl9jV8QP2wWCiHYj0RVH6CS+XxK90QePA34Kk10tMbZjkf1+4GlGqAaMRScZOamop169ahQ4fsAmFxcXHC5xUrVqhax7hx43DvvfciTx6qARJMSkoKLl686PeKFMoOxS5rIxe8bP0N+OU+FesM4PAaYPEHErNnzT/vTeDYpsiq/dM7jVsXw9iNFgoFYq1GbLlRGgKSmpaRIppuVrRUvGfd1KlL+Z6orsEktW8u+XY36e2pEVWsZva8oSw34aA2msvt9hTmLFZdehqVinhgCtB9jPpt87BUNqdPn0ZGRgZKlCBzWzb0+fjx0InUyDeHhqUee0y+TtLw4cNRoEAB36tcuXKIFOYES7nDGwbyW9QN7FmgPI/Sj83rZxPIyR3A0pEq2+DgQpUMYyQ26zx0iZuQjr1hiBsawjEjWirUepQE2e2jgHt/FFmuQjgU67kfKg3rlazneU8qom2dCbmAah09uYmiFMuHpcKBrDb16tVDs2bNZOcZNGgQLly44HsdOnQoYu3LzHRj65ELuPGDEAJCzC8qTJxiJEslqPyh0nyXjoWYR+uPzQ2kaLCOsbhhmOgnIzW0dUN4UyFechXUl0fmWQVLcajhMF3Vs8XfqRVlLuljptZyo9Wyde/PQNNHgUf+DpigQyjX6OI/ZGVz8S2XSzoiFC1aVHAGPnHihN/39Jn8aZRITk7GL7/8gmHDFGL3qVZYYqLwsgKKlnryx/U4ePYKkEvlQuTPQmOxYqcyRUQX1Kh6wNPrNLSQLDfzjRcfWkyrNvtBMAyjA/EQi+KwVHzozrvXH57o0UMr1W8/T7EA3xgjQ8EDil8G4TIwasvgWnsFywG3qbSiZzdC+useP3oeXHPmAQpX9OTRUbNcLFpucubMiSZNmmD+/OwONjMzU/jcooVy+N2vv/4q+NM8+KBC1kWLIZ+ba2l6LlYNRdzEn8mpjyKZ1F5kZkUzafqB2usHwTD2xR0llhuFXDZqyi+QA+sjs5Xnu+3jwAVDNNAV3rGlbL+U4bfNSxKrVvC5kZpXiXB9bozALXMs6IE7d0FPzasbX/QkZVSzXKwOS1EY+Ndff42JEydi+/bt6Nevn2CVoegpomfPnsLQktSQVLdu3VCkiMaxxAjidrsRH6cjo6WmiyRgXrUhmVLLGiFuqO1alqEwboZxCmXlh8gdTTgOxXpEgGL4tcR97eIR5fWFuueSlaLraCAxP0Jyx+dA/Xs9kVlBiParRX/P+02vi9oR5sOwWpGVv7SO7WhoR6wPSxE9evTAqVOnMHjwYMGJuGHDhpg9e7bPyfjgwYNCBJWYnTt3YunSpfj778BxRHuRQaNLurz/wyhNT8JCrThS85Sg9Uni0lFgvSibcShO79K2fiZ6oKRj056ALaGw4KWBT/8GcFg+AakjKdXQ897tC+Dnew1wKNaLOzKFM6VX7v+xQFngzrGh79+tngWa9/XMf3gdsGuWJ2FfOIS69z/wG3DyX0/tKYdjubgh+vfvL7ykWLhwYdB3NWrUEKwididDyXKjhBaH4KBhKg1WEzVPCVotN+cPel4MQ+Zrxjjsds97ZmO2BaBG5xAzqxyWMuTYqCwu6b8C/dvW61BM/5NPDPG/CcDRDUC5UJY/ie3kKwWUvc4zHKgUMUZU6+B5KeKM2lK2EDdOhaKl5LWNyxifm8B5tYgRylUTCo5mYvRis5ud7aC0/gfV5fOyJVQrSrPlORKWG4nth7KghxMtpcmh2CUfel1BTZkHmXU+Old5/ZEgn72STFruc+NkKENxnKBudOSfUTejtOVG7fLfdVWxCRY3DGMKFHWiiSgRi1JD2V4rXkQsNxIYtl2dVcFDLR8uWpyajebBqZ5EhZ0lkrpaCFtuTOSLhXuEd5fmm5KWaKcwLDeqthFifaOvByq2MnabDGM6ruhrQ6QsYVR7aW+wO0BYw91eXxvVKS40bzQyw1KyeW70YFOx6tbYrqrtPS+bwZabCOAyNFpKIRTcCnFzajuw5htjt8k4Ax6WMpc7vzZnveWuB17Yac49IyKWG6nrzqBhqXBFcaiAEFvghhNgcRMBTLPcSM1n9A/GDnkXmCjFxjfJoARkUXg8C1Uyr0ZdOP4TSvcM06KW3JG5FuV8bqz0dWEkYXFjhbgJJUDUWl9kh6UM7FTERe0YRgt2fTItUQ8oWdfqVgT/TgtorHsndKg2PMZKUZhGOBRTpeqgbYZ5HMKx3LCwsSUsbkyka9xS4T340g8lbtRWEw8zFJxhTMWGHS9RtJrJeU90ormTdEWfKA33uFdoBdw9XmJCOPdUDYQbLeWHjjZFQki5bfq71YgNf+HO4ZOcXygMS+kMBVeqCq41WophzCRS12GcnriICHQSt7yv7fiELO6ocxdq3KpyRrkNGUi4SfwKV5ZeR8hrzaBhKzWWJyUBEhVWHjecAIubCBAoblbuOYWL19IMSuIX+B1bbpgYu0neOtKeYbNNPSVkTOv4qcCuGgpV9CSJi6QobdwrfMvNMxs0bDBMy413+q0fKc8n1f7Aa4kfLm0BixsLGDFnJ9YeOG+QQ7HJPjcMo5dICW0aqtBKJIalciRqmz+kVcCt3h+O/Iq85EwCcuQKnue5rUC/5TCMTu963m//FLjjU09IeTjHXarNqnDpt9xc9xiQI7dGAapTKLMIMhXOc2MyRXFBu9RQuuhDRS8dXa91a7EH3WDZwmX+cYrUzTuXimKGfmhJl28mbm0df+DxTFcQN+Ldy1VQep6kItnp/5XapZYWTwENH/BUjvYWEQ3Ml6NJVGo4R+4w25+nmLphTjWWG0UCfCY1wz43amFxYzJrc/UL+i4embgpfqP2lS3+EPjnrezP2/8C0q+F2cIYhMWNOuISwouWi9QxVlOpORCrHIrJZ+TsXmPaJK7ErQTVG5KKxJLrlMPp3LzCxit29vwD1L1L3T6SMAqFbJtDXGtK+3TDwIDUACoLF2d/CdWILT+mlaJgCBY3FvBJztH6fohiYUNMfcy4RsUSwk0l3epW2B9KmR9WKoAIPQFSXR4jfW6oMvNqmarO4VCyHpC3RLa4CXIo1ipulM6NaP8S83pC37t/BVw+DswdHDyPGv+X41uA9d8Bu+epFzp95qv3KwqcJnWOVAkvDftFBSfbv6FjGzpJzOe5vjJSgXwlzNsOwz43VlDKdVZ5hsCnEPqxcTI9+0RsRDNacqmEW9XbruZtypMiJyTq9wC6mFQjxx3iC6nSBJQtWG7+/GXUbddrIWjQw98/SVZMuaUtTrW76oxME7clTsM0LUMwoTIUmxnernGoiK6v20fBvrjhBFjcRMPFNb4T8FkTqxrjPOyY4yRSNLhX/byV2oS3rdKNYEtqUmh0iA6p1h0mbDhEMk8t1+XtnwBlm6qbV269eoalwh1Kic+pMFGFSNA7lCY7XY/zcQiiItw7Ch9KNBLDd/koubg2/gwcWgWc22dli5xFLI91a3nyLlRB27pbPuP/uXRD2I4nFocYlsr6/p7vItkq/237fSXTziYPa1it3G1eRyccbuHLhCT5aYH7qkkkRKj8QgyJg2iHxY0tyfpxHFoNTO9rdWOcR7Q/WUVK2Gm1cCUohNDahVIN1A3JmHGNCHmpNDqriufX0mmK1yXeV/E6ZPdRYTvFasG88Pgwjrleh2Ldfj0i8pXSNj8TEdih2I7Qj+vgSs9wFGM8sTwspeXJW+txCtcfQxcaOsSCFSwWuCGyi0vtS/7SCvMrISNu/Nah4xjcMMAToSkM7elAMXuvCp8bO1lFGj0ItB/iySMUKWL5wUwjMXyXtzNuYN9iqxvhXIxwKC7fEshdGKZBycSUTPh2sdy0fVW7g6uRqBVgj/wN9F2iZoUwjVAds1THVekG8zpEPf4rZJ27+S2gvNjR2SDCGZYKu/yCjnnp95+3OBxHUhE4ARY3dsROTydOxAjLjdnWH0oDn6uA8evV0mGE2sf7fvG3BGlxVjYKqTY+vw2443P/78o3N+d4mu5Q7Ar/viA+5+EOS5mJmt+U3jZrOXbh3n+j1bpy1zig9QDpzNJRCIsbW8LixvYOxXa9gbV6Vnm6Jr8NhdsDhQXX6Ox/LMkiZoa1SWsbC5QFqrSD7RCG7ZSOv1nXVIj13vl1ZIVfp+Eq2xkJy40J0VLRSr27gQ5D7Htv0wiLGzsi/FCdcYE513Ljsv4mWL5FcJhtx2GROU7evEtBQ3wB1+2Tq4xpizg9vpo2xmus6xQJQtVKMrJT8XMoDrHe+vcAL+2PnOW4xZOeYVcv3lpO1TqEsVK38b+rpKLGrdMwuF9QC4sbG+J2Z/A1bCbhhrMKuGxQwiHgIsmZV1sn0GcB0O41hdUrXITefQ8UF4HLFK8JXP8UwqZYTW3+U3llxJCVhIwmc5nUgauoZ2TIb0Jnm57fCvSeDVTtEPr6k0tCacSQnZe7vgFaPw88Nlf7suG0hTEUFjc2JD2DfxxRYbmJ9tNUpjHQ5iWFGdSIGxVDfO1ETseRPJd+2X1jzHLjFy2l0W8n0p1znqJAhQArpBwtn9aRHFAj5CTcYagnKzMTtbC4sSHpGVxqwVwM6ERiofimEcNS3tpGRkdgeIcOKBzXSLGgZpk8xfXXwFLKWyMlKiqGiJaqJpMuwiF+E6qtX9Vu9q/fZCVOPfZRBosbG5KWHuPihvKRNOkNVO8M+2LQsNTNbwN3fIaoEzc0dCo1T6RM9fdPAu79yfOEbaSFLlQ7C5QHBu6CLsTVsdVStCrQfx3w8n7ptt35FXCbljpFas5DFJok43P4W3co4kfTcdEDixg7w+LGhqRlONwioMZMTYXlqH6OXZ+sjLLc0I1Yla8MVat+PMR+GDzkkJ4S2nITVrHDMKDoHkokZ1bGWznIh0jP9UPChgp2akrqJxI4uQtJT6fK2017Syzkkv6/aHXl6ytnPqBFf0Q1ZLnp+bvMcYlygcJWIdWwuLGt5SZCF3GzJxB7P2QN623cU2YVLiAz3ZjmyDnF/m8CkJAn+3ORav7TE/Or38YDU4B+K0LP9/BMz3vnD4BtU+Xn8wq7wLa7bGQNMHJYqnEvz6vraP3DaOFez0Y4zdKDw9PrgRd2Bs/XZYTHQlTAgmSM4VCwvNUtYGwIixsbFmScvuEIIoatSxGYJG4ohXy4JQXouGWmqVtHhVaeaBCKwJBblxSUBXbQYfn1lm3iHyKt1PlV6wiUqB1aZFRsBQy9ADR/AkhN1uFQbOKwlNzxU1NuQS1FAwSkuAjoHZ/qz0jrExg6a0Xp3p7wwX9akSpAvpKhh3fsDmWdrnITcP+v+tfBlhDHYueeLfp4ciVQ586wVzN57UHsPa3QsdhZ3HQfa9y6wr3xPPCbxDrjlZ1QvXR4E+j0rkJSOg1to2R3FA0iFy2jJIrlQnSpXdc/6ckoahZqhqWCLDcqMsje+KL2tjS831PHp8H9QKvn1C1DZQLq/Q94aLq6+aldskMyKs73gwqWLitxagdOWacfmuYZKtSLGfXQOBTcFrC4MZJi1T0ZHsPEBTemrDsSnTe+IL+CgMykNNQSKaSSgsUnqFu29XNAi6cUqgnrKEApt4yWdVHHTpEhZNHJmSfg/Mm0tfMI431u5ByK5URAzds970VreHLr9F/rGR5RAz2dN7jPs6/dvwQ6vqluuaTCnpwlctmKKcuyOCrpptflfXgCfyePzAFuegOoeVv2d1Xbm9zxGZHnxiZYLbhuHelxDqd3rZS9zrpyI4xqosgGGTuQuIlaKNxVKTPp8S0aVmbCDVBrPgxvJ67l5kwWGqqcnD1zwHsY4iaoYw9xjMhPpHmAI7JaSBT8Oz2EQ7FKy03n94Fy1wE1unjmkRv+keLub83pDP83EbhwGNj0syc6T8oKOc3rk+YKHjKk16SHVG7MgDT/+cQVwjVsT++x6/gWMPcN4IaBcBzXPep56YGGmK+d9/gv2VG4MQJsubEhJV3ncHP82shsbM04bfOLn1T1oKm2kRk3CY3r9Hbi4WzDZ7kJ+N47PBM49CRExkjh1n6Mwhl2VEq+57PcqKwHRLlumjysz2fFiCruUlDbC5bzJDKUymgsfjLXWlnbjN8GHb+mj3pC4DWhs42tnvEUISWLltHQvhBmF2ns/pVHgPf40bh1kl+SnLDR6+vFGA5bbmzIDznlCsuZQPpVbfOHnYzNYquUmvt800dUWG5U5IAJnFe8TPE62aUPAtf1aIi07/4rN+94i0PUA61R3lT5pRqaL0i9tYcsRWa/xNFsiou7VIiZEOcqR07gtpHG15ZSgoqQmkGJOsBL+4BcBWEqDXp4wvAj4Sj9xBLgyhmgcCUTN8JWIbWw5SbWIQdNLZSo63G21YuW3DBKN+XmffVtX40lhsKgQ81/6Zh6i4d3P8T7Q+G2vu/Foqe2tiEbMxFbTGgIp4rIp+TGl7JzsDw2H3h2szk33xL17BHBI3ctth8MlKwP3PaxjcW9TTtE8olSW9OK7jlPLNa3nUhdP6Xq27MafYxiC3EzevRoVKxYEbly5ULz5s2xevVqxfnPnz+Pp556CqVKlUJiYiKqV6+OmTOz8nMw2p9stN7kydnWSNN7kGNpGDdjMqGTU3PvWdLT1eSmETsdy1luDq8Brusj7/RLkXNKlptb3hNNF4mI7mOgCb+6QRLTGwX6hGgZFoz3jyoRb0vsW1W2KVCogjmWm/ylYA9c8u3ru8Tf2qeagHNRuhFMwQk+IBQtV6qB1a1gogjLxc2kSZMwYMAADBkyBOvXr0eDBg3QqVMnnDx5UnL+1NRUdOzYEfv378eUKVOwc+dOfP311yhTpkx0FMezmsDQZq25edRYXmrdrrSC4K+Ccm64VRRulOmki9UC7pkIVGgpPT1DZW6aUNvxOslKJcajzqR4Lf/Pwnucf64R3/Q4dU6jWiNtKBqEhIcRlhvVHaTRHalNOmYzBAKFtouh6Ks2rwD5yzrzGDJMLImbkSNHok+fPujduzdq166NMWPGICkpCePHj5ecn74/e/Yspk+fjlatWgkWnzZt2giiyBZQR12mCaKGOBPEDUWZlG4ss7yUU6yKEOmg/CMB66FQXhpbp5wySshZYvQMY9GxExLjhRsKLvaPCOcnGXBM8pUIOYsi4rao7dyNFgG2sTqobEeF1jIi1SWdMDHQ6brdIHXXVCDPbgJu/1R6e3Y5hOHAuWOccy5jQdyQFWbdunXo0CE7H0lcXJzwecUK6VTxf/zxB1q0aCEMS5UoUQJ169bFu+++iwyZStopKSm4ePGi38t0vP4IdqDPP0Ddu+V/HVqTWKkRN5R/Rc56U6hi8HeB1iNaPrACMAlGSqond7OjnDR3jw8/siawyrIRJRZCiZtwwnaV5g+3Q/A7lmy5UQVdg5RY8ZFZ2s6JmsSSStDvqkkvdRmKowWKGizfEijXXH9maCZmsVTcnD59WhAlJFLE0Ofjx49LLrN3715hOIqWIz+bN954Ax999BHefvttyfmHDx+OAgUK+F7lypWD6Wi1DpgJRSMo3JivaW2q2g5TbpsUQtlvecC8AZehN4JC7PuSdiXUBtW1Sym6pc8CoMf3JpxLiWEpv8nh/AzFPjcGV3wOFL5UH0lNQctwEfuv2CVRmto6XmQto0SegSI+lDgSn5ZWz3re63TX2EiHWTromPWe6UmYaBsLnsXUu8fzXu56q1tie2wQhqCNzMxMFC9eHF999RXi4+PRpEkTHDlyBCNGjBD8dgIZNGiQ4NPjhSw3pgscI6pFG8R1I1bi1YSj6J71EO6G208GDJyyFZ+bsW9KHTaFgSpFM4jrJXlJvRLwvc6bd68/5KeVaWxQnhu5Y6EiV4qRlptwEVvUaB9aPuMRL5QxWI66dwIL3gkvrT1FHt38NnBmD1CyHiyFIueOrAeqB1j0DEd0PVdsDby41xNNZMT6olkYRHPbzYAc91856KnezthX3BQtWlQQKCdOnPD7nj6XLCld2I0ipBISEoTlvNSqVUuw9NAwV86c/hloKZqKXhHFRl79l5ELmaJO9UpqBvKI7hf7zlwFNB0eN9xuf4Ek+MOs+BzIV0pe3Dy+UP0m2g4K/i71siej6MEVnkKUKTqGF2vdod3B1gihKpfEL3uG4HkNQUIAkjWAxAeVQdDqUEx5VprJRIh5oSEZclpXU4pAijYvZw9NUmit1VABUUMIZbkJOFd5ws0nJSI+wvc/xlyMsI7GAJYOS5EQIcvL/Pnz/Swz9Jn8aqQgJ+Ldu3cL83nZtWuXIHoChY1lFCwPu3BVUC7ZN9YAWSJ0f0PTekouOz+jkce8Ls5r484Mtnjf8AJwz3f+eSgCO2m1Ya5kbpXKFktVmamzpaf6end7ygrQ030oBmz3FNd7/aSnjeI2R0zchBqWCsc/QuP8lENn4H9Av2UqVh2nfTtkhWvZ3z9aTAvh+p44sWyJHuhHSlXUGz6g/1wwTBRjebQUDRlRKPfEiROxfft29OvXD8nJyUL0FNGzZ09haMkLTadoqWeffVYQNTNmzBAcisnBmJGrVCXfMdG0CRm3AAN2BE074S7kicIQ57Vxu5ERqG4oky0VIRQ7/em2QASs+5kNwL0/A5UDkmOR0Gn5dOjV5S/tGUahgoh6REQoS4Uanx5NlhuX/jD6QCEm53dB50lNAVGjstxqQbYKu0Pp8qFn6E3KWhkuHYYC3b7goR0mJrHc56ZHjx44deoUBg8eLAwtNWzYELNnz/Y5GR88eFCIoPJC/jJz5szB888/j/r16wv5bUjovPxyljmb8fFs6pNBfVyw5cYlW1CSpn2/Yj9uq18avmpH7kxkZLrh1zVKdZR6xU1gh1y4sudlNGotMkr+JVLkTNIRCi4xr1qq3xIhXy9XZDp6pZo90Yxc3iUSz1oFtCoc4FDMMNEsboj+/fsLLykWLgz21aAhq5UrRRlgGUnOweN0pmS58frjZGZmSJrx3vh9G2ZtPQ5fqT63G5mBAkTqyVDcSbd7XfoJPWQElJmYdPOv30O+RpOaUHCtIsLv2JvYoRWtbs567//VU3m625fSDt3RDtVPSj4V+ZIaToiWYphoFzeMOaRm2VfEDsWBeIVPl08WYXbANO9yy/ecAXwuAW7BcqOp022TVf1azMMzgNmD1PnNRNPNn2oNeek0HDi2Eah2s/pQcKUhBKo7pUSQ5caAfSSfpZTL0n5QRlD9Zs/LqVDEU1hRTwzD6IHFjYNJdecIstzI1SE+ejlTJGCylvcffMpaIBPnr6Rl2YQUUCojQNBT+qNzgr6+nA7M33gEXRuaXU5DQ8dPBSP3ZDu9K0K+PV5aeIYFfejNUNx3GXBqB1C5jfK2zRiWIp8lJgotKmy5YWIbyx2KGfNIgceP5jT8QwefSc12vvYKn4vIi7fSHsSbaQ9heNp9+C+zDEandw1eqduNGz5Y4PfVbZ8twTdL9vrPR2UQhCiqgKR4WXy1eA9avfcPjpy/mrWSj4WaOl0P/A/P/rIRa/efhW06mft+Afou9VTGDgdV/jQSlpuSdT0RYqEIEjfsSBpzlL3O895YOgKSYWIFFjcO5lqW5WVMurgUgguzM5v5PomtOuMyuuDbjM4Ym3E7OqaOwFlkZ2V1Z2VcvVgpOJnZ1iMX8faM7cHWCBqiqX2HZNvenblDEDYjZu/Izko7YBv2uD0Wmz2nLsNcNIgbyu9iRDI5r++NETWclMQNOeYmFQHu+Ez/upjopOcfwGP/eFIlMEwMw8NSDiY16/QmQ1SjKUDQKPnjiHm7/HjMPrYFR8Yck53nWloGciWEru104Wp2Ze7UjExrrPe6NhBmo8iaVbubRM4fg5P4UfTNdY9xCHAsQtF6ZaOocC/DmARbbqKNHP5CRYkUt3RSwzTkwIyMZlicUQ/73dKZoAMZt+o4jkDZqbTmG7ORnKJcaHLc0n1o8Obfvs+iXIx+vDJ1i5AJ2TT0dPxy7aGsvESbV5SXp9w890z0zxsU3DDt7ZJcDQsbe8K+MAwTCVjcmMVNEuHPWjLjGtBpZSqc3qfSnkPPNEocZmwnuHqfsq/MW3/96/c5KCGgiF0nTByaavlsaKfnIERtfSRboAnDb0+vB9qGEDdyGDUsFW74eqUbI7/tWCOwoCbDMKbA4sYsbhgINO8XHOpMHSHlvgikwf2qV32ycVbV4BBcQJ6IPzeeSU7VNL+SdUZVyLle8hbD5ac2IyM+tz7LTblm/oKkSBX9wqRgOWvFDTlz3zVO1vmbMRC6HzS4D+j1l9UtYRhHw+LGLKiT6vyedIkAqbwXFBGjBrcbxW8eKDs5xZ0DV5/fg4bXxgrDT5Fm4K+bsHzPadXzewXM7pOXgpbT1M/rEAVP/rQBKek6w6eNFCGJ+YDntgAv7IIlUJFKisbKXdCa7ccS9NvvPgaodIPVLWEYR8Pixi5c1weoe5e6eRWcTu9LfR0JeQvjvEwmGqVsxUZx/9er8Ph3a/HnpqMh581wA8cvXEOHkYuF5cSYbcRYvOuUnyWLwtmvpCr7DJlabDWfp+QIowNyoPZWqGcYJuZhcWMXKNy4+1jgiSWepHEqxY27ZH3PP4UrI6VoHXz0/CPIER+HZ9tHON17AH//ewJP/7zBzwdHagjq36MXcP1w6QR5Sv7Egeu6eDUNs7ceQ5pM9JXsekRij8LZh88MLiCqqkGMtXT+AHh8EdBxmNUtYRjGBnAoeCRo9RywbBRw40vK81EBylL1gWaPq86I66Lom6SiQK78SHS7USnL3PF8x+q4qWZxdB29DFZyz9gVSMwRJwz/5MwRrKVPX07V7HOz9cgF9Bq/Gi/cXAPdk0oj95WjuGVqCo6mrMfAm6uj/03VcOFKmqAB8+fyz7J8OSUdAyZtxO0NpJ2JlYfUjBE31Ia8ifzTMxSKRCvd0OpWMAxjE9hyEwk6DAX6rwXavRr+um79yHMj95KroCBs1I7j5EnMgQm9s7KYRgivX0uqRv+Wj+fuQvXXZqH9RwuFHDpeXpi8SXBcfnXaFtQ7+x7qXvsGR1M8tSP+2nwMV1Mz0GDY32j+znyfhWfA5I3CUNnoBbt9ViXipNvfz8SldAx1WG4yM92Y++8JnLx4Tfg8bcNh1B0yB18vDsjozDAMwxgGi5tIQB0mVQU2womkTndP/SKKbqFhLIWifLVK5UeZgrnRsFx2B55QqBza1iiOaGD+jpNCkr89p5Lx8+qDvu+vpWcLnXTkwGUk+T5TxfLtxy8K/19Ny0BahhvpGZmYuv6IIGpmbPZPQvh42gCszqyB+1PVCE/t4mbK+sPo891atPvQU93++UmbhPd3ZgZkdJZg06Hz+EOF3xLDMAzjD9vG7YiSCIrLOmUqag3RMNCiF9sijtZ3cCawdKTHN0EjNISjxjnYTK6kZgjDUU/+uB4Hz16RnY9GsrxWEuKjv3f6pfIJXHa3uyzuSR2irhE6LDcLdpwU3pNTswWZWrxDiuUK5Uaj8oU0L88wDBOrsOXGKu78Rn5aueahxY1KyLk4Ls4FVGwFPPibJx9LANuH3aK4jk/vbYgfHm2O3q3kE5A90aYyzCRnfByen7RRUdh4LTfi8O6xi/di7CKjhoCscSjeeyrZku0yDMNEKyxurKL+/zz+MlJQvpFBR4BqoiKVrnggXykgzvhTljtnPOY8J5+dlvxQWlcriqJ5E2XnqVFCOvTcKGgY57+Tl1X5uJgW1CSzYqVEhEa0xYRTzjAM42j4tmkl9f7neQ8qpEiJ3fJ6oqe8DDoEPLPRtKbUKJkP+9+7VYg2KpE/W8SM69VUVcZgshDZASrnQH96UfaK8l8v5cShpIU3fbRIdX4cPW5XwrAigFV7z2DdgXPaV8AwDBNj2KNHilVufsvjGPzgVHVZZBM8EUFG8P2jzVCxSBImPX693/cURj13QBvf5/a1shPLSYVye0mgoS8bcOjsVZ/TrhF8uXAPOn28GGeprESe7MKhnT9ZgtqD52DKusPYdzoZi3aeEr5ftvs01uwX5fYRCaJQRUWVLGcXr6Whx1crcdeXyzVHnTEMw8QaLG6sJCG3xzFYIeLJLG6oVgwLX2yH5pWLBE2j3DDrXu+AbW+KhsUAPNC8PEoVyCU7tOUEaOiLQsYPZfn2vD97B3aeuITvVuwHqt0slNN4JrU/th/zRGR5SYiPw/krqXjgm1X435gVQoRW4LDU9I1HVLdDPNRFupHy9nihCDI7s/vkZYz8eycuXM1uM8MwTCRhcWNnxMNSEaZI3kQhJ46YfLkSsGJQe8x4prXf9zfXLoEmFfRH8+TLZa+gPQoZp+GmQPFCY0rp7Yfhj8yWQcvkiHcJFhwv6RJDeOkZ6otfUAi7eFhKcAoXOU370biX511t+Q6T6TRqMT79Zzfe/HOb1U1hGCZGYXFjZzq86ak51Gk47ESd0gX8Pn/Vs6kgfO6QyfqrxOahN2P6U61gN8hys+vEJd/n/Lk9QvODOTsl57+WlonuXyz3ffaWgRDLECnBI4e4jATpGleASPJyLjkVu5oMBh6aRrHjvu+/WLgbbUcswMlL2WHxkcLrm7Xh4PmIb5thGIZgcWNnClXwVItu8SSigU/va4RCSeqtTcteuUkYAqtSLC9+6qMQ/m4B19IzcfPHi32fdx6/iKF/bMNXMpmF+/6wzu/z0v9OC8KCshN7ycj0H04aNW+XIEKkEAsY8rnxE0ki4dPq/X9w82ersDPPdZ5hziw+mL0T+89cweh/stefIkp+SAJEKcpLPMQk+BvJoDTNHl5YDMPEIixuGH2UvU4yJ8+9zcoL780r+fsRta8ZnBWZsid7aVmlKOxEYKf9w8qDmLB8v+rl+/24Hs3e8a8P9u7MHUKSQS+j5v0niJCKr8zA69O3+ImPQL8aCnH3MuSPbfgvy6pEyQ2JRbs8yQK91pzs9bh9yQzrDfkbmw+fFxySqaTFg+P8q7AHsv90MjqMXITGb80VRE4g36/YL0x75ucNeGfGv0LNrHDUzY+rDuClKZv89jXQmiU+RgzDMHKwuGH0ce9PngrMPX70+/r5DtXxdc+m+FoUQk7cWD070oh46PoKQausVDQPYhUST7XemI2xi/YIn9NFVh7q7MVh+LO2HkfHjxdjwc5sQeMVOeTU3OituUGh55/9s1sQTHd8vkwo6UBWnWW7z/i1wWvJobIPLYfPx7O/eOpvESRyZm897teON373+NTQ+r5esg8j/94VluXmtWlbMXntYaHsRiDUtvYfLULTt+axwGEYJiT28uRkooe8xYFWzwZ9TeHiHWt7wsd/7nM9XpyyCW93q4vWVYuicJ6cuK5iYRRMSkCuhODoqom9mwlRSR1qlxCqfoszDccCpBuGz9oh+OaUyJ8dlUafNx0O9l95dMIa3/9ULJTYcMh/vp9WHUSlIv6iUews/eA3q3Bn4zKCwzQNu335YBOhkjtx9MK1oKG3obfXRlJiDly+FhzWLvZREufn0crllOAoKxJV3uzUlLGZ6qYxDMPIweKGMY0WVYpg6cs3+dWoUqJ8kSS8fltt4f+tb3bC0z9tECKQKBTby5Dba+PNP//1ff78/kbCsIgGX13bMyLAaZkSBL7825ag+cT7TFXTl/x3Cr2/zRY8XpSKdC7dfVp4eXl0YvDyYmZuOY7Vojw+SuitEyslisTO2GJna7O4dC0N249dQtMKhfwi1RjrIevk4v9OC1GaUg9JDEPwsBRjS8iSMOahJpj93A2C5adsodyY/0IbVC2e12++xBzxQqRWOPRvVxV2RkrYBEJd/0PjVoe9LaUs1KFy7ARqkl0nQpfL8CLO8EzihhytvUVH9YobWqcap2kpKFcRWbAmrz2ka3lGPXSO6CFG7bmi65weaN6btcP0tjHRC4sbxtZQpNCD11cQLEAUVZUUkCyQ8su8dEsN3+d+bYMLg4bitgalULlYdPv7BOW+MQmtVhMKR6dq7kqQLw9le/aycu8ZwdG6d9awm+BInCZytk4Pva8Hz1wR1klV5PWw47jHWjh1vfrEi3IpBR7+djWWi6xjjD9v/bUd7T5ciC8WevzNQrEl63oiXy+GkYPFDRNV1Cjp72uREBeHB5pXwNrXO2Df8C54+Zaaist/9L8GQd8VyZMo+PsEIq6xFci3vbOixWyCOHQ8HLyOyXrFTWBeHXJcfvrnbMdkKUtRYBj9j6sO+jlT3/7ZUtzwwQLfd79vPILe3672iwrzcuLiNYyYswMfzd3pc77Wyo7j2dmn1dQpIzEmJ+BemboZC3eewv3frBJ8ktgZOpjxy/ZJDscyTDiwuGGiiryJOYTSEGLLDUEVy8nKEwjVzxJzV5OyQfNQbp5yhf3nC5XDpV2N4kJ9Lrvwy5rIDJ+IMycHcuDMlaDwd68/kBxUi0uJK2kZghVFLLpoXxfsPIVP//nP9x2Fty/ceRJ3frEcoxfswe8b9T/V3zJqie//UAYxElP3frUSt322VGZ6iu9/ypvU74fQlqTle04LZT8i4VvEME6FxQ0TdVBpCK+PZ60ASw7xaOtKvv+71CuFllWC62epqWiu1JF763MtGNg26Hsn+58qFe30RjMFckwUdUW5cA6fuyIkIiSrTKgOXMkHaP2Bc7j3qxWYteUYqr8+Cw9/uwZHzl+VFFDisPlwhvvID2j4rO2+dlHYvG9eibbmCLgY/pEIcxdDBVLv/3qVULD159XZFiyCjhkNtzEMExqOlmKikk1DbhZKHhSQyIg8qHNNjFu6z9e5UIehBnJaPnwuu3PMGR8Xskgl5ebp3aoivl3mSfDXoFxBHDyTjHOiQpdOQko8qIWcRsm3wntsSxbIJaQF0CtuNh32DAWt3KscvUXFTIkNb3REoTw5g6xKa/efQ7NKhSWr3gdu3esHVL14PmF+8ZAbXSu54uIlfXeC1ut24/3ZO4VCtL1aVvR9f//XK/0sYWIembgWi3edwtiHmqBTnZKK+8wwsQ5bbpiohCKkiuVLDGmJiY+Lw7lkf6FxZ6Myvv9H39/Y9/93jzRD57rZncYEGb+acoWzMysTYj+f+5uVw1WFYZhYxitsvEKALD2bswSKHGeTs4d1woWGs8hSJBZMr/y2WcjU/NZf2ekFxIgNN2tFIfAv/LopqLiqlrxMW49cxJhFe4Rs04Hfy1kASdgQ32b5qDDmQz5SeiPuGGthccM4Gqo4/sLN1YX/H7zeUxrig7vr4+/nbxQckG+tX8o3b+VieYUkdvvfu1V4tawqXRKiWF5/UUVWCC/Ub/ZrExxaHk401rQnWyI+yse6xDW2tNBhZHZ9r3AhP5Zqr81ClVdnYuTcXcIw0vQs35zvVx7wJUIMjHZad+As/j16EXeP8SQ3lBMz5POj5F8k5rQK0SblQ0YYmdOJOu7HJq7FUz/piyqzErN/EeQcT1nDAx3emeiAxQ3jSAbfVhs3VCuK+5uXx52Ny2Lpy+0w7I66PstO9RL5ZDsPOciBmPx3Rt7T0O97cZI38tF4ql2VoCGOaU+2wn1Zdbe+fCDbWqSGRuUL4f6sZaOVPt+thZ34dP5/+G39Yb/vpqw7JBQzFXMmORV3fbkCv6zx93+R4tlfNmLQ1C04cMYz/EY1w+QQh7bL1dKSuzq9loRjF676FVHVA/lDzdt+AjM2H/PLNSTHqUsp6DZ6GSab4MCuNemjGfYUsZXmt3VHBCE5Z5s+Yc5Yiy3EzejRo1GxYkXkypULzZs3x+rV8snIJkyYIHRK4hctxzBiHmldCd8/2tyXwbRsoSRdmWYHZll9hnWtIzgQ/9TnelRUqIFF90YST8PuqOP7bvpTrVAgdwKG31kPe97tgs71sq1FSnSoVVzwryBuruMpaUE+Kv+80EbzfjDBTN/on8PmrRnbhWKmUny34oCqdU7bcATvzNgu+BcpIbb6pAVUi/cydvFeSZ8j+m7V3jNoMfwfwYmaIKtT4Lxr9p/1S4QohXgZ8egLhdkHltMgPpyzExsPncdLv22GHsgCduaytNXKatskDRM2f3c+O207BMvFzaRJkzBgwAAMGTIE69evR4MGDdCpUyecPCn/o8yfPz+OHTvmex04oO7GwzBa6X9TNSGHTs8W2U6fap787mlaDj882hwbB3dEw3IFfdO9w0trXuuAagHZlr0Uz5eIKX1b4Jte1/kcR0lY0fDUwoFtheEzGjYzm8CEiU4jsHCoUiSYFkL5XJEwmSiqMP/HxqOCpYc6/kA6jVosVEsXD5mRHqFhNIJKZ1A5glqDZ/tqgnmvQ8qyTA7QFK6uNTKs6TvzhND1QIFzSVT3iyxOWvxRKH9Ql0+XoMnb8ySna7WkGg1lPD55KUUYvvS0x9LmMNEeLTVy5Ej06dMHvXv3Fj6PGTMGM2bMwPjx4/HKK6/I/ghKllQXLZCSkiK8vFy8GHwDYRglKIeOljB1gqxEratJ++wQ5Aw9d0AbofOgHC51S+fH85M3CUJIHMoeODwl5rd+LfD2jO3YcNATjnxX47LYfuwi/j0W+honodT9i+WK81BGaG82WEY9FO6uRI+vsiOiiBeneKwg/X8O9nvZffKyUC19x7FskUEV4//afMz3ef52z4PgugPnhLD3VlWL+pWroKEkcSFWOcQGJK9FhzIr0xCul4tXs/et6+hlgk/bj481VyVMVu9TjmpzxVi2b8bBlpvU1FSsW7cOHTpkJ2WLi4sTPq9Y4e+8J+by5cuoUKECypUrh65du2LbNv+IAzHDhw9HgQIFfC9ahmGM5rP7Ggkh4bdoDNGljoMEDQ1l0TrkhI0UTSoUFnx5vP3K67fWCrK2fCHy76EEiL1aVMCbd9QJEkpSfHpfIy27wmThFZtauSRRad3LrK3HJCOqCHGuIAp7n7bhsJ9jc/+f1mPsIv/SBjQ9UISRaAoksJsXF1kl4bt8z5mQ9cjE9eKU0GopMUsMscXGGVgqbk6fPo2MjAyUKOHxJ/BCn48fl06bXqNGDcGq8/vvv+OHH35AZmYmWrZsicOH/Z0DvQwaNAgXLlzwvQ4d4kJ4jPFQxfMht9expIL0+tc7YvkrNwk5XNrVLC58lzshXhi6oiSG4pv2m13r+uVVCZXDR4obqxczqOWMGCWRQDmd5Ph6yV6/z89P2uQX2k4lMIbP2iEMbfUcvxoTlu1Dk7fmou6QOX6ZnyeuOBAUZk6WxaF/bAsqqxGY7JISKf656ahQmV4OcVRhqOEsGvIaMGkjvgnYt8DEhmbCGie6sXxYSistWrQQXl5I2NSqVQtjx47FW2+9FTR/YmKi8GIYp0KixmuHefzGyiiSJ6cwNBFIYDg5zfvV4r14oHl5v3pOoRhxd33B8VItRfPmxOnL8qUsoh1y8j5vQNLGNAWfH6WaVHtOBTsvT14b/LBH0WGUK8ebL4dYf/CcXwRZoHj9efUh3/DYD481l9w++fuIIT+zgkk58fe245i05pCQeiEhR5zwEvslkQAXD2e5RHJi0X+nMHXDEeH12A2VfWUpKBrNi1mDR+J2MNGLpeKmaNGiiI+Px4kT/qF29FmtT01CQgIaNWqE3bt3m9RKhokeyPR/r0zYeFyAvZ2SD3ZrWAYViiTJipuf+1wvFKqsViKfzxoQeOv/pmdTPBYQ6k1h70PvqC2EGHuFVsv3/lE9hBFNkAO4EeLmkoKvTqhSIGpYJeHzIhYLXtp/tCjou82H1Q+1Pf79OtzduKwvoqrtiIXCvtUpnV0qpc6QOehQqwS+7tk0e0GX8hBdqAg0wzBR29A+UAkOeqDwRnIyDhyWypkzJ5o0aYL587OfAmmYiT6LrTNK0LDWli1bUKqUuvBahok1utQr6bPUBFpyapfOjzyJOfBn/9aY8UxrwR+HGHmPp3p6iypF8N5d9fFwy4qCzw49bRcWlTBoX7M4OtQugZ1v3yIMzXmdpSnsPTFHvJBjiJxZ6TX5ies1t538kGgbdkaNs64doGGjSECOw+JQca9o2yaKBqNRqcDEjhSt9tu6w7LDVoEWFfqkRixT6PoLkzdJVpGXwmWi7w1FxdFDwugF0g/jNPwXDQVTh8/cjvYfLcQllaVtYnJYisLAe/XqhaZNm6JZs2YYNWoUkpOTfdFTPXv2RJkyZQTHYGLYsGG4/vrrUbVqVZw/fx4jRowQQsEfe+wxi/eEYezJqB6N8MSNF1GvTAHZeeqV9UyrU7oA7m5SVhA8gUKIQuIDy1u0qeEZwiAh8073usLTuVfkBNKgbHZIvFry507AuIevU0yIZzXkEL7kP+Xq5tHOxWvpqkPKw4HKWtzVpKxkxFKg2KAEiw2H/Y2+baqgX5sqsv5ulHSQKF84Cc92qBayDZEISaccRFKh8lSRvmmFQpjSr2VY67+WliFY6ppXKmyKhYhyMBE07OgdNrQbloubHj164NSpUxg8eLDgRNywYUPMnj3b52R88OBBIYLKy7lz54TQcZq3UKFCguVn+fLlqF27toV7wTD2hbIlU0FPtQQKGy9SN0kqNuolf64EoaORg0QRlbyoNGim6rZQqLEU3RqWRvH8uQSfIasRO8o6GS1+Vmp5aJynqGkgUv7GUtqFhq9GzNmJ71bsx8KB7ZArIU5WnBw4Kz2sRU7U1El7cUnkPaLszUk5jesuA4eIiV+y/JvWHsj2g9LLa9O2Cj5WVEdvZA//jOpiyMl84or96Fi7hJD6wUlh87b4Vfbv31+wvlA+mlWrVglZir0sXLhQyErs5eOPP/bNSwKHcuKQzw3DMJGDSlGQz067GtqGjLQ+FTfKEmV/Pd3al62ZoIivV7vUUpWLaFSPhn5DaUYjVU2cUYecxStwtGnPqctBVdLFnLiYIjg29/thvWZH4Tf//FeyevuHf2eX4mjw5t8wEgqhp30SkxwiP5IWfssqLUIO2Up8PG+XkLxQys8q2p2v+VfJMIxmKGNyv7ZVdJnwF7/YTvDp+Skr+oaEyfiHmwp1wMS81a2ub/11yxQQsjXPG3Cj4MAcmKdHLtvz0zdVRbdGZQR/IS9yw2Z6aVqxsKHri3WoXpbYIrD31GWh8/1ioX+uHilmb5NOIeLt8KkeVyjoknvqx/VBDt1URNXrC0S+MaGSNYai5zj/MkPJIWp7kSXpl9UHhXYQVMai6+dL8f2K/b6IujnbjuOigh/MjuMXMU/k6xQqsSJB/kFyPkJ2zglk+bAUwzCxRfkiScLLa5EpVzhJqL11U80SKJyUUxhi+PPp1qhQJDjPTtXi+YSXF3J0pnpOQ++oI5QqCOS5Dp7aYM93rCbkfyHIP8NI59qaJbPbw4TP1qMX/RyKv1nqn3snFCQC5KxpVI+LhkZJNFORVKlaYuSvIlUs84YPFuC5DtWEUizN3pmPPDnjsW3YLYptGbd0n+BAfFv9Uj5nfS9Hzl/122ZgOZBAvlm6Fx/M3in8Tw77O49fwqbDF4TXQy0qChaYb5ftR7NK8mKbfHoICiAgP7tQg0oXrqYJw37Eg80roEBSAqIFFjcMw1gGWWTEDOxUA893rB6Uk0cOEjVv3FZbmH/egDbC06y3vAF1Pt71dG9UFs0qFUGp/LlwTKVj7Le9r0PvrMKUXqiDIj8gsjZRFM4tdUvysJTBkAPwE22ynVR/0pCDiaj++iyse72DrxRKIBSKfTY5VbZIqlIAFi2TnhWWn5yVAJH8Vqj4aa4c8UHXgjd9ApXLEJfMCOTpnzcIQkKJpaIhvMAQ/tOXUzAlK7eRGmvM9uMXBavLpkPZIf5k+aHAADHiCDNPrqUE4eHDi5TllhI6JiXmQBuLk32yuGEYxlaoFTaB81ctntdvWXFUF1GmoMf5Wc3aW1ctKun0SflJvOv1JrtTyrZLOYTkfEWoCOpr07eEfGKPRcYuCs9R/Ksle/HnxqOC03kgK/acUbQGUXZkJT4XDdHc9tkSXzmMHHEurHy1vc//S2l4yMv4pfvwSOtKQWHxUij57jaVKUYqB4XQU6kOMWMW7vWLJvvo75347J/sffXWKxv8e3a5o8BfyMmL19Ava0jPayGzCn7kYBjGMVC4r5db60vnvlITGpsQ75KMzgkUTITSDVwqUzTx/l31ULFoHv8kdoyh4ujohWuCdS2QUMNcixVKSAQirvNFnb83Tw8xRCQC5Bj21784KhqeUsJtYE7m9Ex3kKVo1T5/kS0WNoHRY17I7+j16VuwNiu0/ZwomaW4eKsVsOWGYRjHQJablYPaC0MP3RpJOw5T5BRFetGTNjmuks+ON1qGxNHBs1fwQPMKKJ1l6SHIeZrKWqiB1jv1yZbCesnnJ3BYhcLy727iKeBL4cXPd6guRK0w9iCcbNDiJalCuxqoFIUSv649JBQsTVEoz6HYJrdbEOBiC2OGRKJAsUanobZApLY/cq7nuv1h5UGhlp34gYCSEYYqlmomLG4YhnEUJQvkCoq8CoTEipcn2lQRCj5SKC4VHj109qowxEV8cm9DFMubiJYyFhgpcsS7UL9sQeFFfPdIM6FgpReKFBMPnxXJGyyaXulcU3AQ1cO73evh1WnBZRWYyER6kYigmlwnL6WoWiZUluUXp2Rne9bDL2sOCdf3iLsbZLdTYpsU1k1DUQt3nkKTCv7RiAQlcVx7QNmfRyyQ0tLdgHkZGELC4oZhmJiHQtu9eIUN0bVhGc3OxwmipKNe3xx6ql2++zROXU4JSpYm7hDGPNgEbWsUE4bOutQtJfh0UHZgJa6vXBgr92Z3OiTsKHN0j7ErcPhc8JAHW4rMg3LjUMi6uNp6KA6fk/bJoorsTwaEpOthUJbzsdh5X0rcUHFUshARW45cCJouFuhSzN9+AqUKZFs7Uy0uI8E+NwzDMGFCyQwrZoW331xHuugvWX+kxJI4ERpFX3l9gihcfsPgm0Num4qfBkLO0+KQ4HKFszudPInyPkcUks+EhxZhQzwywb/orJfnJ20UBIdRjF+aHeUkZRU8HmZ5jUcnrsVXi7NzEbG4YRiGcQC/PN5CCBV/s6t/PpNQKAWUiIevpLIw1yiRD3c0lPYturVetkP1G7dKl6fZ9XZnDL7NM41S9Xvrh0UCsYWMCY7YkqqMHg6nL6sbJguH6Ruz80el6fQRMgoWNwzDMAb5+lBZCHE2ZDWEinz/4K76aFC2AGY+09rv+61vdsKc52+UrXl0U83imNK3BTa80VGIzJKK7qK8LBSKvOOtW4QaRKEcQD+9L7jUjZ58Jm93q4vR9zcO+l7rsXMqGW6KjbJv3SY1WF3dnMUNwzCMhYTKBXLPdeXwe//WQs4WqkDuzTAbSgjQeqk0RKE8OVG9RD588UBj/CZTbVouPP6+ZuXwaOtKeOamqniqXRXc0aC0L18QJTOkDNMTH2mmKQ0/Zeu9r1l51CiZT8iFQgKMoGr0m4bc7Fu/NwP1xsEdMff5G2E3lIrEhsvPQpkFdSHidiXVYnHDMplhGMZCaPjok3n/oXnl0DWqJj1xPU5fTvUTAGrpkjVMte1osLOoGLKoDJi8USg42lk0tOWFrEVUa+iuxmV8pTDiXS6kS2SZq1IsD/ac8q/GTX5H3uE2rwDbPPRm5EvMIXxuVbUIJmdl26UM1MS1tEzFdUYCyps0Q5RluJCJpQjEifKilRd/3YyZz95g2fZZ3DAMw1hInsQcWPJSO8SpyMxM6fH1CBsxZCGh3DttZSq6Uyd+c50SskNUZDGiPEFihLZnReA8074aknLGC5adjrVKCGUH7mpS1ldZWyqvS/5c2ULh2Q7VhezQ4gKnNOTnRW3ulNdvrYUS+XMJpQ3CFZ9UEoScrbcduYD9WRmnqTYTI8+/x7ITHFoBixuGYRiLUSNsjIJ8dGY/pzzMozX5GiUu9FYhGtDRU6zUC/n0iClXSFmckXh77676stPFFcO93FCtKCb2boazV1J9pQgSc8RJ5muRg3yUKPlj4HpHP5DtGzTu4euECuVEwdwWJnFhQsI+NwzDMFFO/3ZVhfe7Gpe1ZPvlCmWXvZBj+lOthKGuRuXVCw4ppHLe3d+svCAQxRFleXPlELJM/9Snud+8jcsX9CvMKbb0BPLJvf4O1HlEzttkmWLsC4sbhmGYKIeGTUg8vHdXPUu2/8WDjYVio788fr3sPOQM3a2RuqSISpDlhhydvZBDspRvUN5Ez1BXyypFgwSLVFFUqe+oVIcYsgaJhxPf6V5Xsa3NKmb7UdUsmU/wF4oVEgMqpEcalp4MwzBRDjnoeiOprICyLv/wmL+FxCxoCGz4nTRs5RKitMghWYq6ZfIHfUeRX+UKJ0mG35N/Tigo8uze68r5hA/VIKMhvJdkSiRQ4dTVWUUlf+3bQvBXqjRoJiJB5aJ5sPd05B2vxefJSljcMAzDMLaH8v18MGcHPvyfp0bS8DulrVTLXrkJl66l+ZUCCKzjRPXCAsmdM16wfnUbvUyxHYH+QPc0LSeIFqlSCbc1KIXapfMLQiufyGmaIAflwMrcaimWLxGnFGpX1S9bQAj7r/baLFUO0+SbRBXKo9WPTHL7lm6dYRiGYVRA+X7WvNbBV5BUySG5Zslgq43YGfm+5uWFjMyBkPVrVlb4cu1S0uuQonPdkkJNr7IBztIkYDrWLiEptO5pqs8/asHAtj4fKzkm9m4mWJS+6dk05Poo8o18tTrVKSE7DxV7faFjdYy4W97RW80wXyRhyw3DMAzjiISHofAWjKSQesrIvGjXKZxJ9sZ5eahVKj9WDmof5G8Tql1UjZ2o+MoM4b1phUKSJTO8VCvhyRGklUpF82DxrlMy7fCE1efLcnYulCd0Lh6qYUaMfagpBkzaiKkbjgifNw2+Ga44+PIPeflf03K+fbTzsBRbbhiGYZiYICPDP9RKTitRXh0qTREOPVtWlPz+96daYVBnj7Xkf030WW+6Ny6DUqLcP0T5wklY8EJbLBzYFjmyQvm1hvTfnWVNooiyAkkJglDSKyh5WIphGIZhIoDXcuOleeUiwnt+E8K6KWuzFA3KUSh6FcEJfMT/Gshum8LmKSGiFCQ6lr18E3q1qOD7LldCnFBDjJyeveSIC+7ilaxJFFm26MW2+Fkh6k2KD+6ujzw544WIMCqvQTzZ1rzyFGrgYSmGYRgmJgj0iXmnW10hquhOE/IDVcga7gnF8kHtkZqeicZvzfV9R7W0aNiKqoOXLpALy/acwZ+bjvr56ZBlZPDtdTBxxQHhc26J+mAJ8cECa+GLbZGSloGP5u7yRX75t1t9uDoJmoUvthMcnKnuGA1FkXx8sm1V1Cqlb9jNKFjcMAzDMI7mx8eaY/bW40HFLgsm5cQLN9cwdFuU6+fwuauoW0ZdeQahAGqif5V1rz8OCZh7m5UXIrL6tamC6iXy+i3rrdFFJEqIm3jR9B8ebS4MtdH26OX1EQqHhBxxgrAJLL5KEWJWw+KGYRiGcTSUb4ZekeD6rKEurZAPzbEL19ChdnDUEomcUIKhkUSeo5wiv6HGFQoKpTeMxFqvGmVY3DAMwzCMxfz1dGtsPHRetqCpHH/2b43Z246hf7tqkmHxN1QrKkSHSQ1bORkWNwzDMAxjMUXyJqJ9LflcM3JQdXK5CuUulwvfPxqZzNF2g6OlGIZhGIaJeN4hM2FxwzAMwzCMZuwrbVjcMAzDMAyjA3GElN1gccMwDMMwjGq+eKCxkMdn7ENNYFfYoZhhGIZhGNV0qVdKeNkZttwwDMMwDOMoWNwwDMMwDOMobCFuRo8ejYoVKyJXrlxo3rw5Vq9erWq5X375RQhF69atm+ltZBiGYRgmOrBc3EyaNAkDBgzAkCFDsH79ejRo0ACdOnXCyZMnFZfbv38/Bg4ciBtuuCFibWUYhmEYxv5YLm5GjhyJPn36oHfv3qhduzbGjBmDpKQkjB8/XnaZjIwMPPDAA3jzzTdRuXJlxfWnpKTg4sWLfi+GYRiGYZyLpeImNTUV69atQ4cOHbIbFBcnfF6xYoXscsOGDUPx4sXx6KOPhtzG8OHDUaBAAd+rXLngEu8MwzAMwzgHS8XN6dOnBStMiRL+9TTo8/HjxyWXWbp0KcaNG4evv/5a1TYGDRqECxcu+F6HDh0ypO0MwzAMw9iTqMpzc+nSJTz00EOCsClaVF35+sTEROHFMAzDMExsYKm4IYESHx+PEydO+H1Pn0uWLBk0/549ewRH4ttvv933XWZmpvCeI0cO7Ny5E1WqVIlAyxmGYRiGsSuWDkvlzJkTTZo0wfz58/3ECn1u0aJF0Pw1a9bEli1bsHHjRt/rjjvuQLt27YT/2Z+GYRiGYRjLh6UoDLxXr15o2rQpmjVrhlGjRiE5OVmIniJ69uyJMmXKCI7BlAenbt26fssXLFhQeA/8nmEYhmGY2MRycdOjRw+cOnUKgwcPFpyIGzZsiNmzZ/ucjA8ePChEUDEMwzAMw6jB5Xa73YghKM8NhYRT5FT+/Pmtbg7DMAzDMAb332wSYRiGYRjGUVg+LBVpvIYqzlTMMAzDMNGDt99WM+AUc+KGcuUQHFnFMAzDMNHZj9PwlBIx53NDoeZHjx5Fvnz5hIriRqtKEk2UBdmJ/jxO379Y2Een718s7CPvX/Tj9H28aNL+kVwhYVO6dOmQgUYxZ7mhA1K2bFlTt0En04kXbKzsXyzso9P3Lxb2kfcv+nH6PuY3Yf9CWWy8sEMxwzAMwzCOgsUNwzAMwzCOgsWNgVCBziFDhji2UKfT9y8W9tHp+xcL+8j7F/04fR8TbbB/MedQzDAMwzCMs2HLDcMwDMMwjoLFDcMwDMMwjoLFDcMwDMMwjoLFDcMwDMMwjoLFjUGMHj0aFStWRK5cudC8eXOsXr0a0cDw4cNx3XXXCRmbixcvjm7dumHnzp1+87Rt21bI5ix+9e3b12+egwcP4tZbb0VSUpKwnhdffBHp6emwA0OHDg1qf82aNX3Tr127hqeeegpFihRB3rx5cdddd+HEiRNRs3903QXuH71on6L1/C1evBi33367kImU2jt9+nS/6RQHMXjwYJQqVQq5c+dGhw4d8N9///nNc/bsWTzwwANCErGCBQvi0UcfxeXLl/3m2bx5M2644Qbhd0sZVT/44APL9y8tLQ0vv/wy6tWrhzx58gjz9OzZU8isHuq8v/fee7bfP+Lhhx8Oavstt9wSNedPzT5K/SbpNWLEiKg4h8NV9A1G3TsXLlyIxo0bC9FVVatWxYQJE8LfAYqWYsLjl19+cefMmdM9fvx497Zt29x9+vRxFyxY0H3ixAm33enUqZP722+/dW/dutW9ceNGd5cuXdzly5d3X7582TdPmzZthH06duyY73XhwgXf9PT0dHfdunXdHTp0cG/YsME9c+ZMd9GiRd2DBg1y24EhQ4a469Sp49f+U6dO+ab37dvXXa5cOff8+fPda9eudV9//fXuli1bRs3+nTx50m/f5s6dSxGQ7gULFkTt+aM2vPbaa+6pU6cK+zJt2jS/6e+99567QIEC7unTp7s3bdrkvuOOO9yVKlVyX7161TfPLbfc4m7QoIF75cqV7iVLlrirVq3qvu+++3zT6RiUKFHC/cADDwjX/88//+zOnTu3e+zYsZbu3/nz54VzMWnSJPeOHTvcK1ascDdr1szdpEkTv3VUqFDBPWzYML/zKv7d2nX/iF69egnnR9z2s2fP+s1j5/OnZh/F+0Yv6h9cLpd7z549UXEOO6noG4y4d+7du9edlJTkHjBggPvff/91f/bZZ+74+Hj37Nmzw2o/ixsDoBvPU0895fuckZHhLl26tHv48OHuaIM6SvqhLlq0yPcddY7PPvus7DJ0wcbFxbmPHz/u++7LL79058+f352SkuK2g7ihm6QU1JEkJCS4f/31V99327dvF44BdSrRsH+B0LmqUqWKOzMz0xHnL7DjoP0qWbKke8SIEX7nMTExUbj5E3STpOXWrFnjm2fWrFlC53LkyBHh8xdffOEuVKiQ3z6+/PLL7ho1argjiVTHGMjq1auF+Q4cOODXMX788ceyy9h5/0jcdO3aVXaZaDp/as8h7e9NN93k9120nEOpvsGoe+dLL70kPHyK6dGjhyCuwoGHpcIkNTUV69atE8zi4vpV9HnFihWINi5cuCC8Fy5c2O/7H3/8EUWLFkXdunUxaNAgXLlyxTeN9pNM6CVKlPB916lTJ6F42rZt22AHaMiCzMeVK1cWTN1kKiXo3NEwgPj80ZBV+fLlfecvGvZPfD3+8MMPeOSRR/wKw0b7+ROzb98+HD9+3O+cUb0ZGg4WnzMaymjatKlvHpqffpurVq3yzXPjjTciZ86cfvtNpvdz587Bbr9LOp+0T2JoCIOGBBo1aiQMd4jN/XbfPxqKoGGKGjVqoF+/fjhz5oxvmtPOHw3VzJgxQxhaCyRazuGFgL7BqHsnzSNeh3eecPvPmCucaTSnT59GRkaG38kj6POOHTsQbRXTn3vuObRq1UroBL3cf//9qFChgiAOaPyX/AHoxzV16lRhOnU0UvvvnWY11OnRGC7dRI8dO4Y333xTGMPeunWr0D66cQR2GtR+b9vtvn9iaNz//Pnzgk+DU85fIN42SbVZfM6o4xSTI0cO4cYsnqdSpUpB6/BOK1SoEOwA+TXQObvvvvv8ihA+88wzgp8C7dPy5csF0UrX98iRI22/f+Rfc+eddwrt27NnD1599VV07txZ6NDi4+Mddf6IiRMnCr4rtM9iouUcZkr0DUbdO+XmIQF09epVwadODyxuGB/kGEYd/tKlS/2+f/zxx33/kwonJ8727dsLN6UqVarA7tBN00v9+vUFsUOd/eTJk3X/cOzKuHHjhP0lIeOU8xfL0JPxPffcIzhQf/nll37TBgwY4HddU0fzxBNPCI6gdk/rf++99/pdk9R+uhbJmkPXptMYP368YDEmp+BoPIdPyfQNdoaHpcKETP30pBHoIU6fS5YsiWihf//++Ouvv7BgwQKULVtWcV4SB8Tu3buFd9pPqf33TrMb9KRRvXp1of3UPhrKIWuH3PmLlv07cOAA5s2bh8cee8zR58/bJqXfHL2fPHnSbzqZ+ykCJ1rOq1fY0HmdO3eun9VG7rzSPu7fvz8q9k8MDRfTvVR8TUb7+fOyZMkSwVIa6ndp13PYX6ZvMOreKTcPXe/hPHyyuAkTUtpNmjTB/Pnz/Ux49LlFixawO/RESBfvtGnT8M8//wSZQKXYuHGj8E4WAIL2c8uWLX43I+/NuHbt2rAbFE5KVgtqP527hIQEv/NHNyLyyfGev2jZv2+//VYw5VPYpZPPH12jdEMUnzMyYZMvhvic0U2X/AK80PVNv02vuKN5KJyXRIR4v2n40uohDa+wIV8xEqzkkxEKOq/kk+IdzrHz/gVy+PBhwedGfE1G8/kLtKbSfaZBgwZRdQ7dIfoGo+6dNI94Hd55wu4/w3JHZnyh4BSpMWHCBMHL//HHHxdCwcUe4nalX79+QkjtwoUL/cIRr1y5IkzfvXu3EKpIYX779u1z//777+7KlSu7b7zxxqBwv5tvvlkIGaQQvmLFitkmVPqFF14Q9o/av2zZMiEskcIRyfvfG85IIY7//POPsJ8tWrQQXtGyf94IPdoHiqQQE63n79KlS0LoKL3oNjVy5Ejhf2+0EIWC02+M9mfz5s1CJIpUKHijRo3cq1atci9dutRdrVo1v1BiivagMNuHHnpICHel3zGFpEYizFZp/1JTU4XQ9rJlywrnQ/y79EaYLF++XIiyoekUWvzDDz8I56xnz5623z+aNnDgQCGihq7JefPmuRs3biycn2vXrkXF+Qu1j+JQbmoTRQgFYvdz2C9E32DUvdMbCv7iiy8K0VajR4/mUHA7QbH5dJIp3w2FhlNuhmiAfpRSL8pvQBw8eFDoCAsXLiwIOMo1QRehOE8KsX//fnfnzp2FHAwkHEhQpKWlue0AhRWWKlVKODdlypQRPlOn74U6xCeffFIIuaQfWffu3YUfcbTsHzFnzhzhvO3cudPv+2g9f5SjR+q6pBBibzj4G2+8Idz4ab/at28ftO9nzpwROsO8efMKoae9e/cWOiQxlCOndevWwjro2iDRZPX+UYcv97v05i5at26du3nz5kLnkytXLnetWrXc7777rp84sOv+UedInR11chRKTOHQlIcp8GHQzucv1D56IRFCvykSKYHY/RwiRN9g5L2TjmXDhg2FezQ9fIm3oRdX1k4wDMMwDMM4Ava5YRiGYRjGUbC4YRiGYRjGUbC4YRiGYRjGUbC4YRiGYRjGUbC4YRiGYRjGUbC4YRiGYRjGUbC4YRiGYRjGUbC4YRiGYRjGUbC4YRiGAeByuTB9+nSrm8EwjAGwuGEYxnIefvhhQVwEvm655Rarm8YwTBSSw+oGMAzDECRkqLK5mMTERMvawzBM9MKWG4ZhbAEJmZIlS/q9ChUqJEwjK86XX36Jzp07I3fu3KhcuTKmTJnit/yWLVtw0003CdOLFCmCxx9/HJcvX/abZ/z48ahTp46wrVKlSqF///5+00+fPo3u3bsjKSkJ1apVwx9//BGBPWcYxmhY3DAMExW88cYbuOuuu7Bp0yY88MADuPfee7F9+3ZhWnJyMjp16iSIoTVr1uDXX3/FvHnz/MQLiaOnnnpKED0khEi4VK1a1W8bb775Ju655x5s3rwZXbp0EbZz9uzZiO8rwzBhEnZdcYZhmDDp1auXOz4+3p0nTx6/1zvvvCNMp1tV3759/ZZp3ry5u1+/fsL/X331lbtQoULuy5cv+6bPmDHDHRcX5z5+/LjwuXTp0u7XXntNtg20jddff933mdZF382aNcvw/WUYxlzY54ZhGFvQrl07wboipnDhwr7/W7Ro4TeNPm/cuFH4nyw4DRo0QJ48eXzTW7VqhczMTOzcuVMY1jp69Cjat2+v2Ib69ev7/qd15c+fHydPngx73xiGiSwsbhiGsQUkJgKHiYyC/HDUkJCQ4PeZRBEJJIZhogv2uWEYJipYuXJl0OdatWoJ/9M7+eKQ742XZcuWIS4uDjVq1EC+fPlQsWJFzJ8/P+LtZhgm8rDlhmEYW5CSkoLjx4/7fZcjRw4ULVpU+J+chJs2bYrWrVvjxx9/xOrVqzFu3DhhGjn+DhkyBL169cLQoUNx6tQpPP3003jooYdQokQJYR76vm/fvihevLgQdXXp0iVBANF8DMM4CxY3DMPYgtmzZwvh2WLI6rJjxw5fJNMvv/yCJ598Upjv559/Ru3atYVpFLo9Z84cPPvss7juuuuEzxRZNXLkSN+6SPhcu3YNH3/8MQYOHCiIprvvvjvCe8kwTCRwkVdxRLbEMAyjE/J9mTZtGrp162Z1UxiGiQLY54ZhGIZhGEfB4oZhGIZhGEfBPjcMw9geHj1nGEYLbLlhGIZhGMZRsLhhGIZhGMZRsLhhGIZhGMZRsLhhGIZhGMZRsLhhGIZhGMZRsLhhGIZhGMZRsLhhGIZhGMZRsLhhGIZhGAZO4v8uMRsU8SkPMwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.plot(v_losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Train\", \"Val\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "out = model(data.x, data.edge_index)\n",
    "pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "y_pred = pred[data.test_mask].numpy()\n",
    "y_true = data.y[data.test_mask].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6164\n",
      "Precision: 0.1579\n",
      "Recall: 0.2000\n",
      "f1 score: 0.1765\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true, y_pred, normalize=None)\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    ")\n",
    "\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred):.4f}\")\n",
    "print(f\"f1 score: {f1_score(y_true, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341,830\n",
      "GAT model number of params: 341,830\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234567)\n",
    "        self.conv1 = GATConv(data.num_features, hidden_channels)\n",
    "        self.conv2 = GATConv(hidden_channels, hidden_channels * 2)\n",
    "        self.conv3 = GATConv(hidden_channels * 2, hidden_channels * 4)\n",
    "        self.conv4 = GATConv(hidden_channels * 4, hidden_channels * 8)\n",
    "        self.conv5 = GATConv(hidden_channels * 8, hidden_channels * 4)\n",
    "        self.conv6 = GATConv(hidden_channels * 4, hidden_channels * 2)\n",
    "        self.conv7 = GATConv(hidden_channels * 2, 2)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv6(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv7(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = GAT(hidden_channels=64)\n",
    "print(f\"GAT model number of params: {count_parameters(model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train_loss: 0.7044 / Val_loss: 0.7030\n",
      "Epoch: 002, Train_loss: 0.6923 / Val_loss: 0.6954\n",
      "Epoch: 003, Train_loss: 0.6942 / Val_loss: 0.6838\n",
      "Epoch: 004, Train_loss: 0.6836 / Val_loss: 0.6807\n",
      "Epoch: 005, Train_loss: 0.6820 / Val_loss: 0.6838\n",
      "Epoch: 006, Train_loss: 0.6775 / Val_loss: 0.6795\n",
      "Epoch: 007, Train_loss: 0.6724 / Val_loss: 0.6800\n",
      "Epoch: 008, Train_loss: 0.6679 / Val_loss: 0.6735\n",
      "Epoch: 009, Train_loss: 0.6723 / Val_loss: 0.6699\n",
      "Epoch: 010, Train_loss: 0.6673 / Val_loss: 0.6732\n",
      "Epoch: 011, Train_loss: 0.6627 / Val_loss: 0.6657\n",
      "Epoch: 012, Train_loss: 0.6579 / Val_loss: 0.6723\n",
      "Epoch: 013, Train_loss: 0.6567 / Val_loss: 0.6713\n",
      "Epoch: 014, Train_loss: 0.6530 / Val_loss: 0.6662\n",
      "Epoch: 015, Train_loss: 0.6546 / Val_loss: 0.6656\n",
      "Epoch: 016, Train_loss: 0.6481 / Val_loss: 0.6637\n",
      "Epoch: 017, Train_loss: 0.6553 / Val_loss: 0.6546\n",
      "Epoch: 018, Train_loss: 0.6518 / Val_loss: 0.6648\n",
      "Epoch: 019, Train_loss: 0.6465 / Val_loss: 0.6663\n",
      "Epoch: 020, Train_loss: 0.6508 / Val_loss: 0.6672\n",
      "Epoch: 021, Train_loss: 0.6465 / Val_loss: 0.6664\n",
      "Epoch: 022, Train_loss: 0.6436 / Val_loss: 0.6701\n",
      "Epoch: 023, Train_loss: 0.6438 / Val_loss: 0.6629\n",
      "Epoch: 024, Train_loss: 0.6491 / Val_loss: 0.6625\n",
      "Epoch: 025, Train_loss: 0.6434 / Val_loss: 0.6600\n",
      "Epoch: 026, Train_loss: 0.6534 / Val_loss: 0.6535\n",
      "Epoch: 027, Train_loss: 0.6507 / Val_loss: 0.6843\n",
      "Epoch: 028, Train_loss: 0.6472 / Val_loss: 0.6627\n",
      "Epoch: 029, Train_loss: 0.6473 / Val_loss: 0.6723\n",
      "Epoch: 030, Train_loss: 0.6432 / Val_loss: 0.6440\n",
      "Epoch: 031, Train_loss: 0.6466 / Val_loss: 0.6657\n",
      "Epoch: 032, Train_loss: 0.6459 / Val_loss: 0.6492\n",
      "Epoch: 033, Train_loss: 0.6388 / Val_loss: 0.6455\n",
      "Epoch: 034, Train_loss: 0.6364 / Val_loss: 0.6528\n",
      "Epoch: 035, Train_loss: 0.6417 / Val_loss: 0.6408\n",
      "Epoch: 036, Train_loss: 0.6393 / Val_loss: 0.6458\n",
      "Epoch: 037, Train_loss: 0.6325 / Val_loss: 0.6420\n",
      "Epoch: 038, Train_loss: 0.6404 / Val_loss: 0.6452\n",
      "Epoch: 039, Train_loss: 0.6310 / Val_loss: 0.6580\n",
      "Epoch: 040, Train_loss: 0.6394 / Val_loss: 0.6428\n",
      "Epoch: 041, Train_loss: 0.6354 / Val_loss: 0.6335\n",
      "Epoch: 042, Train_loss: 0.6290 / Val_loss: 0.6538\n",
      "Epoch: 043, Train_loss: 0.6328 / Val_loss: 0.6491\n",
      "Epoch: 044, Train_loss: 0.6253 / Val_loss: 0.6493\n",
      "Epoch: 045, Train_loss: 0.6363 / Val_loss: 0.6389\n",
      "Epoch: 046, Train_loss: 0.6248 / Val_loss: 0.6619\n",
      "Epoch: 047, Train_loss: 0.6220 / Val_loss: 0.6529\n",
      "Epoch: 048, Train_loss: 0.6396 / Val_loss: 0.6592\n",
      "Epoch: 049, Train_loss: 0.6326 / Val_loss: 0.6457\n",
      "Epoch: 050, Train_loss: 0.6264 / Val_loss: 0.6415\n",
      "Epoch: 051, Train_loss: 0.6284 / Val_loss: 0.6362\n",
      "Epoch: 052, Train_loss: 0.6292 / Val_loss: 0.6184\n",
      "Epoch: 053, Train_loss: 0.6247 / Val_loss: 0.6519\n",
      "Epoch: 054, Train_loss: 0.6225 / Val_loss: 0.6469\n",
      "Epoch: 055, Train_loss: 0.6305 / Val_loss: 0.6305\n",
      "Epoch: 056, Train_loss: 0.6280 / Val_loss: 0.6325\n",
      "Epoch: 057, Train_loss: 0.6192 / Val_loss: 0.6793\n",
      "Epoch: 058, Train_loss: 0.6201 / Val_loss: 0.6403\n",
      "Epoch: 059, Train_loss: 0.6323 / Val_loss: 0.6750\n",
      "Epoch: 060, Train_loss: 0.6241 / Val_loss: 0.6714\n",
      "Epoch: 061, Train_loss: 0.6245 / Val_loss: 0.6440\n",
      "Epoch: 062, Train_loss: 0.6220 / Val_loss: 0.6378\n",
      "Epoch: 063, Train_loss: 0.6170 / Val_loss: 0.6751\n",
      "Epoch: 064, Train_loss: 0.6178 / Val_loss: 0.6352\n",
      "Epoch: 065, Train_loss: 0.6206 / Val_loss: 0.6275\n",
      "Epoch: 066, Train_loss: 0.6207 / Val_loss: 0.6487\n",
      "Epoch: 067, Train_loss: 0.6258 / Val_loss: 0.6356\n",
      "Epoch: 068, Train_loss: 0.6212 / Val_loss: 0.6336\n",
      "Epoch: 069, Train_loss: 0.6235 / Val_loss: 0.6726\n",
      "Epoch: 070, Train_loss: 0.6143 / Val_loss: 0.6160\n",
      "Epoch: 071, Train_loss: 0.6191 / Val_loss: 0.6258\n",
      "Epoch: 072, Train_loss: 0.6217 / Val_loss: 0.6306\n",
      "Epoch: 073, Train_loss: 0.6193 / Val_loss: 0.6298\n",
      "Epoch: 074, Train_loss: 0.6162 / Val_loss: 0.6309\n",
      "Epoch: 075, Train_loss: 0.6072 / Val_loss: 0.6301\n",
      "Epoch: 076, Train_loss: 0.6159 / Val_loss: 0.6227\n",
      "Epoch: 077, Train_loss: 0.6084 / Val_loss: 0.6388\n",
      "Epoch: 078, Train_loss: 0.6114 / Val_loss: 0.6212\n",
      "Epoch: 079, Train_loss: 0.6110 / Val_loss: 0.6350\n",
      "Epoch: 080, Train_loss: 0.6142 / Val_loss: 0.6906\n",
      "Epoch: 081, Train_loss: 0.6105 / Val_loss: 0.6581\n",
      "Epoch: 082, Train_loss: 0.6132 / Val_loss: 0.6635\n",
      "Epoch: 083, Train_loss: 0.6181 / Val_loss: 0.5997\n",
      "Epoch: 084, Train_loss: 0.6049 / Val_loss: 0.6237\n",
      "Epoch: 085, Train_loss: 0.6105 / Val_loss: 0.6498\n",
      "Epoch: 086, Train_loss: 0.6077 / Val_loss: 0.6068\n",
      "Epoch: 087, Train_loss: 0.6214 / Val_loss: 0.6648\n",
      "Epoch: 088, Train_loss: 0.6194 / Val_loss: 0.6897\n",
      "Epoch: 089, Train_loss: 0.6151 / Val_loss: 0.6169\n",
      "Epoch: 090, Train_loss: 0.6057 / Val_loss: 0.6005\n",
      "Epoch: 091, Train_loss: 0.6136 / Val_loss: 0.6615\n",
      "Epoch: 092, Train_loss: 0.6000 / Val_loss: 0.6069\n",
      "Epoch: 093, Train_loss: 0.6089 / Val_loss: 0.6240\n",
      "Epoch: 094, Train_loss: 0.6023 / Val_loss: 0.6209\n",
      "Epoch: 095, Train_loss: 0.6060 / Val_loss: 0.6439\n",
      "Epoch: 096, Train_loss: 0.6086 / Val_loss: 0.6009\n",
      "Epoch: 097, Train_loss: 0.6045 / Val_loss: 0.6284\n",
      "Epoch: 098, Train_loss: 0.6077 / Val_loss: 0.6026\n",
      "Epoch: 099, Train_loss: 0.6058 / Val_loss: 0.6402\n",
      "Epoch: 100, Train_loss: 0.6112 / Val_loss: 0.6367\n",
      "Epoch: 101, Train_loss: 0.6025 / Val_loss: 0.6220\n",
      "Epoch: 102, Train_loss: 0.6035 / Val_loss: 0.6444\n",
      "Epoch: 103, Train_loss: 0.6036 / Val_loss: 0.6314\n",
      "Epoch: 104, Train_loss: 0.6061 / Val_loss: 0.5917\n",
      "Epoch: 105, Train_loss: 0.5992 / Val_loss: 0.6232\n",
      "Epoch: 106, Train_loss: 0.6066 / Val_loss: 0.6476\n",
      "Epoch: 107, Train_loss: 0.6012 / Val_loss: 0.6419\n",
      "Epoch: 108, Train_loss: 0.6102 / Val_loss: 0.6377\n",
      "Epoch: 109, Train_loss: 0.6011 / Val_loss: 0.6169\n",
      "Epoch: 110, Train_loss: 0.5987 / Val_loss: 0.6388\n",
      "Epoch: 111, Train_loss: 0.6045 / Val_loss: 0.5989\n",
      "Epoch: 112, Train_loss: 0.6009 / Val_loss: 0.6122\n",
      "Epoch: 113, Train_loss: 0.6022 / Val_loss: 0.6703\n",
      "Epoch: 114, Train_loss: 0.5995 / Val_loss: 0.6371\n",
      "Epoch: 115, Train_loss: 0.5952 / Val_loss: 0.6428\n",
      "Epoch: 116, Train_loss: 0.5923 / Val_loss: 0.6413\n",
      "Epoch: 117, Train_loss: 0.5937 / Val_loss: 0.6075\n",
      "Epoch: 118, Train_loss: 0.5926 / Val_loss: 0.6021\n",
      "Epoch: 119, Train_loss: 0.5933 / Val_loss: 0.6038\n",
      "Epoch: 120, Train_loss: 0.5888 / Val_loss: 0.6067\n",
      "Epoch: 121, Train_loss: 0.5930 / Val_loss: 0.6213\n",
      "Epoch: 122, Train_loss: 0.6018 / Val_loss: 0.5985\n",
      "Epoch: 123, Train_loss: 0.5906 / Val_loss: 0.5859\n",
      "Epoch: 124, Train_loss: 0.5946 / Val_loss: 0.6165\n",
      "Epoch: 125, Train_loss: 0.5937 / Val_loss: 0.5932\n",
      "Epoch: 126, Train_loss: 0.5882 / Val_loss: 0.5977\n",
      "Epoch: 127, Train_loss: 0.5964 / Val_loss: 0.6008\n",
      "Epoch: 128, Train_loss: 0.6018 / Val_loss: 0.6124\n",
      "Epoch: 129, Train_loss: 0.6007 / Val_loss: 0.6391\n",
      "Epoch: 130, Train_loss: 0.5870 / Val_loss: 0.5927\n",
      "Epoch: 131, Train_loss: 0.5972 / Val_loss: 0.6974\n",
      "Epoch: 132, Train_loss: 0.5848 / Val_loss: 0.6185\n",
      "Epoch: 133, Train_loss: 0.5824 / Val_loss: 0.5928\n",
      "Epoch: 134, Train_loss: 0.5918 / Val_loss: 0.5993\n",
      "Epoch: 135, Train_loss: 0.5982 / Val_loss: 0.5858\n",
      "Epoch: 136, Train_loss: 0.6087 / Val_loss: 0.6437\n",
      "Epoch: 137, Train_loss: 0.5979 / Val_loss: 0.7090\n",
      "Epoch: 138, Train_loss: 0.5835 / Val_loss: 0.5869\n",
      "Epoch: 139, Train_loss: 0.5835 / Val_loss: 0.5685\n",
      "Epoch: 140, Train_loss: 0.5957 / Val_loss: 0.6413\n",
      "Epoch: 141, Train_loss: 0.5828 / Val_loss: 0.6059\n",
      "Epoch: 142, Train_loss: 0.5865 / Val_loss: 0.6149\n",
      "Epoch: 143, Train_loss: 0.5983 / Val_loss: 0.6698\n",
      "Epoch: 144, Train_loss: 0.5896 / Val_loss: 0.6343\n",
      "Epoch: 145, Train_loss: 0.5822 / Val_loss: 0.5877\n",
      "Epoch: 146, Train_loss: 0.5824 / Val_loss: 0.6201\n",
      "Epoch: 147, Train_loss: 0.5857 / Val_loss: 0.5964\n",
      "Epoch: 148, Train_loss: 0.5819 / Val_loss: 0.6083\n",
      "Epoch: 149, Train_loss: 0.5872 / Val_loss: 0.6167\n",
      "Epoch: 150, Train_loss: 0.5862 / Val_loss: 0.6092\n",
      "Epoch: 151, Train_loss: 0.5846 / Val_loss: 0.6410\n",
      "Epoch: 152, Train_loss: 0.5837 / Val_loss: 0.6450\n",
      "Epoch: 153, Train_loss: 0.5836 / Val_loss: 0.6143\n",
      "Epoch: 154, Train_loss: 0.5892 / Val_loss: 0.6946\n",
      "Epoch: 155, Train_loss: 0.5985 / Val_loss: 0.5966\n",
      "Epoch: 156, Train_loss: 0.5831 / Val_loss: 0.6276\n",
      "Epoch: 157, Train_loss: 0.5722 / Val_loss: 0.6203\n",
      "Epoch: 158, Train_loss: 0.5876 / Val_loss: 0.6712\n",
      "Epoch: 159, Train_loss: 0.5833 / Val_loss: 0.6334\n",
      "Epoch: 160, Train_loss: 0.5833 / Val_loss: 0.6146\n",
      "Epoch: 161, Train_loss: 0.5701 / Val_loss: 0.5831\n",
      "Epoch: 162, Train_loss: 0.5807 / Val_loss: 0.6029\n",
      "Epoch: 163, Train_loss: 0.5878 / Val_loss: 0.6164\n",
      "Epoch: 164, Train_loss: 0.5769 / Val_loss: 0.6374\n",
      "Epoch: 165, Train_loss: 0.5776 / Val_loss: 0.6515\n",
      "Epoch: 166, Train_loss: 0.5804 / Val_loss: 0.6724\n",
      "Epoch: 167, Train_loss: 0.5846 / Val_loss: 0.6125\n",
      "Epoch: 168, Train_loss: 0.5769 / Val_loss: 0.6513\n",
      "Epoch: 169, Train_loss: 0.5883 / Val_loss: 0.6509\n",
      "Epoch: 170, Train_loss: 0.5861 / Val_loss: 0.5981\n",
      "Epoch: 171, Train_loss: 0.5852 / Val_loss: 0.6360\n",
      "Epoch: 172, Train_loss: 0.5878 / Val_loss: 0.7423\n",
      "Epoch: 173, Train_loss: 0.5890 / Val_loss: 0.6090\n",
      "Epoch: 174, Train_loss: 0.5809 / Val_loss: 0.6944\n",
      "Epoch: 175, Train_loss: 0.5811 / Val_loss: 0.6317\n",
      "Epoch: 176, Train_loss: 0.5764 / Val_loss: 0.6085\n",
      "Epoch: 177, Train_loss: 0.5716 / Val_loss: 0.5771\n",
      "Epoch: 178, Train_loss: 0.5760 / Val_loss: 0.6220\n",
      "Epoch: 179, Train_loss: 0.5727 / Val_loss: 0.5900\n",
      "Epoch: 180, Train_loss: 0.5870 / Val_loss: 0.6902\n",
      "Epoch: 181, Train_loss: 0.5704 / Val_loss: 0.6085\n",
      "Epoch: 182, Train_loss: 0.5749 / Val_loss: 0.5959\n",
      "Epoch: 183, Train_loss: 0.5802 / Val_loss: 0.6775\n",
      "Epoch: 184, Train_loss: 0.5750 / Val_loss: 0.6358\n",
      "Epoch: 185, Train_loss: 0.5677 / Val_loss: 0.6041\n",
      "Epoch: 186, Train_loss: 0.5705 / Val_loss: 0.6073\n",
      "Epoch: 187, Train_loss: 0.5738 / Val_loss: 0.6048\n",
      "Epoch: 188, Train_loss: 0.5714 / Val_loss: 0.6424\n",
      "Epoch: 189, Train_loss: 0.5708 / Val_loss: 0.6720\n",
      "Epoch: 190, Train_loss: 0.5580 / Val_loss: 0.5931\n",
      "Epoch: 191, Train_loss: 0.5616 / Val_loss: 0.5916\n",
      "Epoch: 192, Train_loss: 0.5763 / Val_loss: 0.6876\n",
      "Epoch: 193, Train_loss: 0.5723 / Val_loss: 0.6307\n",
      "Epoch: 194, Train_loss: 0.5788 / Val_loss: 0.7880\n",
      "Epoch: 195, Train_loss: 0.5621 / Val_loss: 0.6636\n",
      "Epoch: 196, Train_loss: 0.5708 / Val_loss: 0.6386\n",
      "Epoch: 197, Train_loss: 0.5665 / Val_loss: 0.5981\n",
      "Epoch: 198, Train_loss: 0.5749 / Val_loss: 0.6669\n",
      "Epoch: 199, Train_loss: 0.5715 / Val_loss: 0.6074\n",
      "Epoch: 200, Train_loss: 0.5676 / Val_loss: 0.6393\n",
      "Epoch: 201, Train_loss: 0.5494 / Val_loss: 0.6510\n",
      "Epoch: 202, Train_loss: 0.5581 / Val_loss: 0.5710\n",
      "Epoch: 203, Train_loss: 0.5706 / Val_loss: 0.6837\n",
      "Epoch: 204, Train_loss: 0.5557 / Val_loss: 0.6113\n",
      "Epoch: 205, Train_loss: 0.5629 / Val_loss: 0.6536\n",
      "Epoch: 206, Train_loss: 0.5571 / Val_loss: 0.5790\n",
      "Epoch: 207, Train_loss: 0.5510 / Val_loss: 0.6130\n",
      "Epoch: 208, Train_loss: 0.5689 / Val_loss: 0.6780\n",
      "Epoch: 209, Train_loss: 0.5626 / Val_loss: 0.5889\n",
      "Epoch: 210, Train_loss: 0.5649 / Val_loss: 0.6911\n",
      "Epoch: 211, Train_loss: 0.5498 / Val_loss: 0.5723\n",
      "Epoch: 212, Train_loss: 0.5634 / Val_loss: 0.6482\n",
      "Epoch: 213, Train_loss: 0.5671 / Val_loss: 0.7751\n",
      "Epoch: 214, Train_loss: 0.5520 / Val_loss: 0.7218\n",
      "Epoch: 215, Train_loss: 0.5580 / Val_loss: 0.6940\n",
      "Epoch: 216, Train_loss: 0.5545 / Val_loss: 0.6307\n",
      "Epoch: 217, Train_loss: 0.5532 / Val_loss: 0.6507\n",
      "Epoch: 218, Train_loss: 0.5503 / Val_loss: 0.6402\n",
      "Epoch: 219, Train_loss: 0.5566 / Val_loss: 0.6603\n",
      "Epoch: 220, Train_loss: 0.5633 / Val_loss: 0.6645\n",
      "Epoch: 221, Train_loss: 0.5480 / Val_loss: 0.6187\n",
      "Epoch: 222, Train_loss: 0.5671 / Val_loss: 0.5799\n",
      "Epoch: 223, Train_loss: 0.5440 / Val_loss: 0.6218\n",
      "Epoch: 224, Train_loss: 0.5614 / Val_loss: 0.6992\n",
      "Epoch: 225, Train_loss: 0.5567 / Val_loss: 0.6879\n",
      "Epoch: 226, Train_loss: 0.5435 / Val_loss: 0.6188\n",
      "Epoch: 227, Train_loss: 0.5349 / Val_loss: 0.6347\n",
      "Epoch: 228, Train_loss: 0.5486 / Val_loss: 0.7169\n",
      "Epoch: 229, Train_loss: 0.5484 / Val_loss: 0.6594\n",
      "Epoch: 230, Train_loss: 0.5654 / Val_loss: 0.6969\n",
      "Epoch: 231, Train_loss: 0.5497 / Val_loss: 0.6541\n",
      "Epoch: 232, Train_loss: 0.5506 / Val_loss: 0.6726\n",
      "Epoch: 233, Train_loss: 0.5421 / Val_loss: 0.6661\n",
      "Epoch: 234, Train_loss: 0.5480 / Val_loss: 0.6528\n",
      "Epoch: 235, Train_loss: 0.5399 / Val_loss: 0.6601\n",
      "Epoch: 236, Train_loss: 0.5518 / Val_loss: 0.7179\n",
      "Epoch: 237, Train_loss: 0.5566 / Val_loss: 0.7454\n",
      "Epoch: 238, Train_loss: 0.5466 / Val_loss: 0.6690\n",
      "Epoch: 239, Train_loss: 0.5512 / Val_loss: 0.7283\n",
      "Epoch: 240, Train_loss: 0.5405 / Val_loss: 0.6517\n",
      "Epoch: 241, Train_loss: 0.5602 / Val_loss: 0.6896\n",
      "Epoch: 242, Train_loss: 0.5552 / Val_loss: 0.7382\n",
      "Epoch: 243, Train_loss: 0.5478 / Val_loss: 0.6120\n",
      "Epoch: 244, Train_loss: 0.5410 / Val_loss: 0.6126\n",
      "Epoch: 245, Train_loss: 0.5411 / Val_loss: 0.6246\n",
      "Epoch: 246, Train_loss: 0.5393 / Val_loss: 0.6915\n",
      "Epoch: 247, Train_loss: 0.5431 / Val_loss: 0.7512\n",
      "Epoch: 248, Train_loss: 0.5259 / Val_loss: 0.5896\n",
      "Epoch: 249, Train_loss: 0.5359 / Val_loss: 0.6548\n",
      "Epoch: 250, Train_loss: 0.5550 / Val_loss: 0.7033\n",
      "Epoch: 251, Train_loss: 0.5445 / Val_loss: 0.6764\n",
      "Epoch: 252, Train_loss: 0.5293 / Val_loss: 0.6325\n",
      "Epoch: 253, Train_loss: 0.5504 / Val_loss: 0.6646\n",
      "Epoch: 254, Train_loss: 0.5337 / Val_loss: 0.6210\n",
      "Epoch: 255, Train_loss: 0.5471 / Val_loss: 0.6810\n",
      "Epoch: 256, Train_loss: 0.5344 / Val_loss: 0.6929\n",
      "Epoch: 257, Train_loss: 0.5377 / Val_loss: 0.5888\n",
      "Epoch: 258, Train_loss: 0.5353 / Val_loss: 0.6531\n",
      "Epoch: 259, Train_loss: 0.5402 / Val_loss: 0.7056\n",
      "Epoch: 260, Train_loss: 0.5555 / Val_loss: 0.7396\n",
      "Epoch: 261, Train_loss: 0.5468 / Val_loss: 0.6380\n",
      "Epoch: 262, Train_loss: 0.5497 / Val_loss: 0.7068\n",
      "Epoch: 263, Train_loss: 0.5632 / Val_loss: 0.8029\n",
      "Epoch: 264, Train_loss: 0.5257 / Val_loss: 0.6636\n",
      "Epoch: 265, Train_loss: 0.5420 / Val_loss: 0.7130\n",
      "Epoch: 266, Train_loss: 0.5327 / Val_loss: 0.7779\n",
      "Epoch: 267, Train_loss: 0.5402 / Val_loss: 0.6298\n",
      "Epoch: 268, Train_loss: 0.5297 / Val_loss: 0.6045\n",
      "Epoch: 269, Train_loss: 0.5387 / Val_loss: 0.6940\n",
      "Epoch: 270, Train_loss: 0.5477 / Val_loss: 0.7544\n",
      "Epoch: 271, Train_loss: 0.5441 / Val_loss: 0.6741\n",
      "Epoch: 272, Train_loss: 0.5299 / Val_loss: 0.7527\n",
      "Epoch: 273, Train_loss: 0.5444 / Val_loss: 0.6299\n",
      "Epoch: 274, Train_loss: 0.5245 / Val_loss: 0.6810\n",
      "Epoch: 275, Train_loss: 0.5280 / Val_loss: 0.6621\n",
      "Epoch: 276, Train_loss: 0.5282 / Val_loss: 0.7078\n",
      "Epoch: 277, Train_loss: 0.5382 / Val_loss: 0.7158\n",
      "Epoch: 278, Train_loss: 0.5289 / Val_loss: 0.6787\n",
      "Epoch: 279, Train_loss: 0.5354 / Val_loss: 0.7514\n",
      "Epoch: 280, Train_loss: 0.5414 / Val_loss: 0.7572\n",
      "Epoch: 281, Train_loss: 0.5305 / Val_loss: 0.6775\n",
      "Epoch: 282, Train_loss: 0.5262 / Val_loss: 0.6851\n",
      "Epoch: 283, Train_loss: 0.5231 / Val_loss: 0.6550\n",
      "Epoch: 284, Train_loss: 0.5394 / Val_loss: 0.6406\n",
      "Epoch: 285, Train_loss: 0.5265 / Val_loss: 0.6657\n",
      "Epoch: 286, Train_loss: 0.5381 / Val_loss: 0.6161\n",
      "Epoch: 287, Train_loss: 0.5401 / Val_loss: 0.6114\n",
      "Epoch: 288, Train_loss: 0.5257 / Val_loss: 0.6473\n",
      "Epoch: 289, Train_loss: 0.5211 / Val_loss: 0.6702\n",
      "Epoch: 290, Train_loss: 0.5404 / Val_loss: 0.7392\n",
      "Epoch: 291, Train_loss: 0.5315 / Val_loss: 0.6538\n",
      "Epoch: 292, Train_loss: 0.5305 / Val_loss: 0.7125\n",
      "Epoch: 293, Train_loss: 0.5199 / Val_loss: 0.7632\n",
      "Epoch: 294, Train_loss: 0.5270 / Val_loss: 0.6807\n",
      "Epoch: 295, Train_loss: 0.5413 / Val_loss: 0.6392\n",
      "Epoch: 296, Train_loss: 0.5447 / Val_loss: 0.6610\n",
      "Epoch: 297, Train_loss: 0.5467 / Val_loss: 0.6748\n",
      "Epoch: 298, Train_loss: 0.5302 / Val_loss: 0.5927\n",
      "Epoch: 299, Train_loss: 0.5235 / Val_loss: 0.6699\n",
      "Epoch: 300, Train_loss: 0.5344 / Val_loss: 0.6495\n",
      "Epoch: 301, Train_loss: 0.5243 / Val_loss: 0.6583\n",
      "Epoch: 302, Train_loss: 0.5300 / Val_loss: 0.6585\n",
      "Epoch: 303, Train_loss: 0.5121 / Val_loss: 0.6590\n",
      "Epoch: 304, Train_loss: 0.5539 / Val_loss: 0.6305\n",
      "Epoch: 305, Train_loss: 0.5324 / Val_loss: 0.6478\n",
      "Epoch: 306, Train_loss: 0.5390 / Val_loss: 0.7277\n",
      "Epoch: 307, Train_loss: 0.5317 / Val_loss: 0.6765\n",
      "Epoch: 308, Train_loss: 0.5373 / Val_loss: 0.7471\n",
      "Epoch: 309, Train_loss: 0.5299 / Val_loss: 0.6218\n",
      "Epoch: 310, Train_loss: 0.5303 / Val_loss: 0.7095\n",
      "Epoch: 311, Train_loss: 0.5187 / Val_loss: 0.6192\n",
      "Epoch: 312, Train_loss: 0.5204 / Val_loss: 0.6444\n",
      "Epoch: 313, Train_loss: 0.5293 / Val_loss: 0.6977\n",
      "Epoch: 314, Train_loss: 0.5441 / Val_loss: 0.8240\n",
      "Epoch: 315, Train_loss: 0.5316 / Val_loss: 0.7250\n",
      "Epoch: 316, Train_loss: 0.5445 / Val_loss: 0.7599\n",
      "Epoch: 317, Train_loss: 0.5397 / Val_loss: 0.6988\n",
      "Epoch: 318, Train_loss: 0.5160 / Val_loss: 0.7759\n",
      "Epoch: 319, Train_loss: 0.5218 / Val_loss: 0.6147\n",
      "Epoch: 320, Train_loss: 0.5265 / Val_loss: 0.6647\n",
      "Epoch: 321, Train_loss: 0.5316 / Val_loss: 0.7639\n",
      "Epoch: 322, Train_loss: 0.5187 / Val_loss: 0.6762\n",
      "Epoch: 323, Train_loss: 0.5225 / Val_loss: 0.6752\n",
      "Epoch: 324, Train_loss: 0.5290 / Val_loss: 0.7333\n",
      "Epoch: 325, Train_loss: 0.5238 / Val_loss: 0.7186\n",
      "Epoch: 326, Train_loss: 0.5085 / Val_loss: 0.7018\n",
      "Epoch: 327, Train_loss: 0.5278 / Val_loss: 0.7461\n",
      "Epoch: 328, Train_loss: 0.5315 / Val_loss: 0.7435\n",
      "Epoch: 329, Train_loss: 0.5395 / Val_loss: 0.7324\n",
      "Epoch: 330, Train_loss: 0.5371 / Val_loss: 0.6578\n",
      "Epoch: 331, Train_loss: 0.5322 / Val_loss: 0.6473\n",
      "Epoch: 332, Train_loss: 0.5370 / Val_loss: 0.6975\n",
      "Epoch: 333, Train_loss: 0.5265 / Val_loss: 0.7141\n",
      "Epoch: 334, Train_loss: 0.5074 / Val_loss: 0.6755\n",
      "Epoch: 335, Train_loss: 0.5389 / Val_loss: 0.7394\n",
      "Epoch: 336, Train_loss: 0.5167 / Val_loss: 0.6358\n",
      "Epoch: 337, Train_loss: 0.5141 / Val_loss: 0.7347\n",
      "Epoch: 338, Train_loss: 0.5184 / Val_loss: 0.7002\n",
      "Epoch: 339, Train_loss: 0.5167 / Val_loss: 0.7329\n",
      "Epoch: 340, Train_loss: 0.5213 / Val_loss: 0.6880\n",
      "Epoch: 341, Train_loss: 0.5205 / Val_loss: 0.6444\n",
      "Epoch: 342, Train_loss: 0.5193 / Val_loss: 0.6415\n",
      "Epoch: 343, Train_loss: 0.5217 / Val_loss: 0.6359\n",
      "Epoch: 344, Train_loss: 0.5224 / Val_loss: 0.7442\n",
      "Epoch: 345, Train_loss: 0.5193 / Val_loss: 0.7119\n",
      "Epoch: 346, Train_loss: 0.5170 / Val_loss: 0.6515\n",
      "Epoch: 347, Train_loss: 0.5157 / Val_loss: 0.7196\n",
      "Epoch: 348, Train_loss: 0.5212 / Val_loss: 0.7313\n",
      "Epoch: 349, Train_loss: 0.5163 / Val_loss: 0.6686\n",
      "Epoch: 350, Train_loss: 0.5213 / Val_loss: 0.7298\n",
      "Epoch: 351, Train_loss: 0.5319 / Val_loss: 0.6647\n",
      "Epoch: 352, Train_loss: 0.5170 / Val_loss: 0.6974\n",
      "Epoch: 353, Train_loss: 0.5092 / Val_loss: 0.6920\n",
      "Epoch: 354, Train_loss: 0.5267 / Val_loss: 0.6465\n",
      "Epoch: 355, Train_loss: 0.5224 / Val_loss: 0.6669\n",
      "Epoch: 356, Train_loss: 0.5127 / Val_loss: 0.6840\n",
      "Epoch: 357, Train_loss: 0.5128 / Val_loss: 0.6648\n",
      "Epoch: 358, Train_loss: 0.5358 / Val_loss: 0.6868\n",
      "Epoch: 359, Train_loss: 0.5209 / Val_loss: 0.6641\n",
      "Epoch: 360, Train_loss: 0.5125 / Val_loss: 0.6394\n",
      "Epoch: 361, Train_loss: 0.5270 / Val_loss: 0.6886\n",
      "Epoch: 362, Train_loss: 0.5165 / Val_loss: 0.7814\n",
      "Epoch: 363, Train_loss: 0.5110 / Val_loss: 0.6750\n",
      "Epoch: 364, Train_loss: 0.5081 / Val_loss: 0.7040\n",
      "Epoch: 365, Train_loss: 0.5071 / Val_loss: 0.6450\n",
      "Epoch: 366, Train_loss: 0.5046 / Val_loss: 0.7033\n",
      "Epoch: 367, Train_loss: 0.5124 / Val_loss: 0.6873\n",
      "Epoch: 368, Train_loss: 0.5143 / Val_loss: 0.6282\n",
      "Epoch: 369, Train_loss: 0.5180 / Val_loss: 0.7188\n",
      "Epoch: 370, Train_loss: 0.5289 / Val_loss: 0.6672\n",
      "Epoch: 371, Train_loss: 0.5150 / Val_loss: 0.6831\n",
      "Epoch: 372, Train_loss: 0.5011 / Val_loss: 0.6455\n",
      "Epoch: 373, Train_loss: 0.5075 / Val_loss: 0.7422\n",
      "Epoch: 374, Train_loss: 0.5067 / Val_loss: 0.6468\n",
      "Epoch: 375, Train_loss: 0.5230 / Val_loss: 0.6912\n",
      "Epoch: 376, Train_loss: 0.5061 / Val_loss: 0.6682\n",
      "Epoch: 377, Train_loss: 0.5075 / Val_loss: 0.7247\n",
      "Epoch: 378, Train_loss: 0.5191 / Val_loss: 0.7237\n",
      "Epoch: 379, Train_loss: 0.5153 / Val_loss: 0.7033\n",
      "Epoch: 380, Train_loss: 0.5314 / Val_loss: 0.7813\n",
      "Epoch: 381, Train_loss: 0.5060 / Val_loss: 0.7058\n",
      "Epoch: 382, Train_loss: 0.5222 / Val_loss: 0.6801\n",
      "Epoch: 383, Train_loss: 0.5196 / Val_loss: 0.6913\n",
      "Epoch: 384, Train_loss: 0.5180 / Val_loss: 0.6962\n",
      "Epoch: 385, Train_loss: 0.5126 / Val_loss: 0.6984\n",
      "Epoch: 386, Train_loss: 0.5195 / Val_loss: 0.6739\n",
      "Epoch: 387, Train_loss: 0.5227 / Val_loss: 0.7444\n",
      "Epoch: 388, Train_loss: 0.5159 / Val_loss: 0.8122\n",
      "Epoch: 389, Train_loss: 0.5229 / Val_loss: 0.7567\n",
      "Epoch: 390, Train_loss: 0.5197 / Val_loss: 0.7290\n",
      "Epoch: 391, Train_loss: 0.5116 / Val_loss: 0.6846\n",
      "Epoch: 392, Train_loss: 0.5163 / Val_loss: 0.7433\n",
      "Epoch: 393, Train_loss: 0.5162 / Val_loss: 0.6016\n",
      "Epoch: 394, Train_loss: 0.5061 / Val_loss: 0.7061\n",
      "Epoch: 395, Train_loss: 0.5071 / Val_loss: 0.7926\n",
      "Epoch: 396, Train_loss: 0.5066 / Val_loss: 0.7202\n",
      "Epoch: 397, Train_loss: 0.5068 / Val_loss: 0.6314\n",
      "Epoch: 398, Train_loss: 0.5214 / Val_loss: 0.8270\n",
      "Epoch: 399, Train_loss: 0.5049 / Val_loss: 0.7225\n",
      "Epoch: 400, Train_loss: 0.5368 / Val_loss: 0.8193\n",
      "Epoch: 401, Train_loss: 0.5153 / Val_loss: 0.7183\n",
      "Epoch: 402, Train_loss: 0.5213 / Val_loss: 0.7142\n",
      "Epoch: 403, Train_loss: 0.5344 / Val_loss: 0.7253\n",
      "Epoch: 404, Train_loss: 0.5026 / Val_loss: 0.6726\n",
      "Epoch: 405, Train_loss: 0.5212 / Val_loss: 0.7282\n",
      "Epoch: 406, Train_loss: 0.5133 / Val_loss: 0.6537\n",
      "Epoch: 407, Train_loss: 0.5113 / Val_loss: 0.7173\n",
      "Epoch: 408, Train_loss: 0.5059 / Val_loss: 0.7236\n",
      "Epoch: 409, Train_loss: 0.5236 / Val_loss: 0.6921\n",
      "Epoch: 410, Train_loss: 0.5084 / Val_loss: 0.6526\n",
      "Epoch: 411, Train_loss: 0.5278 / Val_loss: 0.8194\n",
      "Epoch: 412, Train_loss: 0.5136 / Val_loss: 0.7562\n",
      "Epoch: 413, Train_loss: 0.5156 / Val_loss: 0.7498\n",
      "Epoch: 414, Train_loss: 0.5218 / Val_loss: 0.7816\n",
      "Epoch: 415, Train_loss: 0.4986 / Val_loss: 0.7930\n",
      "Epoch: 416, Train_loss: 0.5055 / Val_loss: 0.6780\n",
      "Epoch: 417, Train_loss: 0.5074 / Val_loss: 0.7075\n",
      "Epoch: 418, Train_loss: 0.5156 / Val_loss: 0.7083\n",
      "Epoch: 419, Train_loss: 0.5213 / Val_loss: 0.7553\n",
      "Epoch: 420, Train_loss: 0.4908 / Val_loss: 0.7404\n",
      "Epoch: 421, Train_loss: 0.5063 / Val_loss: 0.7061\n",
      "Epoch: 422, Train_loss: 0.5094 / Val_loss: 0.7464\n",
      "Epoch: 423, Train_loss: 0.5121 / Val_loss: 0.7306\n",
      "Epoch: 424, Train_loss: 0.4965 / Val_loss: 0.7297\n",
      "Epoch: 425, Train_loss: 0.5299 / Val_loss: 0.7227\n",
      "Epoch: 426, Train_loss: 0.5165 / Val_loss: 0.7733\n",
      "Epoch: 427, Train_loss: 0.5268 / Val_loss: 0.6949\n",
      "Epoch: 428, Train_loss: 0.5269 / Val_loss: 0.7899\n",
      "Epoch: 429, Train_loss: 0.5182 / Val_loss: 0.7889\n",
      "Epoch: 430, Train_loss: 0.5177 / Val_loss: 0.7542\n",
      "Epoch: 431, Train_loss: 0.5121 / Val_loss: 0.7206\n",
      "Epoch: 432, Train_loss: 0.4949 / Val_loss: 0.7161\n",
      "Epoch: 433, Train_loss: 0.5092 / Val_loss: 0.7231\n",
      "Epoch: 434, Train_loss: 0.5023 / Val_loss: 0.7412\n",
      "Epoch: 435, Train_loss: 0.5270 / Val_loss: 0.7232\n",
      "Epoch: 436, Train_loss: 0.5089 / Val_loss: 0.7635\n",
      "Epoch: 437, Train_loss: 0.5250 / Val_loss: 0.6772\n",
      "Epoch: 438, Train_loss: 0.5022 / Val_loss: 0.6625\n",
      "Epoch: 439, Train_loss: 0.5109 / Val_loss: 0.6427\n",
      "Epoch: 440, Train_loss: 0.4970 / Val_loss: 0.6704\n",
      "Epoch: 441, Train_loss: 0.5065 / Val_loss: 0.8770\n",
      "Epoch: 442, Train_loss: 0.5053 / Val_loss: 0.8491\n",
      "Epoch: 443, Train_loss: 0.5100 / Val_loss: 0.7297\n",
      "Epoch: 444, Train_loss: 0.5190 / Val_loss: 0.7805\n",
      "Epoch: 445, Train_loss: 0.5065 / Val_loss: 0.7767\n",
      "Epoch: 446, Train_loss: 0.4855 / Val_loss: 0.7036\n",
      "Epoch: 447, Train_loss: 0.5170 / Val_loss: 0.6855\n",
      "Epoch: 448, Train_loss: 0.5047 / Val_loss: 0.7073\n",
      "Epoch: 449, Train_loss: 0.5107 / Val_loss: 0.6542\n",
      "Epoch: 450, Train_loss: 0.5074 / Val_loss: 0.6563\n",
      "Epoch: 451, Train_loss: 0.5078 / Val_loss: 0.6776\n",
      "Epoch: 452, Train_loss: 0.5105 / Val_loss: 0.7271\n",
      "Epoch: 453, Train_loss: 0.5002 / Val_loss: 0.7106\n",
      "Epoch: 454, Train_loss: 0.5212 / Val_loss: 0.7727\n",
      "Epoch: 455, Train_loss: 0.4843 / Val_loss: 0.6689\n",
      "Epoch: 456, Train_loss: 0.5098 / Val_loss: 0.6496\n",
      "Epoch: 457, Train_loss: 0.5020 / Val_loss: 0.7610\n",
      "Epoch: 458, Train_loss: 0.5083 / Val_loss: 0.6667\n",
      "Epoch: 459, Train_loss: 0.5033 / Val_loss: 0.7416\n",
      "Epoch: 460, Train_loss: 0.5017 / Val_loss: 0.8966\n",
      "Epoch: 461, Train_loss: 0.5039 / Val_loss: 0.6795\n",
      "Epoch: 462, Train_loss: 0.5072 / Val_loss: 0.7038\n",
      "Epoch: 463, Train_loss: 0.5183 / Val_loss: 0.7685\n",
      "Epoch: 464, Train_loss: 0.5009 / Val_loss: 0.7026\n",
      "Epoch: 465, Train_loss: 0.5170 / Val_loss: 0.7119\n",
      "Epoch: 466, Train_loss: 0.5230 / Val_loss: 0.7995\n",
      "Epoch: 467, Train_loss: 0.5088 / Val_loss: 0.8981\n",
      "Epoch: 468, Train_loss: 0.4906 / Val_loss: 0.7165\n",
      "Epoch: 469, Train_loss: 0.5271 / Val_loss: 0.6803\n",
      "Epoch: 470, Train_loss: 0.5033 / Val_loss: 0.7517\n",
      "Epoch: 471, Train_loss: 0.4977 / Val_loss: 0.7503\n",
      "Epoch: 472, Train_loss: 0.5022 / Val_loss: 0.6479\n",
      "Epoch: 473, Train_loss: 0.4939 / Val_loss: 0.7050\n",
      "Epoch: 474, Train_loss: 0.5051 / Val_loss: 0.7347\n",
      "Epoch: 475, Train_loss: 0.4940 / Val_loss: 0.7463\n",
      "Epoch: 476, Train_loss: 0.5325 / Val_loss: 0.8051\n",
      "Epoch: 477, Train_loss: 0.4990 / Val_loss: 0.7733\n",
      "Epoch: 478, Train_loss: 0.5130 / Val_loss: 0.6870\n",
      "Epoch: 479, Train_loss: 0.5238 / Val_loss: 0.8829\n",
      "Epoch: 480, Train_loss: 0.4982 / Val_loss: 0.7694\n",
      "Epoch: 481, Train_loss: 0.4975 / Val_loss: 0.6999\n",
      "Epoch: 482, Train_loss: 0.4966 / Val_loss: 0.8201\n",
      "Epoch: 483, Train_loss: 0.5013 / Val_loss: 0.8091\n",
      "Epoch: 484, Train_loss: 0.4983 / Val_loss: 0.6486\n",
      "Epoch: 485, Train_loss: 0.4970 / Val_loss: 0.7172\n",
      "Epoch: 486, Train_loss: 0.5066 / Val_loss: 0.6328\n",
      "Epoch: 487, Train_loss: 0.4972 / Val_loss: 0.6803\n",
      "Epoch: 488, Train_loss: 0.4902 / Val_loss: 0.7666\n",
      "Epoch: 489, Train_loss: 0.5076 / Val_loss: 0.7358\n",
      "Epoch: 490, Train_loss: 0.5045 / Val_loss: 0.9545\n",
      "Epoch: 491, Train_loss: 0.5068 / Val_loss: 0.8588\n",
      "Epoch: 492, Train_loss: 0.4857 / Val_loss: 0.7058\n",
      "Epoch: 493, Train_loss: 0.4875 / Val_loss: 0.7040\n",
      "Epoch: 494, Train_loss: 0.4918 / Val_loss: 0.6680\n",
      "Epoch: 495, Train_loss: 0.4884 / Val_loss: 0.7711\n",
      "Epoch: 496, Train_loss: 0.5047 / Val_loss: 0.7330\n",
      "Epoch: 497, Train_loss: 0.4950 / Val_loss: 0.7146\n",
      "Epoch: 498, Train_loss: 0.5095 / Val_loss: 0.6833\n",
      "Epoch: 499, Train_loss: 0.5119 / Val_loss: 0.6950\n",
      "Epoch: 500, Train_loss: 0.5074 / Val_loss: 0.8825\n",
      "Epoch: 501, Train_loss: 0.4941 / Val_loss: 0.7622\n",
      "Epoch: 502, Train_loss: 0.4960 / Val_loss: 0.7734\n",
      "Epoch: 503, Train_loss: 0.4962 / Val_loss: 0.7696\n",
      "Epoch: 504, Train_loss: 0.5089 / Val_loss: 0.7292\n",
      "Epoch: 505, Train_loss: 0.5009 / Val_loss: 0.7230\n",
      "Epoch: 506, Train_loss: 0.4924 / Val_loss: 0.7144\n",
      "Epoch: 507, Train_loss: 0.5164 / Val_loss: 0.7225\n",
      "Epoch: 508, Train_loss: 0.4894 / Val_loss: 0.8051\n",
      "Epoch: 509, Train_loss: 0.5028 / Val_loss: 0.7671\n",
      "Epoch: 510, Train_loss: 0.5119 / Val_loss: 0.8202\n",
      "Epoch: 511, Train_loss: 0.4855 / Val_loss: 0.7091\n",
      "Epoch: 512, Train_loss: 0.4884 / Val_loss: 0.8267\n",
      "Epoch: 513, Train_loss: 0.5252 / Val_loss: 0.7511\n",
      "Epoch: 514, Train_loss: 0.4969 / Val_loss: 0.8352\n",
      "Epoch: 515, Train_loss: 0.4932 / Val_loss: 0.6031\n",
      "Epoch: 516, Train_loss: 0.5277 / Val_loss: 0.7458\n",
      "Epoch: 517, Train_loss: 0.4941 / Val_loss: 0.7665\n",
      "Epoch: 518, Train_loss: 0.4993 / Val_loss: 0.7593\n",
      "Epoch: 519, Train_loss: 0.5054 / Val_loss: 0.8054\n",
      "Epoch: 520, Train_loss: 0.4920 / Val_loss: 0.9649\n",
      "Epoch: 521, Train_loss: 0.4993 / Val_loss: 0.6853\n",
      "Epoch: 522, Train_loss: 0.4935 / Val_loss: 0.6542\n",
      "Epoch: 523, Train_loss: 0.5019 / Val_loss: 0.8059\n",
      "Epoch: 524, Train_loss: 0.4839 / Val_loss: 0.7298\n",
      "Epoch: 525, Train_loss: 0.5060 / Val_loss: 0.8124\n",
      "Epoch: 526, Train_loss: 0.4826 / Val_loss: 0.8278\n",
      "Epoch: 527, Train_loss: 0.4830 / Val_loss: 0.6905\n",
      "Epoch: 528, Train_loss: 0.4887 / Val_loss: 0.7708\n",
      "Epoch: 529, Train_loss: 0.4854 / Val_loss: 0.7341\n",
      "Epoch: 530, Train_loss: 0.4962 / Val_loss: 0.7562\n",
      "Epoch: 531, Train_loss: 0.5012 / Val_loss: 0.7545\n",
      "Epoch: 532, Train_loss: 0.4952 / Val_loss: 0.6595\n",
      "Epoch: 533, Train_loss: 0.5019 / Val_loss: 0.7944\n",
      "Epoch: 534, Train_loss: 0.5025 / Val_loss: 0.8126\n",
      "Epoch: 535, Train_loss: 0.4868 / Val_loss: 0.7751\n",
      "Epoch: 536, Train_loss: 0.5090 / Val_loss: 0.6823\n",
      "Epoch: 537, Train_loss: 0.4944 / Val_loss: 0.7956\n",
      "Epoch: 538, Train_loss: 0.4802 / Val_loss: 0.6616\n",
      "Epoch: 539, Train_loss: 0.4732 / Val_loss: 0.7810\n",
      "Epoch: 540, Train_loss: 0.4874 / Val_loss: 0.7650\n",
      "Epoch: 541, Train_loss: 0.4844 / Val_loss: 0.8188\n",
      "Epoch: 542, Train_loss: 0.4820 / Val_loss: 0.8813\n",
      "Epoch: 543, Train_loss: 0.4762 / Val_loss: 0.8137\n",
      "Epoch: 544, Train_loss: 0.4953 / Val_loss: 0.8627\n",
      "Epoch: 545, Train_loss: 0.4811 / Val_loss: 0.8580\n",
      "Epoch: 546, Train_loss: 0.4989 / Val_loss: 0.7764\n",
      "Epoch: 547, Train_loss: 0.4973 / Val_loss: 0.6992\n",
      "Epoch: 548, Train_loss: 0.4941 / Val_loss: 0.7675\n",
      "Epoch: 549, Train_loss: 0.4885 / Val_loss: 0.8628\n",
      "Epoch: 550, Train_loss: 0.4969 / Val_loss: 0.7102\n",
      "Epoch: 551, Train_loss: 0.4815 / Val_loss: 0.7565\n",
      "Epoch: 552, Train_loss: 0.4799 / Val_loss: 0.6998\n",
      "Epoch: 553, Train_loss: 0.4910 / Val_loss: 0.7122\n",
      "Epoch: 554, Train_loss: 0.5007 / Val_loss: 0.8562\n",
      "Epoch: 555, Train_loss: 0.4950 / Val_loss: 0.8449\n",
      "Epoch: 556, Train_loss: 0.4820 / Val_loss: 0.8949\n",
      "Epoch: 557, Train_loss: 0.4867 / Val_loss: 1.0022\n",
      "Epoch: 558, Train_loss: 0.4982 / Val_loss: 0.8260\n",
      "Epoch: 559, Train_loss: 0.4867 / Val_loss: 0.7341\n",
      "Epoch: 560, Train_loss: 0.5092 / Val_loss: 0.7724\n",
      "Epoch: 561, Train_loss: 0.4966 / Val_loss: 0.7161\n",
      "Epoch: 562, Train_loss: 0.4897 / Val_loss: 0.6636\n",
      "Epoch: 563, Train_loss: 0.4959 / Val_loss: 0.8284\n",
      "Epoch: 564, Train_loss: 0.4848 / Val_loss: 0.8988\n",
      "Epoch: 565, Train_loss: 0.4845 / Val_loss: 0.7267\n",
      "Epoch: 566, Train_loss: 0.4758 / Val_loss: 0.7762\n",
      "Epoch: 567, Train_loss: 0.4839 / Val_loss: 0.8061\n",
      "Epoch: 568, Train_loss: 0.4867 / Val_loss: 1.0186\n",
      "Epoch: 569, Train_loss: 0.5072 / Val_loss: 0.9146\n",
      "Epoch: 570, Train_loss: 0.4906 / Val_loss: 0.9000\n",
      "Epoch: 571, Train_loss: 0.4950 / Val_loss: 0.8471\n",
      "Epoch: 572, Train_loss: 0.4682 / Val_loss: 0.8245\n",
      "Epoch: 573, Train_loss: 0.4783 / Val_loss: 0.7560\n",
      "Epoch: 574, Train_loss: 0.5019 / Val_loss: 0.6379\n",
      "Epoch: 575, Train_loss: 0.5022 / Val_loss: 0.9144\n",
      "Epoch: 576, Train_loss: 0.5044 / Val_loss: 0.8061\n",
      "Epoch: 577, Train_loss: 0.4874 / Val_loss: 0.8227\n",
      "Epoch: 578, Train_loss: 0.5083 / Val_loss: 0.8067\n",
      "Epoch: 579, Train_loss: 0.4856 / Val_loss: 0.7430\n",
      "Epoch: 580, Train_loss: 0.5005 / Val_loss: 0.7982\n",
      "Epoch: 581, Train_loss: 0.5160 / Val_loss: 0.6921\n",
      "Epoch: 582, Train_loss: 0.4823 / Val_loss: 0.8950\n",
      "Epoch: 583, Train_loss: 0.4800 / Val_loss: 0.7210\n",
      "Epoch: 584, Train_loss: 0.4923 / Val_loss: 0.7690\n",
      "Epoch: 585, Train_loss: 0.4818 / Val_loss: 0.7353\n",
      "Epoch: 586, Train_loss: 0.4951 / Val_loss: 0.6632\n",
      "Epoch: 587, Train_loss: 0.4879 / Val_loss: 0.7725\n",
      "Epoch: 588, Train_loss: 0.4924 / Val_loss: 0.7613\n",
      "Epoch: 589, Train_loss: 0.4874 / Val_loss: 0.8650\n",
      "Epoch: 590, Train_loss: 0.4845 / Val_loss: 0.7320\n",
      "Epoch: 591, Train_loss: 0.4948 / Val_loss: 0.7337\n",
      "Epoch: 592, Train_loss: 0.4742 / Val_loss: 0.8177\n",
      "Epoch: 593, Train_loss: 0.4894 / Val_loss: 0.8294\n",
      "Epoch: 594, Train_loss: 0.5018 / Val_loss: 0.9500\n",
      "Epoch: 595, Train_loss: 0.5065 / Val_loss: 0.8637\n",
      "Epoch: 596, Train_loss: 0.4900 / Val_loss: 0.8422\n",
      "Epoch: 597, Train_loss: 0.4753 / Val_loss: 0.8991\n",
      "Epoch: 598, Train_loss: 0.4971 / Val_loss: 0.7488\n",
      "Epoch: 599, Train_loss: 0.4932 / Val_loss: 0.8088\n",
      "Epoch: 600, Train_loss: 0.5042 / Val_loss: 0.7349\n",
      "Epoch: 601, Train_loss: 0.4884 / Val_loss: 0.8479\n",
      "Epoch: 602, Train_loss: 0.4840 / Val_loss: 0.7897\n",
      "Epoch: 603, Train_loss: 0.4932 / Val_loss: 0.8251\n",
      "Epoch: 604, Train_loss: 0.4724 / Val_loss: 0.9067\n",
      "Epoch: 605, Train_loss: 0.4757 / Val_loss: 0.8625\n",
      "Epoch: 606, Train_loss: 0.4787 / Val_loss: 0.9198\n",
      "Epoch: 607, Train_loss: 0.4695 / Val_loss: 0.7912\n",
      "Epoch: 608, Train_loss: 0.4852 / Val_loss: 0.7667\n",
      "Epoch: 609, Train_loss: 0.4686 / Val_loss: 0.7808\n",
      "Epoch: 610, Train_loss: 0.4691 / Val_loss: 0.8932\n",
      "Epoch: 611, Train_loss: 0.4737 / Val_loss: 0.8536\n",
      "Epoch: 612, Train_loss: 0.4826 / Val_loss: 0.8050\n",
      "Epoch: 613, Train_loss: 0.4809 / Val_loss: 0.8696\n",
      "Epoch: 614, Train_loss: 0.4896 / Val_loss: 0.8001\n",
      "Epoch: 615, Train_loss: 0.4687 / Val_loss: 0.7889\n",
      "Epoch: 616, Train_loss: 0.4912 / Val_loss: 0.9102\n",
      "Epoch: 617, Train_loss: 0.4746 / Val_loss: 0.8681\n",
      "Epoch: 618, Train_loss: 0.4838 / Val_loss: 0.8812\n",
      "Epoch: 619, Train_loss: 0.4763 / Val_loss: 1.1981\n",
      "Epoch: 620, Train_loss: 0.4707 / Val_loss: 0.9110\n",
      "Epoch: 621, Train_loss: 0.4747 / Val_loss: 0.8271\n",
      "Epoch: 622, Train_loss: 0.4761 / Val_loss: 0.8460\n",
      "Epoch: 623, Train_loss: 0.5148 / Val_loss: 0.8810\n",
      "Epoch: 624, Train_loss: 0.4988 / Val_loss: 0.7676\n",
      "Epoch: 625, Train_loss: 0.4864 / Val_loss: 0.7583\n",
      "Epoch: 626, Train_loss: 0.5079 / Val_loss: 0.7235\n",
      "Epoch: 627, Train_loss: 0.4810 / Val_loss: 0.7903\n",
      "Epoch: 628, Train_loss: 0.4810 / Val_loss: 1.1275\n",
      "Epoch: 629, Train_loss: 0.4803 / Val_loss: 0.9102\n",
      "Epoch: 630, Train_loss: 0.4662 / Val_loss: 1.0843\n",
      "Epoch: 631, Train_loss: 0.5449 / Val_loss: 0.8974\n",
      "Epoch: 632, Train_loss: 0.4907 / Val_loss: 1.1329\n",
      "Epoch: 633, Train_loss: 0.4707 / Val_loss: 0.8438\n",
      "Epoch: 634, Train_loss: 0.4566 / Val_loss: 0.7946\n",
      "Epoch: 635, Train_loss: 0.4821 / Val_loss: 0.9602\n",
      "Epoch: 636, Train_loss: 0.4819 / Val_loss: 1.1055\n",
      "Epoch: 637, Train_loss: 0.4805 / Val_loss: 0.8508\n",
      "Epoch: 638, Train_loss: 0.4651 / Val_loss: 1.1530\n",
      "Epoch: 639, Train_loss: 0.4821 / Val_loss: 0.7788\n",
      "Epoch: 640, Train_loss: 0.4770 / Val_loss: 0.7091\n",
      "Epoch: 641, Train_loss: 0.4608 / Val_loss: 0.9319\n",
      "Epoch: 642, Train_loss: 0.4616 / Val_loss: 0.8803\n",
      "Epoch: 643, Train_loss: 0.5004 / Val_loss: 0.7921\n",
      "Epoch: 644, Train_loss: 0.4803 / Val_loss: 0.8480\n",
      "Epoch: 645, Train_loss: 0.4703 / Val_loss: 0.7599\n",
      "Epoch: 646, Train_loss: 0.4725 / Val_loss: 1.1189\n",
      "Epoch: 647, Train_loss: 0.4769 / Val_loss: 0.9171\n",
      "Epoch: 648, Train_loss: 0.4754 / Val_loss: 0.9692\n",
      "Epoch: 649, Train_loss: 0.4830 / Val_loss: 0.9767\n",
      "Epoch: 650, Train_loss: 0.4744 / Val_loss: 1.0909\n",
      "Epoch: 651, Train_loss: 0.4792 / Val_loss: 0.9723\n",
      "Epoch: 652, Train_loss: 0.4773 / Val_loss: 1.0611\n",
      "Epoch: 653, Train_loss: 0.4815 / Val_loss: 0.9808\n",
      "Epoch: 654, Train_loss: 0.4501 / Val_loss: 0.8346\n",
      "Epoch: 655, Train_loss: 0.4766 / Val_loss: 0.9029\n",
      "Epoch: 656, Train_loss: 0.4911 / Val_loss: 0.9638\n",
      "Epoch: 657, Train_loss: 0.4999 / Val_loss: 0.8688\n",
      "Epoch: 658, Train_loss: 0.4852 / Val_loss: 0.7681\n",
      "Epoch: 659, Train_loss: 0.4809 / Val_loss: 1.0506\n",
      "Epoch: 660, Train_loss: 0.4680 / Val_loss: 0.7421\n",
      "Epoch: 661, Train_loss: 0.4570 / Val_loss: 1.0324\n",
      "Epoch: 662, Train_loss: 0.4734 / Val_loss: 1.1169\n",
      "Epoch: 663, Train_loss: 0.5050 / Val_loss: 0.8415\n",
      "Epoch: 664, Train_loss: 0.4480 / Val_loss: 1.0028\n",
      "Epoch: 665, Train_loss: 0.4806 / Val_loss: 0.8886\n",
      "Epoch: 666, Train_loss: 0.4838 / Val_loss: 0.9207\n",
      "Epoch: 667, Train_loss: 0.4530 / Val_loss: 1.0413\n",
      "Epoch: 668, Train_loss: 0.4653 / Val_loss: 0.8948\n",
      "Epoch: 669, Train_loss: 0.4875 / Val_loss: 0.7955\n",
      "Epoch: 670, Train_loss: 0.4864 / Val_loss: 0.9282\n",
      "Epoch: 671, Train_loss: 0.4610 / Val_loss: 0.7798\n",
      "Epoch: 672, Train_loss: 0.4647 / Val_loss: 1.0930\n",
      "Epoch: 673, Train_loss: 0.4748 / Val_loss: 0.8633\n",
      "Epoch: 674, Train_loss: 0.4801 / Val_loss: 0.8459\n",
      "Epoch: 675, Train_loss: 0.4978 / Val_loss: 0.7626\n",
      "Epoch: 676, Train_loss: 0.4771 / Val_loss: 1.0362\n",
      "Epoch: 677, Train_loss: 0.4897 / Val_loss: 1.0233\n",
      "Epoch: 678, Train_loss: 0.4877 / Val_loss: 1.0453\n",
      "Epoch: 679, Train_loss: 0.4798 / Val_loss: 0.8609\n",
      "Epoch: 680, Train_loss: 0.4742 / Val_loss: 0.8488\n",
      "Epoch: 681, Train_loss: 0.4788 / Val_loss: 1.1558\n",
      "Epoch: 682, Train_loss: 0.4591 / Val_loss: 0.7684\n",
      "Epoch: 683, Train_loss: 0.4822 / Val_loss: 1.0921\n",
      "Epoch: 684, Train_loss: 0.4626 / Val_loss: 0.9530\n",
      "Epoch: 685, Train_loss: 0.4604 / Val_loss: 0.8969\n",
      "Epoch: 686, Train_loss: 0.4932 / Val_loss: 1.1168\n",
      "Epoch: 687, Train_loss: 0.4971 / Val_loss: 1.0925\n",
      "Epoch: 688, Train_loss: 0.4630 / Val_loss: 0.8062\n",
      "Epoch: 689, Train_loss: 0.5038 / Val_loss: 0.9660\n",
      "Epoch: 690, Train_loss: 0.4676 / Val_loss: 1.0177\n",
      "Epoch: 691, Train_loss: 0.4483 / Val_loss: 0.8397\n",
      "Epoch: 692, Train_loss: 0.4688 / Val_loss: 0.8132\n",
      "Epoch: 693, Train_loss: 0.4596 / Val_loss: 0.9854\n",
      "Epoch: 694, Train_loss: 0.4737 / Val_loss: 1.1251\n",
      "Epoch: 695, Train_loss: 0.4843 / Val_loss: 0.7226\n",
      "Epoch: 696, Train_loss: 0.4619 / Val_loss: 1.1514\n",
      "Epoch: 697, Train_loss: 0.4834 / Val_loss: 1.1574\n",
      "Epoch: 698, Train_loss: 0.4652 / Val_loss: 1.0079\n",
      "Epoch: 699, Train_loss: 0.4703 / Val_loss: 1.0008\n",
      "Epoch: 700, Train_loss: 0.4714 / Val_loss: 0.9641\n",
      "Epoch: 701, Train_loss: 0.4666 / Val_loss: 1.0114\n",
      "Epoch: 702, Train_loss: 0.4647 / Val_loss: 0.8005\n",
      "Epoch: 703, Train_loss: 0.4730 / Val_loss: 1.0204\n",
      "Epoch: 704, Train_loss: 0.4611 / Val_loss: 0.9054\n",
      "Epoch: 705, Train_loss: 0.4679 / Val_loss: 1.1286\n",
      "Epoch: 706, Train_loss: 0.4671 / Val_loss: 0.9155\n",
      "Epoch: 707, Train_loss: 0.4555 / Val_loss: 0.9283\n",
      "Epoch: 708, Train_loss: 0.4768 / Val_loss: 1.2300\n",
      "Epoch: 709, Train_loss: 0.4661 / Val_loss: 0.9812\n",
      "Epoch: 710, Train_loss: 0.4419 / Val_loss: 1.0662\n",
      "Epoch: 711, Train_loss: 0.4738 / Val_loss: 0.9444\n",
      "Epoch: 712, Train_loss: 0.4605 / Val_loss: 1.0771\n",
      "Epoch: 713, Train_loss: 0.5824 / Val_loss: 0.8760\n",
      "Epoch: 714, Train_loss: 0.4790 / Val_loss: 0.9350\n",
      "Epoch: 715, Train_loss: 0.4682 / Val_loss: 1.0263\n",
      "Epoch: 716, Train_loss: 0.4979 / Val_loss: 0.6791\n",
      "Epoch: 717, Train_loss: 0.4416 / Val_loss: 0.9522\n",
      "Epoch: 718, Train_loss: 0.4905 / Val_loss: 0.9055\n",
      "Epoch: 719, Train_loss: 0.4585 / Val_loss: 0.8519\n",
      "Epoch: 720, Train_loss: 0.4890 / Val_loss: 0.8940\n",
      "Epoch: 721, Train_loss: 0.4649 / Val_loss: 0.7705\n",
      "Epoch: 722, Train_loss: 0.4663 / Val_loss: 0.8577\n",
      "Epoch: 723, Train_loss: 0.4931 / Val_loss: 0.8274\n",
      "Epoch: 724, Train_loss: 0.4832 / Val_loss: 0.9597\n",
      "Epoch: 725, Train_loss: 0.4627 / Val_loss: 1.1396\n",
      "Epoch: 726, Train_loss: 0.4476 / Val_loss: 0.9877\n",
      "Epoch: 727, Train_loss: 0.4703 / Val_loss: 0.8872\n",
      "Epoch: 728, Train_loss: 0.4781 / Val_loss: 1.0815\n",
      "Epoch: 729, Train_loss: 0.4942 / Val_loss: 1.1151\n",
      "Epoch: 730, Train_loss: 0.4760 / Val_loss: 1.0778\n",
      "Epoch: 731, Train_loss: 0.4764 / Val_loss: 1.1983\n",
      "Epoch: 732, Train_loss: 0.4778 / Val_loss: 1.0765\n",
      "Epoch: 733, Train_loss: 0.4699 / Val_loss: 1.1069\n",
      "Epoch: 734, Train_loss: 0.4927 / Val_loss: 0.9156\n",
      "Epoch: 735, Train_loss: 0.4717 / Val_loss: 1.0839\n",
      "Epoch: 736, Train_loss: 0.4595 / Val_loss: 0.8548\n",
      "Epoch: 737, Train_loss: 0.4561 / Val_loss: 1.2020\n",
      "Epoch: 738, Train_loss: 0.4453 / Val_loss: 0.9372\n",
      "Epoch: 739, Train_loss: 0.4515 / Val_loss: 1.2321\n",
      "Epoch: 740, Train_loss: 0.4648 / Val_loss: 0.9361\n",
      "Epoch: 741, Train_loss: 0.4748 / Val_loss: 0.9192\n",
      "Epoch: 742, Train_loss: 0.4749 / Val_loss: 0.9522\n",
      "Epoch: 743, Train_loss: 0.4557 / Val_loss: 0.9463\n",
      "Epoch: 744, Train_loss: 0.4677 / Val_loss: 1.1883\n",
      "Epoch: 745, Train_loss: 0.4457 / Val_loss: 1.1421\n",
      "Epoch: 746, Train_loss: 0.4658 / Val_loss: 1.0372\n",
      "Epoch: 747, Train_loss: 0.4848 / Val_loss: 1.0742\n",
      "Epoch: 748, Train_loss: 0.4561 / Val_loss: 1.1390\n",
      "Epoch: 749, Train_loss: 0.4668 / Val_loss: 1.1228\n",
      "Epoch: 750, Train_loss: 0.4506 / Val_loss: 0.8910\n",
      "Epoch: 751, Train_loss: 0.4673 / Val_loss: 0.9288\n",
      "Epoch: 752, Train_loss: 0.4503 / Val_loss: 0.9753\n",
      "Epoch: 753, Train_loss: 0.4819 / Val_loss: 0.8124\n",
      "Epoch: 754, Train_loss: 0.4489 / Val_loss: 1.0572\n",
      "Epoch: 755, Train_loss: 0.4473 / Val_loss: 1.1068\n",
      "Epoch: 756, Train_loss: 0.4627 / Val_loss: 0.8898\n",
      "Epoch: 757, Train_loss: 0.4452 / Val_loss: 0.9400\n",
      "Epoch: 758, Train_loss: 0.4577 / Val_loss: 0.9540\n",
      "Epoch: 759, Train_loss: 0.4591 / Val_loss: 1.0753\n",
      "Epoch: 760, Train_loss: 0.4496 / Val_loss: 0.8759\n",
      "Epoch: 761, Train_loss: 0.4802 / Val_loss: 1.2202\n",
      "Epoch: 762, Train_loss: 0.4564 / Val_loss: 1.2896\n",
      "Epoch: 763, Train_loss: 0.4509 / Val_loss: 1.0870\n",
      "Epoch: 764, Train_loss: 0.4433 / Val_loss: 0.9687\n",
      "Epoch: 765, Train_loss: 0.4522 / Val_loss: 1.1129\n",
      "Epoch: 766, Train_loss: 0.4696 / Val_loss: 0.9936\n",
      "Epoch: 767, Train_loss: 0.4756 / Val_loss: 0.9188\n",
      "Epoch: 768, Train_loss: 0.4703 / Val_loss: 0.8890\n",
      "Epoch: 769, Train_loss: 0.4667 / Val_loss: 0.8287\n",
      "Epoch: 770, Train_loss: 0.4557 / Val_loss: 1.0207\n",
      "Epoch: 771, Train_loss: 0.4674 / Val_loss: 1.0870\n",
      "Epoch: 772, Train_loss: 0.4588 / Val_loss: 1.0166\n",
      "Epoch: 773, Train_loss: 0.4445 / Val_loss: 0.8971\n",
      "Epoch: 774, Train_loss: 0.4559 / Val_loss: 0.6656\n",
      "Epoch: 775, Train_loss: 0.4694 / Val_loss: 1.1902\n",
      "Epoch: 776, Train_loss: 0.4521 / Val_loss: 0.9856\n",
      "Epoch: 777, Train_loss: 0.4616 / Val_loss: 1.2357\n",
      "Epoch: 778, Train_loss: 0.4819 / Val_loss: 1.1830\n",
      "Epoch: 779, Train_loss: 0.4498 / Val_loss: 0.9948\n",
      "Epoch: 780, Train_loss: 0.4537 / Val_loss: 0.8485\n",
      "Epoch: 781, Train_loss: 0.4671 / Val_loss: 1.1646\n",
      "Epoch: 782, Train_loss: 0.4632 / Val_loss: 0.8213\n",
      "Epoch: 783, Train_loss: 0.4563 / Val_loss: 1.2901\n",
      "Epoch: 784, Train_loss: 0.4583 / Val_loss: 1.1368\n",
      "Epoch: 785, Train_loss: 0.4788 / Val_loss: 1.5110\n",
      "Epoch: 786, Train_loss: 0.4505 / Val_loss: 1.0013\n",
      "Epoch: 787, Train_loss: 0.4691 / Val_loss: 1.0119\n",
      "Epoch: 788, Train_loss: 0.4478 / Val_loss: 1.2319\n",
      "Epoch: 789, Train_loss: 0.4458 / Val_loss: 1.1864\n",
      "Epoch: 790, Train_loss: 0.4484 / Val_loss: 1.0640\n",
      "Epoch: 791, Train_loss: 0.4807 / Val_loss: 1.5520\n",
      "Epoch: 792, Train_loss: 0.4666 / Val_loss: 1.0224\n",
      "Epoch: 793, Train_loss: 0.4392 / Val_loss: 1.2793\n",
      "Epoch: 794, Train_loss: 0.4770 / Val_loss: 0.9710\n",
      "Epoch: 795, Train_loss: 0.5048 / Val_loss: 1.0153\n",
      "Epoch: 796, Train_loss: 0.4678 / Val_loss: 1.1589\n",
      "Epoch: 797, Train_loss: 0.4517 / Val_loss: 1.0930\n",
      "Epoch: 798, Train_loss: 0.4757 / Val_loss: 1.2193\n",
      "Epoch: 799, Train_loss: 0.4505 / Val_loss: 1.2026\n",
      "Epoch: 800, Train_loss: 0.4422 / Val_loss: 1.0633\n",
      "Epoch: 801, Train_loss: 0.4591 / Val_loss: 0.9491\n",
      "Epoch: 802, Train_loss: 0.4645 / Val_loss: 0.9187\n",
      "Epoch: 803, Train_loss: 0.4676 / Val_loss: 1.4250\n",
      "Epoch: 804, Train_loss: 0.4638 / Val_loss: 0.7903\n",
      "Epoch: 805, Train_loss: 0.4644 / Val_loss: 1.3329\n",
      "Epoch: 806, Train_loss: 0.4508 / Val_loss: 1.0510\n",
      "Epoch: 807, Train_loss: 0.4374 / Val_loss: 1.4060\n",
      "Epoch: 808, Train_loss: 0.4403 / Val_loss: 1.0758\n",
      "Epoch: 809, Train_loss: 0.4671 / Val_loss: 1.2672\n",
      "Epoch: 810, Train_loss: 0.4888 / Val_loss: 1.3575\n",
      "Epoch: 811, Train_loss: 0.4564 / Val_loss: 1.3248\n",
      "Epoch: 812, Train_loss: 0.4612 / Val_loss: 1.0254\n",
      "Epoch: 813, Train_loss: 0.4900 / Val_loss: 1.2062\n",
      "Epoch: 814, Train_loss: 0.4604 / Val_loss: 1.1862\n",
      "Epoch: 815, Train_loss: 0.4447 / Val_loss: 0.8283\n",
      "Epoch: 816, Train_loss: 0.4727 / Val_loss: 0.9415\n",
      "Epoch: 817, Train_loss: 0.4492 / Val_loss: 1.2564\n",
      "Epoch: 818, Train_loss: 0.4547 / Val_loss: 1.1542\n",
      "Epoch: 819, Train_loss: 0.4563 / Val_loss: 1.1441\n",
      "Epoch: 820, Train_loss: 0.4956 / Val_loss: 0.7874\n",
      "Epoch: 821, Train_loss: 0.4488 / Val_loss: 1.1250\n",
      "Epoch: 822, Train_loss: 0.4562 / Val_loss: 1.5243\n",
      "Epoch: 823, Train_loss: 0.4437 / Val_loss: 1.0627\n",
      "Epoch: 824, Train_loss: 0.4571 / Val_loss: 0.9580\n",
      "Epoch: 825, Train_loss: 0.4494 / Val_loss: 0.7972\n",
      "Epoch: 826, Train_loss: 0.4801 / Val_loss: 0.9687\n",
      "Epoch: 827, Train_loss: 0.4912 / Val_loss: 1.2138\n",
      "Epoch: 828, Train_loss: 0.4484 / Val_loss: 1.1433\n",
      "Epoch: 829, Train_loss: 0.4565 / Val_loss: 0.9856\n",
      "Epoch: 830, Train_loss: 0.4373 / Val_loss: 1.0929\n",
      "Epoch: 831, Train_loss: 0.4477 / Val_loss: 1.2822\n",
      "Epoch: 832, Train_loss: 0.4611 / Val_loss: 1.0880\n",
      "Epoch: 833, Train_loss: 0.4680 / Val_loss: 1.0102\n",
      "Epoch: 834, Train_loss: 0.4551 / Val_loss: 1.1208\n",
      "Epoch: 835, Train_loss: 0.4527 / Val_loss: 1.3751\n",
      "Epoch: 836, Train_loss: 0.4599 / Val_loss: 1.1558\n",
      "Epoch: 837, Train_loss: 0.4380 / Val_loss: 1.0038\n",
      "Epoch: 838, Train_loss: 0.4421 / Val_loss: 1.1049\n",
      "Epoch: 839, Train_loss: 0.4564 / Val_loss: 1.3063\n",
      "Epoch: 840, Train_loss: 0.4594 / Val_loss: 1.2636\n",
      "Epoch: 841, Train_loss: 0.4429 / Val_loss: 1.0190\n",
      "Epoch: 842, Train_loss: 0.4602 / Val_loss: 0.8521\n",
      "Epoch: 843, Train_loss: 0.4818 / Val_loss: 1.4549\n",
      "Epoch: 844, Train_loss: 0.4735 / Val_loss: 1.2627\n",
      "Epoch: 845, Train_loss: 0.4766 / Val_loss: 1.1207\n",
      "Epoch: 846, Train_loss: 0.4572 / Val_loss: 1.0803\n",
      "Epoch: 847, Train_loss: 0.4916 / Val_loss: 1.4742\n",
      "Epoch: 848, Train_loss: 0.4467 / Val_loss: 1.2739\n",
      "Epoch: 849, Train_loss: 0.4494 / Val_loss: 0.7902\n",
      "Epoch: 850, Train_loss: 0.4800 / Val_loss: 0.9502\n",
      "Epoch: 851, Train_loss: 0.4503 / Val_loss: 1.1244\n",
      "Epoch: 852, Train_loss: 0.4700 / Val_loss: 1.1528\n",
      "Epoch: 853, Train_loss: 0.4476 / Val_loss: 1.0262\n",
      "Epoch: 854, Train_loss: 0.4587 / Val_loss: 0.9237\n",
      "Epoch: 855, Train_loss: 0.4656 / Val_loss: 1.6273\n",
      "Epoch: 856, Train_loss: 0.4630 / Val_loss: 1.1292\n",
      "Epoch: 857, Train_loss: 0.4356 / Val_loss: 0.8979\n",
      "Epoch: 858, Train_loss: 0.4591 / Val_loss: 0.7446\n",
      "Epoch: 859, Train_loss: 0.4518 / Val_loss: 1.2792\n",
      "Epoch: 860, Train_loss: 0.4425 / Val_loss: 1.4274\n",
      "Epoch: 861, Train_loss: 0.4441 / Val_loss: 1.2280\n",
      "Epoch: 862, Train_loss: 0.4478 / Val_loss: 1.0911\n",
      "Epoch: 863, Train_loss: 0.4876 / Val_loss: 1.0019\n",
      "Epoch: 864, Train_loss: 0.4409 / Val_loss: 0.9753\n",
      "Epoch: 865, Train_loss: 0.4392 / Val_loss: 1.2547\n",
      "Epoch: 866, Train_loss: 0.4530 / Val_loss: 1.1031\n",
      "Epoch: 867, Train_loss: 0.4585 / Val_loss: 0.7668\n",
      "Epoch: 868, Train_loss: 0.4972 / Val_loss: 1.0400\n",
      "Epoch: 869, Train_loss: 0.4233 / Val_loss: 1.0585\n",
      "Epoch: 870, Train_loss: 0.4317 / Val_loss: 0.9126\n",
      "Epoch: 871, Train_loss: 0.4560 / Val_loss: 1.0894\n",
      "Epoch: 872, Train_loss: 0.4701 / Val_loss: 1.1955\n",
      "Epoch: 873, Train_loss: 0.4534 / Val_loss: 1.1165\n",
      "Epoch: 874, Train_loss: 0.4396 / Val_loss: 1.1561\n",
      "Epoch: 875, Train_loss: 0.4549 / Val_loss: 1.0740\n",
      "Epoch: 876, Train_loss: 0.4397 / Val_loss: 0.8921\n",
      "Epoch: 877, Train_loss: 0.4610 / Val_loss: 0.8783\n",
      "Epoch: 878, Train_loss: 0.4360 / Val_loss: 1.0202\n",
      "Epoch: 879, Train_loss: 0.4550 / Val_loss: 1.3909\n",
      "Epoch: 880, Train_loss: 0.4689 / Val_loss: 0.7987\n",
      "Epoch: 881, Train_loss: 0.4348 / Val_loss: 1.2952\n",
      "Epoch: 882, Train_loss: 0.4285 / Val_loss: 1.2551\n",
      "Epoch: 883, Train_loss: 0.4266 / Val_loss: 1.4950\n",
      "Epoch: 884, Train_loss: 0.4598 / Val_loss: 0.8704\n",
      "Epoch: 885, Train_loss: 0.4425 / Val_loss: 0.9849\n",
      "Epoch: 886, Train_loss: 0.4557 / Val_loss: 1.3387\n",
      "Epoch: 887, Train_loss: 0.4675 / Val_loss: 0.9149\n",
      "Epoch: 888, Train_loss: 0.4216 / Val_loss: 1.3808\n",
      "Epoch: 889, Train_loss: 0.4582 / Val_loss: 0.8341\n",
      "Epoch: 890, Train_loss: 0.4421 / Val_loss: 1.7647\n",
      "Epoch: 891, Train_loss: 0.4300 / Val_loss: 1.1062\n",
      "Epoch: 892, Train_loss: 0.4706 / Val_loss: 1.0009\n",
      "Epoch: 893, Train_loss: 0.4439 / Val_loss: 1.2269\n",
      "Epoch: 894, Train_loss: 0.4312 / Val_loss: 1.5362\n",
      "Epoch: 895, Train_loss: 0.4412 / Val_loss: 1.0858\n",
      "Epoch: 896, Train_loss: 0.4487 / Val_loss: 0.9609\n",
      "Epoch: 897, Train_loss: 0.4308 / Val_loss: 1.0072\n",
      "Epoch: 898, Train_loss: 0.4846 / Val_loss: 0.9253\n",
      "Epoch: 899, Train_loss: 0.4434 / Val_loss: 1.4029\n",
      "Epoch: 900, Train_loss: 0.4349 / Val_loss: 1.0577\n",
      "Epoch: 901, Train_loss: 0.4428 / Val_loss: 1.4676\n",
      "Epoch: 902, Train_loss: 0.4299 / Val_loss: 1.0619\n",
      "Epoch: 903, Train_loss: 0.4248 / Val_loss: 1.0347\n",
      "Epoch: 904, Train_loss: 0.4624 / Val_loss: 0.9748\n",
      "Epoch: 905, Train_loss: 0.4382 / Val_loss: 1.2190\n",
      "Epoch: 906, Train_loss: 0.4362 / Val_loss: 1.0666\n",
      "Epoch: 907, Train_loss: 0.4431 / Val_loss: 1.3029\n",
      "Epoch: 908, Train_loss: 0.4483 / Val_loss: 1.4324\n",
      "Epoch: 909, Train_loss: 0.4261 / Val_loss: 0.8956\n",
      "Epoch: 910, Train_loss: 0.4529 / Val_loss: 1.3023\n",
      "Epoch: 911, Train_loss: 0.5023 / Val_loss: 1.1070\n",
      "Epoch: 912, Train_loss: 0.4588 / Val_loss: 1.5126\n",
      "Epoch: 913, Train_loss: 0.4516 / Val_loss: 1.4306\n",
      "Epoch: 914, Train_loss: 0.4711 / Val_loss: 1.1967\n",
      "Epoch: 915, Train_loss: 0.4414 / Val_loss: 1.3995\n",
      "Epoch: 916, Train_loss: 0.4739 / Val_loss: 0.8572\n",
      "Epoch: 917, Train_loss: 0.4683 / Val_loss: 0.9120\n",
      "Epoch: 918, Train_loss: 0.4588 / Val_loss: 1.0725\n",
      "Epoch: 919, Train_loss: 0.4383 / Val_loss: 0.9640\n",
      "Epoch: 920, Train_loss: 0.4583 / Val_loss: 1.0735\n",
      "Epoch: 921, Train_loss: 0.4385 / Val_loss: 1.0418\n",
      "Epoch: 922, Train_loss: 0.4508 / Val_loss: 1.1989\n",
      "Epoch: 923, Train_loss: 0.4217 / Val_loss: 1.3657\n",
      "Epoch: 924, Train_loss: 0.4605 / Val_loss: 1.2260\n",
      "Epoch: 925, Train_loss: 0.4402 / Val_loss: 1.6907\n",
      "Epoch: 926, Train_loss: 0.4388 / Val_loss: 1.3519\n",
      "Epoch: 927, Train_loss: 0.4983 / Val_loss: 0.9720\n",
      "Epoch: 928, Train_loss: 0.4255 / Val_loss: 1.5124\n",
      "Epoch: 929, Train_loss: 0.4417 / Val_loss: 1.3258\n",
      "Epoch: 930, Train_loss: 0.4316 / Val_loss: 1.3046\n",
      "Epoch: 931, Train_loss: 0.5114 / Val_loss: 1.3364\n",
      "Epoch: 932, Train_loss: 0.4609 / Val_loss: 1.0927\n",
      "Epoch: 933, Train_loss: 0.4596 / Val_loss: 1.0477\n",
      "Epoch: 934, Train_loss: 0.4746 / Val_loss: 1.1812\n",
      "Epoch: 935, Train_loss: 0.4608 / Val_loss: 0.8239\n",
      "Epoch: 936, Train_loss: 0.4572 / Val_loss: 0.8811\n",
      "Epoch: 937, Train_loss: 0.4555 / Val_loss: 0.9646\n",
      "Epoch: 938, Train_loss: 0.4367 / Val_loss: 0.8263\n",
      "Epoch: 939, Train_loss: 0.4599 / Val_loss: 1.0183\n",
      "Epoch: 940, Train_loss: 0.4484 / Val_loss: 0.8704\n",
      "Epoch: 941, Train_loss: 0.4523 / Val_loss: 1.0002\n",
      "Epoch: 942, Train_loss: 0.4310 / Val_loss: 1.3678\n",
      "Epoch: 943, Train_loss: 0.4350 / Val_loss: 1.0129\n",
      "Epoch: 944, Train_loss: 0.4441 / Val_loss: 1.1013\n",
      "Epoch: 945, Train_loss: 0.4558 / Val_loss: 1.0188\n",
      "Epoch: 946, Train_loss: 0.4293 / Val_loss: 0.9810\n",
      "Epoch: 947, Train_loss: 0.4635 / Val_loss: 1.3722\n",
      "Epoch: 948, Train_loss: 0.4586 / Val_loss: 1.3081\n",
      "Epoch: 949, Train_loss: 0.4287 / Val_loss: 1.2329\n",
      "Epoch: 950, Train_loss: 0.4534 / Val_loss: 1.1189\n",
      "Epoch: 951, Train_loss: 0.4595 / Val_loss: 1.3200\n",
      "Epoch: 952, Train_loss: 0.4476 / Val_loss: 1.0444\n",
      "Epoch: 953, Train_loss: 0.4415 / Val_loss: 1.1154\n",
      "Epoch: 954, Train_loss: 0.4694 / Val_loss: 1.0203\n",
      "Epoch: 955, Train_loss: 0.4736 / Val_loss: 1.1764\n",
      "Epoch: 956, Train_loss: 0.4485 / Val_loss: 1.2146\n",
      "Epoch: 957, Train_loss: 0.4380 / Val_loss: 1.4109\n",
      "Epoch: 958, Train_loss: 0.4386 / Val_loss: 1.0044\n",
      "Epoch: 959, Train_loss: 0.4328 / Val_loss: 1.2060\n",
      "Epoch: 960, Train_loss: 0.4285 / Val_loss: 1.2978\n",
      "Epoch: 961, Train_loss: 0.4362 / Val_loss: 1.0095\n",
      "Epoch: 962, Train_loss: 0.4552 / Val_loss: 0.8915\n",
      "Epoch: 963, Train_loss: 0.4454 / Val_loss: 1.6050\n",
      "Epoch: 964, Train_loss: 0.4467 / Val_loss: 1.4684\n",
      "Epoch: 965, Train_loss: 0.4229 / Val_loss: 0.9710\n",
      "Epoch: 966, Train_loss: 0.4415 / Val_loss: 1.1921\n",
      "Epoch: 967, Train_loss: 0.4664 / Val_loss: 1.6212\n",
      "Epoch: 968, Train_loss: 0.4462 / Val_loss: 1.3249\n",
      "Epoch: 969, Train_loss: 0.4243 / Val_loss: 1.1658\n",
      "Epoch: 970, Train_loss: 0.4313 / Val_loss: 0.8520\n",
      "Epoch: 971, Train_loss: 0.4567 / Val_loss: 1.1734\n",
      "Epoch: 972, Train_loss: 0.4437 / Val_loss: 1.3677\n",
      "Epoch: 973, Train_loss: 0.4254 / Val_loss: 1.2044\n",
      "Epoch: 974, Train_loss: 0.4430 / Val_loss: 1.1840\n",
      "Epoch: 975, Train_loss: 0.4372 / Val_loss: 1.3148\n",
      "Epoch: 976, Train_loss: 0.4794 / Val_loss: 0.8486\n",
      "Epoch: 977, Train_loss: 0.4300 / Val_loss: 1.2102\n",
      "Epoch: 978, Train_loss: 0.4691 / Val_loss: 0.8632\n",
      "Epoch: 979, Train_loss: 0.4474 / Val_loss: 1.0561\n",
      "Epoch: 980, Train_loss: 0.4374 / Val_loss: 1.0010\n",
      "Epoch: 981, Train_loss: 0.4242 / Val_loss: 1.0177\n",
      "Epoch: 982, Train_loss: 0.4388 / Val_loss: 1.2340\n",
      "Epoch: 983, Train_loss: 0.4327 / Val_loss: 1.1529\n",
      "Epoch: 984, Train_loss: 0.4614 / Val_loss: 0.9100\n",
      "Epoch: 985, Train_loss: 0.4522 / Val_loss: 1.0709\n",
      "Epoch: 986, Train_loss: 0.4377 / Val_loss: 1.1428\n",
      "Epoch: 987, Train_loss: 0.4746 / Val_loss: 1.0717\n",
      "Epoch: 988, Train_loss: 0.4181 / Val_loss: 1.1250\n",
      "Epoch: 989, Train_loss: 0.4353 / Val_loss: 1.2503\n",
      "Epoch: 990, Train_loss: 0.4326 / Val_loss: 1.2676\n",
      "Epoch: 991, Train_loss: 0.4215 / Val_loss: 1.4401\n",
      "Epoch: 992, Train_loss: 0.4247 / Val_loss: 1.5616\n",
      "Epoch: 993, Train_loss: 0.4440 / Val_loss: 1.1864\n",
      "Epoch: 994, Train_loss: 0.4268 / Val_loss: 1.0547\n",
      "Epoch: 995, Train_loss: 0.4388 / Val_loss: 1.1802\n",
      "Epoch: 996, Train_loss: 0.4362 / Val_loss: 1.7000\n",
      "Epoch: 997, Train_loss: 0.4788 / Val_loss: 1.3947\n",
      "Epoch: 998, Train_loss: 0.4285 / Val_loss: 1.4707\n",
      "Epoch: 999, Train_loss: 0.4385 / Val_loss: 1.0061\n",
      "Epoch: 1000, Train_loss: 0.4658 / Val_loss: 1.3807\n",
      "Epoch: 1001, Train_loss: 0.4323 / Val_loss: 0.9906\n",
      "Epoch: 1002, Train_loss: 0.4337 / Val_loss: 0.8491\n",
      "Epoch: 1003, Train_loss: 0.4466 / Val_loss: 0.7326\n",
      "Epoch: 1004, Train_loss: 0.4357 / Val_loss: 1.1768\n",
      "Epoch: 1005, Train_loss: 0.4371 / Val_loss: 1.0353\n",
      "Epoch: 1006, Train_loss: 0.4494 / Val_loss: 1.0237\n",
      "Epoch: 1007, Train_loss: 0.4288 / Val_loss: 1.0385\n",
      "Epoch: 1008, Train_loss: 0.4385 / Val_loss: 1.1913\n",
      "Epoch: 1009, Train_loss: 0.4340 / Val_loss: 1.1413\n",
      "Epoch: 1010, Train_loss: 0.4101 / Val_loss: 1.2779\n",
      "Epoch: 1011, Train_loss: 0.4416 / Val_loss: 0.9101\n",
      "Epoch: 1012, Train_loss: 0.4586 / Val_loss: 1.0423\n",
      "Epoch: 1013, Train_loss: 0.4299 / Val_loss: 1.4348\n",
      "Epoch: 1014, Train_loss: 0.4555 / Val_loss: 1.3314\n",
      "Epoch: 1015, Train_loss: 0.4352 / Val_loss: 1.0420\n",
      "Epoch: 1016, Train_loss: 0.4229 / Val_loss: 1.0372\n",
      "Epoch: 1017, Train_loss: 0.4379 / Val_loss: 1.3274\n",
      "Epoch: 1018, Train_loss: 0.4934 / Val_loss: 1.4211\n",
      "Epoch: 1019, Train_loss: 0.4264 / Val_loss: 1.6671\n",
      "Epoch: 1020, Train_loss: 0.4291 / Val_loss: 1.1904\n",
      "Epoch: 1021, Train_loss: 0.4623 / Val_loss: 1.4971\n",
      "Epoch: 1022, Train_loss: 0.4221 / Val_loss: 1.1248\n",
      "Epoch: 1023, Train_loss: 0.4174 / Val_loss: 1.1966\n",
      "Epoch: 1024, Train_loss: 0.4431 / Val_loss: 0.9470\n",
      "Epoch: 1025, Train_loss: 0.4471 / Val_loss: 1.1209\n",
      "Epoch: 1026, Train_loss: 0.4328 / Val_loss: 1.1622\n",
      "Epoch: 1027, Train_loss: 0.4278 / Val_loss: 1.1740\n",
      "Epoch: 1028, Train_loss: 0.4480 / Val_loss: 1.1292\n",
      "Epoch: 1029, Train_loss: 0.4365 / Val_loss: 1.2525\n",
      "Epoch: 1030, Train_loss: 0.4309 / Val_loss: 1.1108\n",
      "Epoch: 1031, Train_loss: 0.4328 / Val_loss: 1.0238\n",
      "Epoch: 1032, Train_loss: 0.4408 / Val_loss: 1.1398\n",
      "Epoch: 1033, Train_loss: 0.4128 / Val_loss: 1.4695\n",
      "Epoch: 1034, Train_loss: 0.4739 / Val_loss: 1.3060\n",
      "Epoch: 1035, Train_loss: 0.4153 / Val_loss: 1.5397\n",
      "Epoch: 1036, Train_loss: 0.4222 / Val_loss: 1.0973\n",
      "Epoch: 1037, Train_loss: 0.4859 / Val_loss: 1.2334\n",
      "Epoch: 1038, Train_loss: 0.4428 / Val_loss: 1.4311\n",
      "Epoch: 1039, Train_loss: 0.4198 / Val_loss: 1.2516\n",
      "Epoch: 1040, Train_loss: 0.4478 / Val_loss: 1.0980\n",
      "Epoch: 1041, Train_loss: 0.4713 / Val_loss: 0.9534\n",
      "Epoch: 1042, Train_loss: 0.4270 / Val_loss: 1.2940\n",
      "Epoch: 1043, Train_loss: 0.4214 / Val_loss: 1.5418\n",
      "Epoch: 1044, Train_loss: 0.4355 / Val_loss: 0.9925\n",
      "Epoch: 1045, Train_loss: 0.4455 / Val_loss: 1.1726\n",
      "Epoch: 1046, Train_loss: 0.4418 / Val_loss: 1.0770\n",
      "Epoch: 1047, Train_loss: 0.4193 / Val_loss: 1.7389\n",
      "Epoch: 1048, Train_loss: 0.4227 / Val_loss: 0.9650\n",
      "Epoch: 1049, Train_loss: 0.4674 / Val_loss: 1.1705\n",
      "Epoch: 1050, Train_loss: 0.4417 / Val_loss: 1.1514\n",
      "Epoch: 1051, Train_loss: 0.4481 / Val_loss: 1.3073\n",
      "Epoch: 1052, Train_loss: 0.4522 / Val_loss: 1.1217\n",
      "Epoch: 1053, Train_loss: 0.4313 / Val_loss: 0.9758\n",
      "Epoch: 1054, Train_loss: 0.4126 / Val_loss: 1.3025\n",
      "Epoch: 1055, Train_loss: 0.4253 / Val_loss: 1.3225\n",
      "Epoch: 1056, Train_loss: 0.4227 / Val_loss: 1.1418\n",
      "Epoch: 1057, Train_loss: 0.4224 / Val_loss: 1.4684\n",
      "Epoch: 1058, Train_loss: 0.4626 / Val_loss: 1.1709\n",
      "Epoch: 1059, Train_loss: 0.4516 / Val_loss: 1.4544\n",
      "Epoch: 1060, Train_loss: 0.4181 / Val_loss: 1.2567\n",
      "Epoch: 1061, Train_loss: 0.4325 / Val_loss: 1.4412\n",
      "Epoch: 1062, Train_loss: 0.4701 / Val_loss: 1.2227\n",
      "Epoch: 1063, Train_loss: 0.4586 / Val_loss: 1.3490\n",
      "Epoch: 1064, Train_loss: 0.4404 / Val_loss: 1.0537\n",
      "Epoch: 1065, Train_loss: 0.4357 / Val_loss: 1.3804\n",
      "Epoch: 1066, Train_loss: 0.4179 / Val_loss: 0.9398\n",
      "Epoch: 1067, Train_loss: 0.4239 / Val_loss: 0.8373\n",
      "Epoch: 1068, Train_loss: 0.4647 / Val_loss: 1.2981\n",
      "Epoch: 1069, Train_loss: 0.4292 / Val_loss: 1.1310\n",
      "Epoch: 1070, Train_loss: 0.4769 / Val_loss: 1.1297\n",
      "Epoch: 1071, Train_loss: 0.4220 / Val_loss: 1.3197\n",
      "Epoch: 1072, Train_loss: 0.4218 / Val_loss: 1.4130\n",
      "Epoch: 1073, Train_loss: 0.4698 / Val_loss: 1.2446\n",
      "Epoch: 1074, Train_loss: 0.4251 / Val_loss: 1.2150\n",
      "Epoch: 1075, Train_loss: 0.4351 / Val_loss: 1.5459\n",
      "Epoch: 1076, Train_loss: 0.4159 / Val_loss: 1.2331\n",
      "Epoch: 1077, Train_loss: 0.4386 / Val_loss: 1.4641\n",
      "Epoch: 1078, Train_loss: 0.4471 / Val_loss: 1.2922\n",
      "Epoch: 1079, Train_loss: 0.4462 / Val_loss: 1.3622\n",
      "Epoch: 1080, Train_loss: 0.4225 / Val_loss: 0.9006\n",
      "Epoch: 1081, Train_loss: 0.4358 / Val_loss: 1.0984\n",
      "Epoch: 1082, Train_loss: 0.4251 / Val_loss: 1.3266\n",
      "Epoch: 1083, Train_loss: 0.4200 / Val_loss: 1.2390\n",
      "Epoch: 1084, Train_loss: 0.4583 / Val_loss: 1.0661\n",
      "Epoch: 1085, Train_loss: 0.4464 / Val_loss: 1.3385\n",
      "Epoch: 1086, Train_loss: 0.4291 / Val_loss: 0.9963\n",
      "Epoch: 1087, Train_loss: 0.4164 / Val_loss: 1.3308\n",
      "Epoch: 1088, Train_loss: 0.4399 / Val_loss: 0.9089\n",
      "Epoch: 1089, Train_loss: 0.4493 / Val_loss: 1.1214\n",
      "Epoch: 1090, Train_loss: 0.4326 / Val_loss: 1.3902\n",
      "Epoch: 1091, Train_loss: 0.4452 / Val_loss: 0.8924\n",
      "Epoch: 1092, Train_loss: 0.4415 / Val_loss: 1.4116\n",
      "Epoch: 1093, Train_loss: 0.4643 / Val_loss: 1.2383\n",
      "Epoch: 1094, Train_loss: 0.4307 / Val_loss: 1.1920\n",
      "Epoch: 1095, Train_loss: 0.4547 / Val_loss: 1.0232\n",
      "Epoch: 1096, Train_loss: 0.4464 / Val_loss: 1.1103\n",
      "Epoch: 1097, Train_loss: 0.4791 / Val_loss: 1.5446\n",
      "Epoch: 1098, Train_loss: 0.4212 / Val_loss: 1.1561\n",
      "Epoch: 1099, Train_loss: 0.4488 / Val_loss: 1.0064\n",
      "Epoch: 1100, Train_loss: 0.4852 / Val_loss: 0.9451\n",
      "Epoch: 1101, Train_loss: 0.4202 / Val_loss: 1.1770\n",
      "Epoch: 1102, Train_loss: 0.4296 / Val_loss: 1.3164\n",
      "Epoch: 1103, Train_loss: 0.4462 / Val_loss: 1.1115\n",
      "Epoch: 1104, Train_loss: 0.4474 / Val_loss: 1.2453\n",
      "Epoch: 1105, Train_loss: 0.4799 / Val_loss: 1.2323\n",
      "Epoch: 1106, Train_loss: 0.4278 / Val_loss: 1.0115\n",
      "Epoch: 1107, Train_loss: 0.4341 / Val_loss: 1.5150\n",
      "Epoch: 1108, Train_loss: 0.4329 / Val_loss: 1.6941\n",
      "Epoch: 1109, Train_loss: 0.4478 / Val_loss: 1.2611\n",
      "Epoch: 1110, Train_loss: 0.4063 / Val_loss: 1.1888\n",
      "Epoch: 1111, Train_loss: 0.4328 / Val_loss: 0.9671\n",
      "Epoch: 1112, Train_loss: 0.4781 / Val_loss: 1.0923\n",
      "Epoch: 1113, Train_loss: 0.4238 / Val_loss: 1.1300\n",
      "Epoch: 1114, Train_loss: 0.4386 / Val_loss: 1.2051\n",
      "Epoch: 1115, Train_loss: 0.4188 / Val_loss: 1.3155\n",
      "Epoch: 1116, Train_loss: 0.4418 / Val_loss: 0.9941\n",
      "Epoch: 1117, Train_loss: 0.4184 / Val_loss: 1.1087\n",
      "Epoch: 1118, Train_loss: 0.4249 / Val_loss: 1.1605\n",
      "Epoch: 1119, Train_loss: 0.4120 / Val_loss: 0.9550\n",
      "Epoch: 1120, Train_loss: 0.4205 / Val_loss: 1.1369\n",
      "Epoch: 1121, Train_loss: 0.4185 / Val_loss: 1.2103\n",
      "Epoch: 1122, Train_loss: 0.4345 / Val_loss: 0.9894\n",
      "Epoch: 1123, Train_loss: 0.4200 / Val_loss: 1.0398\n",
      "Epoch: 1124, Train_loss: 0.4270 / Val_loss: 1.2078\n",
      "Epoch: 1125, Train_loss: 0.4532 / Val_loss: 1.6762\n",
      "Epoch: 1126, Train_loss: 0.4210 / Val_loss: 1.2984\n",
      "Epoch: 1127, Train_loss: 0.4201 / Val_loss: 1.1451\n",
      "Epoch: 1128, Train_loss: 0.4408 / Val_loss: 1.4160\n",
      "Epoch: 1129, Train_loss: 0.4942 / Val_loss: 1.0164\n",
      "Epoch: 1130, Train_loss: 0.4139 / Val_loss: 1.7202\n",
      "Epoch: 1131, Train_loss: 0.4230 / Val_loss: 1.1626\n",
      "Epoch: 1132, Train_loss: 0.4432 / Val_loss: 1.0269\n",
      "Epoch: 1133, Train_loss: 0.4129 / Val_loss: 0.9455\n",
      "Epoch: 1134, Train_loss: 0.4097 / Val_loss: 1.0957\n",
      "Epoch: 1135, Train_loss: 0.4178 / Val_loss: 1.1021\n",
      "Epoch: 1136, Train_loss: 0.4415 / Val_loss: 1.1912\n",
      "Epoch: 1137, Train_loss: 0.4487 / Val_loss: 0.9855\n",
      "Epoch: 1138, Train_loss: 0.4376 / Val_loss: 1.0917\n",
      "Epoch: 1139, Train_loss: 0.4252 / Val_loss: 1.1339\n",
      "Epoch: 1140, Train_loss: 0.4100 / Val_loss: 0.9206\n",
      "Epoch: 1141, Train_loss: 0.4580 / Val_loss: 1.1510\n",
      "Epoch: 1142, Train_loss: 0.4253 / Val_loss: 0.9947\n",
      "Epoch: 1143, Train_loss: 0.4333 / Val_loss: 1.0912\n",
      "Epoch: 1144, Train_loss: 0.4076 / Val_loss: 1.1111\n",
      "Epoch: 1145, Train_loss: 0.4340 / Val_loss: 0.9601\n",
      "Epoch: 1146, Train_loss: 0.4104 / Val_loss: 1.2541\n",
      "Epoch: 1147, Train_loss: 0.4678 / Val_loss: 1.5460\n",
      "Epoch: 1148, Train_loss: 0.4396 / Val_loss: 1.4725\n",
      "Epoch: 1149, Train_loss: 0.4336 / Val_loss: 1.5259\n",
      "Epoch: 1150, Train_loss: 0.4422 / Val_loss: 1.4329\n",
      "Epoch: 1151, Train_loss: 0.4189 / Val_loss: 1.3405\n",
      "Epoch: 1152, Train_loss: 0.3984 / Val_loss: 1.3916\n",
      "Epoch: 1153, Train_loss: 0.4422 / Val_loss: 1.2169\n",
      "Epoch: 1154, Train_loss: 0.4362 / Val_loss: 0.8470\n",
      "Epoch: 1155, Train_loss: 0.4277 / Val_loss: 0.9954\n",
      "Epoch: 1156, Train_loss: 0.4285 / Val_loss: 1.1365\n",
      "Epoch: 1157, Train_loss: 0.4390 / Val_loss: 1.2116\n",
      "Epoch: 1158, Train_loss: 0.4543 / Val_loss: 1.0707\n",
      "Epoch: 1159, Train_loss: 0.4435 / Val_loss: 1.4538\n",
      "Epoch: 1160, Train_loss: 0.4452 / Val_loss: 1.0445\n",
      "Epoch: 1161, Train_loss: 0.4628 / Val_loss: 0.9696\n",
      "Epoch: 1162, Train_loss: 0.4280 / Val_loss: 1.1409\n",
      "Epoch: 1163, Train_loss: 0.4561 / Val_loss: 1.3979\n",
      "Epoch: 1164, Train_loss: 0.4271 / Val_loss: 1.2763\n",
      "Epoch: 1165, Train_loss: 0.4397 / Val_loss: 1.1251\n",
      "Epoch: 1166, Train_loss: 0.4568 / Val_loss: 1.5569\n",
      "Epoch: 1167, Train_loss: 0.3997 / Val_loss: 1.2173\n",
      "Epoch: 1168, Train_loss: 0.4116 / Val_loss: 1.3419\n",
      "Epoch: 1169, Train_loss: 0.4086 / Val_loss: 1.2059\n",
      "Epoch: 1170, Train_loss: 0.4412 / Val_loss: 1.7004\n",
      "Epoch: 1171, Train_loss: 0.4314 / Val_loss: 1.4704\n",
      "Epoch: 1172, Train_loss: 0.4184 / Val_loss: 1.6406\n",
      "Epoch: 1173, Train_loss: 0.4482 / Val_loss: 1.0815\n",
      "Epoch: 1174, Train_loss: 0.4443 / Val_loss: 1.1639\n",
      "Epoch: 1175, Train_loss: 0.4548 / Val_loss: 1.1643\n",
      "Epoch: 1176, Train_loss: 0.4236 / Val_loss: 1.3017\n",
      "Epoch: 1177, Train_loss: 0.4255 / Val_loss: 1.0635\n",
      "Epoch: 1178, Train_loss: 0.4256 / Val_loss: 0.9306\n",
      "Epoch: 1179, Train_loss: 0.4239 / Val_loss: 1.3359\n",
      "Epoch: 1180, Train_loss: 0.4543 / Val_loss: 0.8933\n",
      "Epoch: 1181, Train_loss: 0.4312 / Val_loss: 0.7629\n",
      "Epoch: 1182, Train_loss: 0.4468 / Val_loss: 1.2179\n",
      "Epoch: 1183, Train_loss: 0.4125 / Val_loss: 1.2170\n",
      "Epoch: 1184, Train_loss: 0.4067 / Val_loss: 0.9816\n",
      "Epoch: 1185, Train_loss: 0.4103 / Val_loss: 1.1066\n",
      "Epoch: 1186, Train_loss: 0.4151 / Val_loss: 1.2583\n",
      "Epoch: 1187, Train_loss: 0.4183 / Val_loss: 1.5093\n",
      "Epoch: 1188, Train_loss: 0.4327 / Val_loss: 1.6959\n",
      "Epoch: 1189, Train_loss: 0.4398 / Val_loss: 0.9957\n",
      "Epoch: 1190, Train_loss: 0.4355 / Val_loss: 1.2899\n",
      "Epoch: 1191, Train_loss: 0.4301 / Val_loss: 1.6747\n",
      "Epoch: 1192, Train_loss: 0.4529 / Val_loss: 1.3702\n",
      "Epoch: 1193, Train_loss: 0.4066 / Val_loss: 1.6604\n",
      "Epoch: 1194, Train_loss: 0.4345 / Val_loss: 1.2482\n",
      "Epoch: 1195, Train_loss: 0.4035 / Val_loss: 1.5768\n",
      "Epoch: 1196, Train_loss: 0.4703 / Val_loss: 0.8510\n",
      "Epoch: 1197, Train_loss: 0.4178 / Val_loss: 1.5561\n",
      "Epoch: 1198, Train_loss: 0.3993 / Val_loss: 1.4654\n",
      "Epoch: 1199, Train_loss: 0.4164 / Val_loss: 1.1341\n",
      "Epoch: 1200, Train_loss: 0.4230 / Val_loss: 1.0817\n",
      "Epoch: 1201, Train_loss: 0.4253 / Val_loss: 1.6193\n",
      "Epoch: 1202, Train_loss: 0.4177 / Val_loss: 1.3318\n",
      "Epoch: 1203, Train_loss: 0.4313 / Val_loss: 1.4158\n",
      "Epoch: 1204, Train_loss: 0.4176 / Val_loss: 1.3736\n",
      "Epoch: 1205, Train_loss: 0.4255 / Val_loss: 1.0390\n",
      "Epoch: 1206, Train_loss: 0.4281 / Val_loss: 1.1623\n",
      "Epoch: 1207, Train_loss: 0.4139 / Val_loss: 1.1660\n",
      "Epoch: 1208, Train_loss: 0.4758 / Val_loss: 1.0710\n",
      "Epoch: 1209, Train_loss: 0.4240 / Val_loss: 1.3020\n",
      "Epoch: 1210, Train_loss: 0.4256 / Val_loss: 1.0194\n",
      "Epoch: 1211, Train_loss: 0.4257 / Val_loss: 1.4011\n",
      "Epoch: 1212, Train_loss: 0.4150 / Val_loss: 1.3029\n",
      "Epoch: 1213, Train_loss: 0.3994 / Val_loss: 1.2275\n",
      "Epoch: 1214, Train_loss: 0.4208 / Val_loss: 1.5805\n",
      "Epoch: 1215, Train_loss: 0.4095 / Val_loss: 1.2456\n",
      "Epoch: 1216, Train_loss: 0.4062 / Val_loss: 1.3667\n",
      "Epoch: 1217, Train_loss: 0.4330 / Val_loss: 1.3179\n",
      "Epoch: 1218, Train_loss: 0.3996 / Val_loss: 1.3366\n",
      "Epoch: 1219, Train_loss: 0.4036 / Val_loss: 1.2785\n",
      "Epoch: 1220, Train_loss: 0.4285 / Val_loss: 1.9347\n",
      "Epoch: 1221, Train_loss: 0.4268 / Val_loss: 1.5792\n",
      "Epoch: 1222, Train_loss: 0.4319 / Val_loss: 1.5573\n",
      "Epoch: 1223, Train_loss: 0.4254 / Val_loss: 1.2282\n",
      "Epoch: 1224, Train_loss: 0.4251 / Val_loss: 1.3495\n",
      "Epoch: 1225, Train_loss: 0.4301 / Val_loss: 1.2994\n",
      "Epoch: 1226, Train_loss: 0.4174 / Val_loss: 0.9004\n",
      "Epoch: 1227, Train_loss: 0.4202 / Val_loss: 1.4164\n",
      "Epoch: 1228, Train_loss: 0.4031 / Val_loss: 1.4498\n",
      "Epoch: 1229, Train_loss: 0.4233 / Val_loss: 1.1306\n",
      "Epoch: 1230, Train_loss: 0.4217 / Val_loss: 1.2279\n",
      "Epoch: 1231, Train_loss: 0.4502 / Val_loss: 1.1141\n",
      "Epoch: 1232, Train_loss: 0.4458 / Val_loss: 1.2034\n",
      "Epoch: 1233, Train_loss: 0.4219 / Val_loss: 1.3433\n",
      "Epoch: 1234, Train_loss: 0.4215 / Val_loss: 1.3388\n",
      "Epoch: 1235, Train_loss: 0.4264 / Val_loss: 1.2466\n",
      "Epoch: 1236, Train_loss: 0.4132 / Val_loss: 1.5603\n",
      "Epoch: 1237, Train_loss: 0.4280 / Val_loss: 1.9107\n",
      "Epoch: 1238, Train_loss: 0.4406 / Val_loss: 1.6908\n",
      "Epoch: 1239, Train_loss: 0.4104 / Val_loss: 1.1717\n",
      "Epoch: 1240, Train_loss: 0.4405 / Val_loss: 1.4899\n",
      "Epoch: 1241, Train_loss: 0.4408 / Val_loss: 1.5037\n",
      "Epoch: 1242, Train_loss: 0.4066 / Val_loss: 1.1167\n",
      "Epoch: 1243, Train_loss: 0.4249 / Val_loss: 1.3504\n",
      "Epoch: 1244, Train_loss: 0.4249 / Val_loss: 1.6498\n",
      "Epoch: 1245, Train_loss: 0.4480 / Val_loss: 1.4032\n",
      "Epoch: 1246, Train_loss: 0.4025 / Val_loss: 1.3891\n",
      "Epoch: 1247, Train_loss: 0.4132 / Val_loss: 1.3709\n",
      "Epoch: 1248, Train_loss: 0.4505 / Val_loss: 1.4363\n",
      "Epoch: 1249, Train_loss: 0.4217 / Val_loss: 1.1245\n",
      "Epoch: 1250, Train_loss: 0.4198 / Val_loss: 1.1620\n",
      "Epoch: 1251, Train_loss: 0.4157 / Val_loss: 1.2468\n",
      "Epoch: 1252, Train_loss: 0.4187 / Val_loss: 1.2177\n",
      "Epoch: 1253, Train_loss: 0.4180 / Val_loss: 1.2999\n",
      "Epoch: 1254, Train_loss: 0.4570 / Val_loss: 1.5869\n",
      "Epoch: 1255, Train_loss: 0.4108 / Val_loss: 1.0929\n",
      "Epoch: 1256, Train_loss: 0.4085 / Val_loss: 1.4578\n",
      "Epoch: 1257, Train_loss: 0.4548 / Val_loss: 1.6326\n",
      "Epoch: 1258, Train_loss: 0.4456 / Val_loss: 1.4894\n",
      "Epoch: 1259, Train_loss: 0.3971 / Val_loss: 1.2307\n",
      "Epoch: 1260, Train_loss: 0.4034 / Val_loss: 1.3551\n",
      "Epoch: 1261, Train_loss: 0.4072 / Val_loss: 1.4803\n",
      "Epoch: 1262, Train_loss: 0.3913 / Val_loss: 1.5019\n",
      "Epoch: 1263, Train_loss: 0.4186 / Val_loss: 1.3696\n",
      "Epoch: 1264, Train_loss: 0.4295 / Val_loss: 1.1638\n",
      "Epoch: 1265, Train_loss: 0.4176 / Val_loss: 1.0989\n",
      "Epoch: 1266, Train_loss: 0.4432 / Val_loss: 1.3215\n",
      "Epoch: 1267, Train_loss: 0.4104 / Val_loss: 0.8571\n",
      "Epoch: 1268, Train_loss: 0.4103 / Val_loss: 1.2983\n",
      "Epoch: 1269, Train_loss: 0.4122 / Val_loss: 1.4335\n",
      "Epoch: 1270, Train_loss: 0.4201 / Val_loss: 0.9556\n",
      "Epoch: 1271, Train_loss: 0.4482 / Val_loss: 1.3830\n",
      "Epoch: 1272, Train_loss: 0.4664 / Val_loss: 1.0411\n",
      "Epoch: 1273, Train_loss: 0.4096 / Val_loss: 1.0643\n",
      "Epoch: 1274, Train_loss: 0.4054 / Val_loss: 1.7721\n",
      "Epoch: 1275, Train_loss: 0.4268 / Val_loss: 1.3697\n",
      "Epoch: 1276, Train_loss: 0.4148 / Val_loss: 1.4024\n",
      "Epoch: 1277, Train_loss: 0.4410 / Val_loss: 1.5222\n",
      "Epoch: 1278, Train_loss: 0.4157 / Val_loss: 1.5661\n",
      "Epoch: 1279, Train_loss: 0.4141 / Val_loss: 1.5625\n",
      "Epoch: 1280, Train_loss: 0.4060 / Val_loss: 1.2631\n",
      "Epoch: 1281, Train_loss: 0.4348 / Val_loss: 1.5430\n",
      "Epoch: 1282, Train_loss: 0.4189 / Val_loss: 1.3248\n",
      "Epoch: 1283, Train_loss: 0.4074 / Val_loss: 1.5242\n",
      "Epoch: 1284, Train_loss: 0.4106 / Val_loss: 1.2779\n",
      "Epoch: 1285, Train_loss: 0.4084 / Val_loss: 1.0597\n",
      "Epoch: 1286, Train_loss: 0.4093 / Val_loss: 1.4213\n",
      "Epoch: 1287, Train_loss: 0.4173 / Val_loss: 0.9678\n",
      "Epoch: 1288, Train_loss: 0.4548 / Val_loss: 1.4010\n",
      "Epoch: 1289, Train_loss: 0.3876 / Val_loss: 1.4496\n",
      "Epoch: 1290, Train_loss: 0.4417 / Val_loss: 1.0680\n",
      "Epoch: 1291, Train_loss: 0.4335 / Val_loss: 1.2404\n",
      "Epoch: 1292, Train_loss: 0.4122 / Val_loss: 1.1231\n",
      "Epoch: 1293, Train_loss: 0.4031 / Val_loss: 1.2198\n",
      "Epoch: 1294, Train_loss: 0.4374 / Val_loss: 0.9670\n",
      "Epoch: 1295, Train_loss: 0.4359 / Val_loss: 1.3738\n",
      "Epoch: 1296, Train_loss: 0.4092 / Val_loss: 1.1051\n",
      "Epoch: 1297, Train_loss: 0.4130 / Val_loss: 1.4225\n",
      "Epoch: 1298, Train_loss: 0.4448 / Val_loss: 1.4718\n",
      "Epoch: 1299, Train_loss: 0.4081 / Val_loss: 1.3286\n",
      "Epoch: 1300, Train_loss: 0.4187 / Val_loss: 1.2703\n",
      "Epoch: 1301, Train_loss: 0.4112 / Val_loss: 1.0826\n",
      "Epoch: 1302, Train_loss: 0.4107 / Val_loss: 1.3381\n",
      "Epoch: 1303, Train_loss: 0.3993 / Val_loss: 1.2939\n",
      "Epoch: 1304, Train_loss: 0.4162 / Val_loss: 1.2271\n",
      "Epoch: 1305, Train_loss: 0.4160 / Val_loss: 1.8582\n",
      "Epoch: 1306, Train_loss: 0.4193 / Val_loss: 1.8248\n",
      "Epoch: 1307, Train_loss: 0.4006 / Val_loss: 1.4633\n",
      "Epoch: 1308, Train_loss: 0.4426 / Val_loss: 1.2125\n",
      "Epoch: 1309, Train_loss: 0.4295 / Val_loss: 1.0944\n",
      "Epoch: 1310, Train_loss: 0.4029 / Val_loss: 1.2860\n",
      "Epoch: 1311, Train_loss: 0.4218 / Val_loss: 1.4081\n",
      "Epoch: 1312, Train_loss: 0.4147 / Val_loss: 1.0872\n",
      "Epoch: 1313, Train_loss: 0.4266 / Val_loss: 1.2655\n",
      "Epoch: 1314, Train_loss: 0.4266 / Val_loss: 1.2734\n",
      "Epoch: 1315, Train_loss: 0.4305 / Val_loss: 1.1358\n",
      "Epoch: 1316, Train_loss: 0.4129 / Val_loss: 1.1016\n",
      "Epoch: 1317, Train_loss: 0.4687 / Val_loss: 1.0456\n",
      "Epoch: 1318, Train_loss: 0.4106 / Val_loss: 1.1562\n",
      "Epoch: 1319, Train_loss: 0.4265 / Val_loss: 1.3311\n",
      "Epoch: 1320, Train_loss: 0.4538 / Val_loss: 1.1455\n",
      "Epoch: 1321, Train_loss: 0.4369 / Val_loss: 1.0978\n",
      "Epoch: 1322, Train_loss: 0.4016 / Val_loss: 1.3534\n",
      "Epoch: 1323, Train_loss: 0.4147 / Val_loss: 1.3871\n",
      "Epoch: 1324, Train_loss: 0.3942 / Val_loss: 1.2220\n",
      "Epoch: 1325, Train_loss: 0.4241 / Val_loss: 1.1160\n",
      "Epoch: 1326, Train_loss: 0.4215 / Val_loss: 1.3230\n",
      "Epoch: 1327, Train_loss: 0.3954 / Val_loss: 1.3885\n",
      "Epoch: 1328, Train_loss: 0.4133 / Val_loss: 1.4018\n",
      "Epoch: 1329, Train_loss: 0.4187 / Val_loss: 0.9429\n",
      "Epoch: 1330, Train_loss: 0.3983 / Val_loss: 1.4410\n",
      "Epoch: 1331, Train_loss: 0.4271 / Val_loss: 1.4043\n",
      "Epoch: 1332, Train_loss: 0.4306 / Val_loss: 0.9966\n",
      "Epoch: 1333, Train_loss: 0.4079 / Val_loss: 1.5570\n",
      "Epoch: 1334, Train_loss: 0.4011 / Val_loss: 1.6715\n",
      "Epoch: 1335, Train_loss: 0.4061 / Val_loss: 1.7096\n",
      "Epoch: 1336, Train_loss: 0.4381 / Val_loss: 1.6677\n",
      "Epoch: 1337, Train_loss: 0.4471 / Val_loss: 1.3549\n",
      "Epoch: 1338, Train_loss: 0.4427 / Val_loss: 1.3641\n",
      "Epoch: 1339, Train_loss: 0.4343 / Val_loss: 1.4040\n",
      "Epoch: 1340, Train_loss: 0.4249 / Val_loss: 1.5640\n",
      "Epoch: 1341, Train_loss: 0.4224 / Val_loss: 1.5346\n",
      "Epoch: 1342, Train_loss: 0.4200 / Val_loss: 0.8868\n",
      "Epoch: 1343, Train_loss: 0.4480 / Val_loss: 1.4456\n",
      "Epoch: 1344, Train_loss: 0.4464 / Val_loss: 0.9688\n",
      "Epoch: 1345, Train_loss: 0.4362 / Val_loss: 1.0649\n",
      "Epoch: 1346, Train_loss: 0.4109 / Val_loss: 1.2783\n",
      "Epoch: 1347, Train_loss: 0.4263 / Val_loss: 1.3566\n",
      "Epoch: 1348, Train_loss: 0.4042 / Val_loss: 1.3549\n",
      "Epoch: 1349, Train_loss: 0.4129 / Val_loss: 1.4713\n",
      "Epoch: 1350, Train_loss: 0.4327 / Val_loss: 0.9536\n",
      "Epoch: 1351, Train_loss: 0.4233 / Val_loss: 1.6091\n",
      "Epoch: 1352, Train_loss: 0.4297 / Val_loss: 1.5237\n",
      "Epoch: 1353, Train_loss: 0.4300 / Val_loss: 1.7266\n",
      "Epoch: 1354, Train_loss: 0.4016 / Val_loss: 1.5142\n",
      "Epoch: 1355, Train_loss: 0.4271 / Val_loss: 1.2313\n",
      "Epoch: 1356, Train_loss: 0.4024 / Val_loss: 1.2413\n",
      "Epoch: 1357, Train_loss: 0.3983 / Val_loss: 1.4589\n",
      "Epoch: 1358, Train_loss: 0.3930 / Val_loss: 1.4429\n",
      "Epoch: 1359, Train_loss: 0.4307 / Val_loss: 1.2710\n",
      "Epoch: 1360, Train_loss: 0.4041 / Val_loss: 1.6525\n",
      "Epoch: 1361, Train_loss: 0.4364 / Val_loss: 1.3998\n",
      "Epoch: 1362, Train_loss: 0.4191 / Val_loss: 1.2560\n",
      "Epoch: 1363, Train_loss: 0.4355 / Val_loss: 1.7772\n",
      "Epoch: 1364, Train_loss: 0.4229 / Val_loss: 1.2437\n",
      "Epoch: 1365, Train_loss: 0.4164 / Val_loss: 1.3205\n",
      "Epoch: 1366, Train_loss: 0.4119 / Val_loss: 1.7911\n",
      "Epoch: 1367, Train_loss: 0.3950 / Val_loss: 1.1455\n",
      "Epoch: 1368, Train_loss: 0.4403 / Val_loss: 1.3592\n",
      "Epoch: 1369, Train_loss: 0.4222 / Val_loss: 1.5224\n",
      "Epoch: 1370, Train_loss: 0.3941 / Val_loss: 1.2296\n",
      "Epoch: 1371, Train_loss: 0.4265 / Val_loss: 1.3067\n",
      "Epoch: 1372, Train_loss: 0.4074 / Val_loss: 1.3757\n",
      "Epoch: 1373, Train_loss: 0.3997 / Val_loss: 1.7270\n",
      "Epoch: 1374, Train_loss: 0.4234 / Val_loss: 1.3786\n",
      "Epoch: 1375, Train_loss: 0.4156 / Val_loss: 1.1309\n",
      "Epoch: 1376, Train_loss: 0.4032 / Val_loss: 1.5621\n",
      "Epoch: 1377, Train_loss: 0.4198 / Val_loss: 1.2254\n",
      "Epoch: 1378, Train_loss: 0.4356 / Val_loss: 1.6350\n",
      "Epoch: 1379, Train_loss: 0.4245 / Val_loss: 1.4820\n",
      "Epoch: 1380, Train_loss: 0.4198 / Val_loss: 1.3487\n",
      "Epoch: 1381, Train_loss: 0.4137 / Val_loss: 1.3318\n",
      "Epoch: 1382, Train_loss: 0.4402 / Val_loss: 1.2815\n",
      "Epoch: 1383, Train_loss: 0.4027 / Val_loss: 1.5842\n",
      "Epoch: 1384, Train_loss: 0.4154 / Val_loss: 1.4269\n",
      "Epoch: 1385, Train_loss: 0.4374 / Val_loss: 1.3838\n",
      "Epoch: 1386, Train_loss: 0.4093 / Val_loss: 1.2638\n",
      "Epoch: 1387, Train_loss: 0.4212 / Val_loss: 1.5131\n",
      "Epoch: 1388, Train_loss: 0.4466 / Val_loss: 1.3185\n",
      "Epoch: 1389, Train_loss: 0.3961 / Val_loss: 1.1911\n",
      "Epoch: 1390, Train_loss: 0.3873 / Val_loss: 1.4338\n",
      "Epoch: 1391, Train_loss: 0.4099 / Val_loss: 1.8773\n",
      "Epoch: 1392, Train_loss: 0.4090 / Val_loss: 1.2763\n",
      "Epoch: 1393, Train_loss: 0.3947 / Val_loss: 1.4779\n",
      "Epoch: 1394, Train_loss: 0.3931 / Val_loss: 1.5351\n",
      "Epoch: 1395, Train_loss: 0.4020 / Val_loss: 1.6283\n",
      "Epoch: 1396, Train_loss: 0.4047 / Val_loss: 1.4653\n",
      "Epoch: 1397, Train_loss: 0.4284 / Val_loss: 1.7401\n",
      "Epoch: 1398, Train_loss: 0.4259 / Val_loss: 1.9421\n",
      "Epoch: 1399, Train_loss: 0.4229 / Val_loss: 1.3966\n",
      "Epoch: 1400, Train_loss: 0.4391 / Val_loss: 1.2679\n",
      "Epoch: 1401, Train_loss: 0.4099 / Val_loss: 1.4153\n",
      "Epoch: 1402, Train_loss: 0.4156 / Val_loss: 1.3848\n",
      "Epoch: 1403, Train_loss: 0.4247 / Val_loss: 1.8972\n",
      "Epoch: 1404, Train_loss: 0.4211 / Val_loss: 1.2700\n",
      "Epoch: 1405, Train_loss: 0.3991 / Val_loss: 1.2223\n",
      "Epoch: 1406, Train_loss: 0.3866 / Val_loss: 1.0653\n",
      "Epoch: 1407, Train_loss: 0.4680 / Val_loss: 1.8411\n",
      "Epoch: 1408, Train_loss: 0.4079 / Val_loss: 1.3827\n",
      "Epoch: 1409, Train_loss: 0.4051 / Val_loss: 0.8239\n",
      "Epoch: 1410, Train_loss: 0.4091 / Val_loss: 1.0228\n",
      "Epoch: 1411, Train_loss: 0.4214 / Val_loss: 1.5803\n",
      "Epoch: 1412, Train_loss: 0.4055 / Val_loss: 1.1927\n",
      "Epoch: 1413, Train_loss: 0.4378 / Val_loss: 1.4789\n",
      "Epoch: 1414, Train_loss: 0.4230 / Val_loss: 1.3653\n",
      "Epoch: 1415, Train_loss: 0.4255 / Val_loss: 1.1258\n",
      "Epoch: 1416, Train_loss: 0.3956 / Val_loss: 1.5933\n",
      "Epoch: 1417, Train_loss: 0.4124 / Val_loss: 1.1203\n",
      "Epoch: 1418, Train_loss: 0.4138 / Val_loss: 1.5818\n",
      "Epoch: 1419, Train_loss: 0.4070 / Val_loss: 1.7399\n",
      "Epoch: 1420, Train_loss: 0.3985 / Val_loss: 1.4753\n",
      "Epoch: 1421, Train_loss: 0.4004 / Val_loss: 1.3957\n",
      "Epoch: 1422, Train_loss: 0.4199 / Val_loss: 1.4254\n",
      "Epoch: 1423, Train_loss: 0.4198 / Val_loss: 1.2396\n",
      "Epoch: 1424, Train_loss: 0.3969 / Val_loss: 1.4772\n",
      "Epoch: 1425, Train_loss: 0.4104 / Val_loss: 1.4486\n",
      "Epoch: 1426, Train_loss: 0.3996 / Val_loss: 1.4355\n",
      "Epoch: 1427, Train_loss: 0.4085 / Val_loss: 1.6635\n",
      "Epoch: 1428, Train_loss: 0.4054 / Val_loss: 1.8024\n",
      "Epoch: 1429, Train_loss: 0.4028 / Val_loss: 1.6814\n",
      "Epoch: 1430, Train_loss: 0.4324 / Val_loss: 1.0707\n",
      "Epoch: 1431, Train_loss: 0.4279 / Val_loss: 1.3812\n",
      "Epoch: 1432, Train_loss: 0.4016 / Val_loss: 1.3608\n",
      "Epoch: 1433, Train_loss: 0.4409 / Val_loss: 1.4054\n",
      "Epoch: 1434, Train_loss: 0.4047 / Val_loss: 1.2282\n",
      "Epoch: 1435, Train_loss: 0.3898 / Val_loss: 1.3135\n",
      "Epoch: 1436, Train_loss: 0.4028 / Val_loss: 1.5539\n",
      "Epoch: 1437, Train_loss: 0.4174 / Val_loss: 1.3695\n",
      "Epoch: 1438, Train_loss: 0.4080 / Val_loss: 1.4847\n",
      "Epoch: 1439, Train_loss: 0.3927 / Val_loss: 1.3216\n",
      "Epoch: 1440, Train_loss: 0.4244 / Val_loss: 1.3143\n",
      "Epoch: 1441, Train_loss: 0.3888 / Val_loss: 1.2370\n",
      "Epoch: 1442, Train_loss: 0.4212 / Val_loss: 0.9894\n",
      "Epoch: 1443, Train_loss: 0.4516 / Val_loss: 1.6311\n",
      "Epoch: 1444, Train_loss: 0.3962 / Val_loss: 1.6678\n",
      "Epoch: 1445, Train_loss: 0.4125 / Val_loss: 1.8022\n",
      "Epoch: 1446, Train_loss: 0.4146 / Val_loss: 1.2385\n",
      "Epoch: 1447, Train_loss: 0.4116 / Val_loss: 1.4083\n",
      "Epoch: 1448, Train_loss: 0.4044 / Val_loss: 1.2724\n",
      "Epoch: 1449, Train_loss: 0.4321 / Val_loss: 2.3526\n",
      "Epoch: 1450, Train_loss: 0.4034 / Val_loss: 1.2754\n",
      "Epoch: 1451, Train_loss: 0.4128 / Val_loss: 1.4955\n",
      "Epoch: 1452, Train_loss: 0.4003 / Val_loss: 1.7345\n",
      "Epoch: 1453, Train_loss: 0.4771 / Val_loss: 1.9207\n",
      "Epoch: 1454, Train_loss: 0.4253 / Val_loss: 1.2400\n",
      "Epoch: 1455, Train_loss: 0.3901 / Val_loss: 1.5450\n",
      "Epoch: 1456, Train_loss: 0.4435 / Val_loss: 1.3142\n",
      "Epoch: 1457, Train_loss: 0.3980 / Val_loss: 1.6484\n",
      "Epoch: 1458, Train_loss: 0.4065 / Val_loss: 1.4167\n",
      "Epoch: 1459, Train_loss: 0.3971 / Val_loss: 1.6228\n",
      "Epoch: 1460, Train_loss: 0.4166 / Val_loss: 1.3709\n",
      "Epoch: 1461, Train_loss: 0.4003 / Val_loss: 1.4220\n",
      "Epoch: 1462, Train_loss: 0.4179 / Val_loss: 1.0940\n",
      "Epoch: 1463, Train_loss: 0.4020 / Val_loss: 1.5543\n",
      "Epoch: 1464, Train_loss: 0.4243 / Val_loss: 1.3582\n",
      "Epoch: 1465, Train_loss: 0.3905 / Val_loss: 1.2439\n",
      "Epoch: 1466, Train_loss: 0.4243 / Val_loss: 1.3448\n",
      "Epoch: 1467, Train_loss: 0.4319 / Val_loss: 1.1994\n",
      "Epoch: 1468, Train_loss: 0.4133 / Val_loss: 1.2937\n",
      "Epoch: 1469, Train_loss: 0.3945 / Val_loss: 1.1719\n",
      "Epoch: 1470, Train_loss: 0.4222 / Val_loss: 1.7598\n",
      "Epoch: 1471, Train_loss: 0.4047 / Val_loss: 1.2577\n",
      "Epoch: 1472, Train_loss: 0.3897 / Val_loss: 1.5468\n",
      "Epoch: 1473, Train_loss: 0.4278 / Val_loss: 1.3450\n",
      "Epoch: 1474, Train_loss: 0.4252 / Val_loss: 1.6522\n",
      "Epoch: 1475, Train_loss: 0.4002 / Val_loss: 1.7356\n",
      "Epoch: 1476, Train_loss: 0.4066 / Val_loss: 1.4595\n",
      "Epoch: 1477, Train_loss: 0.4294 / Val_loss: 1.6708\n",
      "Epoch: 1478, Train_loss: 0.4202 / Val_loss: 1.2910\n",
      "Epoch: 1479, Train_loss: 0.4233 / Val_loss: 1.3685\n",
      "Epoch: 1480, Train_loss: 0.3991 / Val_loss: 1.1927\n",
      "Epoch: 1481, Train_loss: 0.4036 / Val_loss: 1.5563\n",
      "Epoch: 1482, Train_loss: 0.4235 / Val_loss: 1.4351\n",
      "Epoch: 1483, Train_loss: 0.4016 / Val_loss: 1.4127\n",
      "Epoch: 1484, Train_loss: 0.4115 / Val_loss: 1.5314\n",
      "Epoch: 1485, Train_loss: 0.4162 / Val_loss: 1.1093\n",
      "Epoch: 1486, Train_loss: 0.4222 / Val_loss: 1.1751\n",
      "Epoch: 1487, Train_loss: 0.4475 / Val_loss: 1.5129\n",
      "Epoch: 1488, Train_loss: 0.4106 / Val_loss: 1.3325\n",
      "Epoch: 1489, Train_loss: 0.4257 / Val_loss: 1.2024\n",
      "Epoch: 1490, Train_loss: 0.3968 / Val_loss: 1.2502\n",
      "Epoch: 1491, Train_loss: 0.3924 / Val_loss: 1.6254\n",
      "Epoch: 1492, Train_loss: 0.4073 / Val_loss: 1.2025\n",
      "Epoch: 1493, Train_loss: 0.4691 / Val_loss: 1.6568\n",
      "Epoch: 1494, Train_loss: 0.4061 / Val_loss: 1.2949\n",
      "Epoch: 1495, Train_loss: 0.4091 / Val_loss: 1.2293\n",
      "Epoch: 1496, Train_loss: 0.4330 / Val_loss: 1.2644\n",
      "Epoch: 1497, Train_loss: 0.4364 / Val_loss: 1.4561\n",
      "Epoch: 1498, Train_loss: 0.4281 / Val_loss: 1.2189\n",
      "Epoch: 1499, Train_loss: 0.4020 / Val_loss: 1.2580\n",
      "Epoch: 1500, Train_loss: 0.4087 / Val_loss: 1.0898\n",
      "Epoch: 1501, Train_loss: 0.4094 / Val_loss: 1.4325\n",
      "Epoch: 1502, Train_loss: 0.4013 / Val_loss: 1.5577\n",
      "Epoch: 1503, Train_loss: 0.3999 / Val_loss: 1.3223\n",
      "Epoch: 1504, Train_loss: 0.4434 / Val_loss: 1.7989\n",
      "Epoch: 1505, Train_loss: 0.3976 / Val_loss: 1.0525\n",
      "Epoch: 1506, Train_loss: 0.4105 / Val_loss: 1.5498\n",
      "Epoch: 1507, Train_loss: 0.4200 / Val_loss: 1.6507\n",
      "Epoch: 1508, Train_loss: 0.4041 / Val_loss: 1.5472\n",
      "Epoch: 1509, Train_loss: 0.4038 / Val_loss: 1.5047\n",
      "Epoch: 1510, Train_loss: 0.4103 / Val_loss: 1.3890\n",
      "Epoch: 1511, Train_loss: 0.4084 / Val_loss: 1.6058\n",
      "Epoch: 1512, Train_loss: 0.4159 / Val_loss: 1.2963\n",
      "Epoch: 1513, Train_loss: 0.4289 / Val_loss: 1.2197\n",
      "Epoch: 1514, Train_loss: 0.3871 / Val_loss: 1.3290\n",
      "Epoch: 1515, Train_loss: 0.4084 / Val_loss: 1.2502\n",
      "Epoch: 1516, Train_loss: 0.3924 / Val_loss: 1.4942\n",
      "Epoch: 1517, Train_loss: 0.4236 / Val_loss: 1.4001\n",
      "Epoch: 1518, Train_loss: 0.3874 / Val_loss: 1.4531\n",
      "Epoch: 1519, Train_loss: 0.4692 / Val_loss: 1.4849\n",
      "Epoch: 1520, Train_loss: 0.4316 / Val_loss: 1.4180\n",
      "Epoch: 1521, Train_loss: 0.4081 / Val_loss: 1.4421\n",
      "Epoch: 1522, Train_loss: 0.4042 / Val_loss: 1.4968\n",
      "Epoch: 1523, Train_loss: 0.3901 / Val_loss: 1.5319\n",
      "Epoch: 1524, Train_loss: 0.4181 / Val_loss: 1.6387\n",
      "Epoch: 1525, Train_loss: 0.4064 / Val_loss: 1.4924\n",
      "Epoch: 1526, Train_loss: 0.3929 / Val_loss: 1.3807\n",
      "Epoch: 1527, Train_loss: 0.3956 / Val_loss: 1.3681\n",
      "Epoch: 1528, Train_loss: 0.4273 / Val_loss: 1.0829\n",
      "Epoch: 1529, Train_loss: 0.4138 / Val_loss: 1.2099\n",
      "Epoch: 1530, Train_loss: 0.4124 / Val_loss: 0.9770\n",
      "Epoch: 1531, Train_loss: 0.4318 / Val_loss: 1.3877\n",
      "Epoch: 1532, Train_loss: 0.3957 / Val_loss: 1.6423\n",
      "Epoch: 1533, Train_loss: 0.3957 / Val_loss: 1.4959\n",
      "Epoch: 1534, Train_loss: 0.4179 / Val_loss: 1.4131\n",
      "Epoch: 1535, Train_loss: 0.4254 / Val_loss: 1.6127\n",
      "Epoch: 1536, Train_loss: 0.3855 / Val_loss: 1.2321\n",
      "Epoch: 1537, Train_loss: 0.4220 / Val_loss: 1.1077\n",
      "Epoch: 1538, Train_loss: 0.3973 / Val_loss: 1.2257\n",
      "Epoch: 1539, Train_loss: 0.3997 / Val_loss: 1.4942\n",
      "Epoch: 1540, Train_loss: 0.3888 / Val_loss: 1.3880\n",
      "Epoch: 1541, Train_loss: 0.3951 / Val_loss: 1.4702\n",
      "Epoch: 1542, Train_loss: 0.4274 / Val_loss: 1.0667\n",
      "Epoch: 1543, Train_loss: 0.4152 / Val_loss: 1.1997\n",
      "Epoch: 1544, Train_loss: 0.4009 / Val_loss: 1.5577\n",
      "Epoch: 1545, Train_loss: 0.3928 / Val_loss: 1.2413\n",
      "Epoch: 1546, Train_loss: 0.4371 / Val_loss: 1.3198\n",
      "Epoch: 1547, Train_loss: 0.4097 / Val_loss: 1.2994\n",
      "Epoch: 1548, Train_loss: 0.4265 / Val_loss: 1.3068\n",
      "Epoch: 1549, Train_loss: 0.4102 / Val_loss: 1.2874\n",
      "Epoch: 1550, Train_loss: 0.4011 / Val_loss: 1.6860\n",
      "Epoch: 1551, Train_loss: 0.4027 / Val_loss: 1.5914\n",
      "Epoch: 1552, Train_loss: 0.4132 / Val_loss: 1.3094\n",
      "Epoch: 1553, Train_loss: 0.4044 / Val_loss: 1.3485\n",
      "Epoch: 1554, Train_loss: 0.3964 / Val_loss: 1.3689\n",
      "Epoch: 1555, Train_loss: 0.4056 / Val_loss: 1.8995\n",
      "Epoch: 1556, Train_loss: 0.3910 / Val_loss: 1.3148\n",
      "Epoch: 1557, Train_loss: 0.4041 / Val_loss: 1.3140\n",
      "Epoch: 1558, Train_loss: 0.4114 / Val_loss: 1.3085\n",
      "Epoch: 1559, Train_loss: 0.4206 / Val_loss: 1.4048\n",
      "Epoch: 1560, Train_loss: 0.3915 / Val_loss: 1.6164\n",
      "Epoch: 1561, Train_loss: 0.4076 / Val_loss: 1.3231\n",
      "Epoch: 1562, Train_loss: 0.4182 / Val_loss: 1.7076\n",
      "Epoch: 1563, Train_loss: 0.4017 / Val_loss: 1.6281\n",
      "Epoch: 1564, Train_loss: 0.4012 / Val_loss: 1.0862\n",
      "Epoch: 1565, Train_loss: 0.3998 / Val_loss: 1.0686\n",
      "Epoch: 1566, Train_loss: 0.4066 / Val_loss: 1.3442\n",
      "Epoch: 1567, Train_loss: 0.4477 / Val_loss: 1.5305\n",
      "Epoch: 1568, Train_loss: 0.4150 / Val_loss: 1.5183\n",
      "Epoch: 1569, Train_loss: 0.3987 / Val_loss: 1.3350\n",
      "Epoch: 1570, Train_loss: 0.4844 / Val_loss: 1.1791\n",
      "Epoch: 1571, Train_loss: 0.4203 / Val_loss: 1.4134\n",
      "Epoch: 1572, Train_loss: 0.3981 / Val_loss: 1.1911\n",
      "Epoch: 1573, Train_loss: 0.4343 / Val_loss: 1.3800\n",
      "Epoch: 1574, Train_loss: 0.4270 / Val_loss: 1.2322\n",
      "Epoch: 1575, Train_loss: 0.4395 / Val_loss: 1.2165\n",
      "Epoch: 1576, Train_loss: 0.4173 / Val_loss: 1.5058\n",
      "Epoch: 1577, Train_loss: 0.3888 / Val_loss: 1.5110\n",
      "Epoch: 1578, Train_loss: 0.4155 / Val_loss: 1.4190\n",
      "Epoch: 1579, Train_loss: 0.4090 / Val_loss: 1.5818\n",
      "Epoch: 1580, Train_loss: 0.3999 / Val_loss: 1.5196\n",
      "Epoch: 1581, Train_loss: 0.4037 / Val_loss: 1.3985\n",
      "Epoch: 1582, Train_loss: 0.3996 / Val_loss: 1.2310\n",
      "Epoch: 1583, Train_loss: 0.4037 / Val_loss: 1.3826\n",
      "Epoch: 1584, Train_loss: 0.4057 / Val_loss: 1.2956\n",
      "Epoch: 1585, Train_loss: 0.3943 / Val_loss: 1.3045\n",
      "Epoch: 1586, Train_loss: 0.3995 / Val_loss: 1.4746\n",
      "Epoch: 1587, Train_loss: 0.4651 / Val_loss: 1.6990\n",
      "Epoch: 1588, Train_loss: 0.4224 / Val_loss: 1.4824\n",
      "Epoch: 1589, Train_loss: 0.4062 / Val_loss: 1.7099\n",
      "Epoch: 1590, Train_loss: 0.3916 / Val_loss: 1.7873\n",
      "Epoch: 1591, Train_loss: 0.4016 / Val_loss: 1.8331\n",
      "Epoch: 1592, Train_loss: 0.4060 / Val_loss: 1.2960\n",
      "Epoch: 1593, Train_loss: 0.3955 / Val_loss: 1.4057\n",
      "Epoch: 1594, Train_loss: 0.4058 / Val_loss: 1.2735\n",
      "Epoch: 1595, Train_loss: 0.3936 / Val_loss: 1.4471\n",
      "Epoch: 1596, Train_loss: 0.4093 / Val_loss: 1.7874\n",
      "Epoch: 1597, Train_loss: 0.4122 / Val_loss: 1.4216\n",
      "Epoch: 1598, Train_loss: 0.4397 / Val_loss: 1.2112\n",
      "Epoch: 1599, Train_loss: 0.3989 / Val_loss: 1.3947\n",
      "Epoch: 1600, Train_loss: 0.4109 / Val_loss: 1.1550\n",
      "Epoch: 1601, Train_loss: 0.3927 / Val_loss: 1.4040\n",
      "Epoch: 1602, Train_loss: 0.3916 / Val_loss: 1.2012\n",
      "Epoch: 1603, Train_loss: 0.3957 / Val_loss: 1.3156\n",
      "Epoch: 1604, Train_loss: 0.3895 / Val_loss: 1.4666\n",
      "Epoch: 1605, Train_loss: 0.4100 / Val_loss: 1.4329\n",
      "Epoch: 1606, Train_loss: 0.4078 / Val_loss: 1.4993\n",
      "Epoch: 1607, Train_loss: 0.4043 / Val_loss: 0.9313\n",
      "Epoch: 1608, Train_loss: 0.3999 / Val_loss: 1.2991\n",
      "Epoch: 1609, Train_loss: 0.4128 / Val_loss: 1.5072\n",
      "Epoch: 1610, Train_loss: 0.4025 / Val_loss: 1.7792\n",
      "Epoch: 1611, Train_loss: 0.4345 / Val_loss: 1.5891\n",
      "Epoch: 1612, Train_loss: 0.4128 / Val_loss: 1.6245\n",
      "Epoch: 1613, Train_loss: 0.4077 / Val_loss: 1.7049\n",
      "Epoch: 1614, Train_loss: 0.4295 / Val_loss: 1.2551\n",
      "Epoch: 1615, Train_loss: 0.4076 / Val_loss: 1.7025\n",
      "Epoch: 1616, Train_loss: 0.3948 / Val_loss: 1.5103\n",
      "Epoch: 1617, Train_loss: 0.4110 / Val_loss: 1.5576\n",
      "Epoch: 1618, Train_loss: 0.4172 / Val_loss: 1.7317\n",
      "Epoch: 1619, Train_loss: 0.4103 / Val_loss: 1.6360\n",
      "Epoch: 1620, Train_loss: 0.4225 / Val_loss: 1.8860\n",
      "Epoch: 1621, Train_loss: 0.4067 / Val_loss: 1.3042\n",
      "Epoch: 1622, Train_loss: 0.4168 / Val_loss: 1.5201\n",
      "Epoch: 1623, Train_loss: 0.3915 / Val_loss: 1.7096\n",
      "Epoch: 1624, Train_loss: 0.4103 / Val_loss: 0.9676\n",
      "Epoch: 1625, Train_loss: 0.4209 / Val_loss: 1.3580\n",
      "Epoch: 1626, Train_loss: 0.4220 / Val_loss: 1.3698\n",
      "Epoch: 1627, Train_loss: 0.4095 / Val_loss: 1.2254\n",
      "Epoch: 1628, Train_loss: 0.4103 / Val_loss: 1.1305\n",
      "Epoch: 1629, Train_loss: 0.4390 / Val_loss: 1.5586\n",
      "Epoch: 1630, Train_loss: 0.4072 / Val_loss: 1.6264\n",
      "Epoch: 1631, Train_loss: 0.3976 / Val_loss: 1.2945\n",
      "Epoch: 1632, Train_loss: 0.4349 / Val_loss: 1.4236\n",
      "Epoch: 1633, Train_loss: 0.4124 / Val_loss: 1.2212\n",
      "Epoch: 1634, Train_loss: 0.3898 / Val_loss: 1.9608\n",
      "Epoch: 1635, Train_loss: 0.3920 / Val_loss: 1.4059\n",
      "Epoch: 1636, Train_loss: 0.3958 / Val_loss: 1.6105\n",
      "Epoch: 1637, Train_loss: 0.4096 / Val_loss: 1.5113\n",
      "Epoch: 1638, Train_loss: 0.3955 / Val_loss: 1.4798\n",
      "Epoch: 1639, Train_loss: 0.4057 / Val_loss: 1.2623\n",
      "Epoch: 1640, Train_loss: 0.4049 / Val_loss: 1.5299\n",
      "Epoch: 1641, Train_loss: 0.4100 / Val_loss: 1.2546\n",
      "Epoch: 1642, Train_loss: 0.3926 / Val_loss: 1.6568\n",
      "Epoch: 1643, Train_loss: 0.4012 / Val_loss: 1.4206\n",
      "Epoch: 1644, Train_loss: 0.3971 / Val_loss: 1.4687\n",
      "Epoch: 1645, Train_loss: 0.4201 / Val_loss: 1.8086\n",
      "Epoch: 1646, Train_loss: 0.4240 / Val_loss: 1.8372\n",
      "Epoch: 1647, Train_loss: 0.3939 / Val_loss: 1.0244\n",
      "Epoch: 1648, Train_loss: 0.3771 / Val_loss: 1.3390\n",
      "Epoch: 1649, Train_loss: 0.4037 / Val_loss: 1.7685\n",
      "Epoch: 1650, Train_loss: 0.4057 / Val_loss: 1.6890\n",
      "Epoch: 1651, Train_loss: 0.4160 / Val_loss: 1.5276\n",
      "Epoch: 1652, Train_loss: 0.4110 / Val_loss: 1.8444\n",
      "Epoch: 1653, Train_loss: 0.4078 / Val_loss: 1.2123\n",
      "Epoch: 1654, Train_loss: 0.4013 / Val_loss: 1.5576\n",
      "Epoch: 1655, Train_loss: 0.4359 / Val_loss: 1.6729\n",
      "Epoch: 1656, Train_loss: 0.4075 / Val_loss: 1.5204\n",
      "Epoch: 1657, Train_loss: 0.3936 / Val_loss: 1.4067\n",
      "Epoch: 1658, Train_loss: 0.4135 / Val_loss: 1.2435\n",
      "Epoch: 1659, Train_loss: 0.4059 / Val_loss: 1.2478\n",
      "Epoch: 1660, Train_loss: 0.4080 / Val_loss: 1.5694\n",
      "Epoch: 1661, Train_loss: 0.3805 / Val_loss: 1.4903\n",
      "Epoch: 1662, Train_loss: 0.4570 / Val_loss: 1.4132\n",
      "Epoch: 1663, Train_loss: 0.4054 / Val_loss: 1.5347\n",
      "Epoch: 1664, Train_loss: 0.4191 / Val_loss: 1.3394\n",
      "Epoch: 1665, Train_loss: 0.3962 / Val_loss: 1.1615\n",
      "Epoch: 1666, Train_loss: 0.4143 / Val_loss: 1.4488\n",
      "Epoch: 1667, Train_loss: 0.4121 / Val_loss: 1.6399\n",
      "Epoch: 1668, Train_loss: 0.3916 / Val_loss: 1.4174\n",
      "Epoch: 1669, Train_loss: 0.4074 / Val_loss: 1.0163\n",
      "Epoch: 1670, Train_loss: 0.3803 / Val_loss: 1.3592\n",
      "Epoch: 1671, Train_loss: 0.4128 / Val_loss: 1.3522\n",
      "Epoch: 1672, Train_loss: 0.4205 / Val_loss: 1.2983\n",
      "Epoch: 1673, Train_loss: 0.4109 / Val_loss: 1.7091\n",
      "Epoch: 1674, Train_loss: 0.3961 / Val_loss: 1.4118\n",
      "Epoch: 1675, Train_loss: 0.3906 / Val_loss: 1.3408\n",
      "Epoch: 1676, Train_loss: 0.4274 / Val_loss: 1.2997\n",
      "Epoch: 1677, Train_loss: 0.4227 / Val_loss: 1.6133\n",
      "Epoch: 1678, Train_loss: 0.4151 / Val_loss: 1.6961\n",
      "Epoch: 1679, Train_loss: 0.3909 / Val_loss: 1.5337\n",
      "Epoch: 1680, Train_loss: 0.4015 / Val_loss: 1.5671\n",
      "Epoch: 1681, Train_loss: 0.3828 / Val_loss: 1.7727\n",
      "Epoch: 1682, Train_loss: 0.4008 / Val_loss: 1.4895\n",
      "Epoch: 1683, Train_loss: 0.4116 / Val_loss: 1.8477\n",
      "Epoch: 1684, Train_loss: 0.3995 / Val_loss: 1.6005\n",
      "Epoch: 1685, Train_loss: 0.4363 / Val_loss: 1.7889\n",
      "Epoch: 1686, Train_loss: 0.4191 / Val_loss: 1.0689\n",
      "Epoch: 1687, Train_loss: 0.4023 / Val_loss: 1.5727\n",
      "Epoch: 1688, Train_loss: 0.3891 / Val_loss: 1.2821\n",
      "Epoch: 1689, Train_loss: 0.4017 / Val_loss: 1.4068\n",
      "Epoch: 1690, Train_loss: 0.3933 / Val_loss: 1.1144\n",
      "Epoch: 1691, Train_loss: 0.3911 / Val_loss: 1.1973\n",
      "Epoch: 1692, Train_loss: 0.4070 / Val_loss: 1.3531\n",
      "Epoch: 1693, Train_loss: 0.4275 / Val_loss: 1.5874\n",
      "Epoch: 1694, Train_loss: 0.4080 / Val_loss: 0.9359\n",
      "Epoch: 1695, Train_loss: 0.3927 / Val_loss: 1.4585\n",
      "Epoch: 1696, Train_loss: 0.3882 / Val_loss: 1.6825\n",
      "Epoch: 1697, Train_loss: 0.4222 / Val_loss: 1.3145\n",
      "Epoch: 1698, Train_loss: 0.3976 / Val_loss: 1.6165\n",
      "Epoch: 1699, Train_loss: 0.3950 / Val_loss: 1.3220\n",
      "Epoch: 1700, Train_loss: 0.4247 / Val_loss: 1.1840\n",
      "Epoch: 1701, Train_loss: 0.4025 / Val_loss: 1.4964\n",
      "Epoch: 1702, Train_loss: 0.4101 / Val_loss: 1.5762\n",
      "Epoch: 1703, Train_loss: 0.3842 / Val_loss: 1.4563\n",
      "Epoch: 1704, Train_loss: 0.4105 / Val_loss: 1.3658\n",
      "Epoch: 1705, Train_loss: 0.4102 / Val_loss: 1.6195\n",
      "Epoch: 1706, Train_loss: 0.4048 / Val_loss: 1.4632\n",
      "Epoch: 1707, Train_loss: 0.4102 / Val_loss: 1.4877\n",
      "Epoch: 1708, Train_loss: 0.4886 / Val_loss: 1.2178\n",
      "Epoch: 1709, Train_loss: 0.3875 / Val_loss: 1.8068\n",
      "Epoch: 1710, Train_loss: 0.4151 / Val_loss: 1.1165\n",
      "Epoch: 1711, Train_loss: 0.4026 / Val_loss: 1.1364\n",
      "Epoch: 1712, Train_loss: 0.3944 / Val_loss: 1.5829\n",
      "Epoch: 1713, Train_loss: 0.4239 / Val_loss: 1.2116\n",
      "Epoch: 1714, Train_loss: 0.3989 / Val_loss: 1.4540\n",
      "Epoch: 1715, Train_loss: 0.3968 / Val_loss: 1.5462\n",
      "Epoch: 1716, Train_loss: 0.4015 / Val_loss: 1.4432\n",
      "Epoch: 1717, Train_loss: 0.4062 / Val_loss: 1.2073\n",
      "Epoch: 1718, Train_loss: 0.3891 / Val_loss: 1.4831\n",
      "Epoch: 1719, Train_loss: 0.4098 / Val_loss: 1.3772\n",
      "Epoch: 1720, Train_loss: 0.3915 / Val_loss: 1.6115\n",
      "Epoch: 1721, Train_loss: 0.3974 / Val_loss: 1.8112\n",
      "Epoch: 1722, Train_loss: 0.4112 / Val_loss: 1.3207\n",
      "Epoch: 1723, Train_loss: 0.3999 / Val_loss: 1.4912\n",
      "Epoch: 1724, Train_loss: 0.4229 / Val_loss: 1.4158\n",
      "Epoch: 1725, Train_loss: 0.4015 / Val_loss: 1.1138\n",
      "Epoch: 1726, Train_loss: 0.4004 / Val_loss: 1.6822\n",
      "Epoch: 1727, Train_loss: 0.4456 / Val_loss: 1.5917\n",
      "Epoch: 1728, Train_loss: 0.4145 / Val_loss: 1.3838\n",
      "Epoch: 1729, Train_loss: 0.4050 / Val_loss: 1.4104\n",
      "Epoch: 1730, Train_loss: 0.3993 / Val_loss: 1.5574\n",
      "Epoch: 1731, Train_loss: 0.4135 / Val_loss: 1.3371\n",
      "Epoch: 1732, Train_loss: 0.4494 / Val_loss: 1.5711\n",
      "Epoch: 1733, Train_loss: 0.3872 / Val_loss: 1.5005\n",
      "Epoch: 1734, Train_loss: 0.4000 / Val_loss: 1.6680\n",
      "Epoch: 1735, Train_loss: 0.4014 / Val_loss: 1.5161\n",
      "Epoch: 1736, Train_loss: 0.4141 / Val_loss: 1.4134\n",
      "Epoch: 1737, Train_loss: 0.3969 / Val_loss: 1.3747\n",
      "Epoch: 1738, Train_loss: 0.4174 / Val_loss: 1.3503\n",
      "Epoch: 1739, Train_loss: 0.4061 / Val_loss: 1.7227\n",
      "Epoch: 1740, Train_loss: 0.4181 / Val_loss: 1.3975\n",
      "Epoch: 1741, Train_loss: 0.4125 / Val_loss: 1.2447\n",
      "Epoch: 1742, Train_loss: 0.4007 / Val_loss: 1.1094\n",
      "Epoch: 1743, Train_loss: 0.4132 / Val_loss: 1.1835\n",
      "Epoch: 1744, Train_loss: 0.3977 / Val_loss: 1.5859\n",
      "Epoch: 1745, Train_loss: 0.4303 / Val_loss: 1.3264\n",
      "Epoch: 1746, Train_loss: 0.3756 / Val_loss: 1.5301\n",
      "Epoch: 1747, Train_loss: 0.3928 / Val_loss: 0.9785\n",
      "Epoch: 1748, Train_loss: 0.4048 / Val_loss: 1.3675\n",
      "Epoch: 1749, Train_loss: 0.3863 / Val_loss: 1.8074\n",
      "Epoch: 1750, Train_loss: 0.3888 / Val_loss: 1.6499\n",
      "Epoch: 1751, Train_loss: 0.4052 / Val_loss: 1.4525\n",
      "Epoch: 1752, Train_loss: 0.4011 / Val_loss: 1.2194\n",
      "Epoch: 1753, Train_loss: 0.4019 / Val_loss: 1.3886\n",
      "Epoch: 1754, Train_loss: 0.4026 / Val_loss: 1.2729\n",
      "Epoch: 1755, Train_loss: 0.3862 / Val_loss: 1.7209\n",
      "Epoch: 1756, Train_loss: 0.3931 / Val_loss: 1.4136\n",
      "Epoch: 1757, Train_loss: 0.4064 / Val_loss: 1.3170\n",
      "Epoch: 1758, Train_loss: 0.4239 / Val_loss: 1.2944\n",
      "Epoch: 1759, Train_loss: 0.4039 / Val_loss: 1.5726\n",
      "Epoch: 1760, Train_loss: 0.3811 / Val_loss: 1.6884\n",
      "Epoch: 1761, Train_loss: 0.4000 / Val_loss: 1.4036\n",
      "Epoch: 1762, Train_loss: 0.4052 / Val_loss: 1.1815\n",
      "Epoch: 1763, Train_loss: 0.4019 / Val_loss: 1.4362\n",
      "Epoch: 1764, Train_loss: 0.4215 / Val_loss: 0.9864\n",
      "Epoch: 1765, Train_loss: 0.4227 / Val_loss: 1.0372\n",
      "Epoch: 1766, Train_loss: 0.3920 / Val_loss: 1.0521\n",
      "Epoch: 1767, Train_loss: 0.3881 / Val_loss: 1.1090\n",
      "Epoch: 1768, Train_loss: 0.3921 / Val_loss: 1.3147\n",
      "Epoch: 1769, Train_loss: 0.4000 / Val_loss: 1.3998\n",
      "Epoch: 1770, Train_loss: 0.4001 / Val_loss: 1.2937\n",
      "Epoch: 1771, Train_loss: 0.4172 / Val_loss: 1.3846\n",
      "Epoch: 1772, Train_loss: 0.3988 / Val_loss: 1.5450\n",
      "Epoch: 1773, Train_loss: 0.4194 / Val_loss: 1.0354\n",
      "Epoch: 1774, Train_loss: 0.3902 / Val_loss: 1.1681\n",
      "Epoch: 1775, Train_loss: 0.3818 / Val_loss: 1.2717\n",
      "Epoch: 1776, Train_loss: 0.3946 / Val_loss: 1.6254\n",
      "Epoch: 1777, Train_loss: 0.3777 / Val_loss: 1.4599\n",
      "Epoch: 1778, Train_loss: 0.3923 / Val_loss: 1.2471\n",
      "Epoch: 1779, Train_loss: 0.4046 / Val_loss: 2.1064\n",
      "Epoch: 1780, Train_loss: 0.3965 / Val_loss: 1.4251\n",
      "Epoch: 1781, Train_loss: 0.4010 / Val_loss: 1.2938\n",
      "Epoch: 1782, Train_loss: 0.3810 / Val_loss: 1.3562\n",
      "Epoch: 1783, Train_loss: 0.4295 / Val_loss: 1.6004\n",
      "Epoch: 1784, Train_loss: 0.4279 / Val_loss: 1.0847\n",
      "Epoch: 1785, Train_loss: 0.3843 / Val_loss: 1.4374\n",
      "Epoch: 1786, Train_loss: 0.3957 / Val_loss: 1.5022\n",
      "Epoch: 1787, Train_loss: 0.3869 / Val_loss: 1.6340\n",
      "Epoch: 1788, Train_loss: 0.4110 / Val_loss: 0.8209\n",
      "Epoch: 1789, Train_loss: 0.4143 / Val_loss: 1.3944\n",
      "Epoch: 1790, Train_loss: 0.3955 / Val_loss: 1.3243\n",
      "Epoch: 1791, Train_loss: 0.4024 / Val_loss: 1.3364\n",
      "Epoch: 1792, Train_loss: 0.4226 / Val_loss: 1.3801\n",
      "Epoch: 1793, Train_loss: 0.3904 / Val_loss: 1.5499\n",
      "Epoch: 1794, Train_loss: 0.3842 / Val_loss: 1.3214\n",
      "Epoch: 1795, Train_loss: 0.4052 / Val_loss: 1.5776\n",
      "Epoch: 1796, Train_loss: 0.3877 / Val_loss: 1.5894\n",
      "Epoch: 1797, Train_loss: 0.3922 / Val_loss: 1.5544\n",
      "Epoch: 1798, Train_loss: 0.3963 / Val_loss: 0.8715\n",
      "Epoch: 1799, Train_loss: 0.4104 / Val_loss: 1.3731\n",
      "Epoch: 1800, Train_loss: 0.3795 / Val_loss: 1.4825\n",
      "Epoch: 1801, Train_loss: 0.3871 / Val_loss: 2.0241\n",
      "Epoch: 1802, Train_loss: 0.3761 / Val_loss: 2.1136\n",
      "Epoch: 1803, Train_loss: 0.4077 / Val_loss: 1.8535\n",
      "Epoch: 1804, Train_loss: 0.4433 / Val_loss: 1.6439\n",
      "Epoch: 1805, Train_loss: 0.4331 / Val_loss: 1.3954\n",
      "Epoch: 1806, Train_loss: 0.4023 / Val_loss: 1.3841\n",
      "Epoch: 1807, Train_loss: 0.4089 / Val_loss: 1.4217\n",
      "Epoch: 1808, Train_loss: 0.3957 / Val_loss: 1.5502\n",
      "Epoch: 1809, Train_loss: 0.3961 / Val_loss: 1.5626\n",
      "Epoch: 1810, Train_loss: 0.4367 / Val_loss: 1.4620\n",
      "Epoch: 1811, Train_loss: 0.3805 / Val_loss: 1.6372\n",
      "Epoch: 1812, Train_loss: 0.3933 / Val_loss: 1.5669\n",
      "Epoch: 1813, Train_loss: 0.4092 / Val_loss: 1.9052\n",
      "Epoch: 1814, Train_loss: 0.3843 / Val_loss: 1.8225\n",
      "Epoch: 1815, Train_loss: 0.3967 / Val_loss: 2.1961\n",
      "Epoch: 1816, Train_loss: 0.3818 / Val_loss: 1.7053\n",
      "Epoch: 1817, Train_loss: 0.4097 / Val_loss: 1.4622\n",
      "Epoch: 1818, Train_loss: 0.3921 / Val_loss: 1.3594\n",
      "Epoch: 1819, Train_loss: 0.4110 / Val_loss: 1.5329\n",
      "Epoch: 1820, Train_loss: 0.4083 / Val_loss: 1.6336\n",
      "Epoch: 1821, Train_loss: 0.3918 / Val_loss: 1.5547\n",
      "Epoch: 1822, Train_loss: 0.4053 / Val_loss: 1.4036\n",
      "Epoch: 1823, Train_loss: 0.3881 / Val_loss: 1.5418\n",
      "Epoch: 1824, Train_loss: 0.3855 / Val_loss: 1.4994\n",
      "Epoch: 1825, Train_loss: 0.3946 / Val_loss: 1.2728\n",
      "Epoch: 1826, Train_loss: 0.4093 / Val_loss: 1.5215\n",
      "Epoch: 1827, Train_loss: 0.4031 / Val_loss: 1.6073\n",
      "Epoch: 1828, Train_loss: 0.3978 / Val_loss: 1.3563\n",
      "Epoch: 1829, Train_loss: 0.3789 / Val_loss: 1.9606\n",
      "Epoch: 1830, Train_loss: 0.3853 / Val_loss: 1.2499\n",
      "Epoch: 1831, Train_loss: 0.3938 / Val_loss: 1.6473\n",
      "Epoch: 1832, Train_loss: 0.3873 / Val_loss: 1.4550\n",
      "Epoch: 1833, Train_loss: 0.4116 / Val_loss: 1.0087\n",
      "Epoch: 1834, Train_loss: 0.3997 / Val_loss: 1.5191\n",
      "Epoch: 1835, Train_loss: 0.4220 / Val_loss: 1.2292\n",
      "Epoch: 1836, Train_loss: 0.3939 / Val_loss: 1.2906\n",
      "Epoch: 1837, Train_loss: 0.3757 / Val_loss: 1.9995\n",
      "Epoch: 1838, Train_loss: 0.3791 / Val_loss: 1.8076\n",
      "Epoch: 1839, Train_loss: 0.4322 / Val_loss: 1.6815\n",
      "Epoch: 1840, Train_loss: 0.3864 / Val_loss: 1.5513\n",
      "Epoch: 1841, Train_loss: 0.4354 / Val_loss: 1.3998\n",
      "Epoch: 1842, Train_loss: 0.3858 / Val_loss: 1.4323\n",
      "Epoch: 1843, Train_loss: 0.3863 / Val_loss: 1.2466\n",
      "Epoch: 1844, Train_loss: 0.4144 / Val_loss: 1.6133\n",
      "Epoch: 1845, Train_loss: 0.3984 / Val_loss: 1.6916\n",
      "Epoch: 1846, Train_loss: 0.3869 / Val_loss: 1.0046\n",
      "Epoch: 1847, Train_loss: 0.4242 / Val_loss: 1.6201\n",
      "Epoch: 1848, Train_loss: 0.4017 / Val_loss: 1.3522\n",
      "Epoch: 1849, Train_loss: 0.3941 / Val_loss: 1.0585\n",
      "Epoch: 1850, Train_loss: 0.3915 / Val_loss: 1.7611\n",
      "Epoch: 1851, Train_loss: 0.4270 / Val_loss: 1.6459\n",
      "Epoch: 1852, Train_loss: 0.3958 / Val_loss: 1.6802\n",
      "Epoch: 1853, Train_loss: 0.3929 / Val_loss: 1.3656\n",
      "Epoch: 1854, Train_loss: 0.3859 / Val_loss: 1.7988\n",
      "Epoch: 1855, Train_loss: 0.3843 / Val_loss: 1.3652\n",
      "Epoch: 1856, Train_loss: 0.4011 / Val_loss: 1.3481\n",
      "Epoch: 1857, Train_loss: 0.3944 / Val_loss: 1.3350\n",
      "Epoch: 1858, Train_loss: 0.3825 / Val_loss: 1.1191\n",
      "Epoch: 1859, Train_loss: 0.4118 / Val_loss: 1.7549\n",
      "Epoch: 1860, Train_loss: 0.4211 / Val_loss: 1.6090\n",
      "Epoch: 1861, Train_loss: 0.3839 / Val_loss: 1.3783\n",
      "Epoch: 1862, Train_loss: 0.4054 / Val_loss: 1.4320\n",
      "Epoch: 1863, Train_loss: 0.4249 / Val_loss: 1.8399\n",
      "Epoch: 1864, Train_loss: 0.3968 / Val_loss: 1.9782\n",
      "Epoch: 1865, Train_loss: 0.4043 / Val_loss: 1.4588\n",
      "Epoch: 1866, Train_loss: 0.3829 / Val_loss: 1.6390\n",
      "Epoch: 1867, Train_loss: 0.3928 / Val_loss: 1.4393\n",
      "Epoch: 1868, Train_loss: 0.3899 / Val_loss: 1.7683\n",
      "Epoch: 1869, Train_loss: 0.3781 / Val_loss: 1.5000\n",
      "Epoch: 1870, Train_loss: 0.3955 / Val_loss: 1.6601\n",
      "Epoch: 1871, Train_loss: 0.3904 / Val_loss: 1.4462\n",
      "Epoch: 1872, Train_loss: 0.4015 / Val_loss: 1.4594\n",
      "Epoch: 1873, Train_loss: 0.4007 / Val_loss: 1.6945\n",
      "Epoch: 1874, Train_loss: 0.4014 / Val_loss: 1.3359\n",
      "Epoch: 1875, Train_loss: 0.4165 / Val_loss: 1.3946\n",
      "Epoch: 1876, Train_loss: 0.4380 / Val_loss: 1.5531\n",
      "Epoch: 1877, Train_loss: 0.3792 / Val_loss: 1.4389\n",
      "Epoch: 1878, Train_loss: 0.4240 / Val_loss: 1.9017\n",
      "Epoch: 1879, Train_loss: 0.4130 / Val_loss: 1.2580\n",
      "Epoch: 1880, Train_loss: 0.3952 / Val_loss: 1.6460\n",
      "Epoch: 1881, Train_loss: 0.3720 / Val_loss: 1.6003\n",
      "Epoch: 1882, Train_loss: 0.3864 / Val_loss: 1.5919\n",
      "Epoch: 1883, Train_loss: 0.3848 / Val_loss: 1.5298\n",
      "Epoch: 1884, Train_loss: 0.4024 / Val_loss: 1.6010\n",
      "Epoch: 1885, Train_loss: 0.4000 / Val_loss: 0.9869\n",
      "Epoch: 1886, Train_loss: 0.3893 / Val_loss: 1.5582\n",
      "Epoch: 1887, Train_loss: 0.3877 / Val_loss: 1.4845\n",
      "Epoch: 1888, Train_loss: 0.4014 / Val_loss: 1.4794\n",
      "Epoch: 1889, Train_loss: 0.4122 / Val_loss: 1.3922\n",
      "Epoch: 1890, Train_loss: 0.4234 / Val_loss: 1.3198\n",
      "Epoch: 1891, Train_loss: 0.4104 / Val_loss: 1.4027\n",
      "Epoch: 1892, Train_loss: 0.3950 / Val_loss: 1.1520\n",
      "Epoch: 1893, Train_loss: 0.3961 / Val_loss: 1.8995\n",
      "Epoch: 1894, Train_loss: 0.4102 / Val_loss: 1.1220\n",
      "Epoch: 1895, Train_loss: 0.3898 / Val_loss: 1.3240\n",
      "Epoch: 1896, Train_loss: 0.3720 / Val_loss: 1.3034\n",
      "Epoch: 1897, Train_loss: 0.3805 / Val_loss: 1.5400\n",
      "Epoch: 1898, Train_loss: 0.3816 / Val_loss: 1.5907\n",
      "Epoch: 1899, Train_loss: 0.4038 / Val_loss: 1.5903\n",
      "Epoch: 1900, Train_loss: 0.3996 / Val_loss: 2.0218\n",
      "Epoch: 1901, Train_loss: 0.3939 / Val_loss: 1.8195\n",
      "Epoch: 1902, Train_loss: 0.3865 / Val_loss: 1.6637\n",
      "Epoch: 1903, Train_loss: 0.3930 / Val_loss: 1.9637\n",
      "Epoch: 1904, Train_loss: 0.3826 / Val_loss: 1.5544\n",
      "Epoch: 1905, Train_loss: 0.3789 / Val_loss: 2.1008\n",
      "Epoch: 1906, Train_loss: 0.3754 / Val_loss: 1.5497\n",
      "Epoch: 1907, Train_loss: 0.3901 / Val_loss: 1.8337\n",
      "Epoch: 1908, Train_loss: 0.4048 / Val_loss: 1.8888\n",
      "Epoch: 1909, Train_loss: 0.3863 / Val_loss: 1.7017\n",
      "Epoch: 1910, Train_loss: 0.3868 / Val_loss: 1.6417\n",
      "Epoch: 1911, Train_loss: 0.4172 / Val_loss: 1.6444\n",
      "Epoch: 1912, Train_loss: 0.4080 / Val_loss: 1.4653\n",
      "Epoch: 1913, Train_loss: 0.3872 / Val_loss: 1.6537\n",
      "Epoch: 1914, Train_loss: 0.3850 / Val_loss: 1.5274\n",
      "Epoch: 1915, Train_loss: 0.4589 / Val_loss: 1.3727\n",
      "Epoch: 1916, Train_loss: 0.4132 / Val_loss: 1.3746\n",
      "Epoch: 1917, Train_loss: 0.4138 / Val_loss: 1.9030\n",
      "Epoch: 1918, Train_loss: 0.4036 / Val_loss: 2.1547\n",
      "Epoch: 1919, Train_loss: 0.3923 / Val_loss: 1.5137\n",
      "Epoch: 1920, Train_loss: 0.4021 / Val_loss: 1.4406\n",
      "Epoch: 1921, Train_loss: 0.4051 / Val_loss: 1.5372\n",
      "Epoch: 1922, Train_loss: 0.3782 / Val_loss: 1.8499\n",
      "Epoch: 1923, Train_loss: 0.4331 / Val_loss: 1.3190\n",
      "Epoch: 1924, Train_loss: 0.3854 / Val_loss: 2.0605\n",
      "Epoch: 1925, Train_loss: 0.4087 / Val_loss: 1.3804\n",
      "Epoch: 1926, Train_loss: 0.3812 / Val_loss: 1.4346\n",
      "Epoch: 1927, Train_loss: 0.3669 / Val_loss: 1.8068\n",
      "Epoch: 1928, Train_loss: 0.3952 / Val_loss: 1.5503\n",
      "Epoch: 1929, Train_loss: 0.3734 / Val_loss: 1.1491\n",
      "Epoch: 1930, Train_loss: 0.3849 / Val_loss: 1.3762\n",
      "Epoch: 1931, Train_loss: 0.3888 / Val_loss: 1.6003\n",
      "Epoch: 1932, Train_loss: 0.3863 / Val_loss: 1.2753\n",
      "Epoch: 1933, Train_loss: 0.4236 / Val_loss: 1.9549\n",
      "Epoch: 1934, Train_loss: 0.3928 / Val_loss: 1.9376\n",
      "Epoch: 1935, Train_loss: 0.3992 / Val_loss: 1.1321\n",
      "Epoch: 1936, Train_loss: 0.3995 / Val_loss: 1.4918\n",
      "Epoch: 1937, Train_loss: 0.3947 / Val_loss: 1.8662\n",
      "Epoch: 1938, Train_loss: 0.3771 / Val_loss: 1.4005\n",
      "Epoch: 1939, Train_loss: 0.3870 / Val_loss: 1.3633\n",
      "Epoch: 1940, Train_loss: 0.3854 / Val_loss: 1.3103\n",
      "Epoch: 1941, Train_loss: 0.4158 / Val_loss: 1.4181\n",
      "Epoch: 1942, Train_loss: 0.4063 / Val_loss: 1.5514\n",
      "Epoch: 1943, Train_loss: 0.3800 / Val_loss: 1.3145\n",
      "Epoch: 1944, Train_loss: 0.3943 / Val_loss: 1.6223\n",
      "Epoch: 1945, Train_loss: 0.4159 / Val_loss: 1.3048\n",
      "Epoch: 1946, Train_loss: 0.4110 / Val_loss: 1.4580\n",
      "Epoch: 1947, Train_loss: 0.3935 / Val_loss: 1.4969\n",
      "Epoch: 1948, Train_loss: 0.3899 / Val_loss: 1.3013\n",
      "Epoch: 1949, Train_loss: 0.3945 / Val_loss: 1.3329\n",
      "Epoch: 1950, Train_loss: 0.4070 / Val_loss: 1.4797\n",
      "Epoch: 1951, Train_loss: 0.3849 / Val_loss: 1.8904\n",
      "Epoch: 1952, Train_loss: 0.3917 / Val_loss: 1.2483\n",
      "Epoch: 1953, Train_loss: 0.3759 / Val_loss: 1.5040\n",
      "Epoch: 1954, Train_loss: 0.3969 / Val_loss: 1.2539\n",
      "Epoch: 1955, Train_loss: 0.4221 / Val_loss: 1.4224\n",
      "Epoch: 1956, Train_loss: 0.3985 / Val_loss: 1.5285\n",
      "Epoch: 1957, Train_loss: 0.3819 / Val_loss: 1.6713\n",
      "Epoch: 1958, Train_loss: 0.4009 / Val_loss: 1.4246\n",
      "Epoch: 1959, Train_loss: 0.3728 / Val_loss: 1.3778\n",
      "Epoch: 1960, Train_loss: 0.3872 / Val_loss: 1.5204\n",
      "Epoch: 1961, Train_loss: 0.3965 / Val_loss: 2.0549\n",
      "Epoch: 1962, Train_loss: 0.3855 / Val_loss: 1.5832\n",
      "Epoch: 1963, Train_loss: 0.3969 / Val_loss: 1.6595\n",
      "Epoch: 1964, Train_loss: 0.4045 / Val_loss: 1.2705\n",
      "Epoch: 1965, Train_loss: 0.3813 / Val_loss: 1.5417\n",
      "Epoch: 1966, Train_loss: 0.4258 / Val_loss: 1.4774\n",
      "Epoch: 1967, Train_loss: 0.3812 / Val_loss: 1.7718\n",
      "Epoch: 1968, Train_loss: 0.3845 / Val_loss: 1.5260\n",
      "Epoch: 1969, Train_loss: 0.3872 / Val_loss: 1.5336\n",
      "Epoch: 1970, Train_loss: 0.3814 / Val_loss: 1.6002\n",
      "Epoch: 1971, Train_loss: 0.3941 / Val_loss: 1.7464\n",
      "Epoch: 1972, Train_loss: 0.3844 / Val_loss: 1.3326\n",
      "Epoch: 1973, Train_loss: 0.3744 / Val_loss: 1.4155\n",
      "Epoch: 1974, Train_loss: 0.3873 / Val_loss: 1.8119\n",
      "Epoch: 1975, Train_loss: 0.3858 / Val_loss: 1.4226\n",
      "Epoch: 1976, Train_loss: 0.3748 / Val_loss: 1.6490\n",
      "Epoch: 1977, Train_loss: 0.3701 / Val_loss: 1.4918\n",
      "Epoch: 1978, Train_loss: 0.3896 / Val_loss: 1.6746\n",
      "Epoch: 1979, Train_loss: 0.3826 / Val_loss: 1.4938\n",
      "Epoch: 1980, Train_loss: 0.3738 / Val_loss: 1.3620\n",
      "Epoch: 1981, Train_loss: 0.3963 / Val_loss: 1.9379\n",
      "Epoch: 1982, Train_loss: 0.4167 / Val_loss: 1.6112\n",
      "Epoch: 1983, Train_loss: 0.3788 / Val_loss: 1.4296\n",
      "Epoch: 1984, Train_loss: 0.3882 / Val_loss: 1.6174\n",
      "Epoch: 1985, Train_loss: 0.4088 / Val_loss: 1.4524\n",
      "Epoch: 1986, Train_loss: 0.3866 / Val_loss: 1.4779\n",
      "Epoch: 1987, Train_loss: 0.3867 / Val_loss: 1.4572\n",
      "Epoch: 1988, Train_loss: 0.4500 / Val_loss: 1.5258\n",
      "Epoch: 1989, Train_loss: 0.3924 / Val_loss: 1.4853\n",
      "Epoch: 1990, Train_loss: 0.3918 / Val_loss: 1.7764\n",
      "Epoch: 1991, Train_loss: 0.3904 / Val_loss: 1.8649\n",
      "Epoch: 1992, Train_loss: 0.4065 / Val_loss: 1.4031\n",
      "Epoch: 1993, Train_loss: 0.3926 / Val_loss: 1.5297\n",
      "Epoch: 1994, Train_loss: 0.3777 / Val_loss: 1.6032\n",
      "Epoch: 1995, Train_loss: 0.3820 / Val_loss: 1.4858\n",
      "Epoch: 1996, Train_loss: 0.4357 / Val_loss: 1.5133\n",
      "Epoch: 1997, Train_loss: 0.3851 / Val_loss: 1.7094\n",
      "Epoch: 1998, Train_loss: 0.3829 / Val_loss: 1.3794\n",
      "Epoch: 1999, Train_loss: 0.3870 / Val_loss: 1.4004\n",
      "Epoch: 2000, Train_loss: 0.4549 / Val_loss: 1.5626\n"
     ]
    }
   ],
   "source": [
    "weight = torch.Tensor([1.0, 2.5])\n",
    "log_softmax = torch.nn.LogSoftmax(dim=1)\n",
    "criterion = torch.nn.NLLLoss(weight=weight)  # Define loss criterion.\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)  # Define optimizer.\n",
    "\n",
    "losses = []\n",
    "v_losses = []\n",
    "best_v_loss = 100000\n",
    "COUNT = 2000\n",
    "val_early_stop_count = COUNT\n",
    "val_early_stop_continuous_flag = False\n",
    "\n",
    "for epoch in range(1, 2001):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    outs = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "    preds = outs[data.train_mask].squeeze()\n",
    "    loss = criterion(log_softmax(preds), data.y[data.train_mask].to(dtype=torch.long))  # Compute the loss solely based on the training nodes.\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        v_preds = outs[data.val_mask].squeeze()\n",
    "        v_loss = criterion(log_softmax(v_preds), data.y[data.val_mask].to(dtype=torch.long))\n",
    "        v_losses.append(v_loss.item())\n",
    "    print(f'Epoch: {epoch:03d}, Train_loss: {loss:.4f} / Val_loss: {v_loss:.4f}')\n",
    "    \n",
    "    if v_loss.item() < best_v_loss:\n",
    "        best_v_loss = v_loss.item()\n",
    "        val_early_stop_continuous_flag = False\n",
    "        val_early_stop_count = COUNT\n",
    "    else:\n",
    "        val_early_stop_continuous_flag = True\n",
    "        val_early_stop_count -= 1\n",
    "        if val_early_stop_count == 0:\n",
    "            print(f\"============== Early stopped at Epoch: {epoch}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.plot(v_losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Train\", \"Val\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "out = model(data.x, data.edge_index)\n",
    "pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "y_pred = pred[data.test_mask].numpy()\n",
    "y_true = data.y[data.test_mask].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6712\n",
      "Precision: 0.2353\n",
      "Recall: 0.2667\n",
      "f1 score: 0.2500\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true, y_pred, normalize=None)\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    ")\n",
    "\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred):.4f}\")\n",
    "print(f\"f1 score: {f1_score(y_true, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.19334719334719336)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
